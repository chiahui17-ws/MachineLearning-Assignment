{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77eb2321",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Note to self, if it takes too long to run, then just don't run any of the parts that take too long, unless tweaks are applied to the data preprocessing part. You only need to run it once for the output. Hello."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d0b204",
   "metadata": {},
   "source": [
    "### Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0296cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c59e4e",
   "metadata": {},
   "source": [
    "## Part A - Model Variety Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb3fc9a",
   "metadata": {},
   "source": [
    "### Import Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef3b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from a Folder called Datasets, plaed inside C drive.\n",
    "df_raw = pd.read_csv(\"C:\\Datasets\\Crime_Data_from_2020_to_Present.csv\", low_memory=\"False\")\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e0684",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc22403",
   "metadata": {},
   "source": [
    "### View Unique values for Crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_desc = df_raw[\"Crm Cd Desc\"].dropna().unique()\n",
    "len(unique_desc), unique_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14cb973",
   "metadata": {},
   "source": [
    "## DataPrep\n",
    "\n",
    "### Map each Crime commited to a matching Criminal Offense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b6aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword-based mapping rules for auto‚Äêlabeling\n",
    "mapping_rules = {\n",
    "    \"Violent Crime\": [\n",
    "        \"ASSAULT\", \"BATTERY\", \"HOMICIDE\", \"MANSLAUGHTER\", \"RAPE\",\n",
    "        \"SEXUAL\", \"SODOMY\", \"ORAL COPULATION\", \"KIDNAPPING\",\n",
    "        \"LYNCHING\", \"STALKING\", \"THREATS\", \"INTIMATE PARTNER\"\n",
    "    ],\n",
    "    \"Property Crime\": [\n",
    "        \"THEFT\", \"BURGLARY\", \"VANDALISM\", \"ARSON\", \"SHOPLIFTING\",\n",
    "        \"BIKE - STOLEN\", \"COIN MACHINE\"\n",
    "    ],\n",
    "    \"Vehicle Crime\": [\n",
    "        \"VEHICLE\", \"DRIVING WITHOUT OWNER CONSENT\", \"DWOC\"\n",
    "    ],\n",
    "    \"Fraud / Financial Crime\": [\n",
    "        \"FRAUD\", \"EMBEZZLEMENT\", \"COUNTERFEIT\", \"BUNCO\",\n",
    "        \"CREDIT CARD\", \"DOCUMENT WORTHLESS\", \"INSURANCE\"\n",
    "    ],\n",
    "    \"Weapons / Public Safety\": [\n",
    "        \"FIREARM\", \"WEAPON\", \"SHOTS FIRED\", \"BOMB\", \"BRANDISH\"\n",
    "    ],\n",
    "    \"Sex Crime\": [\n",
    "        \"LEWD\", \"INDECENT EXPOSURE\", \"CHILD PORNOGRAPHY\",\n",
    "        \"PANDERING\", \"PIMPING\", \"HUMAN TRAFFICKING\"\n",
    "    ],\n",
    "    \"Child-Related Crime\": [\n",
    "        \"CHILD\", \"CONTRIBUTING\", \"CHILD NEGLECT\"\n",
    "    ],\n",
    "    \"Court / Restraining Order / Legal\": [\n",
    "        \"COURT\", \"RESTRAINING\", \"CONTEMPT\", \"FAILURE TO APPEAR\",\n",
    "        \"VIOLATION\"\n",
    "    ],\n",
    "    \"Public Disturbance / Disorder\": [\n",
    "        \"DISTURBANCE\", \"PEACE\", \"TRESPASS\", \"DISRUPT\",\n",
    "        \"RIOT\", \"DISOBEY\"\n",
    "    ],\n",
    "    \"Other Crime\": []  # fallback\n",
    "}\n",
    "\n",
    "# Function to classify crimes\n",
    "def classify(description: str):\n",
    "    if not isinstance(description, str):\n",
    "        return \"Other Crime\"\n",
    "    desc = description.upper()\n",
    "    for category, keywords in mapping_rules.items():\n",
    "        for kw in keywords:\n",
    "            if kw in desc:\n",
    "                return category\n",
    "    return \"Other Crime\"\n",
    "\n",
    "# Create new class column\n",
    "df_raw[\"Crime_Class\"] = df_raw[\"Crm Cd Desc\"].apply(classify)\n",
    "\n",
    "# Save a preview\n",
    "preview = df_raw[[\"Crm Cd Desc\", \"Crime_Class\"]].head(30)\n",
    "preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17561bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['Crime_Class'].value_counts().reset_index(name='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6dc426",
   "metadata": {},
   "source": [
    "Let's start with RAW, unprocesseed model training, then work our way up.\n",
    "\n",
    "## Category: Machine Learning Models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e937dc",
   "metadata": {},
   "source": [
    "### Tree Based: Decision Tree (RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63963c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model = df_raw.drop(columns=[\n",
    "    \"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\",\n",
    "    \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\"\n",
    "])\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model[\"Crime_Class\"])\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "dt_model_1 = DecisionTreeClassifier()\n",
    "dt_model_1.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_test_1 = dt_model_1.predict(X_test)\n",
    "y_pred_train_1 = dt_model_1.predict(X_train)\n",
    "\n",
    "# Evaluation\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_1)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test_1)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f22142",
   "metadata": {},
   "source": [
    "### Tree Based: Random Forest (RAW)\n",
    "\n",
    "*Without any parameters, this thing will take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd85f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Random Forest Crime Classification ===\")\n",
    "\n",
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model = df_raw.drop(columns=[\n",
    "    \"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\",\n",
    "    \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\"\n",
    "])\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model.drop(columns=[\"Crime_Class\"])\n",
    "y, class_names = pd.factorize(df_model[\"Crime_Class\"])\n",
    "\n",
    "# Convert datetime columns to int timestamps\n",
    "for col in X.select_dtypes(include=['datetime', 'datetimetz']).columns:\n",
    "    X[col] = X[col].view('int64')\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Train-test split (stratify for class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Initialize Random Forest with balanced, regularized params\n",
    "rf_model_1 = RandomForestClassifier()\n",
    "# Save paraneter tunning for PART B. \n",
    "\n",
    "rf_model_1.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_test_1 = rf_model_1.predict(X_test)\n",
    "y_pred_train_1 = rf_model_1.predict(X_train)\n",
    "\n",
    "# Accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_1)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test_1)\n",
    "\n",
    "print(\"\\n=== Performance ===\")\n",
    "print(f\"Training Set Accuracy: {train_accuracy}\")\n",
    "print(f\"Testing Set Accuracy:  {test_accuracy}\")\n",
    "print(f\"Overfit Gap:          {train_accuracy - test_accuracy:.4f}\")\n",
    "\n",
    "# Evaluation reports\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa3a193",
   "metadata": {},
   "source": [
    "### Linear/Probability Based: Logistic Regression (RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# ... (Assuming df_raw is already loaded) ...\n",
    "\n",
    "# 1. Remove leakage columns\n",
    "df_model = df_raw.drop(columns=[\n",
    "    \"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\",\n",
    "    \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\"\n",
    "])\n",
    "\n",
    "# 2. Prepare training data\n",
    "X = df_model.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model[\"Crime_Class\"])\n",
    "\n",
    "# 3. Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# 4. Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# 5. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 6. Scale features \n",
    "# (Critically important for Logistic Regression convergence)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CHANGE: Build Logistic Regression Model (No Parameters)\n",
    "# ---------------------------------------------------------\n",
    "lr_model = LogisticRegression() \n",
    "\n",
    "# Train model\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_train_1 = lr_model.predict(X_train_scaled)\n",
    "y_pred_test_1 = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_1)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test_1)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2ff7c9",
   "metadata": {},
   "source": [
    "### Linear/Probability Based: Naive Bayes (RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f264448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. Clean up leakage columns first to free space immediately\n",
    "drop_cols = [\n",
    "    \"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\",\n",
    "    \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\"\n",
    "]\n",
    "# Only drop if they actually exist in the dataframe\n",
    "cols_to_drop = [c for c in drop_cols if c in df_raw.columns]\n",
    "df_model = df_raw.drop(columns=cols_to_drop)\n",
    "\n",
    "# 2. Separate Target\n",
    "y, _ = pd.factorize(df_model[\"Crime_Class\"])\n",
    "X = df_model.drop(columns=[\"Crime_Class\"])\n",
    "\n",
    "# 3. THE FIX: In-Place Memory Optimized Conversion\n",
    "# Instead of 'apply' (which clones data), we loop and modify column by column.\n",
    "# .cat.codes is extremely memory efficient.\n",
    "print(\"Converting columns to codes...\")\n",
    "for col in X.columns:\n",
    "    # Convert to category type first\n",
    "    X[col] = X[col].astype('category')\n",
    "    # Extract codes (returns -1 for NaNs)\n",
    "    X[col] = X[col].cat.codes\n",
    "    \n",
    "    # Handle NaNs (-1) by shifting everything up by 1\n",
    "    # This also ensures no value is 0, which MultinomialNB prefers\n",
    "    X[col] = X[col] + 1\n",
    "\n",
    "# 4. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 5. Model\n",
    "# We stick to MultinomialNB because CategoricalNB is the one that wanted 18GB of RAM earlier.\n",
    "print(\"Training MultinomialNB...\")\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Evaluate\n",
    "print(\"Predicting...\")\n",
    "y_pred_train = nb_model.predict(X_train)\n",
    "y_pred_test = nb_model.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Testing Accuracy:  {test_accuracy}\")\n",
    "print(\"-\" * 30)\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0305e36",
   "metadata": {},
   "source": [
    "### Gradient: XGBoost (RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b04d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leakage columns\n",
    "df_model = df_raw.drop(columns=[\n",
    "    \"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\",\n",
    "    \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\"\n",
    "])\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model[\"Crime_Class\"])\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model_1 = XGBClassifier()\n",
    "#    n_estimators=300,\n",
    "#    learning_rate=0.1,\n",
    "#    max_depth=6,\n",
    "#    subsample=0.8,\n",
    "#    colsample_bytree=0.8,\n",
    "#    eval_metric=\"mlogloss\",\n",
    "#    random_state=42\n",
    "# )\n",
    "\n",
    "xgb_model_1.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = xgb_model_1.predict(X_train)\n",
    "y_pred_test = xgb_model_1.predict(X_test)\n",
    "\n",
    "# Evaluation reports\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de13e84c",
   "metadata": {},
   "source": [
    "## Category: Deep Learning Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaa63b7",
   "metadata": {},
   "source": [
    "\n",
    "### Neural Networks: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30252c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leakage columns\n",
    "df_model = df_raw.drop(columns=[\n",
    "    \"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\",\n",
    "    \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\"\n",
    "])\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model[\"Crime_Class\"])\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ====== RESHAPE FOR CNN (Conv1D needs shape: samples, timesteps, features) ======\n",
    "X_train_cnn = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
    "X_test_cnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# ====== BUILD CNN MODEL ======\n",
    "model = Sequential([\n",
    "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ====== TRAIN ======\n",
    "history = model.fit(\n",
    "    X_train_cnn, y_train_cat,\n",
    "    epochs=10,              # Use epoch size = 10, since the datset is fairly large. Fewer epochs means less strain and timne\n",
    "    batch_size=32,          #Default values is 32.\n",
    "    validation_split=0.2,   #Keras default is 0.0\n",
    "    verbose=1               #Keras default is 1\n",
    ")\n",
    "\n",
    "# ====== PREDICT ======\n",
    "y_pred_train = model.predict(X_train_cnn).argmax(axis=1)\n",
    "y_pred_test = model.predict(X_test_cnn).argmax(axis=1)\n",
    "\n",
    "# ====== EVALUATION ======\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600dec6e",
   "metadata": {},
   "source": [
    "### Neural Network: ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2315963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leakage columns\n",
    "df_model = df_raw.drop(columns=[\n",
    "    \"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\",\n",
    "    \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\"\n",
    "])\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model[\"Crime_Class\"])\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# ====== BUILD ANN MODEL ======\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ====== TRAIN ======\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_cat,\n",
    "    epochs=10,              #Use 10 as a derfault value for epochs\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ====== PREDICT ======\n",
    "y_pred_train = model.predict(X_train_scaled).argmax(axis=1)\n",
    "y_pred_test = model.predict(X_test_scaled).argmax(axis=1)\n",
    "\n",
    "# ====== EVALUATION ======\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed052e64",
   "metadata": {},
   "source": [
    "Can be improved? Time to find out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa087c01",
   "metadata": {},
   "source": [
    "## Part A - Feature Engineering and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b40162",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d938e44",
   "metadata": {},
   "source": [
    "Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd75799",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_raw.drop_duplicates()\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e0e6f7",
   "metadata": {},
   "source": [
    "None found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa9fc5f",
   "metadata": {},
   "source": [
    "### Removing Columns \n",
    "Do not proceed without caution. In this context, the chosen columns were dropped due to them having a direct relationship to the target class, which may cause a leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526382ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.drop(columns=[\"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\", \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\"])\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c199f66",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679d198f",
   "metadata": {},
   "source": [
    "In this phase, TAKE NOTE that anything, once you hit run, results in the dataframe being permanently changed. So to rerun this segment, you MUST reload and reimport the DataFrame again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b832648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clean DATE OCC (mixed formats)\n",
    "df_new['DATE OCC'] = pd.to_datetime(df_new['DATE OCC'], format='mixed', errors='coerce')\n",
    "\n",
    "# 2. Clean TIME OCC (force numeric ‚Üí Int64 ‚Üí 4-digit HHMM)\n",
    "df_new['TIME OCC'] = pd.to_numeric(df_new['TIME OCC'], errors='coerce').astype('Int64')\n",
    "time_str = df_new['TIME OCC'].astype(str).str.zfill(4)\n",
    "\n",
    "# 3. Combine DATE OCC + TIME OCC into a single datetime\n",
    "df_new['DateTime OCC'] = pd.to_datetime(\n",
    "    df_new['DATE OCC'].dt.strftime('%Y-%m-%d') + ' ' + time_str,\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# 4. Drop the original columns used for merging\n",
    "df_new = df_new.drop(columns=['DATE OCC', 'TIME OCC'])\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45512be",
   "metadata": {},
   "source": [
    "### Check for NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f79449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b2bc98",
   "metadata": {},
   "source": [
    "Leave as NULL, since some records do in fact not possess the given info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b4c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.drop(columns=[' '])\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda99625",
   "metadata": {},
   "source": [
    "Remove the Weapon Used Cd column, and change the Weapon Desc column to binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08685736",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "sns.heatmap(df_new.isna(), cbar=False, yticklabels=False)\n",
    "plt.title(\"Missing Value Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc52334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Drop the Weapon Used Cd column (if it exists)\n",
    "df_new = df_new.drop(columns=['Weapon Used Cd'], errors='ignore')\n",
    "\n",
    "# 2. Create a binary Weapon_Present column\n",
    "df_new['Weapon_Present'] = df_new['Weapon Desc'].apply(\n",
    "    lambda x: 'Present' if pd.notna(x) and str(x).strip() != '' else 'Absent'\n",
    ")\n",
    "\n",
    "# 3. (Optional) Drop Weapon Desc if you want to fully remove the text info\n",
    "df_new = df_new.drop(columns=['Weapon Desc'], errors='ignore')\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e89334",
   "metadata": {},
   "source": [
    "Check again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "sns.heatmap(df_new.isna(), cbar=False, yticklabels=False)\n",
    "plt.title(\"Missing Value Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b8eb84",
   "metadata": {},
   "source": [
    "### Dropping columns that provide meaningless value:\n",
    "\n",
    "Start with obvious ones, Location of the crime will often be unique among all records, but the area/district may not. So it can be dropped.\n",
    "\n",
    "To do so, apply a test such as Pearson Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf261ba",
   "metadata": {},
   "source": [
    "Cross Street possess a lot of missing values. This can be dropped completely if Location is already sufficient info.\n",
    "\n",
    "As for Mo Codes, this is neglectable, since some records may only be a minor offense. So no MO Code may have been recorded.\n",
    "\n",
    "This applies to victim sex and descent as well, since not all crimes have a victim involved, such as vandalisme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bad0fc",
   "metadata": {},
   "source": [
    "### Test Pearson Correlation (Numeric Features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a57ed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the DataFrame to analyze; use the most recent processed one if available\n",
    "try:\n",
    "    df_corr_source = df_new.copy()\n",
    "except NameError:\n",
    "    df_corr_source = df_raw.copy()\n",
    "\n",
    "# Ensure target encoding (optional): demonstrate correlation against encoded target when present\n",
    "if 'Crime_Class' in df_corr_source.columns:\n",
    "    df_corr_source['Crime_Class_numeric'] = df_corr_source['Crime_Class'].astype('category').cat.codes\n",
    "\n",
    "# Select only numeric columns\n",
    "num_df = df_corr_source.select_dtypes(include=['number'])\n",
    "\n",
    "# Pearson correlation matrix\n",
    "corr = num_df.corr(numeric_only=True)\n",
    "\n",
    "# Upper triangle flatten for pairwise sorted report\n",
    "upper = corr.where(~np.tril(np.ones(corr.shape)).astype(bool))\n",
    "corr_report = (\n",
    "    upper.stack()\n",
    "          .reset_index()\n",
    "          .rename(columns={'level_0': 'Feature 1', 'level_1': 'Feature 2', 0: 'Correlation'})\n",
    ")\n",
    "\n",
    "# Sort by absolute correlation strength\n",
    "corr_report = corr_report.iloc[corr_report['Correlation'].abs().sort_values(ascending=False).index]\n",
    "\n",
    "# Show top pairs\n",
    "print(\"Top 25 strongest Pearson correlations (absolute):\")\n",
    "print(corr_report.head(25))\n",
    "\n",
    "# Optional: heatmap for a quick visual\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0)\n",
    "plt.title('Pearson Correlation (Numeric Features)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08140085",
   "metadata": {},
   "source": [
    "### What can be derived freom this correlation table?\n",
    "\n",
    "1. Area and Rpt Dist No are inheritelly the same info, if you know the area where the crime occured, is the specific District Number really required?\n",
    "2. Many features have a correlation near 0, this implies that many features are highly independent. In  which, leave them be.\n",
    "3. Latitude and Longitude do provide the coordinates of the crime, but neither predicts each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c173ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the data\n",
    "df_corr = df_new.copy()\n",
    "\n",
    "# Convert Crime_Class (categorical) ‚Üí numeric labels\n",
    "df_corr['Crime_Class_numeric'] = df_corr['Crime_Class'].astype('category').cat.codes\n",
    "\n",
    "# Select only numeric columns\n",
    "num_df = df_corr.select_dtypes(include=['number'])\n",
    "\n",
    "# Compute correlation with the numeric-encoded target\n",
    "target_corr = num_df.corr(numeric_only=True)['Crime_Class_numeric']\n",
    "\n",
    "# Remove the target itself\n",
    "target_corr = target_corr.drop(labels=['Crime_Class_numeric'])\n",
    "\n",
    "# Turn into sorted dataframe\n",
    "target_corr_report = (\n",
    "    target_corr\n",
    "        .abs()\n",
    "        .sort_values(ascending=False)\n",
    "        .rename(\"Correlation_with_Crime_Class\")\n",
    "        .to_frame()\n",
    ")\n",
    "\n",
    "target_corr_report.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5400a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d75b12",
   "metadata": {},
   "source": [
    "### Let's tackle Mocodes first, these represent a given crime/offense commited. You can find the full list in the file attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeae450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Clean & explode the MO Codes column ---\n",
    "# Convert NaN to empty string\n",
    "df_new['Mocodes'] = df_new['Mocodes'].fillna('')\n",
    "\n",
    "# Split by spaces ‚Üí expand into list\n",
    "df_new['MOCODES_LIST'] = df_new['Mocodes'].str.strip().str.split()\n",
    "\n",
    "# Explode (each code becomes a row)\n",
    "exploded = df_new.explode('MOCODES_LIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26002ed3",
   "metadata": {},
   "source": [
    "Then, extract all unique MO code entries present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15b458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_codes = sorted({code for sublist in df_new['MOCODES_LIST'] for code in sublist})\n",
    "print(len(all_codes), \"unique MO codes found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64adcdd8",
   "metadata": {},
   "source": [
    "Count the frequency of each MO Code in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5d3d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Count MO code frequencies ---\n",
    "mo_counts = (\n",
    "    exploded['MOCODES_LIST']\n",
    "    .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde9444a",
   "metadata": {},
   "source": [
    "Select the top 100 MO Codes to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b5cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Select the Top 100 codes ---\n",
    "top_100 = set(mo_counts.head(100).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb18582",
   "metadata": {},
   "source": [
    "Filter MO list into top codes and ‚Äúothers‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009be6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Create one-hot columns for each top code ---\n",
    "for code in top_100:\n",
    "    df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
    "\n",
    "# --- Step 5: Create the OTHERS column ---\n",
    "# OTHERS = true if the row contains any MO code NOT in the top 100\n",
    "df_new['MO_OTHERS'] = df_new['MOCODES_LIST'].apply(\n",
    "    lambda lst: any(code not in top_100 for code in lst)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6797c46",
   "metadata": {},
   "source": [
    "Filter each crime‚Äôs MO list to only keep top 100 codes, create an Others column to store everything else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc42cdc9",
   "metadata": {},
   "source": [
    "Multi-hot encode only the top 100 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76fca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 6: Convert booleans to integers (0/1) ---\n",
    "mo_cols = [col for col in df_new.columns if col.startswith(\"MO_\")]\n",
    "df_new[mo_cols] = df_new[mo_cols].astype(int)\n",
    "\n",
    "# --- Step 7: Clean up temporary column ---\n",
    "df_new_1 = df_new.drop(columns=[\"MOCODES_LIST\"])\n",
    "\n",
    "# --- Done ---\n",
    "print(f\"Created {len(mo_cols)} MO Code features (100 Top + OTHERS).\")\n",
    "print(mo_cols[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f33476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_1 = df_new_1.drop(columns=['Mocodes'], errors='ignore')\n",
    "df_new_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2f4b36",
   "metadata": {},
   "source": [
    "### Next, tackle the location based columns\n",
    "\n",
    "As mentioned, since all crimes will more times than not, occur in unique, varying locations, it is best to assume that there is no association or pattern to be determined from them. They are simply too specific to be trained upon.\n",
    "\n",
    "Another key feature that could be dropped is the Date of te Report. Since each report will have its own unique entry date, hence it is safe to assume that the column is noisy and unfeasible in model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae127faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_1 = df_new_1.drop(columns=['LOCATION', 'Cross Street', 'DateTime OCC', 'Date Rptd'], errors='ignore') #Remove the dates\n",
    "df_new_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3e61f9",
   "metadata": {},
   "source": [
    "### Next, we need to choose bewteen keeping AREA, or DISTRICT.\n",
    "\n",
    "AREA:\n",
    "- It encodes neighborhood-level crime patterns\n",
    "- It‚Äôs stable and interpretable\n",
    "\n",
    "Rpt District:\n",
    "- This is a finer-grained region ID.\n",
    "- Usually LAPD districts are ~1‚Äì2 square miles.\n",
    "\n",
    "But using both AREA and Rpt Dist No creates strong multicollinearity, because:\n",
    "- AREA is a parent region\n",
    "- Rpt Dist No is the subregion\n",
    "\n",
    "Which is Better?\n",
    "\n",
    "Refer back to the correlation test, Rpt District is SLIGHTLY better than AREA, so that is what we will keep. It may contain more info than AREA, as AREA is a bit too general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178439b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_1 = df_new_1.drop(columns=['AREA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255b7efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_1 = df_new_1.drop(columns=['AREA NAME'])\n",
    "df_new_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172089c5",
   "metadata": {},
   "source": [
    "### Finally, we need to decide what to do with LAT and LON\n",
    "\n",
    "These are very powerful IF transformed.\n",
    "\n",
    "Raw lat/lon are NOT useful directly because:\n",
    "- models cannot interpret earth geometry\n",
    "- correlation is near zero\n",
    "- linear models especially fail with raw coordinates\n",
    "\n",
    "Raw latitude and longitude values:\n",
    "- have no linear meaning\n",
    "- give almost zero Pearson correlation\n",
    "- confuse tree models (too many splits)\n",
    "- confuse linear models (not linear!)\n",
    "- are extremely sensitive to tiny changes\n",
    "\n",
    "But crimes happen in spatial hotspots:\n",
    "- Downtown\n",
    "- Hollywood\n",
    "- South LA\n",
    "- Venice\n",
    "- San Fernando Valley\n",
    "- Pico-Union\n",
    "- Koreatown\n",
    "- Westlake\n",
    "- etc.\n",
    "\n",
    "### Is there a way to make them useful via transformation?\n",
    "\n",
    "### Clustering the LAT and LON into Bins of range values, may provide much more use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc24ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "coords = df_new_1[['LAT', 'LON']].dropna()\n",
    "\n",
    "kmeans = KMeans(n_clusters=100, random_state=42)\n",
    "\n",
    "df_new_1['Location_Cluster'] = kmeans.fit_predict(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2127bc9",
   "metadata": {},
   "source": [
    "### Method 1 ‚Äî KMeans Clustering\n",
    "\n",
    "This learns 50‚Äì200 ‚Äúcrime regions‚Äù directly from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf0fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3807886",
   "metadata": {},
   "source": [
    "### Method 2 ‚Äî Spatial Binning (ranges)\n",
    "\n",
    "This converts lat/lon into a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6b522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_1['Lat_bin'] = pd.cut(df_new_1['LAT'], bins=50, labels=False)\n",
    "df_new_1['Lon_bin'] = pd.cut(df_new_1['LON'], bins=50, labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed89586",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc8c42b",
   "metadata": {},
   "source": [
    "This creates 2 features:\n",
    "- Lat_bin\n",
    "- Lon_bin\n",
    "\n",
    "Which together form a 2D grid, like ‚ÄúRegion (12, 34)‚Äù.\n",
    "\n",
    "This is good for:\n",
    "- linear models\n",
    "- tree models\n",
    "- giant datasets\n",
    "- preserving spatial structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c6009a",
   "metadata": {},
   "source": [
    "### üü¢ Combining Both Is Even Better\n",
    "\n",
    "Crime prediction systems often use:\n",
    "\n",
    "‚úî Location_Cluster (KMeans)\n",
    "\n",
    "‚úî Lat_bin + Lon_bin (50x50 grid)\n",
    "\n",
    "This gives:\n",
    "- global structure (clusters)\n",
    "- local structure (grid bins)\n",
    "- Without storing raw LAT/LON."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f917f2",
   "metadata": {},
   "source": [
    "#### Function for Plotting Confusion Matrix. You'll be using this later, so intialize it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def plot_crime_matrix(y_test, y_pred, model_name=\"Model\", labels=None):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix with counts and percentages.\n",
    "    \"\"\"\n",
    "    # Compute matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Calculate percentages for the heatmap annotations\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=annot, fmt='', cmap='Blues', \n",
    "                xticklabels=labels if labels is not None else \"auto\",\n",
    "                yticklabels=labels if labels is not None else \"auto\")\n",
    "    plt.title(f'Confusion Matrix: {model_name}')\n",
    "    plt.ylabel('Actual Crime Class')\n",
    "    plt.xlabel('Predicted Crime Class')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418e56b4",
   "metadata": {},
   "source": [
    "## Part A - Remodelling with Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d052275e",
   "metadata": {},
   "source": [
    "Now, let's try building the Models again.\n",
    "\n",
    "### Tree-Based: Decision Tree (Processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9fc9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# Convert datetime columns to int64 timestamps\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view('int64')\n",
    "\n",
    "# Convert list columns to strings so they can be factorized\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test_dt = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "dt_model_3 = DecisionTreeClassifier()\n",
    "dt_model_3.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_dt = dt_model_3.predict(X_test)\n",
    "y_pred_train = dt_model_3.predict(X_train)\n",
    "\n",
    "# Evaluation\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_dt, y_pred_dt, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test_dt, y_pred_dt)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94530910",
   "metadata": {},
   "source": [
    "A highly Noticeable increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efb18a8",
   "metadata": {},
   "source": [
    "Now, let's plot the Error vs Complexity curve.\n",
    "\n",
    "This first one shall use a stratified sampling approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca247af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import validation_curve\n",
    "import numpy as np\n",
    "\n",
    "# Compute log-loss for Decision Tree\n",
    "train_loss = log_loss(y_train, dt_model_3.predict_proba(X_train))\n",
    "test_loss  = log_loss(y_test,  dt_model_3.predict_proba(X_test))\n",
    "\n",
    "print(\"------------------------\")\n",
    "print(\"Decision Tree Log Loss\")\n",
    "print(\"------------------------\")\n",
    "print(\"Training Loss:\")\n",
    "print(train_loss)\n",
    "print(\"------------------------\")\n",
    "print(\"Testing Loss:\")\n",
    "print(test_loss)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# Gap analysis\n",
    "acc_gap  = train_accuracy - test_accuracy\n",
    "loss_gap = test_loss - train_loss\n",
    "\n",
    "print(\"Accuracy Gap (Train - Test):\")\n",
    "print(acc_gap)\n",
    "print(\"------------------------\")\n",
    "print(\"Loss Gap (Test - Train):\")\n",
    "print(loss_gap)\n",
    "print(\"------------------------\")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 1. FAST STRATIFIED SUBSAMPLING\n",
    "# ================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Take only 5% of the data (tweak 0.05 ‚Üí 0.02 or 0.01 if still slow)\n",
    "sample_ratio = 0.25  \n",
    "X_small, _, y_small, _ = train_test_split(\n",
    "    X, y, \n",
    "    train_size=sample_ratio, \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split the small subset into train/test\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n",
    "    X_small, y_small,\n",
    "    test_size=0.3,\n",
    "    stratify=y_small,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ==================================\n",
    "# 2. MODEL COMPLEXITY VS ERROR\n",
    "# ==================================\n",
    "depths = range(2, 41, 2)\n",
    "train_losses_curve = []\n",
    "test_losses_curve = []\n",
    "train_acc_curve = []\n",
    "test_acc_curve = []\n",
    "\n",
    "for d in depths:\n",
    "    model = DecisionTreeClassifier(max_depth=d)\n",
    "\n",
    "    # Fit on *small* dataset\n",
    "    model.fit(X_train_s, y_train_s)\n",
    "\n",
    "    # Probabilities\n",
    "    train_proba = model.predict_proba(X_train_s)\n",
    "    test_proba  = model.predict_proba(X_test_s)\n",
    "\n",
    "    # Loss\n",
    "    train_losses_curve.append(log_loss(y_train_s, train_proba))\n",
    "    test_losses_curve.append(log_loss(y_test_s, test_proba))\n",
    "\n",
    "    # Accuracy\n",
    "    y_train_pred = model.predict(X_train_s)\n",
    "    y_test_pred  = model.predict(X_test_s)\n",
    "\n",
    "    train_acc_curve.append(accuracy_score(y_train_s, y_train_pred))\n",
    "    test_acc_curve.append(accuracy_score(y_test_s, y_test_pred))\n",
    "\n",
    "# ================================\n",
    "# 3. PLOT\n",
    "# ================================\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(depths, train_losses_curve, label=\"Training Loss\")\n",
    "plt.plot(depths, test_losses_curve, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Model Complexity (max_depth)\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.title(\"Model Complexity vs Error (Decision Tree)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc51d1",
   "metadata": {},
   "source": [
    "The second one will use all rows present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da9ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Convert y ‚Üí Series so we can subsample safely\n",
    "# ----------------------------------------------------\n",
    "y_train = pd.Series(y_train).reset_index(drop=True)\n",
    "y_test  = pd.Series(y_test).reset_index(drop=True)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test  = X_test.reset_index(drop=True)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Subsample 250k rows for faster computation\n",
    "# ----------------------------------------------------\n",
    "sample_size = min(250_000, len(X_train), len(X_test))\n",
    "\n",
    "X_train_sub = X_train.sample(sample_size, random_state=42)\n",
    "y_train_sub = y_train.loc[X_train_sub.index]\n",
    "\n",
    "X_test_sub = X_test.sample(sample_size, random_state=42)\n",
    "y_test_sub = y_test.loc[X_test_sub.index]\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Complexity levels (same as original)\n",
    "# ----------------------------------------------------\n",
    "complexity_values = [5, 10, 15, 20, 25, 30, 35, None]\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(\"=== Generating Decision Tree Log-Loss vs Complexity Curve ===\")\n",
    "\n",
    "for depth in complexity_values:\n",
    "    print(f\"Training Decision Tree with max_depth={depth}\")\n",
    "\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        max_depth=depth,\n",
    "        random_state=42  # no tuning params, just default DT\n",
    "    )\n",
    "    \n",
    "    dt_model.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "    # Predict probs so we can compute log-loss\n",
    "    train_proba = dt_model.predict_proba(X_train_sub)\n",
    "    test_proba  = dt_model.predict_proba(X_test_sub)\n",
    "\n",
    "    train_losses.append(log_loss(y_train_sub, train_proba))\n",
    "    test_losses.append(log_loss(y_test_sub, test_proba))\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# PLOT\n",
    "# ----------------------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([str(d) for d in complexity_values], train_losses, marker='o', label=\"Training Log Loss\")\n",
    "plt.plot([str(d) for d in complexity_values], test_losses, marker='o', label=\"Testing Log Loss\")\n",
    "\n",
    "plt.xlabel(\"Model Complexity (max_depth)\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.title(\"Decision Tree Log-Loss vs Complexity Curve (Subsample 250k)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f759bd81",
   "metadata": {},
   "source": [
    "### Evaluate Feature Importance (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c275b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = dt_model_3.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "fi = pd.DataFrame({\"feature\": features, \"importance\": importance})\n",
    "fi.sort_values(by=\"importance\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad7cd55",
   "metadata": {},
   "source": [
    "### Perform Shuffle Split Validation to verify the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2349ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== Decision Tree Cross-Validation: Stratified Shuffle-Split ===\")\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        max_depth=6,      # similar to XGB's depth, tweak as needed\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    dt_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = dt_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Mean Accuracy:  \", np.mean(accuracies))\n",
    "print(\"Std Deviation: \", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f0f6ae",
   "metadata": {},
   "source": [
    "Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5ba55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the class names (optional, makes the plot readable)\n",
    "crime_labels = df_new_1[\"Crime_Class\"].unique()\n",
    "crime_labels.sort() # Ensure they are in the same order as factorize usually does\n",
    "\n",
    "# 2. Plot the matrix\n",
    "# Ensure you pass the predictions you just made (y_pred_test)\n",
    "plot_crime_matrix(y_test_dt, y_pred_dt, model_name=\"Decision Tree\", labels=crime_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb6fbe7",
   "metadata": {},
   "source": [
    "### Tree-Based: Random Forest (Processed)\n",
    "\n",
    "*Yawn..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a36f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Random Forest Crime Classification (PROCESSED) ===\")\n",
    "\n",
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# Convert datetime columns to int64 timestamps\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view('int64')\n",
    "\n",
    "# Convert list columns to strings so they can be factorized\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Fill any remaining NaN values before training\n",
    "X = X.fillna(-1)\n",
    "\n",
    "# Train-test split (stratify for class balance)\n",
    "X_train, X_test, y_train, y_test_rf = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train model (Correctly named rf_model_3)\n",
    "rf_model_3 = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "rf_model_3.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_rf = rf_model_3.predict(X_test)\n",
    "y_pred_train_rf = rf_model_3.predict(X_train)\n",
    "\n",
    "# Evaluation\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_rf, y_pred_rf, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_rf, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_rf)\n",
    "test_accuracy = accuracy_score(y_test_rf, y_pred_rf)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(f\"Overfit Gap:          {train_accuracy - test_accuracy:.4f}\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a706d7e",
   "metadata": {},
   "source": [
    "A respectful increment.\n",
    "\n",
    "### Now, let's validate the results:\n",
    "\n",
    "Since RF is a very complex and time consuming ML, we'll need to use alternatie validation methods to ensure time and compuational efficiency.\n",
    "\n",
    "Method 1: Use Subsamples for Cross Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f537e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Take a manageable subsample\n",
    "sample_size = 100_000\n",
    "X_sub = X.sample(sample_size, random_state=42)\n",
    "y_sub = y[X_sub.index]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accs = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in skf.split(X_sub, y_sub):\n",
    "    X_train, X_test = X_sub.iloc[train_idx], X_sub.iloc[test_idx]\n",
    "    y_train, y_test = y_sub[train_idx], y_sub[test_idx]\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    acc = accuracy_score(y_test, rf.predict(X_test))\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    accs.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"K-Fold CV Accuracy Mean:\", np.mean(accs))\n",
    "print(\"Std:\", np.std(accs))\n",
    "print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf079b52",
   "metadata": {},
   "source": [
    "Method 2: Use Stratified Shuffle-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab4a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== Random Forest Cross-Validation: Stratified Shuffle-Split ===\")\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Mean Accuracy:  \", np.mean(accuracies))\n",
    "print(\"Std Deviation: \", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee42b4c",
   "metadata": {},
   "source": [
    "Plot the error versus complexity curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b0c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# --- 1. Subsample the data to 250k ---\n",
    "print(\"=== Subsampling Training Data ===\")\n",
    "# We verify we have enough data, then sample 250k without replacement\n",
    "n_samples = min(100000, len(X_train))\n",
    "X_train_sub, y_train_sub = resample(\n",
    "    X_train, y_train, \n",
    "    n_samples=n_samples, \n",
    "    replace=False, \n",
    "    random_state=42\n",
    ")\n",
    "print(f\"Training data reduced to: {X_train_sub.shape[0]} samples\")\n",
    "\n",
    "# --- 2. Define Depth Range (Complexity) ---\n",
    "# We range from depth 1 (very simple) to 25 (very complex)\n",
    "depth_settings = range(1, 501) #Adjust to larger value range if needed\n",
    "\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "print(\"=== Generating Error vs Complexity (Max Depth) Curve ===\")\n",
    "\n",
    "for d in depth_settings:\n",
    "    print(f\"Training model with max_depth={d}\")\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=50,  # Fixed: We isolate depth as the variable\n",
    "        max_depth=d,      # Variable: This controls complexity\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Fit on the subsampled data\n",
    "    rf.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "    # Predict\n",
    "    train_pred = rf.predict(X_train_sub)\n",
    "    test_pred  = rf.predict(X_test)\n",
    "\n",
    "    # Compute error (1 - accuracy)\n",
    "    train_err = 1 - accuracy_score(y_train_sub, train_pred)\n",
    "    test_err  = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "    train_errors.append(train_err)\n",
    "    test_errors.append(test_err)\n",
    "\n",
    "# --- 3. Plot ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plotting the curves\n",
    "plt.plot(depth_settings, train_errors, marker='o', label=\"Training Error\", color='blue')\n",
    "plt.plot(depth_settings, test_errors, marker='o', label=\"Testing Error\", color='red')\n",
    "\n",
    "# Formatting\n",
    "plt.xlabel(\"Model Complexity (max_depth)\")\n",
    "plt.ylabel(\"Error (1 - Accuracy)\")\n",
    "plt.title(\"Random Forest: Error vs. Max Depth\")\n",
    "plt.xticks(depth_settings) # Ensure we see all depth ticks\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a040cb6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    " ### Evaluate Feature Importance (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb9903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Feature Importance\n",
    "# -------------------------------------------\n",
    "importance = rf_model_3.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "fi = pd.DataFrame({\"feature\": features, \"importance\": importance})\n",
    "fi.sort_values(by=\"importance\", ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91be946",
   "metadata": {},
   "source": [
    "Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7d1b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the class names (optional, makes the plot readable)\n",
    "crime_labels = df_new_1[\"Crime_Class\"].unique()\n",
    "crime_labels.sort() # Ensure they are in the same order as factorize usually does\n",
    "\n",
    "# 2. Plot the matrix\n",
    "# Ensure you pass the predictions you just made (y_pred_test)\n",
    "plot_crime_matrix(y_test_rf, y_pred_rf, model_name=\"Random Forest\", labels=crime_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d418998f",
   "metadata": {},
   "source": [
    "### Probabilistic: Logistic Regression (Processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36155fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. Setup Data\n",
    "# (Assuming df_new_1 is already loaded)\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# 2. Prepare X and y\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# 3. Pre-processing (Memory Safe Version)\n",
    "\n",
    "# A. Convert datetimes to int64 (if any exist)\n",
    "# Using 'view' on datetimes is fast and memory efficient\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].values.astype(np.int64)\n",
    "\n",
    "# B. Convert list columns to strings\n",
    "# (Necessary because lists are not hashable and break many functions)\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# C. Factorize Objects (The \"Pro\" way to avoid MemoryError)\n",
    "# We loop instead of using .apply() to save RAM\n",
    "print(\"Encoding columns...\")\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].astype('category').cat.codes\n",
    "\n",
    "# D. Handle Missing Values\n",
    "# Logistic Regression cannot handle NaNs. \n",
    "# Since we used cat.codes, NaNs are already -1, but we ensure everything is numeric.\n",
    "X = X.fillna(-1)\n",
    "\n",
    "# 4. Train-test split\n",
    "X_train, X_test, y_train, y_test_lr = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 5. Scale features \n",
    "# Logistic Regression works best when features are on the same scale (e.g., -1 to 1)\n",
    "print(\"Scaling data...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 6. Build Logistic Regression Model\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr_model_1 = LogisticRegression() # Default parameters\n",
    "\n",
    "# Train model\n",
    "lr_model_1.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 7. Predict\n",
    "print(\"Predicting...\")\n",
    "y_pred_train_1 = lr_model_1.predict(X_train_scaled)\n",
    "y_pred_test_lr = lr_model_1.predict(X_test_scaled)\n",
    "\n",
    "# 8. Evaluation\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_lr, y_pred_test_lr, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_1)\n",
    "test_accuracy = accuracy_score(y_test_lr, y_pred_test_lr)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe518e3",
   "metadata": {},
   "source": [
    "### Probabilistic: Naive Bayes (Processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871599c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler  # <--- Changed from StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB   # <--- The Model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. Setup Data\n",
    "# (Assuming df_new_1 is already loaded)\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# 2. Prepare X and y\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# 3. Pre-processing (Memory Safe Version)\n",
    "\n",
    "# A. Convert datetimes to int64\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].values.astype(np.int64)\n",
    "\n",
    "# B. Convert list columns to strings\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# C. Factorize Objects (Using cat.codes for memory efficiency)\n",
    "print(\"Encoding columns...\")\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].astype('category').cat.codes\n",
    "\n",
    "# D. Handle Missing Values\n",
    "# We stick to your logic, but Naive Bayes hates -1.\n",
    "# We will fix the -1s in the Scaling step below.\n",
    "X = X.fillna(-1)\n",
    "\n",
    "# 4. Train-test split\n",
    "X_train, X_test, y_train, y_test_nb = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 5. Scale features \n",
    "# CRITICAL CHANGE: MultinomialNB fails with negative numbers.\n",
    "# StandardScaler produces negatives. MinMaxScaler (0, 1) fixes this.\n",
    "print(\"Scaling data (MinMax)...\")\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 6. Build Naive Bayes Model\n",
    "print(\"Training Multinomial Naive Bayes...\")\n",
    "nb_model_1 = MultinomialNB() \n",
    "\n",
    "# Train model\n",
    "nb_model_1.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 7. Predict\n",
    "print(\"Predicting...\")\n",
    "y_pred_train_1 = nb_model_1.predict(X_train_scaled)\n",
    "y_pred_test_nb = nb_model_1.predict(X_test_scaled)\n",
    "\n",
    "# 8. Evaluation\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_nb, y_pred_test_nb, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_1)\n",
    "test_accuracy = accuracy_score(y_test_nb, y_pred_test_nb)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aa4223",
   "metadata": {},
   "source": [
    "Perform Shuffle-Split Validation for both LR anmd NB models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7575b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Splitter (Same for both)\n",
    "# 5 Splits is a good balance between speed and reliability\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"=========================================================\")\n",
    "print(\"1. Logistic Regression Validation (StandardScaler)\")\n",
    "print(\"=========================================================\")\n",
    "\n",
    "lr_accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    # 1. Slice Data (Memory efficient indexing)\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # 2. Scale (Critical: Fit on Train, Transform Test)\n",
    "    # StandardScaler is best for Logistic Regression speed/convergence\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 3. Train (n_jobs=-1 uses all CPU cores for speed)\n",
    "    lr = LogisticRegression(n_jobs=-1) \n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # 4. Score\n",
    "    acc = accuracy_score(y_test, lr.predict(X_test_scaled))\n",
    "    \n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    lr_accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(f\"LR Mean Accuracy:  {np.mean(lr_accuracies):.8f}\")\n",
    "print(f\"LR Std Deviation:  {np.std(lr_accuracies):.8f}\")\n",
    "\n",
    "\n",
    "print(\"\\n=========================================================\")\n",
    "print(\"2. Multinomial Naive Bayes Validation (MinMaxScaler)\")\n",
    "print(\"=========================================================\")\n",
    "\n",
    "nb_accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    # 1. Slice Data\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # 2. Scale (MinMaxScaler is REQUIRED for NB to avoid negative errors)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 3. Train\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # 4. Score\n",
    "    acc = accuracy_score(y_test, nb.predict(X_test_scaled))\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    nb_accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(f\"NB Mean Accuracy:  {np.mean(nb_accuracies):.8f}\")\n",
    "print(f\"NB Std Deviation:  {np.std(nb_accuracies):.8f}\")\n",
    "print(\"---------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8671203a",
   "metadata": {},
   "source": [
    "Plot the error vs complexity curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94452a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import validation_curve, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# ==========================================\n",
    "# 1. Prepare Data (250K Subsample)\n",
    "# ==========================================\n",
    "print(\"Subsampling 250k rows...\")\n",
    "# Sample first to save time on preprocessing\n",
    "df_sub = df_new_1.sample(n=250000, random_state=42).copy()\n",
    "\n",
    "# Clean up leakage columns\n",
    "drop_cols = [\n",
    "    \"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\",\n",
    "    \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\", \"Crime_Class\"\n",
    "]\n",
    "cols_to_drop = [c for c in drop_cols if c in df_sub.columns]\n",
    "\n",
    "# Prepare X and y\n",
    "y, _ = pd.factorize(df_sub[\"Crime_Class\"])\n",
    "X = df_sub.drop(columns=cols_to_drop) # Drop target + leakage\n",
    "\n",
    "# --- Preprocessing (Optimized) ---\n",
    "# 1. Convert datetimes to int64\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].values.astype(np.int64)\n",
    "\n",
    "# 2. Convert list columns to strings\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# 3. Factorize Objects (cat.codes)\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].astype('category').cat.codes\n",
    "\n",
    "# 4. Handle NaNs/Negatives\n",
    "# Logistic Regression handles -1 fine (as a number), \n",
    "# but NB needs positive. We'll rely on MinMaxScaler for NB later.\n",
    "X = X.fillna(-1)\n",
    "\n",
    "# ==========================================\n",
    "# 2. Setup Models & Validation\n",
    "# ==========================================\n",
    "\n",
    "# Splitter: 3 splits is enough for a curve plot (saves time vs 5)\n",
    "cv_split = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "\n",
    "# Pipeline 1: Logistic Regression (Standard Scaler)\n",
    "pipe_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LogisticRegression(max_iter=1000, n_jobs=-1))\n",
    "])\n",
    "# Test C from 0.001 (Simple) to 100 (Complex)\n",
    "param_range_lr = np.logspace(-3, 5, 9) \n",
    "\n",
    "# Pipeline 2: Naive Bayes (MinMax Scaler)\n",
    "pipe_nb = Pipeline([\n",
    "    ('scaler', MinMaxScaler()), # Fixes negative numbers for NB\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "# Test Alpha from 0.001 (Complex) to 100 (Simple)\n",
    "param_range_nb = np.logspace(-3, 5, 9) \n",
    "\n",
    "# ==========================================\n",
    "# 3. Compute Curves\n",
    "# ==========================================\n",
    "print(\"Computing LR Complexity Curve...\")\n",
    "train_scores_lr, test_scores_lr = validation_curve(\n",
    "    pipe_lr, X, y, \n",
    "    param_name=\"lr__C\", \n",
    "    param_range=param_range_lr,\n",
    "    scoring=\"neg_log_loss\", \n",
    "    cv=cv_split, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Computing NB Complexity Curve...\")\n",
    "train_scores_nb, test_scores_nb = validation_curve(\n",
    "    pipe_nb, X, y, \n",
    "    param_name=\"nb__alpha\", \n",
    "    param_range=param_range_nb,\n",
    "    scoring=\"neg_log_loss\", \n",
    "    cv=cv_split, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Helper to process scores (flip sign for Log Loss)\n",
    "def process_scores(scores):\n",
    "    return -np.mean(scores, axis=1), np.std(scores, axis=1)\n",
    "\n",
    "train_mean_lr, train_std_lr = process_scores(train_scores_lr)\n",
    "test_mean_lr, test_std_lr = process_scores(test_scores_lr)\n",
    "train_mean_nb, train_std_nb = process_scores(train_scores_nb)\n",
    "test_mean_nb, test_std_nb = process_scores(test_scores_nb)\n",
    "\n",
    "# ==========================================\n",
    "# 4. Plotting\n",
    "# ==========================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# LR Plot\n",
    "axes[0].plot(param_range_lr, train_mean_lr, label=\"Training\", color=\"darkorange\", marker='o')\n",
    "axes[0].plot(param_range_lr, test_mean_lr, label=\"Validation\", color=\"navy\", marker='o')\n",
    "axes[0].fill_between(param_range_lr, train_mean_lr - train_std_lr, train_mean_lr + train_std_lr, alpha=0.2, color=\"darkorange\")\n",
    "axes[0].fill_between(param_range_lr, test_mean_lr - test_std_lr, test_mean_lr + test_std_lr, alpha=0.2, color=\"navy\")\n",
    "axes[0].set_title(\"Logistic Regression (Parameter: C)\")\n",
    "axes[0].set_xlabel(\"C (Low=Regulated, High=Complex)\")\n",
    "axes[0].set_ylabel(\"Log Loss (Lower is Better)\")\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# NB Plot\n",
    "axes[1].plot(param_range_nb, train_mean_nb, label=\"Training\", color=\"darkorange\", marker='o')\n",
    "axes[1].plot(param_range_nb, test_mean_nb, label=\"Validation\", color=\"navy\", marker='o')\n",
    "axes[1].fill_between(param_range_nb, train_mean_nb - train_std_nb, train_mean_nb + train_std_nb, alpha=0.2, color=\"darkorange\")\n",
    "axes[1].fill_between(param_range_nb, test_mean_nb - test_std_nb, test_mean_nb + test_std_nb, alpha=0.2, color=\"navy\")\n",
    "axes[1].set_title(\"Naive Bayes (Parameter: Alpha)\")\n",
    "axes[1].set_xlabel(\"Alpha (Low=Complex, High=Smoothed)\")\n",
    "axes[1].set_ylabel(\"Log Loss (Lower is Better)\")\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f0e46",
   "metadata": {},
   "source": [
    "Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9b02fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the class names (optional, makes the plot readable)\n",
    "crime_labels = df_new_1[\"Crime_Class\"].unique()\n",
    "crime_labels.sort() # Ensure they are in the same order as factorize usually does\n",
    "\n",
    "# 2. Plot the matrix\n",
    "# Ensure you pass the predictions you just made (y_pred_test)\n",
    "plot_crime_matrix(y_test_lr, y_pred_test_lr, model_name=\"Logistic Regression\", labels=crime_labels)\n",
    "plot_crime_matrix(y_test_nb, y_pred_test_nb, model_name=\"Naive Bayes\", labels=crime_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26d7540",
   "metadata": {},
   "source": [
    "### XGBoost (Processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f718670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# ---- FIX 1: Convert datetime columns to int64 ----\n",
    "for col in X.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "# ---- FIX 2: Convert lists ‚Üí strings to make them hashable ----\n",
    "for col in X.columns:\n",
    "\t    if X[col].dtype == 'object':\n",
    "\t        X[col] = X[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "# ---- Factorize object columns ----\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test_xgb = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model_2 = XGBClassifier()\n",
    "\n",
    "xgb_model_2.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = xgb_model_2.predict(X_train)\n",
    "y_pred_xgb = xgb_model_2.predict(X_test)\n",
    "\n",
    "# Evaluation reports\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_xgb, y_pred_xgb, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test_xgb, y_pred_xgb)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbfd895",
   "metadata": {},
   "source": [
    "Good Increase.\n",
    "\n",
    "### Validate the results:\n",
    "\n",
    "We'll apply the samne validation methods to ensure time and compuational efficiency.\n",
    "\n",
    "Method 1: Use Subsamples for Cross Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd9efff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Take a manageable subsample\n",
    "sample_size = 100_000\n",
    "X_sub = X.sample(sample_size, random_state=42)\n",
    "y_sub = y[X_sub.index]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accs = []\n",
    "fold = 1\n",
    "\n",
    "print(\"=== XGBoost Stratified K-Fold Validation ===\")\n",
    "\n",
    "for train_idx, test_idx in skf.split(X_sub, y_sub):\n",
    "    X_train, X_test = X_sub.iloc[train_idx], X_sub.iloc[test_idx]\n",
    "    y_train, y_test = y_sub[train_idx], y_sub[test_idx]\n",
    "\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=100,           # you can adjust\n",
    "        max_depth=6,                # default is 6\n",
    "        learning_rate=0.1,          # default\n",
    "        n_jobs=-1,\n",
    "        use_label_encoder=False,    # avoids warning\n",
    "        eval_metric=\"mlogloss\",     # for multiclass\n",
    "        tree_method=\"hist\",         # faster for large datasets\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    acc = accuracy_score(y_test, xgb_model.predict(X_test))\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    accs.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"K-Fold CV Accuracy Mean:\", np.mean(accs))\n",
    "print(\"Std:\", np.std(accs))\n",
    "print(\"---------------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db664690",
   "metadata": {},
   "source": [
    "Method 2: Use Stratified Shuffle-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba8528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== XGBoost Cross-Validation: Stratified Shuffle-Split ===\")\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=100,           # adjust as needed\n",
    "        max_depth=6,                # adjust as needed\n",
    "        learning_rate=0.1,\n",
    "        n_jobs=-1,\n",
    "        use_label_encoder=False,    # avoids warning\n",
    "        eval_metric=\"mlogloss\",     # suitable for multiclass\n",
    "        tree_method=\"hist\",         # faster for large datasets\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Mean Accuracy:  \", np.mean(accuracies))\n",
    "print(\"Std Deviation: \", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c841738",
   "metadata": {},
   "source": [
    "Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the class names (optional, makes the plot readable)\n",
    "crime_labels = df_new_1[\"Crime_Class\"].unique()\n",
    "crime_labels.sort() # Ensure they are in the same order as factorize usually does\n",
    "\n",
    "# 2. Plot the matrix\n",
    "# Ensure you pass the predictions you just made (y_pred_test)\n",
    "plot_crime_matrix(y_test_xgb, y_pred_xgb, model_name=\"XGBoost\", labels=crime_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca84b24",
   "metadata": {},
   "source": [
    "#### Plot the Complexity vs Error Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9510e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "for col in X.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        X[col] = X[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# OPTIONAL: SUBSAMPLE 250K rows for SPEED\n",
    "# ============================================================\n",
    "\n",
    "subset = 250_000\n",
    "# Convert y_train into a Pandas Series with matching indices\n",
    "y_train_series = pd.Series(y_train, index=X_train.index)\n",
    "\n",
    "subset = 250_000\n",
    "if len(X_train) > subset:\n",
    "    X_train_sub = X_train.sample(subset, random_state=42)\n",
    "    y_train_sub = y_train_series.loc[X_train_sub.index]\n",
    "else:\n",
    "    X_train_sub = X_train\n",
    "    y_train_sub = y_train_series\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CREATE CURVE (DEPTH 1 to 50)\n",
    "# ============================================================\n",
    "\n",
    "max_depths = range(1, 51)\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for d in max_depths:\n",
    "    print(f\"Training XGBoost with max_depth={d} ...\")\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        max_depth=d,\n",
    "        objective=\"multi:softprob\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        num_class=len(np.unique(y)),\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "    # Predict PROBABILITIES\n",
    "    y_train_prob = model.predict_proba(X_train_sub)\n",
    "    y_test_prob = model.predict_proba(X_test)\n",
    "\n",
    "    # Log-loss\n",
    "    train_losses.append(log_loss(y_train_sub, y_train_prob))\n",
    "    test_losses.append(log_loss(y_test, y_test_prob))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PLOT THE CURVE\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(max_depths, train_losses, label=\"Training Log-Loss\")\n",
    "plt.plot(max_depths, test_losses, label=\"Validation Log-Loss\")\n",
    "plt.xlabel(\"Model Complexity (max_depth)\")\n",
    "plt.ylabel(\"Log-Loss Error\")\n",
    "plt.title(\"XGBoost Complexity Curve (1‚Äì50 Depth)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec435b1",
   "metadata": {},
   "source": [
    "### Evaluate Feature Importance (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf9f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Feature Importance\n",
    "# -------------------------------------------\n",
    "importance = xgb_model_2.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "fi = pd.DataFrame({\"feature\": features, \"importance\": importance})\n",
    "fi.sort_values(by=\"importance\", ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763c6878",
   "metadata": {},
   "source": [
    "## Category: Deep Learning Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb19d92c",
   "metadata": {},
   "source": [
    "\n",
    "### Neural Networks: CNN (Proessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb1c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model_2 = df_new.copy()\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# ---- FIX 1: Convert datetime columns to int64 ----\n",
    "for col in X.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "# ---- FIX 2: Convert lists ‚Üí strings to make them hashable ----\n",
    "for col in X.columns:\n",
    "\t    if X[col].dtype == 'object':\n",
    "\t        X[col] = X[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ====== RESHAPE FOR CNN (Conv1D needs shape: samples, timesteps, features) ======\n",
    "X_train_cnn = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
    "X_test_cnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# ====== BUILD CNN MODEL ======\n",
    "cnn_model_2 = Sequential([\n",
    "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model_2.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ====== TRAIN ======\n",
    "history = cnn_model_2.fit(\n",
    "    X_train_cnn, y_train_cat,\n",
    "    epochs=10,              # Use epoch size = 10, since the datset is fairly large. Fewer epochs means less strain and timne\n",
    "    batch_size=32,          #Default values is 32.\n",
    "    validation_split=0.2,   #Keras default is 0.0\n",
    "    verbose=1               #Keras default is 1\n",
    ")\n",
    "\n",
    "# ====== PREDICT ======\n",
    "y_pred_train = cnn_model_2.predict(X_train_cnn).argmax(axis=1)\n",
    "y_pred_test = cnn_model_2.predict(X_test_cnn).argmax(axis=1)\n",
    "\n",
    "# ====== EVALUATION ======\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1306a064",
   "metadata": {},
   "source": [
    "#### Perform Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af92eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Use a smaller subsample if your dataset is very large\n",
    "sample_size = 100_000\n",
    "X_sub = X.sample(sample_size, random_state=42)\n",
    "y_sub = y[X_sub.index]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_sub)\n",
    "\n",
    "# Reshape for Conv1D\n",
    "X_cnn = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y_sub))\n",
    "y_cat = to_categorical(y_sub, num_classes)\n",
    "\n",
    "# Stratified Shuffle-Split\n",
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=42)  # fewer splits due to time\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X_cnn, y_sub):\n",
    "    print(f\"=== Fold {fold} ===\")\n",
    "    \n",
    "    X_train, X_test = X_cnn[train_idx], X_cnn[test_idx]\n",
    "    y_train, y_test = y_cat[train_idx], y_cat[test_idx]\n",
    "\n",
    "    # Build CNN model\n",
    "    cnn_model = Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    cnn_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    cnn_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=5,           # keep low for faster CV\n",
    "        batch_size=32,\n",
    "        verbose=0           # silent training for CV\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = cnn_model.predict(X_test).argmax(axis=1)\n",
    "    y_true = y_sub[test_idx]\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Fold {fold} Accuracy: {acc:.4f}\")\n",
    "    accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"CV Accuracy Mean:\", np.mean(accuracies))\n",
    "print(\"CV Accuracy Std:\", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03af14a9",
   "metadata": {},
   "source": [
    "#### Plot the error versus complexity curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683d7db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Use a smaller subsample for speed\n",
    "sample_size = 50_000  # adjust as needed\n",
    "X_sub = X.sample(sample_size, random_state=42)\n",
    "y_sub = y[X_sub.index]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_sub)\n",
    "\n",
    "# Reshape for Conv1D\n",
    "X_cnn = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y_sub))\n",
    "y_cat = to_categorical(y_sub, num_classes)\n",
    "\n",
    "# Complexity levels (number of filters in first Conv1D layer)\n",
    "complexity_values = [8, 16, 32, 64, 128]\n",
    "\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "print(\"=== Generating CNN Error vs Complexity Curve ===\")\n",
    "\n",
    "for filters in complexity_values:\n",
    "    print(f\"Training CNN with {filters} filters in first Conv1D layer\")\n",
    "\n",
    "    # Build CNN model\n",
    "    cnn_model = Sequential([\n",
    "        Conv1D(filters, kernel_size=3, activation='relu', input_shape=(X_cnn.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters*2, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    cnn_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Train (fewer epochs for faster evaluation)\n",
    "    cnn_model.fit(\n",
    "        X_cnn, y_cat,\n",
    "        epochs=5,\n",
    "        batch_size=32,\n",
    "        verbose=0  # silent training\n",
    "    )\n",
    "\n",
    "    # Predict\n",
    "    y_pred_train = cnn_model.predict(X_cnn).argmax(axis=1)\n",
    "    y_true = y_sub\n",
    "    train_err = 1 - accuracy_score(y_true, y_pred_train)\n",
    "\n",
    "    # Optional: split a small testing subset for speed\n",
    "    test_idx = np.random.choice(len(X_cnn), size=int(0.2*len(X_cnn)), replace=False)\n",
    "    X_test_small = X_cnn[test_idx]\n",
    "    y_test_small = y_sub[test_idx]\n",
    "    y_test_cat_small = y_cat[test_idx]\n",
    "\n",
    "    y_pred_test = cnn_model.predict(X_test_small).argmax(axis=1)\n",
    "    test_err = 1 - accuracy_score(y_test_small, y_pred_test)\n",
    "\n",
    "    train_errors.append(train_err)\n",
    "    test_errors.append(test_err)\n",
    "\n",
    "# ---- Plot ----\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(complexity_values, train_errors, marker='o', label=\"Training Error\")\n",
    "plt.plot(complexity_values, test_errors, marker='o', label=\"Testing Error\")\n",
    "plt.xlabel(\"CNN Complexity (Number of Filters in First Conv1D Layer)\")\n",
    "plt.ylabel(\"Error (1 - Accuracy)\")\n",
    "plt.title(\"CNN Error vs Complexity Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f653bf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====== COMPUTE PROBABILITIES ======\n",
    "train_proba = cnn_model_2.predict(X_train_cnn)\n",
    "test_proba  = cnn_model_2.predict(X_test_cnn)\n",
    "\n",
    "# ====== COMPUTE LOG LOSS ======\n",
    "train_loss = log_loss(y_train, train_proba)\n",
    "test_loss  = log_loss(y_test,  test_proba)\n",
    "\n",
    "print(\"------------------------\")\n",
    "print(\"Training Loss\")\n",
    "print(train_loss)\n",
    "print(\"------------------------\")\n",
    "print(\"Testing Loss:\")\n",
    "print(test_loss)\n",
    "print(\"------------------------\")\n",
    "print(\":)\")\n",
    "acc_gap  = train_accuracy - test_accuracy\n",
    "loss_gap = test_loss - train_loss\n",
    "print(\"------------------------\")\n",
    "print(\"Accuracy Gap:\")\n",
    "print(acc_gap)\n",
    "print(\"------------------------\")\n",
    "print(\"Loss Gap:\")\n",
    "print(loss_gap)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# ====== PLOT TRAINING vs VALIDATION LOSS FROM HISTORY ======\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss Curve (CNN)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef14ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "# ======================================================\n",
    "# 1. TAKE A SMALL SUBSET TO AVOID HOURS OF TRAINING\n",
    "# ======================================================\n",
    "subset = 50000   # Use 50k rows for speed (change if needed)\n",
    "\n",
    "X_train_sub = X_train_cnn[:subset]\n",
    "y_train_sub = y_train[:subset]\n",
    "y_train_sub_cat = y_train_cat[:subset]\n",
    "\n",
    "X_val_sub = X_test_cnn[:20000]\n",
    "y_val_sub = y_test[:20000]\n",
    "y_val_sub_cat = y_test_cat[:20000]\n",
    "\n",
    "# ======================================================\n",
    "# 2. DEFINE COMPLEXITY LEVELS (NUMBER OF FILTERS)\n",
    "# ======================================================\n",
    "complexities = [8, 16, 32, 64, 128]\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "# ======================================================\n",
    "# 3. LOOP THROUGH MODEL COMPLEXITIES\n",
    "# ======================================================\n",
    "for filters in complexities:\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv1D(filters, kernel_size=3, activation='relu',\n",
    "               input_shape=(X_train_sub.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "\n",
    "        Conv1D(filters*2, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # short training for speed\n",
    "    model.fit(\n",
    "        X_train_sub, y_train_sub_cat,\n",
    "        epochs=3,          # small number for speed\n",
    "        batch_size=64,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Predictions\n",
    "    train_proba = model.predict(X_train_sub, verbose=0)\n",
    "    test_proba  = model.predict(X_val_sub,   verbose=0)\n",
    "\n",
    "    y_train_pred = np.argmax(train_proba, axis=1)\n",
    "    y_test_pred  = np.argmax(test_proba, axis=1)\n",
    "\n",
    "    # Metrics\n",
    "    train_losses.append(log_loss(y_train_sub, train_proba))\n",
    "    test_losses.append(log_loss(y_val_sub,  test_proba))\n",
    "\n",
    "    train_accs.append(accuracy_score(y_train_sub, y_train_pred))\n",
    "    test_accs.append(accuracy_score(y_val_sub,  y_test_pred))\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 4. PLOT COMPLEXITY vs ERROR\n",
    "# ======================================================\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(complexities, train_losses, label=\"Training Loss\")\n",
    "plt.plot(complexities, test_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Model Complexity (Number of Filters)\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.title(\"CNN Model Complexity vs Error\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0114b1da",
   "metadata": {},
   "source": [
    "### Neural Network: ANN (Processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee57316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model_2 = df_new.copy()\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# ---- FIX 1: Convert datetime columns to int64 ----\n",
    "for col in X.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "# ---- FIX 2: Convert lists ‚Üí strings to make them hashable ----\n",
    "for col in X.columns:\n",
    "\t    if X[col].dtype == 'object':\n",
    "\t        X[col] = X[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# ====== BUILD ANN MODEL ======\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ====== TRAIN ======\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_cat,\n",
    "    epochs=10,              #Use 10 as a derfault value for epochs\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ====== PREDICT ======\n",
    "y_pred_train = model.predict(X_train_scaled).argmax(axis=1)\n",
    "y_pred_test = model.predict(X_test_scaled).argmax(axis=1)\n",
    "\n",
    "# ====== EVALUATION ======\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2354f92b",
   "metadata": {},
   "source": [
    "Validation Time. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d469d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# Optional subsample for speed (same as CNN version)\n",
    "# ============================================================\n",
    "sample_size = 100_000\n",
    "X_sub = X.sample(sample_size, random_state=42)\n",
    "y_sub = y[X_sub.index]\n",
    "\n",
    "# ============================================================\n",
    "# Scale features\n",
    "# ============================================================\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_sub)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y_sub))\n",
    "y_cat = to_categorical(y_sub, num_classes)\n",
    "\n",
    "# ============================================================\n",
    "# Stratified Shuffle-Split\n",
    "# ============================================================\n",
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X_scaled, y_sub):\n",
    "    print(f\"=== Fold {fold} ===\")\n",
    "\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y_cat[train_idx], y_cat[test_idx]\n",
    "\n",
    "    # ============================================================\n",
    "    # Build ANN model (matching your original architecture)\n",
    "    # ============================================================\n",
    "    ann_model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    ann_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Train (silent for CV)\n",
    "    ann_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=5,          # reduced for faster CV, same as CNN version\n",
    "        batch_size=32,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Predict + evaluate\n",
    "    y_pred = ann_model.predict(X_test).argmax(axis=1)\n",
    "    y_true = y_sub[test_idx]\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"Fold {fold} Accuracy: {acc:.4f}\")\n",
    "    accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "# ============================================================\n",
    "# Summary\n",
    "# ============================================================\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"CV Accuracy Mean:\", np.mean(accuracies))\n",
    "print(\"CV Accuracy Std:\", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3d7f3d",
   "metadata": {},
   "source": [
    "Curve Check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a8794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ============================================================\n",
    "# 1. Prepare Data (Updated for 250k)\n",
    "# ============================================================\n",
    "print(\"=== Preparing Data ===\")\n",
    "# Ensure we don't sample more than we have\n",
    "sample_size = min(250_000, len(X))\n",
    "\n",
    "# Assuming X is a DataFrame (based on your .sample code)\n",
    "X_sub = X.sample(n=sample_size, random_state=42)\n",
    "y_sub = y[X_sub.index] # Align y with X\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_sub)\n",
    "\n",
    "num_classes = len(np.unique(y_sub))\n",
    "y_cat = to_categorical(y_sub, num_classes)\n",
    "\n",
    "# Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled, y_cat, test_size=0.3, random_state=42, stratify=y_sub\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Complexity levels (Wider Range)\n",
    "# ============================================================\n",
    "# We go from very simple (10) to very complex (800) to force the curve\n",
    "complexity_levels = [10, 50, 150, 400, 800]\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(f\"=== Starting Training Loop (Subsample: {sample_size}) ===\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. Train ANN for each complexity level\n",
    "# ============================================================\n",
    "for units in complexity_levels:\n",
    "    print(f\"Training model with {units} neurons...\")\n",
    "\n",
    "    model = Sequential([\n",
    "        # INCREASED COMPLEXITY:\n",
    "        # We use a single massive layer.\n",
    "        # CRITICAL: We REMOVED Dropout to allow overfitting.\n",
    "        Dense(units, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # INCREASED EPOCHS:\n",
    "    # We need enough time for the big models to memorize the noise.\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=20,  # Increased from 5 to 20\n",
    "        batch_size=64, # Slightly larger batch for speed\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Store final epoch losses\n",
    "    train_losses.append(history.history['loss'][-1])\n",
    "    val_losses.append(history.history['val_loss'][-1])\n",
    "\n",
    "# ============================================================\n",
    "# 4. Plot Error vs Complexity\n",
    "# ============================================================\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot lines\n",
    "plt.plot(complexity_levels, train_losses, marker='o', label='Training Loss (Bias)', color='blue')\n",
    "plt.plot(complexity_levels, val_losses, marker='o', label='Validation Loss (Variance)', color='orange')\n",
    "\n",
    "plt.title(\"Bias-Variance Tradeoff: ANN Complexity\")\n",
    "plt.xlabel(\"Model Complexity (Neurons in Hidden Layer)\")\n",
    "plt.ylabel(\"Log Loss (Lower is Better)\")\n",
    "plt.xticks(complexity_levels) # Show exact x-axis values\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2113fa",
   "metadata": {},
   "source": [
    "### Part A: (Shorlisting Most Promising Models)\n",
    "\n",
    "#### Now, let's select the most promising models, we will ignore the rest.\n",
    "\n",
    "We're choosing model shorlisters from two ‚Äúfamilies‚Äù of models:\n",
    "\n",
    "Tree-based family (ML Models):\n",
    "- Decision Tree (DT)\n",
    "- Random Forest (RF)\n",
    "- XGBoost (XGB)\n",
    "\n",
    "Neural network family (DL Models):\n",
    "- ANN\n",
    "- CNN\n",
    "\n",
    "Of the 5 models present, XGBoost and ANN proved the most promising, as their complexity vs error, testing results, and SD of validation scores all lie within a highly satifying range. These 2 will be shortlisted as most promising.\n",
    "\n",
    "The question now though is to select a 3rd model to shortlist. As CNN is stricly better than ANN due to CNN being primarily used for images, spatial structures, and grid-like data, ANN will be the only succesor of its famnily.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "üìå XGBoost\n",
    "\n",
    "- Train Acc: 0.9226\n",
    "- Test Acc: 0.9167 ‚Üí tiny generalisation gap\n",
    "- Train F1: 0.7827\n",
    "- Test F1: 0.7359 ‚Üí also stable\n",
    "- CV SD: 0.00019 ‚Üí the most stable model\n",
    "- Highest CV mean: 0.9111\n",
    "\n",
    "Interpretation:\n",
    "- Best generalisation\n",
    "- Best CV score\n",
    "- Lowest variance\n",
    "- Best balance of train-test match\n",
    "- Best F1 of the three\n",
    "\n",
    "Clearly the best tree-based model and likely the best overall model.\n",
    "\n",
    "üìå ANN\n",
    "\n",
    "- Train Acc: 0.9141\n",
    "- Test Acc: 0.9122 ‚Üí tiny generalisation gap\n",
    "- Train F1: 0.7097\n",
    "- Test F1: 0.7036\n",
    "- CV SD: 0.00146 ‚Üí more variance than XGB, but still acceptable\n",
    "\n",
    "Interpretation:\n",
    "- Performs nearly as well as XGB\n",
    "- Much simpler than XGB (depending on architecture)\n",
    "- Good generalisation\n",
    "- Lower F1 than XGB, but still strong\n",
    "\n",
    "Clear winner of the neural-based family.\n",
    "\n",
    "As such, these 3 models will be chosen and will be proceeded forward for Part B training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefb4b3c",
   "metadata": {},
   "source": [
    "## Part B - Parameters\n",
    "\n",
    "### Now, let's implement Hyperparameter Tuning:\n",
    "\n",
    "This will take a while as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cd37ea",
   "metadata": {},
   "source": [
    "### Naive Bayes (Processed & Tunned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a1b022",
   "metadata": {},
   "source": [
    "WARNING: DO NOT ATTEMPT THIS using the full 1 Milliom. Unless you'd like your laptop to crash over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f13379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 1. Setup Data (Assuming df_new_1 already exists)\n",
    "# ----------------------------------------------------\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. Prepare X and y\n",
    "# ----------------------------------------------------\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. Pre-processing (Memory Safe)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# A. Datetime ‚Üí int64\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].values.astype(np.int64)\n",
    "\n",
    "# B. List columns ‚Üí str\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# C. Object columns ‚Üí category codes\n",
    "print(\"Encoding columns...\")\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        X[col] = X[col].astype(\"category\").cat.codes\n",
    "\n",
    "# D. Missing values ‚Üí -1\n",
    "# (safe because MinMaxScaler shifts everything to 0‚Äì1)\n",
    "X = X.fillna(-1)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4. Train‚ÄìTest Split\n",
    "# ----------------------------------------------------\n",
    "X_train, X_test, y_train, y_test_nb = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 5. Scaling\n",
    "# ----------------------------------------------------\n",
    "print(\"Scaling data (MinMax)...\")\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 6. Manual Alpha Search (Safe & Lightweight)\n",
    "# ----------------------------------------------------\n",
    "alphas = [0.1, 0.5, 1.0, 2.0, 5.0,10.0]\n",
    "best_alpha = None\n",
    "best_acc = 0\n",
    "\n",
    "print(\"\\nSearching for best alpha...\")\n",
    "\n",
    "for alpha in alphas:\n",
    "    model = MultinomialNB(alpha=alpha)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test_nb, y_pred)\n",
    "\n",
    "    print(f\"Alpha={alpha} ‚Üí Test Accuracy={acc:.4f}\")\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(f\"\\nBest Alpha Found: {best_alpha} (Accuracy={best_acc:.4f})\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 7. Train Final Model\n",
    "# ----------------------------------------------------\n",
    "print(\"\\nTraining final MultinomialNB model...\")\n",
    "nb_model_1 = MultinomialNB(alpha=best_alpha)\n",
    "nb_model_1.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "print(\"Predicting...\")\n",
    "y_pred_train_1 = nb_model_1.predict(X_train_scaled)\n",
    "y_pred_test_nb = nb_model_1.predict(X_test_scaled)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 8. Evaluation\n",
    "# ----------------------------------------------------\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_1)\n",
    "test_accuracy = accuracy_score(y_test_nb, y_pred_test_nb)\n",
    "\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_nb, y_pred_test_nb, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed723e94",
   "metadata": {},
   "source": [
    "### XGBoost (Processed & Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325e5aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== FAST & MEMORY-EFFICIENT XGBOOST TRAINING ===\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# ============================================================\n",
    "# PREPROCESSING (same as before)\n",
    "# ============================================================\n",
    "\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "# Keep y as a pandas Series instead of numpy array\n",
    "y = pd.Series(pd.factorize(df_model_2[\"Crime_Class\"])[0])\n",
    "\n",
    "\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "X = X.astype(\"float32\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# TINY SUBSAMPLE FOR FAST TUNING\n",
    "# ============================================================\n",
    "\n",
    "tune_size = 10000\n",
    "X_tune = X_train.sample(tune_size, random_state=42)\n",
    "y_tune = y_train[X_tune.index]\n",
    "\n",
    "print(f\"Tuning using {len(X_tune):,} rows\")\n",
    "\n",
    "# ============================================================\n",
    "# FAST XGBOOST RANDOMIZED SEARCH\n",
    "# ============================================================\n",
    "\n",
    "xgb_base = XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=len(np.unique(y)),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"max_depth\": randint(4, 10),\n",
    "    \"learning_rate\": uniform(0.03, 0.2),\n",
    "    \"min_child_weight\": randint(1, 6),\n",
    "    \"subsample\": uniform(0.5, 0.5),\n",
    "    \"colsample_bytree\": uniform(0.5, 0.5),\n",
    "    \"n_estimators\": randint(150, 400)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    xgb_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=15,        # FAST\n",
    "    cv=2,\n",
    "    scoring=\"accuracy\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search.fit(X_tune, y_tune)\n",
    "\n",
    "print(\"\\nBest Params:\", search.best_params_)\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN FINAL MODEL ON FULL DATASET\n",
    "# ============================================================\n",
    "\n",
    "xgb_final = XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=len(np.unique(y)),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    **search.best_params_\n",
    ")\n",
    "\n",
    "xgb_final.fit(X_train, y_train)\n",
    "\n",
    "# ============================================================\n",
    "# EVALUATION\n",
    "# ============================================================\n",
    "\n",
    "y_pred_train = xgb_final.predict(X_train)\n",
    "y_pred_test = xgb_final.predict(X_test)\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "print(\"\\nTRAIN REPORT\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "print(\"\\nTEST REPORT\")\n",
    "print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4044af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== XGBOOST Cross-Validation: Stratified Shuffle-Split ===\\n\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Use your tuned parameters\n",
    "# ------------------------------------------------------------\n",
    "best_params = search.best_params_\n",
    "print(\"Using Best Params:\", best_params, \"\\n\")\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    X_train_cv, X_test_cv = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train_cv, y_test_cv = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # XGBoost model with best params\n",
    "    # --------------------------------------------------------\n",
    "    xgb_cv = XGBClassifier(\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y)),\n",
    "        eval_metric=\"mlogloss\",\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        **best_params\n",
    "    )\n",
    "\n",
    "    xgb_cv.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = xgb_cv.predict(X_test_cv)\n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_test_cv, y_pred)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Mean Accuracy:  \", np.mean(accuracies))\n",
    "print(\"Std Deviation: \", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b75a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Use a subset for speed\n",
    "# -------------------------------\n",
    "subset_size = 250_000  # <--- UPDATED to 250k\n",
    "print(f\"Subsampling {subset_size} rows...\")\n",
    "X_sub = X.sample(subset_size, random_state=42)\n",
    "y_sub = y[X_sub.index] # Ensure target aligns with sampled X\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Complexity range (max_depth)\n",
    "# -------------------------------\n",
    "# Range 1 to 50 with step 5 (1, 6, 11... 46, 51)\n",
    "depth_values = range(1, 51, 5) \n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "# Base tuned params (Make sure 'search' is defined or replace this line!)\n",
    "base_params = search.best_params_.copy()\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Stratified Shuffle-Split\n",
    "# -------------------------------\n",
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "\n",
    "for depth in depth_values:\n",
    "    fold_train_errors = []\n",
    "    fold_test_errors = []\n",
    "    print(f\"Testing max_depth = {depth}...\")\n",
    "\n",
    "    for train_idx, test_idx in sss.split(X_sub, y_sub):\n",
    "        X_train_cv, X_test_cv = X_sub.iloc[train_idx], X_sub.iloc[test_idx]\n",
    "        y_train_cv, y_test_cv = y_sub.iloc[train_idx], y_sub.iloc[test_idx]\n",
    "\n",
    "        # Update params for this specific loop\n",
    "        params = base_params.copy()\n",
    "        params[\"max_depth\"] = depth\n",
    "\n",
    "        model = XGBClassifier(\n",
    "            objective=\"multi:softmax\",\n",
    "            num_class=len(np.unique(y_sub)),\n",
    "            eval_metric=\"mlogloss\",\n",
    "            tree_method=\"hist\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred_train = model.predict(X_train_cv)\n",
    "        y_pred_test  = model.predict(X_test_cv)\n",
    "\n",
    "        # Calculate Error (1 - Accuracy)\n",
    "        fold_train_errors.append(1 - accuracy_score(y_train_cv, y_pred_train))\n",
    "        fold_test_errors.append(1 - accuracy_score(y_test_cv, y_pred_test))\n",
    "\n",
    "    # Average over folds\n",
    "    train_errors.append(np.mean(fold_train_errors))\n",
    "    test_errors.append(np.mean(fold_test_errors))\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Plot\n",
    "# -------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(depth_values, train_errors, marker='o', label=\"Training Error\")\n",
    "plt.plot(depth_values, test_errors, marker='o', label=\"Test Error\")\n",
    "\n",
    "plt.xlabel(\"Model Complexity (max_depth)\")\n",
    "plt.ylabel(\"Error (1 - accuracy)\")\n",
    "plt.title(f\"XGBoost Error vs Model Complexity (Subset: {subset_size:,} rows)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e7cd09",
   "metadata": {},
   "source": [
    "### ANN (Hyperparamters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cae8694",
   "metadata": {},
   "source": [
    "Perform the Shuffle-Split Validation:\n",
    "\n",
    "*Note, if it shows error X_train_scaled is not defined, run the top ANN (Processed) model first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a3d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. Define a lightweight search space\n",
    "# ============================================================\n",
    "\n",
    "param_space = {\n",
    "    \"lr\": [1e-3, 3e-4, 1e-4],\n",
    "    \"hidden_1\": [64, 96, 128],\n",
    "    \"hidden_2\": [32, 48, 64],\n",
    "    \"dropout\": [0.2, 0.3, 0.4],\n",
    "    \"batch_size\": [32, 64, 128]\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Function to build a model from hyperparameters\n",
    "# ============================================================\n",
    "\n",
    "def build_model(params):\n",
    "    model = Sequential([\n",
    "        Dense(params[\"hidden_1\"], activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dropout(params[\"dropout\"]),\n",
    "\n",
    "        Dense(params[\"hidden_2\"], activation='relu'),\n",
    "        Dropout(params[\"dropout\"]),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=Adam(learning_rate=params[\"lr\"]),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. LIGHTWEIGHT BEST PARAMS SEARCH\n",
    "#    (Random sampling + short training + early stopping)\n",
    "# ============================================================\n",
    "\n",
    "def sample_params():\n",
    "    return {\n",
    "        \"lr\": random.choice(param_space[\"lr\"]),\n",
    "        \"hidden_1\": random.choice(param_space[\"hidden_1\"]),\n",
    "        \"hidden_2\": random.choice(param_space[\"hidden_2\"]),\n",
    "        \"dropout\": random.choice(param_space[\"dropout\"]),\n",
    "        \"batch_size\": random.choice(param_space[\"batch_size\"])\n",
    "    }\n",
    "\n",
    "search_results = []\n",
    "N_SEARCH = 4   # Only 4 trials ‚Üí FAST & LIGHT, it strikes a decent balance; or set to a smaller value if time is a concern (Such as 3), or to a a larger value if you have more time (Such as 5-10)\n",
    "\n",
    "print(\"\\n========== STARTING BEST PARAMS SEARCH ==========\\n\")\n",
    "\n",
    "for i in range(N_SEARCH):\n",
    "    params = sample_params()\n",
    "    print(f\"Trial {i+1}/{N_SEARCH}: {params}\")\n",
    "\n",
    "    model = build_model(params)\n",
    "\n",
    "    es = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # SHORT training for search only\n",
    "    history = model.fit(\n",
    "        X_train_scaled,\n",
    "        y_train_cat,\n",
    "        epochs=8,\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        validation_split=0.2,\n",
    "        verbose=0,\n",
    "        callbacks=[es]\n",
    "    )\n",
    "\n",
    "    val_acc = max(history.history[\"val_accuracy\"])\n",
    "    search_results.append((val_acc, params))\n",
    "\n",
    "    print(f\" ‚Üí Best Val Accuracy: {val_acc:.4f}\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. Select best params\n",
    "# ============================================================\n",
    "\n",
    "best_val, best_params = max(search_results, key=lambda x: x[0])\n",
    "print(\"\\n========== BEST PARAMS FOUND ==========\")\n",
    "print(best_params)\n",
    "print(\"Best Validation Accuracy:\", best_val)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. Train FINAL MODEL with best params\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n========== TRAINING FINAL MODEL ==========\\n\")\n",
    "\n",
    "final_model = build_model(best_params)\n",
    "\n",
    "es_final = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history_final = final_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_cat,\n",
    "    epochs=25,\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    "    callbacks=[es_final]\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. Evaluate\n",
    "# ============================================================\n",
    "\n",
    "y_pred_train = final_model.predict(X_train_scaled).argmax(axis=1)\n",
    "y_pred_test = final_model.predict(X_test_scaled).argmax(axis=1)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "print(\"\\n===== TRAINING REPORT =====\")\n",
    "print(pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose())\n",
    "\n",
    "print(\"\\n===== TESTING REPORT =====\")\n",
    "print(pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test, output_dict=True)\n",
    ").transpose())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36585e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#                üìå FULL ANN PIPELINE \n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ============================================================\n",
    "# PREPROCESSING\n",
    "# ============================================================\n",
    "\n",
    "df_model_2 = df_new.copy()\n",
    "\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# Convert datetime ‚Üí int64\n",
    "for col in X.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "# Convert lists ‚Üí strings\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        X[col] = X[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Fill missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# ============================================================\n",
    "# BEST PARAMS (From your search)\n",
    "# ============================================================\n",
    "best_params = {\n",
    "    \"layer1\": 128,\n",
    "    \"layer2\": 64,\n",
    "    \"layer3\": 32,\n",
    "    \"dropout\": 0.3,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 10,       # base training\n",
    "    \"lr\": 0.001         # default Adam LR\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# MODEL BUILDER FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def build_ann():\n",
    "    model = Sequential([\n",
    "        Dense(best_params[\"layer1\"], activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dropout(best_params[\"dropout\"]),\n",
    "\n",
    "        Dense(best_params[\"layer2\"], activation='relu'),\n",
    "        Dropout(best_params[\"dropout\"]),\n",
    "\n",
    "        Dense(best_params[\"layer3\"], activation='relu'),\n",
    "\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN FINAL MODEL\n",
    "# ============================================================\n",
    "\n",
    "model = build_ann()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_cat,\n",
    "    epochs=best_params[\"epochs\"],\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predict\n",
    "y_pred_train = model.predict(X_train_scaled).argmax(axis=1)\n",
    "y_pred_test = model.predict(X_test_scaled).argmax(axis=1)\n",
    "\n",
    "# Evaluation\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Accuracy:\", train_acc)\n",
    "print(\"Testing Accuracy:\", test_acc)\n",
    "\n",
    "print(\"\\nTRAIN REPORT\")\n",
    "print(pd.DataFrame.from_dict(classification_report(y_train, y_pred_train, output_dict=True)).transpose())\n",
    "\n",
    "print(\"\\nTEST REPORT\")\n",
    "print(pd.DataFrame.from_dict(classification_report(y_test, y_pred_test, output_dict=True)).transpose())\n",
    "\n",
    "# ============================================================\n",
    "# SHUFFLE-SPLIT CROSS VALIDATION (FAST + MEMORY EFFICIENT)\n",
    "# ============================================================\n",
    "\n",
    "def ann_shuffle_split_cv(n_splits=5):\n",
    "\n",
    "    ss = ShuffleSplit(n_splits=n_splits, test_size=0.2, random_state=42)\n",
    "    accuracies = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_idx, val_idx in ss.split(X_train_scaled):\n",
    "\n",
    "        print(f\"\\n===== ShuffleSplit Fold {fold}/{n_splits} =====\")\n",
    "\n",
    "        X_tr, X_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "        y_tr, y_val = y_train_cat[train_idx], y_train_cat[val_idx]\n",
    "\n",
    "        model_cv = build_ann()\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "        model_cv.fit(\n",
    "            X_tr, y_tr,\n",
    "            epochs=12,  # small for speed\n",
    "            batch_size=best_params[\"batch_size\"],\n",
    "            validation_data=(X_val, y_val),\n",
    "            verbose=0,\n",
    "            callbacks=[es]\n",
    "        )\n",
    "\n",
    "        loss, acc = model_cv.evaluate(X_val, y_val, verbose=0)\n",
    "        print(f\"Fold Accuracy: {acc:.4f}\")\n",
    "\n",
    "        accuracies.append(acc)\n",
    "        fold += 1\n",
    "\n",
    "    accuracies = np.array(accuracies)\n",
    "    print(\"\\n========== SHUFFLE SPLIT SUMMARY ==========\")\n",
    "    print(\"Accuracies:\", accuracies)\n",
    "    print(\"Mean CV Accuracy:\", accuracies.mean())\n",
    "    print(\"Std Deviation:\", accuracies.std())\n",
    "    print(\"============================================\")\n",
    "\n",
    "    return accuracies.mean(), accuracies.std()\n",
    "\n",
    "# Run CV\n",
    "cv_mean, cv_sd = ann_shuffle_split_cv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaafc41",
   "metadata": {},
   "source": [
    "### Part B - Applying new preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24787fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the binary \"Victim_Involved?\" column first\n",
    "# We check if 'Vict Age', 'Vict Sex', or 'Vict Descent' have valid data.\n",
    "# Adjust the condition if you only want to check specific columns.\n",
    "# Here, if ALL victim columns are null, it's 0. If ANY has data, it's 1.\n",
    "# (Alternatively, you can just check one if they are always missing together)\n",
    "df_new_1['Victim_Involved?'] = df_new_1.apply(\n",
    "    lambda row: 0 if (pd.isna(row['Vict Sex']) or str(row['Vict Sex']).strip() == '') and \n",
    "                     (pd.isna(row['Vict Descent']) or str(row['Vict Descent']).strip() == '') \n",
    "                else 1, axis=1\n",
    ")\n",
    "\n",
    "# 2. Drop the victim-based columns\n",
    "cols_to_drop = ['Vict Age', 'Vict Sex', 'Vict Descent']\n",
    "df_new_1 = df_new_1.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "# Verify the changes\n",
    "print(df_new_1[['Victim_Involved?']].head())\n",
    "print(df_new_1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2115ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_2 = df_new_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4f8b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9542c3e",
   "metadata": {},
   "source": [
    "# Ensemble: XGBoost + Logistic Regression\n",
    "\n",
    "Combining XGBoost and Logistic Regression predictions using averaging and stacking approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f769b8ec",
   "metadata": {},
   "source": [
    "## Get predictions from both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probability predictions from both models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Get the original 2D feature data by reshaping or using the right variables\n",
    "# X_train and X_test might be 3D for CNN, so we need the 2D version\n",
    "# Check if we have 2D data available\n",
    "if len(X_train.shape) == 3:\n",
    "    # If 3D (for CNN), flatten to 2D\n",
    "    X_train_2d = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test_2d = X_test.reshape(X_test.shape[0], -1)\n",
    "else:\n",
    "    # Already 2D, convert to numpy array if DataFrame\n",
    "    X_train_2d = X_train.values if hasattr(X_train, 'values') else X_train\n",
    "    X_test_2d = X_test.values if hasattr(X_test, 'values') else X_test\n",
    "\n",
    "# Convert y_train from one-hot encoding to class labels if needed\n",
    "if len(y_train.shape) == 2:\n",
    "    # y_train is one-hot encoded, convert to class labels\n",
    "    y_train_labels = np.argmax(y_train, axis=1)\n",
    "    y_test_labels = np.argmax(y_test, axis=1)\n",
    "else:\n",
    "    y_train_labels = y_train\n",
    "    y_test_labels = y_test\n",
    "\n",
    "# Handle missing values by filling with 0\n",
    "X_train_2d = np.nan_to_num(X_train_2d, nan=0.0)\n",
    "X_test_2d = np.nan_to_num(X_test_2d, nan=0.0)\n",
    "\n",
    "# Ensure X and y have the same number of samples\n",
    "print(f\"X_train_2d shape: {X_train_2d.shape}\")\n",
    "print(f\"X_test_2d shape: {X_test_2d.shape}\")\n",
    "print(f\"y_train_labels shape: {y_train_labels.shape}\")\n",
    "print(f\"y_test_labels shape: {y_test_labels.shape}\")\n",
    "\n",
    "# Train XGBoost for ensemble\n",
    "print(\"\\nTraining XGBoost for ensemble...\")\n",
    "xgb_ensemble = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, \n",
    "                             random_state=42, n_jobs=-1, eval_metric='mlogloss')\n",
    "xgb_ensemble.fit(X_train_2d, y_train_labels)\n",
    "xgb_train_proba = xgb_ensemble.predict_proba(X_train_2d)\n",
    "xgb_test_proba = xgb_ensemble.predict_proba(X_test_2d)\n",
    "\n",
    "# Train Logistic Regression for ensemble\n",
    "print(\"Training Logistic Regression for ensemble...\")\n",
    "scaler_lr = StandardScaler()\n",
    "X_train_lr_scaled = scaler_lr.fit_transform(X_train_2d)\n",
    "X_test_lr_scaled = scaler_lr.transform(X_test_2d)\n",
    "\n",
    "# Replace any NaN values that might have appeared after scaling\n",
    "X_train_lr_scaled = np.nan_to_num(X_train_lr_scaled, nan=0.0)\n",
    "X_test_lr_scaled = np.nan_to_num(X_test_lr_scaled, nan=0.0)\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "lr_model.fit(X_train_lr_scaled, y_train_labels)\n",
    "\n",
    "# Get probability predictions\n",
    "lr_train_proba = lr_model.predict_proba(X_train_lr_scaled)\n",
    "lr_test_proba = lr_model.predict_proba(X_test_lr_scaled)\n",
    "\n",
    "print(\"\\nProbability shapes:\")\n",
    "print(\"XGBoost train proba shape:\", xgb_train_proba.shape)\n",
    "print(\"XGBoost test proba shape:\", xgb_test_proba.shape)\n",
    "print(\"LR train proba shape:\", lr_train_proba.shape)\n",
    "print(\"LR test proba shape:\", lr_test_proba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454357fd",
   "metadata": {},
   "source": [
    "## Simple Averaging Ensemble\n",
    "\n",
    "Average the probability predictions from both models and evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768e9af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple averaging: equal weights (0.5, 0.5)\n",
    "avg_train_proba = (xgb_train_proba + lr_train_proba) / 2\n",
    "avg_test_proba = (xgb_test_proba + lr_test_proba) / 2\n",
    "\n",
    "# Get predictions by taking argmax\n",
    "y_train_pred_avg = np.argmax(avg_train_proba, axis=1)\n",
    "y_test_pred_avg = np.argmax(avg_test_proba, axis=1)\n",
    "\n",
    "# Evaluate\n",
    "train_acc_avg = accuracy_score(y_train_labels, y_train_pred_avg)\n",
    "test_acc_avg = accuracy_score(y_test_labels, y_test_pred_avg)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AVERAGING ENSEMBLE (XGBoost + LR)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train Accuracy: {train_acc_avg:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc_avg:.4f}\")\n",
    "print(f\"Gap:           {train_acc_avg - test_acc_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed0cd5",
   "metadata": {},
   "source": [
    "## Stacking Ensemble\n",
    "\n",
    "Use a meta-learner (Logistic Regression) trained on the predictions of both base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e7985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking: concatenate probabilities as features\n",
    "stack_train_features = np.concatenate([xgb_train_proba, lr_train_proba], axis=1)\n",
    "stack_test_features = np.concatenate([xgb_test_proba, lr_test_proba], axis=1)\n",
    "\n",
    "print(f\"Stacked train features shape: {stack_train_features.shape}\")\n",
    "print(f\"Stacked test features shape: {stack_test_features.shape}\")\n",
    "\n",
    "# Train meta-learner (Logistic Regression)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "meta_learner = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "meta_learner.fit(stack_train_features, y_train_labels)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_stack = meta_learner.predict(stack_train_features)\n",
    "y_test_pred_stack = meta_learner.predict(stack_test_features)\n",
    "\n",
    "# Evaluate\n",
    "train_acc_stack = accuracy_score(y_train_labels, y_train_pred_stack)\n",
    "test_acc_stack = accuracy_score(y_test_labels, y_test_pred_stack)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STACKING ENSEMBLE (XGBoost + LR with Meta-Learner)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train Accuracy: {train_acc_stack:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc_stack:.4f}\")\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(y_test_labels, y_test_pred_stack))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a191ee3",
   "metadata": {},
   "source": [
    "## Validation Shuffle Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d66e08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "Averaging Ensemble Accuracy: 0.8383\n",
      "Stacking Ensemble Accuracy:   0.8550\n",
      "\n",
      "===== Fold 2 =====\n",
      "Averaging Ensemble Accuracy: 0.8375\n",
      "Stacking Ensemble Accuracy:   0.8551\n",
      "\n",
      "===== Fold 3 =====\n",
      "Averaging Ensemble Accuracy: 0.8388\n",
      "Stacking Ensemble Accuracy:   0.8557\n",
      "\n",
      "===== Fold 4 =====\n",
      "Averaging Ensemble Accuracy: 0.8392\n",
      "Stacking Ensemble Accuracy:   0.8562\n",
      "\n",
      "===== Fold 5 =====\n",
      "Averaging Ensemble Accuracy: 0.8401\n",
      "Stacking Ensemble Accuracy:   0.8574\n",
      "\n",
      "====================================\n",
      "FINAL MEAN ACCURACY OVER SHUFFLE SPLITS\n",
      "====================================\n",
      "Simple Averaging Mean Accuracy: 0.8388\n",
      "Stacking Ensemble Mean Accuracy: 0.8559\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# ===============================\n",
    "#   SHUFFLE SPLIT VALIDATION \n",
    "# ===============================\n",
    "\n",
    "def shuffle_split_validation(X, y, n_splits=5, test_size=0.2):\n",
    "\n",
    "    ss = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
    "\n",
    "    avg_scores = []\n",
    "    stack_scores = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(ss.split(X)):\n",
    "\n",
    "        print(f\"\\n===== Fold {fold+1} =====\")\n",
    "\n",
    "        # Split data\n",
    "        X_train_fold = X[train_idx]\n",
    "        X_test_fold = X[test_idx]\n",
    "        y_train_fold = y[train_idx]\n",
    "        y_test_fold = y[test_idx]\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # Step 1: Train XGBoost\n",
    "        # -------------------------------------------------------\n",
    "        xgb_model = XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "            eval_metric='mlogloss'\n",
    "        )\n",
    "        xgb_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        xgb_train_proba = xgb_model.predict_proba(X_train_fold)\n",
    "        xgb_test_proba = xgb_model.predict_proba(X_test_fold)\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # Step 2: Train Logistic Regression\n",
    "        # -------------------------------------------------------\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_test_scaled = scaler.transform(X_test_fold)\n",
    "\n",
    "        lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        lr_model.fit(X_train_scaled, y_train_fold)\n",
    "\n",
    "        lr_train_proba = lr_model.predict_proba(X_train_scaled)\n",
    "        lr_test_proba = lr_model.predict_proba(X_test_scaled)\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # SIMPLE AVERAGING ENSEMBLE\n",
    "        # -------------------------------------------------------\n",
    "        avg_test_proba = (xgb_test_proba + lr_test_proba) / 2\n",
    "        y_pred_avg = np.argmax(avg_test_proba, axis=1)\n",
    "\n",
    "        avg_acc = accuracy_score(y_test_fold, y_pred_avg)\n",
    "        avg_scores.append(avg_acc)\n",
    "\n",
    "        print(f\"Averaging Ensemble Accuracy: {avg_acc:.4f}\")\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # STACKING ENSEMBLE\n",
    "        # -------------------------------------------------------\n",
    "        stack_train = np.concatenate([xgb_train_proba, lr_train_proba], axis=1)\n",
    "        stack_test = np.concatenate([xgb_test_proba, lr_test_proba], axis=1)\n",
    "\n",
    "        meta_learner = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        meta_learner.fit(stack_train, y_train_fold)\n",
    "\n",
    "        y_pred_stack = meta_learner.predict(stack_test)\n",
    "\n",
    "        stack_acc = accuracy_score(y_test_fold, y_pred_stack)\n",
    "        stack_scores.append(stack_acc)\n",
    "\n",
    "        print(f\"Stacking Ensemble Accuracy:   {stack_acc:.4f}\")\n",
    "\n",
    "    print(\"\\n====================================\")\n",
    "    print(\"FINAL MEAN ACCURACY OVER SHUFFLE SPLITS\")\n",
    "    print(\"====================================\")\n",
    "    print(f\"Simple Averaging Mean Accuracy: {np.mean(avg_scores):.4f}\")\n",
    "    print(f\"Stacking Ensemble Mean Accuracy: {np.mean(stack_scores):.4f}\")\n",
    "\n",
    "    return avg_scores, stack_scores\n",
    "\n",
    "\n",
    "# ========================================================\n",
    "# RUN SHUFFLE SPLIT VALIDATION ON YOUR EXISTING VARIABLES\n",
    "# ========================================================\n",
    "avg_scores, stack_scores = shuffle_split_validation(X_train_2d, y_train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9e6805",
   "metadata": {},
   "source": [
    "## Complexity vs Error Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca0e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Complexity: n_estimators = 20 ===\n",
      "Mean Validation Error: 0.1789\n",
      "\n",
      "=== Complexity: n_estimators = 40 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Error: 0.1707\n",
      "\n",
      "=== Complexity: n_estimators = 60 ===\n",
      "Mean Validation Error: 0.1665\n",
      "\n",
      "=== Complexity: n_estimators = 80 ===\n",
      "Mean Validation Error: 0.1636\n",
      "\n",
      "=== Complexity: n_estimators = 100 ===\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Complexity range for XGBoost (n_estimators)\n",
    "# -----------------------------------------------\n",
    "complexity_list = [20, 40, 60, 80, 100, 150, 200]\n",
    "ensemble_errors = []\n",
    "\n",
    "# ShuffleSplit for stable validation\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "for n in complexity_list:\n",
    "    fold_errors = []\n",
    "    print(f\"\\n=== Complexity: n_estimators = {n} ===\")\n",
    "\n",
    "    for train_idx, test_idx in ss.split(X):\n",
    "        # Split\n",
    "        X_train_fold = X.iloc[train_idx]\n",
    "        X_test_fold = X.iloc[test_idx]\n",
    "        y_train_fold = y[train_idx]\n",
    "        y_test_fold = y[test_idx]\n",
    "\n",
    "\n",
    "        # ---- Handle CNN 3D shape ----\n",
    "        if len(X_train_fold.shape) == 3:\n",
    "            X_train_2d = X_train_fold.reshape(X_train_fold.shape[0], -1)\n",
    "            X_test_2d = X_test_fold.reshape(X_test_fold.shape[0], -1)\n",
    "        else:\n",
    "            X_train_2d = X_train_fold\n",
    "            X_test_2d = X_test_fold\n",
    "\n",
    "        # ---- Convert one-hot labels ----\n",
    "        if len(y_train_fold.shape) == 2:\n",
    "            y_train_labels = np.argmax(y_train_fold, axis=1)\n",
    "            y_test_labels = np.argmax(y_test_fold, axis=1)\n",
    "        else:\n",
    "            y_train_labels = y_train_fold\n",
    "            y_test_labels = y_test_fold\n",
    "\n",
    "        # Fix NaN\n",
    "        X_train_2d = np.nan_to_num(X_train_2d)\n",
    "        X_test_2d = np.nan_to_num(X_test_2d)\n",
    "\n",
    "        # ====================================================\n",
    "        # TRAIN XGBOOST WITH THIS COMPLEXITY\n",
    "        # ====================================================\n",
    "        xgb = XGBClassifier(\n",
    "            n_estimators=n,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "            eval_metric='mlogloss'\n",
    "        )\n",
    "        xgb.fit(X_train_2d, y_train_labels)\n",
    "\n",
    "        xgb_test_proba = xgb.predict_proba(X_test_2d)\n",
    "\n",
    "        # ====================================================\n",
    "        # TRAIN LOGISTIC REGRESSION (fixed model)\n",
    "        # ====================================================\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_2d)\n",
    "        X_test_scaled  = scaler.transform(X_test_2d)\n",
    "\n",
    "        lr_model = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "        lr_model.fit(X_train_scaled, y_train_labels)\n",
    "\n",
    "        lr_test_proba = lr_model.predict_proba(X_test_scaled)\n",
    "\n",
    "        # ====================================================\n",
    "        # AVERAGING ENSEMBLE (YOUR EXACT FORMULA)\n",
    "        # ====================================================\n",
    "        avg_test_proba = (xgb_test_proba + lr_test_proba) / 2\n",
    "        y_pred = np.argmax(avg_test_proba, axis=1)\n",
    "\n",
    "        error = 1 - accuracy_score(y_test_labels, y_pred)\n",
    "        fold_errors.append(error)\n",
    "\n",
    "    # Mean error across folds\n",
    "    mean_error = np.mean(fold_errors)\n",
    "    ensemble_errors.append(mean_error)\n",
    "    print(f\"Mean Validation Error: {mean_error:.4f}\")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# PLOT THE COMPLEXITY vs ERROR CURVE\n",
    "# -----------------------------------------------\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(complexity_list, ensemble_errors, marker='o')\n",
    "plt.xlabel(\"Complexity (XGBoost n_estimators)\")\n",
    "plt.ylabel(\"Validation Error (Averaging Ensemble)\")\n",
    "plt.title(\"Complexity vs Error Curve ‚Äî XGBoost + Logistic Regression Ensemble\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c177a2",
   "metadata": {},
   "source": [
    "## Compare All Approaches\n",
    "\n",
    "Summary comparison of individual models vs ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c943b12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare individual models vs ensemble\n",
    "import pandas as pd\n",
    "\n",
    "# Get individual model accuracies from the ensemble models we just trained\n",
    "xgb_train_pred = xgb_ensemble.predict(X_train_2d)\n",
    "xgb_test_pred = xgb_ensemble.predict(X_test_2d)\n",
    "xgb_train_acc = accuracy_score(y_train_labels, xgb_train_pred)\n",
    "xgb_test_acc = accuracy_score(y_test_labels, xgb_test_pred)\n",
    "\n",
    "lr_train_pred = lr_model.predict(X_train_lr_scaled)\n",
    "lr_test_pred = lr_model.predict(X_test_lr_scaled)\n",
    "lr_train_acc = accuracy_score(y_train_labels, lr_train_pred)\n",
    "lr_test_acc = accuracy_score(y_test_labels, lr_test_pred)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['XGBoost', 'Logistic Regression', 'Averaging Ensemble', 'Stacking Ensemble'],\n",
    "    'Train Accuracy': [xgb_train_acc, lr_train_acc, train_acc_avg, train_acc_stack],\n",
    "    'Test Accuracy': [xgb_test_acc, lr_test_acc, test_acc_avg, test_acc_stack],\n",
    "    'Overfitting': [\n",
    "        xgb_train_acc - xgb_test_acc,\n",
    "        lr_train_acc - lr_test_acc,\n",
    "        train_acc_avg - test_acc_avg,\n",
    "        train_acc_stack - test_acc_stack\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON: XGBoost vs LR vs Ensembles\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a329a5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Ensemble: XGBoost + Naive Bayes\n",
    "\n",
    "Combine XGBoost and Naive Bayes predictions using averaging and stacking ensemble techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872801a",
   "metadata": {},
   "source": [
    "## Get Predictions from Both Models\n",
    "\n",
    "Train both XGBoost and Naive Bayes on the same data split and obtain probability predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b4916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what variables are available from Part A\n",
    "print(\"Checking available variables from Part A...\")\n",
    "print(f\"X_train_xgb exists: {'X_train_xgb' in dir()}\")\n",
    "print(f\"X_train_scaled exists: {'X_train_scaled' in dir()}\")\n",
    "print(f\"y_train_labels exists: {'y_train_labels' in dir()}\")\n",
    "\n",
    "if 'X_train_scaled' in dir():\n",
    "    print(f\"\\nX_train_scaled shape: {X_train_scaled.shape}\")\n",
    "if 'X_test_scaled' in dir():\n",
    "    print(f\"X_test_scaled shape: {X_test_scaled.shape}\")\n",
    "if 'y_train_labels' in dir():\n",
    "    print(f\"y_train_labels shape: {y_train_labels.shape}\")\n",
    "    print(f\"y_train_labels unique values: {np.unique(y_train_labels)}\")\n",
    "if 'y_test_labels' in dir():\n",
    "    print(f\"y_test_labels shape: {y_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4015d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probability predictions from both models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# IMPORTANT: Use the same data from Part A (X_train_xgb, y_train_xgb, etc.)\n",
    "# The CNN data has different split and formatting\n",
    "print(\"Using Part A data for ensemble...\")\n",
    "\n",
    "# Use Part A XGBoost data which should exist\n",
    "try:\n",
    "    print(\"Using X_train_xgb from Part A\")\n",
    "    X_train_nb_2d = X_train_xgb\n",
    "    X_test_nb_2d = X_test_xgb\n",
    "    # Check if y labels are one-hot encoded and convert if needed\n",
    "    if len(y_train_xgb.shape) == 2 and y_train_xgb.shape[1] > 1:\n",
    "        print(\"Converting one-hot encoded labels to class labels\")\n",
    "        y_train_nb_labels = np.argmax(y_train_xgb, axis=1)\n",
    "        y_test_nb_labels = np.argmax(y_test_xgb, axis=1)\n",
    "    else:\n",
    "        y_train_nb_labels = y_train_xgb\n",
    "        y_test_nb_labels = y_test_xgb\n",
    "except NameError:\n",
    "    print(\"X_train_xgb not found, using X_train_scaled from Part A\")\n",
    "    # Fall back to scaled data from Part A\n",
    "    X_train_nb_2d = X_train_scaled\n",
    "    X_test_nb_2d = X_test_scaled\n",
    "    # Get labels from y (not the CNN one-hot encoded version)\n",
    "    if 'y_train_labels' in dir():\n",
    "        y_train_nb_labels = y_train_labels\n",
    "        y_test_nb_labels = y_test_labels\n",
    "    else:\n",
    "        # Convert if one-hot encoded\n",
    "        if len(y_train.shape) == 2 and y_train.shape[1] > 1:\n",
    "            y_train_nb_labels = np.argmax(y_train, axis=1)\n",
    "            y_test_nb_labels = np.argmax(y_test, axis=1)\n",
    "        else:\n",
    "            y_train_nb_labels = y_train\n",
    "            y_test_nb_labels = y_test\n",
    "\n",
    "print(f\"Training data shape: {X_train_nb_2d.shape}\")\n",
    "print(f\"Test data shape: {X_test_nb_2d.shape}\")\n",
    "\n",
    "# Train XGBoost for ensemble\n",
    "print(\"\\nTraining XGBoost for XGB+NB ensemble...\")\n",
    "xgb_nb_ensemble = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, \n",
    "                                random_state=42, n_jobs=-1, eval_metric='mlogloss')\n",
    "xgb_nb_ensemble.fit(X_train_nb_2d, y_train_nb_labels)\n",
    "xgb_nb_train_proba = xgb_nb_ensemble.predict_proba(X_train_nb_2d)\n",
    "xgb_nb_test_proba = xgb_nb_ensemble.predict_proba(X_test_nb_2d)\n",
    "\n",
    "# Naive Bayes requires non-negative features\n",
    "# Scale data to be non-negative (Min-Max scaling)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_nb = MinMaxScaler()\n",
    "X_train_nb_scaled = scaler_nb.fit_transform(X_train_nb_2d)\n",
    "X_test_nb_scaled = scaler_nb.transform(X_test_nb_2d)\n",
    "\n",
    "# Tune Naive Bayes alpha parameter\n",
    "print(\"Tuning Naive Bayes alpha parameter...\")\n",
    "alpha_values = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "best_alpha = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    nb_temp = MultinomialNB(alpha=alpha)\n",
    "    nb_temp.fit(X_train_nb_scaled, y_train_nb_labels)\n",
    "    y_val_pred = nb_temp.predict(X_test_nb_scaled)\n",
    "    val_acc = accuracy_score(y_test_nb_labels, y_val_pred)\n",
    "    print(f\"Alpha={alpha:6.2f}: Test Accuracy = {val_acc:.4f}\")\n",
    "    \n",
    "    if val_acc > best_accuracy:\n",
    "        best_accuracy = val_acc\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(f\"\\nBest Alpha: {best_alpha} with Test Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Train Naive Bayes with best alpha for ensemble\n",
    "print(f\"\\nTraining Naive Bayes with alpha={best_alpha} for ensemble...\")\n",
    "nb_ensemble = MultinomialNB(alpha=best_alpha)\n",
    "nb_ensemble.fit(X_train_nb_scaled, y_train_nb_labels)\n",
    "\n",
    "# Get probability predictions\n",
    "nb_train_proba = nb_ensemble.predict_proba(X_train_nb_scaled)\n",
    "nb_test_proba = nb_ensemble.predict_proba(X_test_nb_scaled)\n",
    "\n",
    "print(\"\\nProbability shapes:\")\n",
    "print(\"XGBoost train proba shape:\", xgb_nb_train_proba.shape)\n",
    "print(\"XGBoost test proba shape:\", xgb_nb_test_proba.shape)\n",
    "print(\"Naive Bayes train proba shape:\", nb_train_proba.shape)\n",
    "print(\"Naive Bayes test proba shape:\", nb_test_proba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25442d1f",
   "metadata": {},
   "source": [
    "## Simple Averaging Ensemble\n",
    "\n",
    "Average the probability predictions from XGBoost and Naive Bayes and evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a6e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple averaging: equal weights (0.5, 0.5)\n",
    "avg_nb_train_proba = (xgb_nb_train_proba + nb_train_proba) / 2\n",
    "avg_nb_test_proba = (xgb_nb_test_proba + nb_test_proba) / 2\n",
    "\n",
    "# Get predictions by taking argmax\n",
    "y_train_pred_avg_nb = np.argmax(avg_nb_train_proba, axis=1)\n",
    "y_test_pred_avg_nb = np.argmax(avg_nb_test_proba, axis=1)\n",
    "\n",
    "# Evaluate\n",
    "train_acc_avg_nb = accuracy_score(y_train_nb_labels, y_train_pred_avg_nb)\n",
    "test_acc_avg_nb = accuracy_score(y_test_nb_labels, y_test_pred_avg_nb)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AVERAGING ENSEMBLE (XGBoost + Naive Bayes)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train Accuracy: {train_acc_avg_nb:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc_avg_nb:.4f}\")\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(y_test_nb_labels, y_test_pred_avg_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcb21c1",
   "metadata": {},
   "source": [
    "## Stacking Ensemble\n",
    "\n",
    "Use a meta-learner (Logistic Regression) trained on the predictions of both base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe218afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking: concatenate probabilities as features\n",
    "stack_nb_train_features = np.concatenate([xgb_nb_train_proba, nb_train_proba], axis=1)\n",
    "stack_nb_test_features = np.concatenate([xgb_nb_test_proba, nb_test_proba], axis=1)\n",
    "\n",
    "print(f\"Stacked train features shape: {stack_nb_train_features.shape}\")\n",
    "print(f\"Stacked test features shape: {stack_nb_test_features.shape}\")\n",
    "\n",
    "# Train meta-learner (Logistic Regression)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "meta_learner_nb = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "meta_learner_nb.fit(stack_nb_train_features, y_train_nb_labels)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_stack_nb = meta_learner_nb.predict(stack_nb_train_features)\n",
    "y_test_pred_stack_nb = meta_learner_nb.predict(stack_nb_test_features)\n",
    "\n",
    "# Evaluate\n",
    "train_acc_stack_nb = accuracy_score(y_train_nb_labels, y_train_pred_stack_nb)\n",
    "test_acc_stack_nb = accuracy_score(y_test_nb_labels, y_test_pred_stack_nb)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STACKING ENSEMBLE (XGBoost + NB with Meta-Learner)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train Accuracy: {train_acc_stack_nb:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc_stack_nb:.4f}\")\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(y_test_nb_labels, y_test_pred_stack_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c7dd32",
   "metadata": {},
   "source": [
    "## Validation Shuffle Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e240adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# SHUFFLE SPLIT VALIDATION FOR XGB + NAIVE BAYES\n",
    "# =============================================\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "def shuffle_split_validation_nb(X, y, n_splits=5, test_size=0.2):\n",
    "\n",
    "    ss = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
    "\n",
    "    avg_scores = []\n",
    "    stack_scores = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(ss.split(X)):\n",
    "        print(f\"\\n===== Fold {fold+1} =====\")\n",
    "\n",
    "        # Split\n",
    "        X_train_fold = X[train_idx]\n",
    "        X_test_fold = X[test_idx]\n",
    "        y_train_fold = y[train_idx]\n",
    "        y_test_fold = y[test_idx]\n",
    "\n",
    "        # Ensure NB gets non-negative values\n",
    "        scaler_nb = MinMaxScaler()\n",
    "        X_train_nb = scaler_nb.fit_transform(X_train_fold)\n",
    "        X_test_nb = scaler_nb.transform(X_test_fold)\n",
    "\n",
    "        # ----------------------------------------------\n",
    "        # Train XGBoost\n",
    "        # ----------------------------------------------\n",
    "        xgb_model = XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "            eval_metric=\"mlogloss\"\n",
    "        )\n",
    "        xgb_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        xgb_train_proba = xgb_model.predict_proba(X_train_fold)\n",
    "        xgb_test_proba = xgb_model.predict_proba(X_test_fold)\n",
    "\n",
    "        # ----------------------------------------------\n",
    "        # Train Naive Bayes\n",
    "        # ----------------------------------------------\n",
    "        nb_model = MultinomialNB(alpha=1.0)\n",
    "        nb_model.fit(X_train_nb, y_train_fold)\n",
    "\n",
    "        nb_train_proba = nb_model.predict_proba(X_train_nb)\n",
    "        nb_test_proba = nb_model.predict_proba(X_test_nb)\n",
    "\n",
    "        # ----------------------------------------------\n",
    "        # Simple Averaging Ensemble\n",
    "        # ----------------------------------------------\n",
    "        avg_test_proba = (xgb_test_proba + nb_test_proba) / 2\n",
    "        y_pred_avg = np.argmax(avg_test_proba, axis=1)\n",
    "\n",
    "        avg_acc = accuracy_score(y_test_fold, y_pred_avg)\n",
    "        avg_scores.append(avg_acc)\n",
    "\n",
    "        print(f\"Averaging Ensemble Accuracy: {avg_acc:.4f}\")\n",
    "\n",
    "        # ----------------------------------------------\n",
    "        # Stacking Ensemble\n",
    "        # ----------------------------------------------\n",
    "        stack_train = np.concatenate([xgb_train_proba, nb_train_proba], axis=1)\n",
    "        stack_test = np.concatenate([xgb_test_proba, nb_test_proba], axis=1)\n",
    "\n",
    "        meta_learner = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        meta_learner.fit(stack_train, y_train_fold)\n",
    "\n",
    "        y_pred_stack = meta_learner.predict(stack_test)\n",
    "\n",
    "        stack_acc = accuracy_score(y_test_fold, y_pred_stack)\n",
    "        stack_scores.append(stack_acc)\n",
    "\n",
    "        print(f\"Stacking Ensemble Accuracy: {stack_acc:.4f}\")\n",
    "\n",
    "    print(\"\\n============================================\")\n",
    "    print(\"FINAL MEAN ACCURACY OVER SHUFFLE SPLITS\")\n",
    "    print(\"============================================\")\n",
    "    print(f\"Simple Averaging (XGB+NB): {np.mean(avg_scores):.4f}\")\n",
    "    print(f\"Stacking (XGB+NB):          {np.mean(stack_scores):.4f}\")\n",
    "\n",
    "    return avg_scores, stack_scores\n",
    "\n",
    "\n",
    "# Run validation on your data\n",
    "avg_scores_nb, stack_scores_nb = shuffle_split_validation_nb(X_train_nb_2d, y_train_nb_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b04c6a",
   "metadata": {},
   "source": [
    "## Complexity vs Error Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783dd9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def complexity_curve_xgb_nb(X_train, y_train, X_test, y_test, nb_alpha=1.0):\n",
    "\n",
    "    scaler_nb = MinMaxScaler()\n",
    "    X_train_nb = scaler_nb.fit_transform(X_train)\n",
    "    X_test_nb = scaler_nb.transform(X_test)\n",
    "\n",
    "    complexities = [10, 50, 100, 150, 200, 300]\n",
    "    errors = []\n",
    "\n",
    "    for n in complexities:\n",
    "        print(f\"Training XGBoost with n_estimators = {n}\")\n",
    "\n",
    "        # XGBoost\n",
    "        xgb = XGBClassifier(\n",
    "            n_estimators=n,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "            eval_metric=\"mlogloss\"\n",
    "        )\n",
    "        xgb.fit(X_train, y_train)\n",
    "\n",
    "        xgb_test_proba = xgb.predict_proba(X_test)\n",
    "\n",
    "        # Naive Bayes\n",
    "        nb = MultinomialNB(alpha=nb_alpha)\n",
    "        nb.fit(X_train_nb, y_train)\n",
    "\n",
    "        nb_test_proba = nb.predict_proba(X_test_nb)\n",
    "\n",
    "        # Averaging ensemble\n",
    "        avg_test_proba = (xgb_test_proba + nb_test_proba) / 2\n",
    "        y_pred = np.argmax(avg_test_proba, axis=1)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        error = 1 - acc\n",
    "        errors.append(error)\n",
    "\n",
    "        print(f\"n_estimators={n}: Accuracy={acc:.4f}, Error={error:.4f}\")\n",
    "\n",
    "    # ---- PLOT ----\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(complexities, errors, marker='o')\n",
    "    plt.xlabel(\"XGBoost Model Complexity (n_estimators)\")\n",
    "    plt.ylabel(\"Test Error (1 - Accuracy)\")\n",
    "    plt.title(\"Complexity vs Error Curve (XGBoost + Naive Bayes Ensemble)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run the complexity curve\n",
    "complexity_curve_xgb_nb(X_train_nb_2d, y_train_nb_labels, X_test_nb_2d, y_test_nb_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04b2173",
   "metadata": {},
   "source": [
    "## Compare All Approaches\n",
    "\n",
    "Summary comparison of individual models vs ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4204c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare individual models vs ensemble\n",
    "import pandas as pd\n",
    "\n",
    "# Get individual model accuracies from the ensemble models we just trained\n",
    "xgb_nb_train_pred = xgb_nb_ensemble.predict(X_train_nb_2d)\n",
    "xgb_nb_test_pred = xgb_nb_ensemble.predict(X_test_nb_2d)\n",
    "xgb_nb_train_acc = accuracy_score(y_train_nb_labels, xgb_nb_train_pred)\n",
    "xgb_nb_test_acc = accuracy_score(y_test_nb_labels, xgb_nb_test_pred)\n",
    "\n",
    "nb_train_pred = nb_ensemble.predict(X_train_nb_scaled)\n",
    "nb_test_pred = nb_ensemble.predict(X_test_nb_scaled)\n",
    "nb_train_acc = accuracy_score(y_train_nb_labels, nb_train_pred)\n",
    "nb_test_acc = accuracy_score(y_test_nb_labels, nb_test_pred)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_nb_df = pd.DataFrame({\n",
    "    'Model': ['XGBoost', 'Naive Bayes', 'Averaging Ensemble', 'Stacking Ensemble'],\n",
    "    'Train Accuracy': [xgb_nb_train_acc, nb_train_acc, train_acc_avg_nb, train_acc_stack_nb],\n",
    "    'Test Accuracy': [xgb_nb_test_acc, nb_test_acc, test_acc_avg_nb, test_acc_stack_nb],\n",
    "    'Overfitting': [\n",
    "        xgb_nb_train_acc - xgb_nb_test_acc,\n",
    "        nb_train_acc - nb_test_acc,\n",
    "        train_acc_avg_nb - test_acc_avg_nb,\n",
    "        train_acc_stack_nb - test_acc_stack_nb\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON: XGBoost vs Naive Bayes vs Ensembles\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_nb_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030ab112",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Ensemble: XGBoost + CNN\n",
    "\n",
    "Combine XGBoost and CNN predictions using averaging and stacking ensemble techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b751aacc",
   "metadata": {},
   "source": [
    "## Step 1: Prepare Data and Train Models\n",
    "\n",
    "Train XGBoost and CNN models on the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8939463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PREPARING DATA FOR XGBOOST + CNN ENSEMBLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use the processed data from Part A\n",
    "df_model_xgb_cnn = df_new.copy()\n",
    "\n",
    "# Prepare features and labels\n",
    "X_xgb_cnn = df_model_xgb_cnn.drop(columns=[\"Crime_Class\"])\n",
    "y_xgb_cnn, _ = pd.factorize(df_model_xgb_cnn[\"Crime_Class\"])\n",
    "\n",
    "# Convert datetime columns to int64\n",
    "for col in X_xgb_cnn.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X_xgb_cnn[col] = X_xgb_cnn[col].view(\"int64\")\n",
    "\n",
    "# Convert lists to strings\n",
    "for col in X_xgb_cnn.columns:\n",
    "    if X_xgb_cnn[col].dtype == 'object':\n",
    "        X_xgb_cnn[col] = X_xgb_cnn[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Factorize object columns\n",
    "X_xgb_cnn = X_xgb_cnn.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Handle missing values\n",
    "X_xgb_cnn = X_xgb_cnn.fillna(X_xgb_cnn.median())\n",
    "\n",
    "# Train-test split\n",
    "X_train_xc, X_test_xc, y_train_xc, y_test_xc = train_test_split(\n",
    "    X_xgb_cnn, y_xgb_cnn, test_size=0.3, random_state=42, stratify=y_xgb_cnn\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler_xc = StandardScaler()\n",
    "X_train_xc_scaled = scaler_xc.fit_transform(X_train_xc)\n",
    "X_test_xc_scaled = scaler_xc.transform(X_test_xc)\n",
    "\n",
    "print(f\"\\nTraining set shape: {X_train_xc_scaled.shape}\")\n",
    "print(f\"Testing set shape: {X_test_xc_scaled.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_xgb_cnn))}\")\n",
    "\n",
    "# Train XGBoost\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING XGBOOST MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "xgb_xc = XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss')\n",
    "xgb_xc.fit(X_train_xc_scaled, y_train_xc)\n",
    "\n",
    "xgb_xc_train_pred = xgb_xc.predict(X_train_xc_scaled)\n",
    "xgb_xc_test_pred = xgb_xc.predict(X_test_xc_scaled)\n",
    "xgb_xc_train_proba = xgb_xc.predict_proba(X_train_xc_scaled)\n",
    "xgb_xc_test_proba = xgb_xc.predict_proba(X_test_xc_scaled)\n",
    "\n",
    "xgb_xc_train_acc = accuracy_score(y_train_xc, xgb_xc_train_pred)\n",
    "xgb_xc_test_acc = accuracy_score(y_test_xc, xgb_xc_test_pred)\n",
    "\n",
    "print(f\"XGBoost Train Accuracy: {xgb_xc_train_acc:.4f}\")\n",
    "print(f\"XGBoost Test Accuracy:  {xgb_xc_test_acc:.4f}\")\n",
    "print(f\"Overfitting Gap:        {xgb_xc_train_acc - xgb_xc_test_acc:.4f}\")\n",
    "\n",
    "# Prepare data for CNN (reshape for Conv1D)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING CNN MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "X_train_xc_cnn = X_train_xc_scaled.reshape(X_train_xc_scaled.shape[0], X_train_xc_scaled.shape[1], 1)\n",
    "X_test_xc_cnn = X_test_xc_scaled.reshape(X_test_xc_scaled.shape[0], X_test_xc_scaled.shape[1], 1)\n",
    "\n",
    "# One-hot encode labels for CNN\n",
    "num_classes_xc = len(np.unique(y_xgb_cnn))\n",
    "y_train_xc_cat = to_categorical(y_train_xc, num_classes_xc)\n",
    "y_test_xc_cat = to_categorical(y_test_xc, num_classes_xc)\n",
    "\n",
    "# Build CNN model\n",
    "cnn_xc = Sequential([\n",
    "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_xc_cnn.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes_xc, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_xc.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Training CNN...\")\n",
    "history_xc = cnn_xc.fit(\n",
    "    X_train_xc_cnn, y_train_xc_cat,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Get CNN predictions\n",
    "cnn_xc_train_proba = cnn_xc.predict(X_train_xc_cnn)\n",
    "cnn_xc_test_proba = cnn_xc.predict(X_test_xc_cnn)\n",
    "cnn_xc_train_pred = np.argmax(cnn_xc_train_proba, axis=1)\n",
    "cnn_xc_test_pred = np.argmax(cnn_xc_test_proba, axis=1)\n",
    "\n",
    "cnn_xc_train_acc = accuracy_score(y_train_xc, cnn_xc_train_pred)\n",
    "cnn_xc_test_acc = accuracy_score(y_test_xc, cnn_xc_test_pred)\n",
    "\n",
    "print(f\"\\nCNN Train Accuracy: {cnn_xc_train_acc:.4f}\")\n",
    "print(f\"CNN Test Accuracy:  {cnn_xc_test_acc:.4f}\")\n",
    "print(f\"Overfitting Gap:    {cnn_xc_train_acc - cnn_xc_test_acc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Both models trained successfully!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3861a",
   "metadata": {},
   "source": [
    "## Step 2: Averaging Ensemble (XGBoost + CNN)\n",
    "\n",
    "Average the probability predictions from both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623af245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple averaging: equal weights (0.5, 0.5)\n",
    "avg_xc_train_proba = (xgb_xc_train_proba + cnn_xc_train_proba) / 2\n",
    "avg_xc_test_proba = (xgb_xc_test_proba + cnn_xc_test_proba) / 2\n",
    "\n",
    "# Get predictions by taking argmax\n",
    "y_train_pred_avg_xc = np.argmax(avg_xc_train_proba, axis=1)\n",
    "y_test_pred_avg_xc = np.argmax(avg_xc_test_proba, axis=1)\n",
    "\n",
    "# Evaluate\n",
    "train_acc_avg_xc = accuracy_score(y_train_xc, y_train_pred_avg_xc)\n",
    "test_acc_avg_xc = accuracy_score(y_test_xc, y_test_pred_avg_xc)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"AVERAGING ENSEMBLE (XGBoost + CNN)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Train Accuracy: {train_acc_avg_xc:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc_avg_xc:.4f}\")\n",
    "print(f\"Gap:            {train_acc_avg_xc - test_acc_avg_xc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1807833d",
   "metadata": {},
   "source": [
    "## Step 3: Stacking Ensemble (XGBoost + CNN)\n",
    "\n",
    "Use a meta-learner (Logistic Regression) trained on predictions from both XGBoost and CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5cc668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Stacking: concatenate probabilities as features\n",
    "stack_xc_train_features = np.concatenate([xgb_xc_train_proba, cnn_xc_train_proba], axis=1)\n",
    "stack_xc_test_features = np.concatenate([xgb_xc_test_proba, cnn_xc_test_proba], axis=1)\n",
    "\n",
    "print(f\"Stacked train features shape: {stack_xc_train_features.shape}\")\n",
    "print(f\"Stacked test features shape:  {stack_xc_test_features.shape}\")\n",
    "\n",
    "# Train meta-learner (Logistic Regression)\n",
    "meta_learner_xc = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "meta_learner_xc.fit(stack_xc_train_features, y_train_xc)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_stack_xc = meta_learner_xc.predict(stack_xc_train_features)\n",
    "y_test_pred_stack_xc = meta_learner_xc.predict(stack_xc_test_features)\n",
    "\n",
    "# Evaluate\n",
    "train_acc_stack_xc = accuracy_score(y_train_xc, y_train_pred_stack_xc)\n",
    "test_acc_stack_xc = accuracy_score(y_test_xc, y_test_pred_stack_xc)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STACKING ENSEMBLE (XGBoost + CNN with Meta-Learner)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Train Accuracy: {train_acc_stack_xc:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc_stack_xc:.4f}\")\n",
    "print(f\"Gap:            {train_acc_stack_xc - test_acc_stack_xc:.4f}\")\n",
    "\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(y_test_xc, y_test_pred_stack_xc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2143dd",
   "metadata": {},
   "source": [
    "## Validation Shuffle Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ab35cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "def shuffle_split_validation_xgb_cnn(X, y, cnn_model, n_splits=5, test_size=0.2):\n",
    "    \"\"\"\n",
    "    X: 2D features (scaled)\n",
    "    y: labels\n",
    "    cnn_model: pre-built CNN model (untrained, will clone and train)\n",
    "    \"\"\"\n",
    "    ss = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
    "    \n",
    "    avg_scores = []\n",
    "    stack_scores = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(ss.split(X)):\n",
    "        print(f\"\\n===== Fold {fold+1} =====\")\n",
    "        X_train_fold = X[train_idx]\n",
    "        X_test_fold  = X[test_idx]\n",
    "        y_train_fold = y[train_idx]\n",
    "        y_test_fold  = y[test_idx]\n",
    "\n",
    "        # ---- XGBoost ----\n",
    "        xgb_fold = XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "            eval_metric='mlogloss'\n",
    "        )\n",
    "        xgb_fold.fit(X_train_fold, y_train_fold)\n",
    "        xgb_train_proba = xgb_fold.predict_proba(X_train_fold)\n",
    "        xgb_test_proba  = xgb_fold.predict_proba(X_test_fold)\n",
    "\n",
    "        # ---- CNN ----\n",
    "        # reshape for Conv1D\n",
    "        X_train_cnn = X_train_fold.reshape(X_train_fold.shape[0], X_train_fold.shape[1], 1)\n",
    "        X_test_cnn  = X_test_fold.reshape(X_test_fold.shape[0], X_test_fold.shape[1], 1)\n",
    "\n",
    "        # one-hot encode labels\n",
    "        num_classes = len(np.unique(y))\n",
    "        y_train_cat = to_categorical(y_train_fold, num_classes)\n",
    "        y_test_cat  = to_categorical(y_test_fold, num_classes)\n",
    "\n",
    "        # Clone CNN architecture\n",
    "        from tensorflow.keras.models import clone_model\n",
    "        cnn_fold = clone_model(cnn_model)\n",
    "        cnn_fold.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        cnn_fold.fit(\n",
    "            X_train_cnn, y_train_cat,\n",
    "            epochs=10,\n",
    "            batch_size=128,\n",
    "            verbose=0\n",
    "        )\n",
    "        cnn_train_proba = cnn_fold.predict(X_train_cnn)\n",
    "        cnn_test_proba  = cnn_fold.predict(X_test_cnn)\n",
    "\n",
    "        # ---- Averaging Ensemble ----\n",
    "        avg_test_proba = (xgb_test_proba + cnn_test_proba) / 2\n",
    "        y_pred_avg = np.argmax(avg_test_proba, axis=1)\n",
    "        avg_acc = accuracy_score(y_test_fold, y_pred_avg)\n",
    "        avg_scores.append(avg_acc)\n",
    "        print(f\"Averaging Ensemble Accuracy: {avg_acc:.4f}\")\n",
    "\n",
    "        # ---- Stacking Ensemble ----\n",
    "        stack_train = np.concatenate([xgb_train_proba, cnn_train_proba], axis=1)\n",
    "        stack_test  = np.concatenate([xgb_test_proba, cnn_test_proba], axis=1)\n",
    "\n",
    "        meta_learner = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        meta_learner.fit(stack_train, y_train_fold)\n",
    "        y_pred_stack = meta_learner.predict(stack_test)\n",
    "        stack_acc = accuracy_score(y_test_fold, y_pred_stack)\n",
    "        stack_scores.append(stack_acc)\n",
    "        print(f\"Stacking Ensemble Accuracy: {stack_acc:.4f}\")\n",
    "\n",
    "    print(\"\\n============================================\")\n",
    "    print(\"FINAL MEAN ACCURACY OVER SHUFFLE SPLITS\")\n",
    "    print(\"============================================\")\n",
    "    print(f\"Simple Averaging (XGB+CNN): {np.mean(avg_scores):.4f}\")\n",
    "    print(f\"Stacking (XGB+CNN):          {np.mean(stack_scores):.4f}\")\n",
    "\n",
    "    return avg_scores, stack_scores\n",
    "\n",
    "\n",
    "# Run validation\n",
    "avg_scores_xc, stack_scores_xc = shuffle_split_validation_xgb_cnn(\n",
    "    X_train_xc_scaled, y_train_xc, cnn_model=cnn_xc\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c77c170",
   "metadata": {},
   "source": [
    "## Complexity vs Error Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def complexity_curve_xgb_cnn(X_train, y_train, X_test, y_test, cnn_model):\n",
    "    \"\"\"\n",
    "    Plot XGBoost complexity vs error curve in XGB+CNN ensemble\n",
    "    \"\"\"\n",
    "    # reshape CNN input\n",
    "    X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test_cnn  = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    y_train_cat = to_categorical(y_train, num_classes)\n",
    "    y_test_cat  = to_categorical(y_test, num_classes)\n",
    "\n",
    "    complexities = [10, 50, 100, 150, 200]\n",
    "    errors = []\n",
    "\n",
    "    for n in complexities:\n",
    "        print(f\"\\nTraining XGBoost with n_estimators = {n}\")\n",
    "\n",
    "        # XGBoost\n",
    "        xgb_model = XGBClassifier(\n",
    "            n_estimators=n,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "            eval_metric='mlogloss'\n",
    "        )\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        xgb_test_proba = xgb_model.predict_proba(X_test)\n",
    "\n",
    "        # CNN (fixed)\n",
    "        cnn_clone = clone_model(cnn_model)\n",
    "        cnn_clone.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        cnn_clone.fit(X_train_cnn, y_train_cat, epochs=10, batch_size=128, verbose=0)\n",
    "        cnn_test_proba = cnn_clone.predict(X_test_cnn)\n",
    "\n",
    "        # Averaging ensemble\n",
    "        avg_test_proba = (xgb_test_proba + cnn_test_proba) / 2\n",
    "        y_pred = np.argmax(avg_test_proba, axis=1)\n",
    "        error = 1 - accuracy_score(y_test, y_pred)\n",
    "        errors.append(error)\n",
    "        print(f\"Error: {error:.4f}\")\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(complexities, errors, marker='o')\n",
    "    plt.xlabel(\"XGBoost n_estimators (Complexity)\")\n",
    "    plt.ylabel(\"Test Error (1 - Accuracy)\")\n",
    "    plt.title(\"Complexity vs Error Curve (XGBoost + CNN Ensemble)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run complexity curve\n",
    "complexity_curve_xgb_cnn(\n",
    "    X_train_xc_scaled, y_train_xc,\n",
    "    X_test_xc_scaled, y_test_xc,\n",
    "    cnn_model=cnn_xc\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8160a8c0",
   "metadata": {},
   "source": [
    "## Step 4: Compare All Approaches (XGBoost + CNN)\n",
    "\n",
    "Summary comparison of XGBoost, CNN, and ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe5a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe for XGBoost + CNN\n",
    "comparison_xc_df = pd.DataFrame({\n",
    "    'Model': ['XGBoost', 'CNN', 'Averaging Ensemble', 'Stacking Ensemble'],\n",
    "    'Train Accuracy': [xgb_xc_train_acc, cnn_xc_train_acc, train_acc_avg_xc, train_acc_stack_xc],\n",
    "    'Test Accuracy': [xgb_xc_test_acc, cnn_xc_test_acc, test_acc_avg_xc, test_acc_stack_xc],\n",
    "    'Overfitting': [\n",
    "        xgb_xc_train_acc - xgb_xc_test_acc,\n",
    "        cnn_xc_train_acc - cnn_xc_test_acc,\n",
    "        train_acc_avg_xc - test_acc_avg_xc,\n",
    "        train_acc_stack_xc - test_acc_stack_xc\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON: XGBoost vs CNN vs Ensembles\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_xc_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80c151e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c26357d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Ensemble: Naive Bayes + ANN\n",
    "\n",
    "Combine Naive Bayes and Artificial Neural Network predictions using averaging and stacking ensemble techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630c3e85",
   "metadata": {},
   "source": [
    "## Step 1: Train Naive Bayes and ANN Models\n",
    "\n",
    "Train both models on the same data and obtain probability predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4a3f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PREPARING DATA FOR NAIVE BAYES + ANN ENSEMBLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use the same data as XGB+NB (to ensure consistency)\n",
    "# If precomputed NB datasets exist, use them; otherwise, create them from num_df/y using sss.\n",
    "try:\n",
    "    X_train_nb_ann = X_train_nb_2d.copy()\n",
    "    X_test_nb_ann = X_test_nb_2d.copy()\n",
    "    y_train_nb_ann = y_train_nb_labels.copy()\n",
    "    y_test_nb_ann = y_test_nb_labels.copy()\n",
    "except NameError:\n",
    "    # Build numeric feature matrix and labels from existing variables\n",
    "    X_all = num_df.drop(columns=['Crime_Class_numeric']).values\n",
    "    y_all = y\n",
    "    # Use predefined StratifiedShuffleSplit to ensure consistent class distribution\n",
    "    train_idx, test_idx = next(sss.split(X_all, y_all))\n",
    "    X_train_nb_ann = X_all[train_idx]\n",
    "    X_test_nb_ann = X_all[test_idx]\n",
    "    y_train_nb_ann = y_all[train_idx]\n",
    "    y_test_nb_ann = y_all[test_idx]\n",
    "\n",
    "print(f\"\\nTraining set shape: {X_train_nb_ann.shape}\")\n",
    "print(f\"Testing set shape: {X_test_nb_ann.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_train_nb_ann))}\")\n",
    "\n",
    "# Train Naive Bayes (needs non-negative features)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING NAIVE BAYES MODEL\")\n",
    "print(\"=\"*70)\n",
    "# Impute missing values with 0 (MultinomialNB requires non-negative features)\n",
    "imputer_nb_ann = SimpleImputer(strategy='constant', fill_value=0.0)\n",
    "X_train_nb_ann_imputed = imputer_nb_ann.fit_transform(X_train_nb_ann)\n",
    "X_test_nb_ann_imputed = imputer_nb_ann.transform(X_test_nb_ann)\n",
    "\n",
    "scaler_nb_ann = MinMaxScaler()\n",
    "X_train_nb_ann_scaled = scaler_nb_ann.fit_transform(X_train_nb_ann_imputed)\n",
    "X_test_nb_ann_scaled = scaler_nb_ann.transform(X_test_nb_ann_imputed)\n",
    "\n",
    "# Use the best alpha from previous tuning\n",
    "nb_ann_model = MultinomialNB(alpha=1.0)\n",
    "nb_ann_model.fit(X_train_nb_ann_scaled, y_train_nb_ann)\n",
    "\n",
    "nb_ann_train_pred = nb_ann_model.predict(X_train_nb_ann_scaled)\n",
    "nb_ann_test_pred = nb_ann_model.predict(X_test_nb_ann_scaled)\n",
    "nb_ann_train_proba = nb_ann_model.predict_proba(X_train_nb_ann_scaled)\n",
    "nb_ann_test_proba = nb_ann_model.predict_proba(X_test_nb_ann_scaled)\n",
    "\n",
    "nb_ann_train_acc = accuracy_score(y_train_nb_ann, nb_ann_train_pred)\n",
    "nb_ann_test_acc = accuracy_score(y_test_nb_ann, nb_ann_test_pred)\n",
    "\n",
    "print(f\"Naive Bayes Train Accuracy: {nb_ann_train_acc:.4f}\")\n",
    "print(f\"Naive Bayes Test Accuracy:  {nb_ann_test_acc:.4f}\")\n",
    "\n",
    "# Train ANN (needs standardized features)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING ANN MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "scaler_ann = StandardScaler()\n",
    "scaler_ann = StandardScaler()\n",
    "X_train_ann_scaled = scaler_ann.fit_transform(X_train_nb_ann_imputed)\n",
    "X_test_ann_scaled = scaler_ann.transform(X_test_nb_ann_imputed)\n",
    "# One-hot encode labels for ANN\n",
    "num_classes_ann = len(np.unique(y_train_nb_ann))\n",
    "y_train_ann_cat = to_categorical(y_train_nb_ann, num_classes_ann)\n",
    "y_test_ann_cat = to_categorical(y_test_nb_ann, num_classes_ann)\n",
    "\n",
    "# Build ANN model\n",
    "ann_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_ann_scaled.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes_ann, activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train ANN\n",
    "history_nb_ann = ann_model.fit(\n",
    "    X_train_ann_scaled, y_train_ann_cat,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test_ann_scaled, y_test_ann_cat)\n",
    ")\n",
    "\n",
    "# Get ANN predictions\n",
    "ann_train_proba = ann_model.predict(X_train_ann_scaled)\n",
    "ann_test_proba = ann_model.predict(X_test_ann_scaled)\n",
    "ann_train_pred = np.argmax(ann_train_proba, axis=1)\n",
    "ann_test_pred = np.argmax(ann_test_proba, axis=1)\n",
    "\n",
    "ann_train_acc = accuracy_score(y_train_nb_ann, ann_train_pred)\n",
    "ann_test_acc = accuracy_score(y_test_nb_ann, ann_test_pred)\n",
    "\n",
    "print(f\"\\nANN Train Accuracy: {ann_train_acc:.4f}\")\n",
    "print(f\"ANN Test Accuracy:  {ann_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f28d6f",
   "metadata": {},
   "source": [
    "## Step 2: Averaging Ensemble\n",
    "\n",
    "Average the probability predictions from both models and evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b74b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple averaging: equal weights (0.5, 0.5)\n",
    "avg_nb_ann_train_proba = (nb_ann_train_proba + ann_train_proba) / 2\n",
    "avg_nb_ann_test_proba = (nb_ann_test_proba + ann_test_proba) / 2\n",
    "\n",
    "# Get predictions by taking argmax\n",
    "y_train_pred_avg_nb_ann = np.argmax(avg_nb_ann_train_proba, axis=1)\n",
    "y_test_pred_avg_nb_ann = np.argmax(avg_nb_ann_test_proba, axis=1)\n",
    "\n",
    "# Evaluate\n",
    "train_acc_avg_nb_ann = accuracy_score(y_train_nb_ann, y_train_pred_avg_nb_ann)\n",
    "test_acc_avg_nb_ann = accuracy_score(y_test_nb_ann, y_test_pred_avg_nb_ann)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"AVERAGING ENSEMBLE (Naive Bayes + ANN)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Train Accuracy: {train_acc_avg_nb_ann:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc_avg_nb_ann:.4f}\")\n",
    "print(f\"Gap:            {train_acc_avg_nb_ann - test_acc_avg_nb_ann:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c6711",
   "metadata": {},
   "source": [
    "## Step 3: Stacking Ensemble\n",
    "\n",
    "Use a meta-learner (Logistic Regression) trained on the predictions of both base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2390dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking: concatenate probabilities as features\n",
    "stack_nb_ann_train_features = np.concatenate([nb_ann_train_proba, ann_train_proba], axis=1)\n",
    "stack_nb_ann_test_features = np.concatenate([nb_ann_test_proba, ann_test_proba], axis=1)\n",
    "\n",
    "print(f\"Stacked train features shape: {stack_nb_ann_train_features.shape}\")\n",
    "print(f\"Stacked test features shape: {stack_nb_ann_test_features.shape}\")\n",
    "\n",
    "# Train meta-learner (Logistic Regression)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "meta_learner_nb_ann = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "meta_learner_nb_ann.fit(stack_nb_ann_train_features, y_train_nb_ann)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_stack_nb_ann = meta_learner_nb_ann.predict(stack_nb_ann_train_features)\n",
    "y_test_pred_stack_nb_ann = meta_learner_nb_ann.predict(stack_nb_ann_test_features)\n",
    "\n",
    "# Evaluate\n",
    "train_acc_stack_nb_ann = accuracy_score(y_train_nb_ann, y_train_pred_stack_nb_ann)\n",
    "test_acc_stack_nb_ann = accuracy_score(y_test_nb_ann, y_test_pred_stack_nb_ann)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STACKING ENSEMBLE (Naive Bayes + ANN with Meta-Learner)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Train Accuracy: {train_acc_stack_nb_ann:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc_stack_nb_ann:.4f}\")\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(y_test_nb_ann, y_test_pred_stack_nb_ann))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb87cceb",
   "metadata": {},
   "source": [
    "## Validation Split Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d056cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.models import clone_model\n",
    "import numpy as np\n",
    "\n",
    "def shuffle_split_validation_nb_ann(X, y, ann_model, n_splits=5, test_size=0.2, nb_alpha=1.0):\n",
    "    \"\"\"\n",
    "    ShuffleSplit validation for Naive Bayes + ANN ensemble.\n",
    "    X: feature matrix (2D)\n",
    "    y: labels\n",
    "    ann_model: pre-built ANN model (untrained, will clone and train per fold)\n",
    "    \"\"\"\n",
    "    ss = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
    "    \n",
    "    avg_scores = []\n",
    "    stack_scores = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(ss.split(X)):\n",
    "        print(f\"\\n===== Fold {fold+1} =====\")\n",
    "        X_train_fold = X[train_idx]\n",
    "        X_test_fold  = X[test_idx]\n",
    "        y_train_fold = y[train_idx]\n",
    "        y_test_fold  = y[test_idx]\n",
    "\n",
    "        # ---- Naive Bayes ----\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        scaler_nb = MinMaxScaler()\n",
    "        X_train_nb = scaler_nb.fit_transform(X_train_fold)\n",
    "        X_test_nb  = scaler_nb.transform(X_test_fold)\n",
    "\n",
    "        nb_model = MultinomialNB(alpha=nb_alpha)\n",
    "        nb_model.fit(X_train_nb, y_train_fold)\n",
    "        nb_train_proba = nb_model.predict_proba(X_train_nb)\n",
    "        nb_test_proba  = nb_model.predict_proba(X_test_nb)\n",
    "\n",
    "        # ---- ANN ----\n",
    "        from tensorflow.keras.utils import to_categorical\n",
    "        num_classes = len(np.unique(y))\n",
    "        y_train_cat = to_categorical(y_train_fold, num_classes)\n",
    "        y_test_cat  = to_categorical(y_test_fold, num_classes)\n",
    "\n",
    "        # Standardize features for ANN\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler_ann = StandardScaler()\n",
    "        X_train_ann = scaler_ann.fit_transform(X_train_fold)\n",
    "        X_test_ann  = scaler_ann.transform(X_test_fold)\n",
    "\n",
    "        # Clone ANN architecture\n",
    "        ann_fold = clone_model(ann_model)\n",
    "        ann_fold.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        ann_fold.fit(\n",
    "            X_train_ann, y_train_cat,\n",
    "            epochs=10,\n",
    "            batch_size=32,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        ann_train_proba = ann_fold.predict(X_train_ann)\n",
    "        ann_test_proba  = ann_fold.predict(X_test_ann)\n",
    "\n",
    "        # ---- Simple Averaging Ensemble ----\n",
    "        avg_test_proba = (nb_test_proba + ann_test_proba) / 2\n",
    "        y_pred_avg = np.argmax(avg_test_proba, axis=1)\n",
    "        avg_acc = accuracy_score(y_test_fold, y_pred_avg)\n",
    "        avg_scores.append(avg_acc)\n",
    "        print(f\"Averaging Ensemble Accuracy: {avg_acc:.4f}\")\n",
    "\n",
    "        # ---- Stacking Ensemble ----\n",
    "        stack_train = np.concatenate([nb_train_proba, ann_train_proba], axis=1)\n",
    "        stack_test  = np.concatenate([nb_test_proba, ann_test_proba], axis=1)\n",
    "\n",
    "        meta_learner = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        meta_learner.fit(stack_train, y_train_fold)\n",
    "        y_pred_stack = meta_learner.predict(stack_test)\n",
    "        stack_acc = accuracy_score(y_test_fold, y_pred_stack)\n",
    "        stack_scores.append(stack_acc)\n",
    "        print(f\"Stacking Ensemble Accuracy: {stack_acc:.4f}\")\n",
    "\n",
    "    print(\"\\n============================================\")\n",
    "    print(\"FINAL MEAN ACCURACY OVER SHUFFLE SPLITS\")\n",
    "    print(\"============================================\")\n",
    "    print(f\"Simple Averaging (NB+ANN): {np.mean(avg_scores):.4f}\")\n",
    "    print(f\"Stacking (NB+ANN):          {np.mean(stack_scores):.4f}\")\n",
    "\n",
    "    return avg_scores, stack_scores\n",
    "\n",
    "# Run validation\n",
    "avg_scores_nb_ann, stack_scores_nb_ann = shuffle_split_validation_nb_ann(\n",
    "    X_train_nb_ann_scaled, y_train_nb_ann, ann_model=ann_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08703971",
   "metadata": {},
   "source": [
    "## Complexity vs Error Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd1cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import clone_model\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "\n",
    "def complexity_curve_nb_ann(X_train, y_train, X_test, y_test, ann_model, nb_alpha=1.0):\n",
    "    \"\"\"\n",
    "    Plot complexity vs error curve for Naive Bayes + ANN averaging ensemble\n",
    "    Complexity measured by increasing ANN hidden layer neurons\n",
    "    \"\"\"\n",
    "    # NB preprocessing\n",
    "    scaler_nb = MinMaxScaler()\n",
    "    X_train_nb = scaler_nb.fit_transform(X_train)\n",
    "    X_test_nb  = scaler_nb.transform(X_test)\n",
    "\n",
    "    # ANN preprocessing\n",
    "    scaler_ann = StandardScaler()\n",
    "    X_train_ann = scaler_ann.fit_transform(X_train)\n",
    "    X_test_ann  = scaler_ann.transform(X_test)\n",
    "\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    y_train_cat = to_categorical(y_train, num_classes)\n",
    "    y_test_cat  = to_categorical(y_test, num_classes)\n",
    "\n",
    "    complexities = [16, 32, 64, 128, 256]  # hidden neurons in first layer\n",
    "    errors = []\n",
    "\n",
    "    for neurons in complexities:\n",
    "        print(f\"\\nTraining ANN with {neurons} hidden neurons\")\n",
    "\n",
    "        # Clone ANN architecture and adjust first layer\n",
    "        ann_clone = Sequential([\n",
    "            Dense(neurons, activation='relu', input_shape=(X_train_ann.shape[1],)),\n",
    "            Dropout(0.3),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        ann_clone.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        ann_clone.fit(X_train_ann, y_train_cat, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "        # Predict ANN\n",
    "        ann_test_proba = ann_clone.predict(X_test_ann)\n",
    "\n",
    "        # NB prediction\n",
    "        nb_model = MultinomialNB(alpha=nb_alpha)\n",
    "        nb_model.fit(X_train_nb, y_train)\n",
    "        nb_test_proba = nb_model.predict_proba(X_test_nb)\n",
    "\n",
    "        # Averaging ensemble\n",
    "        avg_test_proba = (nb_test_proba + ann_test_proba) / 2\n",
    "        y_pred = np.argmax(avg_test_proba, axis=1)\n",
    "        error = 1 - accuracy_score(y_test, y_pred)\n",
    "        errors.append(error)\n",
    "        print(f\"Error: {error:.4f}\")\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(complexities, errors, marker='o')\n",
    "    plt.xlabel(\"ANN Hidden Layer Neurons (Complexity)\")\n",
    "    plt.ylabel(\"Test Error (1 - Accuracy)\")\n",
    "    plt.title(\"Complexity vs Error Curve (NB + ANN Ensemble)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Run complexity curve\n",
    "complexity_curve_nb_ann(\n",
    "    X_train_nb_ann_scaled, y_train_nb_ann,\n",
    "    X_test_nb_ann_scaled, y_test_nb_ann,\n",
    "    ann_model=ann_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3235bd",
   "metadata": {},
   "source": [
    "## Step 4: Compare All Approaches\n",
    "\n",
    "Summary comparison of Naive Bayes, ANN, and ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63fae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe for NB + ANN\n",
    "import pandas as pd\n",
    "\n",
    "comparison_nb_ann_df = pd.DataFrame({\n",
    "    'Model': ['Naive Bayes', 'ANN', 'Averaging Ensemble', 'Stacking Ensemble'],\n",
    "    'Train Accuracy': [nb_ann_train_acc, ann_train_acc, train_acc_avg_nb_ann, train_acc_stack_nb_ann],\n",
    "    'Test Accuracy': [nb_ann_test_acc, ann_test_acc, test_acc_avg_nb_ann, test_acc_stack_nb_ann],\n",
    "    'Overfitting': [\n",
    "        nb_ann_train_acc - nb_ann_test_acc,\n",
    "        ann_train_acc - ann_test_acc,\n",
    "        train_acc_avg_nb_ann - test_acc_avg_nb_ann,\n",
    "        train_acc_stack_nb_ann - test_acc_stack_nb_ann\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON: Naive Bayes vs ANN vs Ensembles\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_nb_ann_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7999673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
