{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77eb2321",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Note to self, if it takes too long to run, then just don't run any of the parts that take too long, unless tweaks are applied to the data preprocessing part. You only need to run it once for the output. Hello."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d0b204",
   "metadata": {},
   "source": [
    "### Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0296cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c59e4e",
   "metadata": {},
   "source": [
    "## Part A - Model Variety Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb3fc9a",
   "metadata": {},
   "source": [
    "### Import Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fef3b218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Temp\\ipykernel_31080\\1256870994.py:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  df_raw = pd.read_csv(\"C:\\Datasets\\Crime_Data_from_2020_to_Present.csv\", low_memory=\"False\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date Rptd</th>\n",
       "      <th>DATE OCC</th>\n",
       "      <th>TIME OCC</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Crm Cd</th>\n",
       "      <th>Crm Cd Desc</th>\n",
       "      <th>...</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>Crm Cd 1</th>\n",
       "      <th>Crm Cd 2</th>\n",
       "      <th>Crm Cd 3</th>\n",
       "      <th>Crm Cd 4</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>Cross Street</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211507896</td>\n",
       "      <td>4/11/2021 0:00</td>\n",
       "      <td>11/7/2020 0:00</td>\n",
       "      <td>845</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>354</td>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>354.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7800    BEEMAN                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>-118.4092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201516622</td>\n",
       "      <td>10/21/2020 12:00:00 AM</td>\n",
       "      <td>10/18/2020 12:00:00 AM</td>\n",
       "      <td>1845</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ATOLL                        AV</td>\n",
       "      <td>N  GAULT</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>-118.4203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240913563</td>\n",
       "      <td>12/10/2024 0:00</td>\n",
       "      <td>10/30/2020 12:00:00 AM</td>\n",
       "      <td>1240</td>\n",
       "      <td>9</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>354</td>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>354.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14600    SYLVAN                       ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>-118.4509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210704711</td>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>1310</td>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>331</td>\n",
       "      <td>THEFT FROM MOTOR VEHICLE - GRAND ($950.01 AND ...</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>331.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6000    COMEY                        AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>-118.3747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201418201</td>\n",
       "      <td>10/3/2020 0:00</td>\n",
       "      <td>09/29/2020 12:00:00 AM</td>\n",
       "      <td>1830</td>\n",
       "      <td>14</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>THEFT FROM MOTOR VEHICLE - PETTY ($950 &amp; UNDER)</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>420.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4700    LA VILLA MARINA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>-118.4350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>252104112</td>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>130</td>\n",
       "      <td>21</td>\n",
       "      <td>Topanga</td>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>946</td>\n",
       "      <td>OTHER MISCELLANEOUS CRIME</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>946.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22100    ROSCOE                       BL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>-118.6126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>250404100</td>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>Hollenbeck</td>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>237</td>\n",
       "      <td>CHILD NEGLECT (SEE 300 W.I.C.)</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3500    PERCY                        ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>-118.1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>251304095</td>\n",
       "      <td>01/31/2025 12:00:00 AM</td>\n",
       "      <td>01/30/2025 12:00:00 AM</td>\n",
       "      <td>1554</td>\n",
       "      <td>13</td>\n",
       "      <td>Newton</td>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>850</td>\n",
       "      <td>INDECENT EXPOSURE</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300 E  53RD                         ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>-118.2701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>251704066</td>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>1600</td>\n",
       "      <td>17</td>\n",
       "      <td>Devonshire</td>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>624</td>\n",
       "      <td>BATTERY - SIMPLE ASSAULT</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>624.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9600    ZELZAH                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>-118.5233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>251904210</td>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>1235</td>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>850</td>\n",
       "      <td>INDECENT EXPOSURE</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11100    OMELVENY                     AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>-118.4417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Date Rptd                DATE OCC  TIME OCC  \\\n",
       "0        211507896          4/11/2021 0:00          11/7/2020 0:00       845   \n",
       "1        201516622  10/21/2020 12:00:00 AM  10/18/2020 12:00:00 AM      1845   \n",
       "2        240913563         12/10/2024 0:00  10/30/2020 12:00:00 AM      1240   \n",
       "3        210704711  12/24/2020 12:00:00 AM  12/24/2020 12:00:00 AM      1310   \n",
       "4        201418201          10/3/2020 0:00  09/29/2020 12:00:00 AM      1830   \n",
       "...            ...                     ...                     ...       ...   \n",
       "1004986  252104112           2/2/2025 0:00           2/2/2025 0:00       130   \n",
       "1004987  250404100  02/18/2025 12:00:00 AM  02/18/2025 12:00:00 AM      1000   \n",
       "1004988  251304095  01/31/2025 12:00:00 AM  01/30/2025 12:00:00 AM      1554   \n",
       "1004989  251704066  01/17/2025 12:00:00 AM  01/17/2025 12:00:00 AM      1600   \n",
       "1004990  251904210  03/25/2025 12:00:00 AM  03/25/2025 12:00:00 AM      1235   \n",
       "\n",
       "         AREA    AREA NAME  Rpt Dist No  Part 1-2  Crm Cd  \\\n",
       "0          15  N Hollywood         1502         2     354   \n",
       "1          15  N Hollywood         1521         1     230   \n",
       "2           9     Van Nuys          933         2     354   \n",
       "3           7     Wilshire          782         1     331   \n",
       "4          14      Pacific         1454         1     420   \n",
       "...       ...          ...          ...       ...     ...   \n",
       "1004986    21      Topanga         2103         2     946   \n",
       "1004987     4   Hollenbeck          479         2     237   \n",
       "1004988    13       Newton         1372         2     850   \n",
       "1004989    17   Devonshire         1774         2     624   \n",
       "1004990    19      Mission         1944         2     850   \n",
       "\n",
       "                                               Crm Cd Desc  ... Status  \\\n",
       "0                                        THEFT OF IDENTITY  ...     IC   \n",
       "1           ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT  ...     IC   \n",
       "2                                        THEFT OF IDENTITY  ...     IC   \n",
       "3        THEFT FROM MOTOR VEHICLE - GRAND ($950.01 AND ...  ...     IC   \n",
       "4          THEFT FROM MOTOR VEHICLE - PETTY ($950 & UNDER)  ...     IC   \n",
       "...                                                    ...  ...    ...   \n",
       "1004986                          OTHER MISCELLANEOUS CRIME  ...     IC   \n",
       "1004987                     CHILD NEGLECT (SEE 300 W.I.C.)  ...     IC   \n",
       "1004988                                  INDECENT EXPOSURE  ...     IC   \n",
       "1004989                           BATTERY - SIMPLE ASSAULT  ...     IC   \n",
       "1004990                                  INDECENT EXPOSURE  ...     IC   \n",
       "\n",
       "         Status Desc Crm Cd 1 Crm Cd 2  Crm Cd 3 Crm Cd 4  \\\n",
       "0        Invest Cont    354.0      NaN       NaN      NaN   \n",
       "1        Invest Cont    230.0      NaN       NaN      NaN   \n",
       "2        Invest Cont    354.0      NaN       NaN      NaN   \n",
       "3        Invest Cont    331.0      NaN       NaN      NaN   \n",
       "4        Invest Cont    420.0      NaN       NaN      NaN   \n",
       "...              ...      ...      ...       ...      ...   \n",
       "1004986  Invest Cont    946.0      NaN       NaN      NaN   \n",
       "1004987  Invest Cont    237.0      NaN       NaN      NaN   \n",
       "1004988  Invest Cont    850.0      NaN       NaN      NaN   \n",
       "1004989  Invest Cont    624.0      NaN       NaN      NaN   \n",
       "1004990  Invest Cont    850.0      NaN       NaN      NaN   \n",
       "\n",
       "                                         LOCATION Cross Street      LAT  \\\n",
       "0         7800    BEEMAN                       AV          NaN  34.2124   \n",
       "1                 ATOLL                        AV     N  GAULT  34.1993   \n",
       "2        14600    SYLVAN                       ST          NaN  34.1847   \n",
       "3         6000    COMEY                        AV          NaN  34.0339   \n",
       "4                         4700    LA VILLA MARINA          NaN  33.9813   \n",
       "...                                           ...          ...      ...   \n",
       "1004986  22100    ROSCOE                       BL          NaN  34.2259   \n",
       "1004987   3500    PERCY                        ST          NaN  34.0277   \n",
       "1004988    300 E  53RD                         ST          NaN  33.9942   \n",
       "1004989   9600    ZELZAH                       AV          NaN  34.2450   \n",
       "1004990  11100    OMELVENY                     AV          NaN  34.2722   \n",
       "\n",
       "              LON  \n",
       "0       -118.4092  \n",
       "1       -118.4203  \n",
       "2       -118.4509  \n",
       "3       -118.3747  \n",
       "4       -118.4350  \n",
       "...           ...  \n",
       "1004986 -118.6126  \n",
       "1004987 -118.1979  \n",
       "1004988 -118.2701  \n",
       "1004989 -118.5233  \n",
       "1004990 -118.4417  \n",
       "\n",
       "[1004991 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset from a Folder called Datasets, plaed inside C drive.\n",
    "df_raw = pd.read_csv(\"C:\\Datasets\\Crime_Data_from_2020_to_Present.csv\", low_memory=\"False\")\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "918e0684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1004991 entries, 0 to 1004990\n",
      "Data columns (total 28 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0                   1004991 non-null  int64  \n",
      " 1   Date Rptd       1004991 non-null  object \n",
      " 2   DATE OCC        1004991 non-null  object \n",
      " 3   TIME OCC        1004991 non-null  int64  \n",
      " 4   AREA            1004991 non-null  int64  \n",
      " 5   AREA NAME       1004991 non-null  object \n",
      " 6   Rpt Dist No     1004991 non-null  int64  \n",
      " 7   Part 1-2        1004991 non-null  int64  \n",
      " 8   Crm Cd          1004991 non-null  int64  \n",
      " 9   Crm Cd Desc     1004991 non-null  object \n",
      " 10  Mocodes         853372 non-null   object \n",
      " 11  Vict Age        1004991 non-null  int64  \n",
      " 12  Vict Sex        860347 non-null   object \n",
      " 13  Vict Descent    860335 non-null   object \n",
      " 14  Premis Cd       1004975 non-null  float64\n",
      " 15  Premis Desc     1004403 non-null  object \n",
      " 16  Weapon Used Cd  327247 non-null   float64\n",
      " 17  Weapon Desc     327247 non-null   object \n",
      " 18  Status          1004990 non-null  object \n",
      " 19  Status Desc     1004991 non-null  object \n",
      " 20  Crm Cd 1        1004980 non-null  float64\n",
      " 21  Crm Cd 2        69160 non-null    float64\n",
      " 22  Crm Cd 3        2314 non-null     float64\n",
      " 23  Crm Cd 4        64 non-null       float64\n",
      " 24  LOCATION        1004991 non-null  object \n",
      " 25  Cross Street    154236 non-null   object \n",
      " 26  LAT             1004991 non-null  float64\n",
      " 27  LON             1004991 non-null  float64\n",
      "dtypes: float64(8), int64(7), object(13)\n",
      "memory usage: 214.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc22403",
   "metadata": {},
   "source": [
    "### View Unique values for Crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb7d0c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140,\n",
       " array(['THEFT OF IDENTITY',\n",
       "        'ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT',\n",
       "        'THEFT FROM MOTOR VEHICLE - GRAND ($950.01 AND OVER)',\n",
       "        'THEFT FROM MOTOR VEHICLE - PETTY ($950 & UNDER)',\n",
       "        'CRM AGNST CHLD (13 OR UNDER) (14-15 & SUSP 10 YRS OLDER)',\n",
       "        'VEHICLE - STOLEN', 'BURGLARY', 'BURGLARY FROM VEHICLE',\n",
       "        'THEFT PLAIN - PETTY ($950 & UNDER)',\n",
       "        'INTIMATE PARTNER - SIMPLE ASSAULT', 'BATTERY - SIMPLE ASSAULT',\n",
       "        'VANDALISM - MISDEAMEANOR ($399 OR UNDER)',\n",
       "        'VEHICLE - ATTEMPT STOLEN',\n",
       "        'VANDALISM - FELONY ($400 & OVER, ALL CHURCH VANDALISMS)',\n",
       "        'ROBBERY', 'FIREARMS RESTRAINING ORDER (FIREARMS RO)',\n",
       "        'BIKE - STOLEN', 'EMBEZZLEMENT, GRAND THEFT ($950.01 & OVER)',\n",
       "        'CHILD ABUSE (PHYSICAL) - SIMPLE ASSAULT',\n",
       "        'CRIMINAL THREATS - NO WEAPON DISPLAYED',\n",
       "        'THEFT-GRAND ($950.01 & OVER)EXCPT,GUNS,FOWL,LIVESTK,PROD',\n",
       "        'BATTERY WITH SEXUAL CONTACT',\n",
       "        'LETTERS, LEWD  -  TELEPHONE CALLS, LEWD',\n",
       "        'VIOLATION OF COURT ORDER', 'ARSON',\n",
       "        'VIOLATION OF RESTRAINING ORDER', 'THEFT, PERSON',\n",
       "        'CONTEMPT OF COURT', 'INTIMATE PARTNER - AGGRAVATED ASSAULT',\n",
       "        'ATTEMPTED ROBBERY', 'LEWD/LASCIVIOUS ACTS WITH CHILD',\n",
       "        'OTHER MISCELLANEOUS CRIME', 'BRANDISH WEAPON', 'TRESPASSING',\n",
       "        'BUNCO, ATTEMPT', 'SHOPLIFTING - PETTY THEFT ($950 & UNDER)',\n",
       "        'BURGLARY, ATTEMPTED', 'DOCUMENT FORGERY / STOLEN FELONY',\n",
       "        'SHOPLIFTING-GRAND THEFT ($950.01 & OVER)', 'FAILURE TO YIELD',\n",
       "        'BATTERY POLICE (SIMPLE)',\n",
       "        'VEHICLE, STOLEN - OTHER (MOTORIZED SCOOTERS, BIKES, ETC)',\n",
       "        'CHILD NEGLECT (SEE 300 W.I.C.)', 'RAPE, ATTEMPTED',\n",
       "        'BUNCO, GRAND THEFT', 'CONTRIBUTING', 'PIMPING', 'OTHER ASSAULT',\n",
       "        'SODOMY/SEXUAL CONTACT B/W PENIS OF ONE PERS TO ANUS OTH',\n",
       "        'RAPE, FORCIBLE', 'SEX OFFENDER REGISTRANT OUT OF COMPLIANCE',\n",
       "        'DISCHARGE FIREARMS/SHOTS FIRED', 'EXTORTION',\n",
       "        'SHOTS FIRED AT MOVING VEHICLE, TRAIN OR AIRCRAFT',\n",
       "        'ASSAULT WITH DEADLY WEAPON ON POLICE OFFICER',\n",
       "        'BUNCO, PETTY THEFT', 'RESISTING ARREST',\n",
       "        'VIOLATION OF TEMPORARY RESTRAINING ORDER',\n",
       "        'CHILD ANNOYING (17YRS & UNDER)',\n",
       "        'SHOTS FIRED AT INHABITED DWELLING',\n",
       "        'BURGLARY FROM VEHICLE, ATTEMPTED',\n",
       "        'THROWING OBJECT AT MOVING VEHICLE',\n",
       "        'SEX,UNLAWFUL(INC MUTUAL CONSENT, PENETRATION W/ FRGN OBJ',\n",
       "        'ORAL COPULATION', 'SEXUAL PENETRATION W/FOREIGN OBJECT',\n",
       "        'LEWD CONDUCT', 'PICKPOCKET', 'CHILD STEALING', 'PURSE SNATCHING',\n",
       "        'THEFT FROM MOTOR VEHICLE - ATTEMPT',\n",
       "        'HUMAN TRAFFICKING - COMMERCIAL SEX ACTS', 'INDECENT EXPOSURE',\n",
       "        'DISHONEST EMPLOYEE - PETTY THEFT',\n",
       "        'EMBEZZLEMENT, PETTY THEFT ($950 & UNDER)', 'KIDNAPPING',\n",
       "        'DISTURBING THE PEACE', 'UNAUTHORIZED COMPUTER ACCESS',\n",
       "        'CRIMINAL HOMICIDE', 'THEFT PLAIN - ATTEMPT',\n",
       "        'REPLICA FIREARMS(SALE,DISPLAY,MANUFACTURE OR DISTRIBUTE)',\n",
       "        'LYNCHING', 'RECKLESS DRIVING', 'THREATENING PHONE CALLS/LETTERS',\n",
       "        'SHOPLIFTING - ATTEMPT', 'BOMB SCARE',\n",
       "        'CHILD ABUSE (PHYSICAL) - AGGRAVATED ASSAULT', 'STALKING',\n",
       "        'DRIVING WITHOUT OWNER CONSENT (DWOC)', 'BATTERY ON A FIREFIGHTER',\n",
       "        'PEEPING TOM', 'FALSE POLICE REPORT', 'BOAT - STOLEN',\n",
       "        'DEFRAUDING INNKEEPER/THEFT OF SERVICES, $950 & UNDER',\n",
       "        'ILLEGAL DUMPING', 'DRUGS, TO A MINOR',\n",
       "        'THEFT, COIN MACHINE - PETTY ($950 & UNDER)',\n",
       "        'CREDIT CARDS, FRAUD USE ($950 & UNDER', 'MANSLAUGHTER, NEGLIGENT',\n",
       "        'THEFT FROM PERSON - ATTEMPT', 'KIDNAPPING - GRAND ATTEMPT',\n",
       "        'THEFT, COIN MACHINE - ATTEMPT', 'PETTY THEFT - AUTO REPAIR',\n",
       "        'DOCUMENT WORTHLESS ($200 & UNDER)', 'FALSE IMPRISONMENT',\n",
       "        'CREDIT CARDS, FRAUD USE ($950.01 & OVER)',\n",
       "        'DEFRAUDING INNKEEPER/THEFT OF SERVICES, OVER $950.01',\n",
       "        'CHILD PORNOGRAPHY', 'PANDERING',\n",
       "        'HUMAN TRAFFICKING - INVOLUNTARY SERVITUDE', 'CRUELTY TO ANIMALS',\n",
       "        'COUNTERFEIT', 'DISHONEST EMPLOYEE - GRAND THEFT', 'PROWLER',\n",
       "        'DOCUMENT WORTHLESS ($200.01 & OVER)',\n",
       "        'WEAPONS POSSESSION/BOMBING', 'GRAND THEFT / AUTO REPAIR',\n",
       "        'CONSPIRACY', 'DRUNK ROLL', 'LYNCHING - ATTEMPTED',\n",
       "        'THEFT, COIN MACHINE - GRAND ($950.01 & OVER)', 'DISRUPT SCHOOL',\n",
       "        'TILL TAP - PETTY ($950 & UNDER)', 'PICKPOCKET, ATTEMPT',\n",
       "        'GRAND THEFT / INSURANCE FRAUD',\n",
       "        'TILL TAP - GRAND THEFT ($950.01 & OVER)',\n",
       "        'PURSE SNATCHING - ATTEMPT', 'BIKE - ATTEMPTED STOLEN', 'BRIBERY',\n",
       "        'CHILD ABANDONMENT', 'TELEPHONE PROPERTY - DAMAGE',\n",
       "        'BEASTIALITY, CRIME AGAINST NATURE SEXUAL ASSLT WITH ANIM',\n",
       "        'BIGAMY', 'FAILURE TO DISPERSE',\n",
       "        'FIREARMS EMERGENCY PROTECTIVE ORDER (FIREARMS EPO)',\n",
       "        'INCEST (SEXUAL ACTS BETWEEN BLOOD RELATIVES)',\n",
       "        'BLOCKING DOOR INDUCTION CENTER', 'INCITING A RIOT',\n",
       "        'DISHONEST EMPLOYEE ATTEMPTED THEFT', 'TRAIN WRECKING',\n",
       "        'DRUNK ROLL - ATTEMPT'], dtype=object))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_desc = df_raw[\"Crm Cd Desc\"].dropna().unique()\n",
    "len(unique_desc), unique_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14cb973",
   "metadata": {},
   "source": [
    "## DataPrep\n",
    "\n",
    "### Map each Crime commited to a matching Criminal Offense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e4b6aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crm Cd Desc</th>\n",
       "      <th>Crime_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>\n",
       "      <td>Violent Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THEFT FROM MOTOR VEHICLE - GRAND ($950.01 AND ...</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THEFT FROM MOTOR VEHICLE - PETTY ($950 &amp; UNDER)</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CRM AGNST CHLD (13 OR UNDER) (14-15 &amp; SUSP 10 ...</td>\n",
       "      <td>Other Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CRM AGNST CHLD (13 OR UNDER) (14-15 &amp; SUSP 10 ...</td>\n",
       "      <td>Other Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VEHICLE - STOLEN</td>\n",
       "      <td>Vehicle Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BURGLARY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BURGLARY FROM VEHICLE</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>THEFT PLAIN - PETTY ($950 &amp; UNDER)</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>INTIMATE PARTNER - SIMPLE ASSAULT</td>\n",
       "      <td>Violent Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BATTERY - SIMPLE ASSAULT</td>\n",
       "      <td>Violent Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BURGLARY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BURGLARY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>THEFT PLAIN - PETTY ($950 &amp; UNDER)</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>THEFT PLAIN - PETTY ($950 &amp; UNDER)</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>THEFT PLAIN - PETTY ($950 &amp; UNDER)</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BURGLARY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>\n",
       "      <td>Violent Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>VANDALISM - MISDEAMEANOR ($399 OR UNDER)</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>VEHICLE - ATTEMPT STOLEN</td>\n",
       "      <td>Vehicle Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>VANDALISM - FELONY ($400 &amp; OVER, ALL CHURCH VA...</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ROBBERY</td>\n",
       "      <td>Other Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>INTIMATE PARTNER - SIMPLE ASSAULT</td>\n",
       "      <td>Violent Crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Crm Cd Desc     Crime_Class\n",
       "0                                   THEFT OF IDENTITY  Property Crime\n",
       "1      ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT   Violent Crime\n",
       "2                                   THEFT OF IDENTITY  Property Crime\n",
       "3   THEFT FROM MOTOR VEHICLE - GRAND ($950.01 AND ...  Property Crime\n",
       "4     THEFT FROM MOTOR VEHICLE - PETTY ($950 & UNDER)  Property Crime\n",
       "5                                   THEFT OF IDENTITY  Property Crime\n",
       "6                                   THEFT OF IDENTITY  Property Crime\n",
       "7   CRM AGNST CHLD (13 OR UNDER) (14-15 & SUSP 10 ...     Other Crime\n",
       "8                                   THEFT OF IDENTITY  Property Crime\n",
       "9                                   THEFT OF IDENTITY  Property Crime\n",
       "10  CRM AGNST CHLD (13 OR UNDER) (14-15 & SUSP 10 ...     Other Crime\n",
       "11                                  THEFT OF IDENTITY  Property Crime\n",
       "12                                   VEHICLE - STOLEN   Vehicle Crime\n",
       "13                                           BURGLARY  Property Crime\n",
       "14                              BURGLARY FROM VEHICLE  Property Crime\n",
       "15                 THEFT PLAIN - PETTY ($950 & UNDER)  Property Crime\n",
       "16                  INTIMATE PARTNER - SIMPLE ASSAULT   Violent Crime\n",
       "17                           BATTERY - SIMPLE ASSAULT   Violent Crime\n",
       "18                                           BURGLARY  Property Crime\n",
       "19                                           BURGLARY  Property Crime\n",
       "20                 THEFT PLAIN - PETTY ($950 & UNDER)  Property Crime\n",
       "21                 THEFT PLAIN - PETTY ($950 & UNDER)  Property Crime\n",
       "22                 THEFT PLAIN - PETTY ($950 & UNDER)  Property Crime\n",
       "23                                           BURGLARY  Property Crime\n",
       "24     ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT   Violent Crime\n",
       "25           VANDALISM - MISDEAMEANOR ($399 OR UNDER)  Property Crime\n",
       "26                           VEHICLE - ATTEMPT STOLEN   Vehicle Crime\n",
       "27  VANDALISM - FELONY ($400 & OVER, ALL CHURCH VA...  Property Crime\n",
       "28                                            ROBBERY     Other Crime\n",
       "29                  INTIMATE PARTNER - SIMPLE ASSAULT   Violent Crime"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keyword-based mapping rules for auto‐labeling\n",
    "mapping_rules = {\n",
    "    \"Violent Crime\": [\n",
    "        \"ASSAULT\", \"BATTERY\", \"HOMICIDE\", \"MANSLAUGHTER\", \"RAPE\",\n",
    "        \"SEXUAL\", \"SODOMY\", \"ORAL COPULATION\", \"KIDNAPPING\",\n",
    "        \"LYNCHING\", \"STALKING\", \"THREATS\", \"INTIMATE PARTNER\"\n",
    "    ],\n",
    "    \"Property Crime\": [\n",
    "        \"THEFT\", \"BURGLARY\", \"VANDALISM\", \"ARSON\", \"SHOPLIFTING\",\n",
    "        \"BIKE - STOLEN\", \"COIN MACHINE\"\n",
    "    ],\n",
    "    \"Vehicle Crime\": [\n",
    "        \"VEHICLE\", \"DRIVING WITHOUT OWNER CONSENT\", \"DWOC\"\n",
    "    ],\n",
    "    \"Fraud / Financial Crime\": [\n",
    "        \"FRAUD\", \"EMBEZZLEMENT\", \"COUNTERFEIT\", \"BUNCO\",\n",
    "        \"CREDIT CARD\", \"DOCUMENT WORTHLESS\", \"INSURANCE\"\n",
    "    ],\n",
    "    \"Weapons / Public Safety\": [\n",
    "        \"FIREARM\", \"WEAPON\", \"SHOTS FIRED\", \"BOMB\", \"BRANDISH\"\n",
    "    ],\n",
    "    \"Sex Crime\": [\n",
    "        \"LEWD\", \"INDECENT EXPOSURE\", \"CHILD PORNOGRAPHY\",\n",
    "        \"PANDERING\", \"PIMPING\", \"HUMAN TRAFFICKING\"\n",
    "    ],\n",
    "    \"Child-Related Crime\": [\n",
    "        \"CHILD\", \"CONTRIBUTING\", \"CHILD NEGLECT\"\n",
    "    ],\n",
    "    \"Court / Restraining Order / Legal\": [\n",
    "        \"COURT\", \"RESTRAINING\", \"CONTEMPT\", \"FAILURE TO APPEAR\",\n",
    "        \"VIOLATION\"\n",
    "    ],\n",
    "    \"Public Disturbance / Disorder\": [\n",
    "        \"DISTURBANCE\", \"PEACE\", \"TRESPASS\", \"DISRUPT\",\n",
    "        \"RIOT\", \"DISOBEY\"\n",
    "    ],\n",
    "    \"Other Crime\": []  # fallback\n",
    "}\n",
    "\n",
    "# Function to classify crimes\n",
    "def classify(description: str):\n",
    "    if not isinstance(description, str):\n",
    "        return \"Other Crime\"\n",
    "    desc = description.upper()\n",
    "    for category, keywords in mapping_rules.items():\n",
    "        for kw in keywords:\n",
    "            if kw in desc:\n",
    "                return category\n",
    "    return \"Other Crime\"\n",
    "\n",
    "# Create new class column\n",
    "df_raw[\"Crime_Class\"] = df_raw[\"Crm Cd Desc\"].apply(classify)\n",
    "\n",
    "# Save a preview\n",
    "preview = df_raw[[\"Crm Cd Desc\", \"Crime_Class\"]].head(30)\n",
    "preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17561bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crime_Class</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Property Crime</td>\n",
       "      <td>508444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>233487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vehicle Crime</td>\n",
       "      <td>123445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Other Crime</td>\n",
       "      <td>63036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Court / Restraining Order / Legal</td>\n",
       "      <td>21771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Public Disturbance / Disorder</td>\n",
       "      <td>19977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Weapons / Public Safety</td>\n",
       "      <td>19431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>11870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Child-Related Crime</td>\n",
       "      <td>2784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fraud / Financial Crime</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Crime_Class   Count\n",
       "0                     Property Crime  508444\n",
       "1                      Violent Crime  233487\n",
       "2                      Vehicle Crime  123445\n",
       "3                        Other Crime   63036\n",
       "4  Court / Restraining Order / Legal   21771\n",
       "5      Public Disturbance / Disorder   19977\n",
       "6            Weapons / Public Safety   19431\n",
       "7                          Sex Crime   11870\n",
       "8                Child-Related Crime    2784\n",
       "9            Fraud / Financial Crime     746"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['Crime_Class'].value_counts().reset_index(name='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87dc460",
   "metadata": {},
   "source": [
    "Raw Model training usually lies here, but we've removed it for convinience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa087c01",
   "metadata": {},
   "source": [
    "## Part A - Feature Engineering and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b40162",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d938e44",
   "metadata": {},
   "source": [
    "Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bd75799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date Rptd</th>\n",
       "      <th>DATE OCC</th>\n",
       "      <th>TIME OCC</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Crm Cd</th>\n",
       "      <th>Crm Cd Desc</th>\n",
       "      <th>...</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>Crm Cd 1</th>\n",
       "      <th>Crm Cd 2</th>\n",
       "      <th>Crm Cd 3</th>\n",
       "      <th>Crm Cd 4</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>Cross Street</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Crime_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211507896</td>\n",
       "      <td>4/11/2021 0:00</td>\n",
       "      <td>11/7/2020 0:00</td>\n",
       "      <td>845</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>354</td>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>354.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7800    BEEMAN                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>-118.4092</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201516622</td>\n",
       "      <td>10/21/2020 12:00:00 AM</td>\n",
       "      <td>10/18/2020 12:00:00 AM</td>\n",
       "      <td>1845</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ATOLL                        AV</td>\n",
       "      <td>N  GAULT</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>-118.4203</td>\n",
       "      <td>Violent Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240913563</td>\n",
       "      <td>12/10/2024 0:00</td>\n",
       "      <td>10/30/2020 12:00:00 AM</td>\n",
       "      <td>1240</td>\n",
       "      <td>9</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>354</td>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>354.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14600    SYLVAN                       ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>-118.4509</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210704711</td>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>1310</td>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>331</td>\n",
       "      <td>THEFT FROM MOTOR VEHICLE - GRAND ($950.01 AND ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>331.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6000    COMEY                        AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>-118.3747</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201418201</td>\n",
       "      <td>10/3/2020 0:00</td>\n",
       "      <td>09/29/2020 12:00:00 AM</td>\n",
       "      <td>1830</td>\n",
       "      <td>14</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>THEFT FROM MOTOR VEHICLE - PETTY ($950 &amp; UNDER)</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>420.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4700    LA VILLA MARINA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>-118.4350</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>252104112</td>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>130</td>\n",
       "      <td>21</td>\n",
       "      <td>Topanga</td>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>946</td>\n",
       "      <td>OTHER MISCELLANEOUS CRIME</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>946.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22100    ROSCOE                       BL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>-118.6126</td>\n",
       "      <td>Other Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>250404100</td>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>Hollenbeck</td>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>237</td>\n",
       "      <td>CHILD NEGLECT (SEE 300 W.I.C.)</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3500    PERCY                        ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>-118.1979</td>\n",
       "      <td>Child-Related Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>251304095</td>\n",
       "      <td>01/31/2025 12:00:00 AM</td>\n",
       "      <td>01/30/2025 12:00:00 AM</td>\n",
       "      <td>1554</td>\n",
       "      <td>13</td>\n",
       "      <td>Newton</td>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>850</td>\n",
       "      <td>INDECENT EXPOSURE</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300 E  53RD                         ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>-118.2701</td>\n",
       "      <td>Sex Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>251704066</td>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>1600</td>\n",
       "      <td>17</td>\n",
       "      <td>Devonshire</td>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>624</td>\n",
       "      <td>BATTERY - SIMPLE ASSAULT</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>624.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9600    ZELZAH                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>-118.5233</td>\n",
       "      <td>Violent Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>251904210</td>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>1235</td>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>850</td>\n",
       "      <td>INDECENT EXPOSURE</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11100    OMELVENY                     AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>-118.4417</td>\n",
       "      <td>Sex Crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Date Rptd                DATE OCC  TIME OCC  \\\n",
       "0        211507896          4/11/2021 0:00          11/7/2020 0:00       845   \n",
       "1        201516622  10/21/2020 12:00:00 AM  10/18/2020 12:00:00 AM      1845   \n",
       "2        240913563         12/10/2024 0:00  10/30/2020 12:00:00 AM      1240   \n",
       "3        210704711  12/24/2020 12:00:00 AM  12/24/2020 12:00:00 AM      1310   \n",
       "4        201418201          10/3/2020 0:00  09/29/2020 12:00:00 AM      1830   \n",
       "...            ...                     ...                     ...       ...   \n",
       "1004986  252104112           2/2/2025 0:00           2/2/2025 0:00       130   \n",
       "1004987  250404100  02/18/2025 12:00:00 AM  02/18/2025 12:00:00 AM      1000   \n",
       "1004988  251304095  01/31/2025 12:00:00 AM  01/30/2025 12:00:00 AM      1554   \n",
       "1004989  251704066  01/17/2025 12:00:00 AM  01/17/2025 12:00:00 AM      1600   \n",
       "1004990  251904210  03/25/2025 12:00:00 AM  03/25/2025 12:00:00 AM      1235   \n",
       "\n",
       "         AREA    AREA NAME  Rpt Dist No  Part 1-2  Crm Cd  \\\n",
       "0          15  N Hollywood         1502         2     354   \n",
       "1          15  N Hollywood         1521         1     230   \n",
       "2           9     Van Nuys          933         2     354   \n",
       "3           7     Wilshire          782         1     331   \n",
       "4          14      Pacific         1454         1     420   \n",
       "...       ...          ...          ...       ...     ...   \n",
       "1004986    21      Topanga         2103         2     946   \n",
       "1004987     4   Hollenbeck          479         2     237   \n",
       "1004988    13       Newton         1372         2     850   \n",
       "1004989    17   Devonshire         1774         2     624   \n",
       "1004990    19      Mission         1944         2     850   \n",
       "\n",
       "                                               Crm Cd Desc  ...  Status Desc  \\\n",
       "0                                        THEFT OF IDENTITY  ...  Invest Cont   \n",
       "1           ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT  ...  Invest Cont   \n",
       "2                                        THEFT OF IDENTITY  ...  Invest Cont   \n",
       "3        THEFT FROM MOTOR VEHICLE - GRAND ($950.01 AND ...  ...  Invest Cont   \n",
       "4          THEFT FROM MOTOR VEHICLE - PETTY ($950 & UNDER)  ...  Invest Cont   \n",
       "...                                                    ...  ...          ...   \n",
       "1004986                          OTHER MISCELLANEOUS CRIME  ...  Invest Cont   \n",
       "1004987                     CHILD NEGLECT (SEE 300 W.I.C.)  ...  Invest Cont   \n",
       "1004988                                  INDECENT EXPOSURE  ...  Invest Cont   \n",
       "1004989                           BATTERY - SIMPLE ASSAULT  ...  Invest Cont   \n",
       "1004990                                  INDECENT EXPOSURE  ...  Invest Cont   \n",
       "\n",
       "         Crm Cd 1 Crm Cd 2 Crm Cd 3  Crm Cd 4  \\\n",
       "0           354.0      NaN      NaN       NaN   \n",
       "1           230.0      NaN      NaN       NaN   \n",
       "2           354.0      NaN      NaN       NaN   \n",
       "3           331.0      NaN      NaN       NaN   \n",
       "4           420.0      NaN      NaN       NaN   \n",
       "...           ...      ...      ...       ...   \n",
       "1004986     946.0      NaN      NaN       NaN   \n",
       "1004987     237.0      NaN      NaN       NaN   \n",
       "1004988     850.0      NaN      NaN       NaN   \n",
       "1004989     624.0      NaN      NaN       NaN   \n",
       "1004990     850.0      NaN      NaN       NaN   \n",
       "\n",
       "                                         LOCATION  Cross Street      LAT  \\\n",
       "0         7800    BEEMAN                       AV           NaN  34.2124   \n",
       "1                 ATOLL                        AV      N  GAULT  34.1993   \n",
       "2        14600    SYLVAN                       ST           NaN  34.1847   \n",
       "3         6000    COMEY                        AV           NaN  34.0339   \n",
       "4                         4700    LA VILLA MARINA           NaN  33.9813   \n",
       "...                                           ...           ...      ...   \n",
       "1004986  22100    ROSCOE                       BL           NaN  34.2259   \n",
       "1004987   3500    PERCY                        ST           NaN  34.0277   \n",
       "1004988    300 E  53RD                         ST           NaN  33.9942   \n",
       "1004989   9600    ZELZAH                       AV           NaN  34.2450   \n",
       "1004990  11100    OMELVENY                     AV           NaN  34.2722   \n",
       "\n",
       "              LON          Crime_Class  \n",
       "0       -118.4092       Property Crime  \n",
       "1       -118.4203        Violent Crime  \n",
       "2       -118.4509       Property Crime  \n",
       "3       -118.3747       Property Crime  \n",
       "4       -118.4350       Property Crime  \n",
       "...           ...                  ...  \n",
       "1004986 -118.6126          Other Crime  \n",
       "1004987 -118.1979  Child-Related Crime  \n",
       "1004988 -118.2701            Sex Crime  \n",
       "1004989 -118.5233        Violent Crime  \n",
       "1004990 -118.4417            Sex Crime  \n",
       "\n",
       "[1004991 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df_raw.drop_duplicates()\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e0e6f7",
   "metadata": {},
   "source": [
    "None found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa9fc5f",
   "metadata": {},
   "source": [
    "### Removing Columns \n",
    "Do not proceed without caution. In this context, the chosen columns were dropped due to them having a direct relationship to the target class, which may cause a leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "526382ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date Rptd</th>\n",
       "      <th>DATE OCC</th>\n",
       "      <th>TIME OCC</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Mocodes</th>\n",
       "      <th>Vict Age</th>\n",
       "      <th>...</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Weapon Used Cd</th>\n",
       "      <th>Weapon Desc</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>Cross Street</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Crime_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211507896</td>\n",
       "      <td>4/11/2021 0:00</td>\n",
       "      <td>11/7/2020 0:00</td>\n",
       "      <td>845</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>7800    BEEMAN                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>-118.4092</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201516622</td>\n",
       "      <td>10/21/2020 12:00:00 AM</td>\n",
       "      <td>10/18/2020 12:00:00 AM</td>\n",
       "      <td>1845</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>0416 0334 2004 1822 1414 0305 0319 0400</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>200.0</td>\n",
       "      <td>KNIFE WITH BLADE 6INCHES OR LESS</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>ATOLL                        AV</td>\n",
       "      <td>N  GAULT</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>-118.4203</td>\n",
       "      <td>Violent Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240913563</td>\n",
       "      <td>12/10/2024 0:00</td>\n",
       "      <td>10/30/2020 12:00:00 AM</td>\n",
       "      <td>1240</td>\n",
       "      <td>9</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>14600    SYLVAN                       ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>-118.4509</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210704711</td>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>1310</td>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>344</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>6000    COMEY                        AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>-118.3747</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201418201</td>\n",
       "      <td>10/3/2020 0:00</td>\n",
       "      <td>09/29/2020 12:00:00 AM</td>\n",
       "      <td>1830</td>\n",
       "      <td>14</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>1300 0344 1606 2032</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>4700    LA VILLA MARINA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>-118.4350</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>252104112</td>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>130</td>\n",
       "      <td>21</td>\n",
       "      <td>Topanga</td>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>22100    ROSCOE                       BL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>-118.6126</td>\n",
       "      <td>Other Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>250404100</td>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>Hollenbeck</td>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>1258 0553 0602</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>3500    PERCY                        ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>-118.1979</td>\n",
       "      <td>Child-Related Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>251304095</td>\n",
       "      <td>01/31/2025 12:00:00 AM</td>\n",
       "      <td>01/30/2025 12:00:00 AM</td>\n",
       "      <td>1554</td>\n",
       "      <td>13</td>\n",
       "      <td>Newton</td>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>300 E  53RD                         ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>-118.2701</td>\n",
       "      <td>Sex Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>251704066</td>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>1600</td>\n",
       "      <td>17</td>\n",
       "      <td>Devonshire</td>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>0400 1259 1822 0356</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>400.0</td>\n",
       "      <td>STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>9600    ZELZAH                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>-118.5233</td>\n",
       "      <td>Violent Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>251904210</td>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>1235</td>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>0529 2024 1815 0913</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>11100    OMELVENY                     AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>-118.4417</td>\n",
       "      <td>Sex Crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Date Rptd                DATE OCC  TIME OCC  \\\n",
       "0        211507896          4/11/2021 0:00          11/7/2020 0:00       845   \n",
       "1        201516622  10/21/2020 12:00:00 AM  10/18/2020 12:00:00 AM      1845   \n",
       "2        240913563         12/10/2024 0:00  10/30/2020 12:00:00 AM      1240   \n",
       "3        210704711  12/24/2020 12:00:00 AM  12/24/2020 12:00:00 AM      1310   \n",
       "4        201418201          10/3/2020 0:00  09/29/2020 12:00:00 AM      1830   \n",
       "...            ...                     ...                     ...       ...   \n",
       "1004986  252104112           2/2/2025 0:00           2/2/2025 0:00       130   \n",
       "1004987  250404100  02/18/2025 12:00:00 AM  02/18/2025 12:00:00 AM      1000   \n",
       "1004988  251304095  01/31/2025 12:00:00 AM  01/30/2025 12:00:00 AM      1554   \n",
       "1004989  251704066  01/17/2025 12:00:00 AM  01/17/2025 12:00:00 AM      1600   \n",
       "1004990  251904210  03/25/2025 12:00:00 AM  03/25/2025 12:00:00 AM      1235   \n",
       "\n",
       "         AREA    AREA NAME  Rpt Dist No  Part 1-2  \\\n",
       "0          15  N Hollywood         1502         2   \n",
       "1          15  N Hollywood         1521         1   \n",
       "2           9     Van Nuys          933         2   \n",
       "3           7     Wilshire          782         1   \n",
       "4          14      Pacific         1454         1   \n",
       "...       ...          ...          ...       ...   \n",
       "1004986    21      Topanga         2103         2   \n",
       "1004987     4   Hollenbeck          479         2   \n",
       "1004988    13       Newton         1372         2   \n",
       "1004989    17   Devonshire         1774         2   \n",
       "1004990    19      Mission         1944         2   \n",
       "\n",
       "                                         Mocodes  Vict Age  ... Vict Descent  \\\n",
       "0                                            377        31  ...            H   \n",
       "1        0416 0334 2004 1822 1414 0305 0319 0400        32  ...            H   \n",
       "2                                            377        30  ...            W   \n",
       "3                                            344        47  ...            A   \n",
       "4                            1300 0344 1606 2032        63  ...            H   \n",
       "...                                          ...       ...  ...          ...   \n",
       "1004986                                      NaN        35  ...            X   \n",
       "1004987                           1258 0553 0602        11  ...            B   \n",
       "1004988                                      NaN        16  ...            H   \n",
       "1004989                      0400 1259 1822 0356        17  ...            H   \n",
       "1004990                      0529 2024 1815 0913        35  ...            H   \n",
       "\n",
       "        Weapon Used Cd                                     Weapon Desc Status  \\\n",
       "0                  NaN                                             NaN     IC   \n",
       "1                200.0                KNIFE WITH BLADE 6INCHES OR LESS     IC   \n",
       "2                  NaN                                             NaN     IC   \n",
       "3                  NaN                                             NaN     IC   \n",
       "4                  NaN                                             NaN     IC   \n",
       "...                ...                                             ...    ...   \n",
       "1004986            NaN                                             NaN     IC   \n",
       "1004987            NaN                                             NaN     IC   \n",
       "1004988            NaN                                             NaN     IC   \n",
       "1004989          400.0  STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)     IC   \n",
       "1004990            NaN                                             NaN     IC   \n",
       "\n",
       "         Status Desc                                  LOCATION Cross Street  \\\n",
       "0        Invest Cont   7800    BEEMAN                       AV          NaN   \n",
       "1        Invest Cont           ATOLL                        AV     N  GAULT   \n",
       "2        Invest Cont  14600    SYLVAN                       ST          NaN   \n",
       "3        Invest Cont   6000    COMEY                        AV          NaN   \n",
       "4        Invest Cont                   4700    LA VILLA MARINA          NaN   \n",
       "...              ...                                       ...          ...   \n",
       "1004986  Invest Cont  22100    ROSCOE                       BL          NaN   \n",
       "1004987  Invest Cont   3500    PERCY                        ST          NaN   \n",
       "1004988  Invest Cont    300 E  53RD                         ST          NaN   \n",
       "1004989  Invest Cont   9600    ZELZAH                       AV          NaN   \n",
       "1004990  Invest Cont  11100    OMELVENY                     AV          NaN   \n",
       "\n",
       "             LAT       LON          Crime_Class  \n",
       "0        34.2124 -118.4092       Property Crime  \n",
       "1        34.1993 -118.4203        Violent Crime  \n",
       "2        34.1847 -118.4509       Property Crime  \n",
       "3        34.0339 -118.3747       Property Crime  \n",
       "4        33.9813 -118.4350       Property Crime  \n",
       "...          ...       ...                  ...  \n",
       "1004986  34.2259 -118.6126          Other Crime  \n",
       "1004987  34.0277 -118.1979  Child-Related Crime  \n",
       "1004988  33.9942 -118.2701            Sex Crime  \n",
       "1004989  34.2450 -118.5233        Violent Crime  \n",
       "1004990  34.2722 -118.4417            Sex Crime  \n",
       "\n",
       "[1004991 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df_new.drop(columns=[\"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\", \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\"])\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c199f66",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679d198f",
   "metadata": {},
   "source": [
    "In this phase, TAKE NOTE that anything, once you hit run, results in the dataframe being permanently changed. So to rerun this segment, you MUST reload and reimport the DataFrame again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b832648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date Rptd</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Mocodes</th>\n",
       "      <th>Vict Age</th>\n",
       "      <th>Vict Sex</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Weapon Used Cd</th>\n",
       "      <th>Weapon Desc</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>Cross Street</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Crime_Class</th>\n",
       "      <th>DateTime OCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211507896</td>\n",
       "      <td>4/11/2021 0:00</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>7800    BEEMAN                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>-118.4092</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-11-07 08:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201516622</td>\n",
       "      <td>10/21/2020 12:00:00 AM</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>0416 0334 2004 1822 1414 0305 0319 0400</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>200.0</td>\n",
       "      <td>KNIFE WITH BLADE 6INCHES OR LESS</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>ATOLL                        AV</td>\n",
       "      <td>N  GAULT</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>-118.4203</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>2020-10-18 18:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240913563</td>\n",
       "      <td>12/10/2024 0:00</td>\n",
       "      <td>9</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>14600    SYLVAN                       ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>-118.4509</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-10-30 12:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210704711</td>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>344</td>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>6000    COMEY                        AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>-118.3747</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-12-24 13:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201418201</td>\n",
       "      <td>10/3/2020 0:00</td>\n",
       "      <td>14</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>1300 0344 1606 2032</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>4700    LA VILLA MARINA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>-118.4350</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-09-29 18:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>252104112</td>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>21</td>\n",
       "      <td>Topanga</td>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>22100    ROSCOE                       BL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>-118.6126</td>\n",
       "      <td>Other Crime</td>\n",
       "      <td>2025-02-02 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>250404100</td>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>4</td>\n",
       "      <td>Hollenbeck</td>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>1258 0553 0602</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>3500    PERCY                        ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>-118.1979</td>\n",
       "      <td>Child-Related Crime</td>\n",
       "      <td>2025-02-18 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>251304095</td>\n",
       "      <td>01/31/2025 12:00:00 AM</td>\n",
       "      <td>13</td>\n",
       "      <td>Newton</td>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>300 E  53RD                         ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>-118.2701</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>2025-01-30 15:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>251704066</td>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>17</td>\n",
       "      <td>Devonshire</td>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>0400 1259 1822 0356</td>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>400.0</td>\n",
       "      <td>STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>9600    ZELZAH                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>-118.5233</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>2025-01-17 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>251904210</td>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>0529 2024 1815 0913</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>11100    OMELVENY                     AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>-118.4417</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>2025-03-25 12:35:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Date Rptd  AREA    AREA NAME  Rpt Dist No  \\\n",
       "0        211507896          4/11/2021 0:00    15  N Hollywood         1502   \n",
       "1        201516622  10/21/2020 12:00:00 AM    15  N Hollywood         1521   \n",
       "2        240913563         12/10/2024 0:00     9     Van Nuys          933   \n",
       "3        210704711  12/24/2020 12:00:00 AM     7     Wilshire          782   \n",
       "4        201418201          10/3/2020 0:00    14      Pacific         1454   \n",
       "...            ...                     ...   ...          ...          ...   \n",
       "1004986  252104112           2/2/2025 0:00    21      Topanga         2103   \n",
       "1004987  250404100  02/18/2025 12:00:00 AM     4   Hollenbeck          479   \n",
       "1004988  251304095  01/31/2025 12:00:00 AM    13       Newton         1372   \n",
       "1004989  251704066  01/17/2025 12:00:00 AM    17   Devonshire         1774   \n",
       "1004990  251904210  03/25/2025 12:00:00 AM    19      Mission         1944   \n",
       "\n",
       "         Part 1-2                                  Mocodes  Vict Age Vict Sex  \\\n",
       "0               2                                      377        31        M   \n",
       "1               1  0416 0334 2004 1822 1414 0305 0319 0400        32        M   \n",
       "2               2                                      377        30        M   \n",
       "3               1                                      344        47        F   \n",
       "4               1                      1300 0344 1606 2032        63        M   \n",
       "...           ...                                      ...       ...      ...   \n",
       "1004986         2                                      NaN        35        M   \n",
       "1004987         2                           1258 0553 0602        11        M   \n",
       "1004988         2                                      NaN        16        F   \n",
       "1004989         2                      0400 1259 1822 0356        17        M   \n",
       "1004990         2                      0529 2024 1815 0913        35        F   \n",
       "\n",
       "        Vict Descent  Weapon Used Cd  \\\n",
       "0                  H             NaN   \n",
       "1                  H           200.0   \n",
       "2                  W             NaN   \n",
       "3                  A             NaN   \n",
       "4                  H             NaN   \n",
       "...              ...             ...   \n",
       "1004986            X             NaN   \n",
       "1004987            B             NaN   \n",
       "1004988            H             NaN   \n",
       "1004989            H           400.0   \n",
       "1004990            H             NaN   \n",
       "\n",
       "                                            Weapon Desc Status  Status Desc  \\\n",
       "0                                                   NaN     IC  Invest Cont   \n",
       "1                      KNIFE WITH BLADE 6INCHES OR LESS     IC  Invest Cont   \n",
       "2                                                   NaN     IC  Invest Cont   \n",
       "3                                                   NaN     IC  Invest Cont   \n",
       "4                                                   NaN     IC  Invest Cont   \n",
       "...                                                 ...    ...          ...   \n",
       "1004986                                             NaN     IC  Invest Cont   \n",
       "1004987                                             NaN     IC  Invest Cont   \n",
       "1004988                                             NaN     IC  Invest Cont   \n",
       "1004989  STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)     IC  Invest Cont   \n",
       "1004990                                             NaN     IC  Invest Cont   \n",
       "\n",
       "                                         LOCATION Cross Street      LAT  \\\n",
       "0         7800    BEEMAN                       AV          NaN  34.2124   \n",
       "1                 ATOLL                        AV     N  GAULT  34.1993   \n",
       "2        14600    SYLVAN                       ST          NaN  34.1847   \n",
       "3         6000    COMEY                        AV          NaN  34.0339   \n",
       "4                         4700    LA VILLA MARINA          NaN  33.9813   \n",
       "...                                           ...          ...      ...   \n",
       "1004986  22100    ROSCOE                       BL          NaN  34.2259   \n",
       "1004987   3500    PERCY                        ST          NaN  34.0277   \n",
       "1004988    300 E  53RD                         ST          NaN  33.9942   \n",
       "1004989   9600    ZELZAH                       AV          NaN  34.2450   \n",
       "1004990  11100    OMELVENY                     AV          NaN  34.2722   \n",
       "\n",
       "              LON          Crime_Class        DateTime OCC  \n",
       "0       -118.4092       Property Crime 2020-11-07 08:45:00  \n",
       "1       -118.4203        Violent Crime 2020-10-18 18:45:00  \n",
       "2       -118.4509       Property Crime 2020-10-30 12:40:00  \n",
       "3       -118.3747       Property Crime 2020-12-24 13:10:00  \n",
       "4       -118.4350       Property Crime 2020-09-29 18:30:00  \n",
       "...           ...                  ...                 ...  \n",
       "1004986 -118.6126          Other Crime 2025-02-02 01:30:00  \n",
       "1004987 -118.1979  Child-Related Crime 2025-02-18 10:00:00  \n",
       "1004988 -118.2701            Sex Crime 2025-01-30 15:54:00  \n",
       "1004989 -118.5233        Violent Crime 2025-01-17 16:00:00  \n",
       "1004990 -118.4417            Sex Crime 2025-03-25 12:35:00  \n",
       "\n",
       "[1004991 rows x 20 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Clean DATE OCC (mixed formats)\n",
    "df_new['DATE OCC'] = pd.to_datetime(df_new['DATE OCC'], format='mixed', errors='coerce')\n",
    "\n",
    "# 2. Clean TIME OCC (force numeric → Int64 → 4-digit HHMM)\n",
    "df_new['TIME OCC'] = pd.to_numeric(df_new['TIME OCC'], errors='coerce').astype('Int64')\n",
    "time_str = df_new['TIME OCC'].astype(str).str.zfill(4)\n",
    "\n",
    "# 3. Combine DATE OCC + TIME OCC into a single datetime\n",
    "df_new['DateTime OCC'] = pd.to_datetime(\n",
    "    df_new['DATE OCC'].dt.strftime('%Y-%m-%d') + ' ' + time_str,\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# 4. Drop the original columns used for merging\n",
    "df_new = df_new.drop(columns=['DATE OCC', 'TIME OCC'])\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45512be",
   "metadata": {},
   "source": [
    "### Check for NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f79449e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       0\n",
       "Date Rptd              0\n",
       "AREA                   0\n",
       "AREA NAME              0\n",
       "Rpt Dist No            0\n",
       "Part 1-2               0\n",
       "Mocodes           151619\n",
       "Vict Age               0\n",
       "Vict Sex          144644\n",
       "Vict Descent      144656\n",
       "Weapon Used Cd    677744\n",
       "Weapon Desc       677744\n",
       "Status                 1\n",
       "Status Desc            0\n",
       "LOCATION               0\n",
       "Cross Street      850755\n",
       "LAT                    0\n",
       "LON                    0\n",
       "Crime_Class            0\n",
       "DateTime OCC           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b2bc98",
   "metadata": {},
   "source": [
    "Leave as NULL, since some records do in fact not possess the given info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0b4c8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Rptd</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Mocodes</th>\n",
       "      <th>Vict Age</th>\n",
       "      <th>Vict Sex</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Weapon Used Cd</th>\n",
       "      <th>Weapon Desc</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>Cross Street</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Crime_Class</th>\n",
       "      <th>DateTime OCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/11/2021 0:00</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>7800    BEEMAN                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>-118.4092</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-11-07 08:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/21/2020 12:00:00 AM</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>0416 0334 2004 1822 1414 0305 0319 0400</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>200.0</td>\n",
       "      <td>KNIFE WITH BLADE 6INCHES OR LESS</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>ATOLL                        AV</td>\n",
       "      <td>N  GAULT</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>-118.4203</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>2020-10-18 18:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/10/2024 0:00</td>\n",
       "      <td>9</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>14600    SYLVAN                       ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>-118.4509</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-10-30 12:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>344</td>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>6000    COMEY                        AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>-118.3747</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-12-24 13:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/3/2020 0:00</td>\n",
       "      <td>14</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>1300 0344 1606 2032</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>4700    LA VILLA MARINA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>-118.4350</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-09-29 18:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>21</td>\n",
       "      <td>Topanga</td>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>22100    ROSCOE                       BL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>-118.6126</td>\n",
       "      <td>Other Crime</td>\n",
       "      <td>2025-02-02 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>4</td>\n",
       "      <td>Hollenbeck</td>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>1258 0553 0602</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>3500    PERCY                        ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>-118.1979</td>\n",
       "      <td>Child-Related Crime</td>\n",
       "      <td>2025-02-18 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>01/31/2025 12:00:00 AM</td>\n",
       "      <td>13</td>\n",
       "      <td>Newton</td>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>300 E  53RD                         ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>-118.2701</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>2025-01-30 15:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>17</td>\n",
       "      <td>Devonshire</td>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>0400 1259 1822 0356</td>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>400.0</td>\n",
       "      <td>STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>9600    ZELZAH                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>-118.5233</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>2025-01-17 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>0529 2024 1815 0913</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>11100    OMELVENY                     AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>-118.4417</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>2025-03-25 12:35:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date Rptd  AREA    AREA NAME  Rpt Dist No  Part 1-2  \\\n",
       "0                4/11/2021 0:00    15  N Hollywood         1502         2   \n",
       "1        10/21/2020 12:00:00 AM    15  N Hollywood         1521         1   \n",
       "2               12/10/2024 0:00     9     Van Nuys          933         2   \n",
       "3        12/24/2020 12:00:00 AM     7     Wilshire          782         1   \n",
       "4                10/3/2020 0:00    14      Pacific         1454         1   \n",
       "...                         ...   ...          ...          ...       ...   \n",
       "1004986           2/2/2025 0:00    21      Topanga         2103         2   \n",
       "1004987  02/18/2025 12:00:00 AM     4   Hollenbeck          479         2   \n",
       "1004988  01/31/2025 12:00:00 AM    13       Newton         1372         2   \n",
       "1004989  01/17/2025 12:00:00 AM    17   Devonshire         1774         2   \n",
       "1004990  03/25/2025 12:00:00 AM    19      Mission         1944         2   \n",
       "\n",
       "                                         Mocodes  Vict Age Vict Sex  \\\n",
       "0                                            377        31        M   \n",
       "1        0416 0334 2004 1822 1414 0305 0319 0400        32        M   \n",
       "2                                            377        30        M   \n",
       "3                                            344        47        F   \n",
       "4                            1300 0344 1606 2032        63        M   \n",
       "...                                          ...       ...      ...   \n",
       "1004986                                      NaN        35        M   \n",
       "1004987                           1258 0553 0602        11        M   \n",
       "1004988                                      NaN        16        F   \n",
       "1004989                      0400 1259 1822 0356        17        M   \n",
       "1004990                      0529 2024 1815 0913        35        F   \n",
       "\n",
       "        Vict Descent  Weapon Used Cd  \\\n",
       "0                  H             NaN   \n",
       "1                  H           200.0   \n",
       "2                  W             NaN   \n",
       "3                  A             NaN   \n",
       "4                  H             NaN   \n",
       "...              ...             ...   \n",
       "1004986            X             NaN   \n",
       "1004987            B             NaN   \n",
       "1004988            H             NaN   \n",
       "1004989            H           400.0   \n",
       "1004990            H             NaN   \n",
       "\n",
       "                                            Weapon Desc Status  Status Desc  \\\n",
       "0                                                   NaN     IC  Invest Cont   \n",
       "1                      KNIFE WITH BLADE 6INCHES OR LESS     IC  Invest Cont   \n",
       "2                                                   NaN     IC  Invest Cont   \n",
       "3                                                   NaN     IC  Invest Cont   \n",
       "4                                                   NaN     IC  Invest Cont   \n",
       "...                                                 ...    ...          ...   \n",
       "1004986                                             NaN     IC  Invest Cont   \n",
       "1004987                                             NaN     IC  Invest Cont   \n",
       "1004988                                             NaN     IC  Invest Cont   \n",
       "1004989  STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)     IC  Invest Cont   \n",
       "1004990                                             NaN     IC  Invest Cont   \n",
       "\n",
       "                                         LOCATION Cross Street      LAT  \\\n",
       "0         7800    BEEMAN                       AV          NaN  34.2124   \n",
       "1                 ATOLL                        AV     N  GAULT  34.1993   \n",
       "2        14600    SYLVAN                       ST          NaN  34.1847   \n",
       "3         6000    COMEY                        AV          NaN  34.0339   \n",
       "4                         4700    LA VILLA MARINA          NaN  33.9813   \n",
       "...                                           ...          ...      ...   \n",
       "1004986  22100    ROSCOE                       BL          NaN  34.2259   \n",
       "1004987   3500    PERCY                        ST          NaN  34.0277   \n",
       "1004988    300 E  53RD                         ST          NaN  33.9942   \n",
       "1004989   9600    ZELZAH                       AV          NaN  34.2450   \n",
       "1004990  11100    OMELVENY                     AV          NaN  34.2722   \n",
       "\n",
       "              LON          Crime_Class        DateTime OCC  \n",
       "0       -118.4092       Property Crime 2020-11-07 08:45:00  \n",
       "1       -118.4203        Violent Crime 2020-10-18 18:45:00  \n",
       "2       -118.4509       Property Crime 2020-10-30 12:40:00  \n",
       "3       -118.3747       Property Crime 2020-12-24 13:10:00  \n",
       "4       -118.4350       Property Crime 2020-09-29 18:30:00  \n",
       "...           ...                  ...                 ...  \n",
       "1004986 -118.6126          Other Crime 2025-02-02 01:30:00  \n",
       "1004987 -118.1979  Child-Related Crime 2025-02-18 10:00:00  \n",
       "1004988 -118.2701            Sex Crime 2025-01-30 15:54:00  \n",
       "1004989 -118.5233        Violent Crime 2025-01-17 16:00:00  \n",
       "1004990 -118.4417            Sex Crime 2025-03-25 12:35:00  \n",
       "\n",
       "[1004991 rows x 19 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df_new.drop(columns=[' '])\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda99625",
   "metadata": {},
   "source": [
    "Remove the Weapon Used Cd column, and change the Weapon Desc column to binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08685736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "sns.heatmap(df_new.isna(), cbar=False, yticklabels=False)\n",
    "plt.title(\"Missing Value Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc52334c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Rptd</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Mocodes</th>\n",
       "      <th>Vict Age</th>\n",
       "      <th>Vict Sex</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>Cross Street</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Crime_Class</th>\n",
       "      <th>DateTime OCC</th>\n",
       "      <th>Weapon_Present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/11/2021 0:00</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>7800    BEEMAN                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>-118.4092</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-11-07 08:45:00</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/21/2020 12:00:00 AM</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>0416 0334 2004 1822 1414 0305 0319 0400</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>ATOLL                        AV</td>\n",
       "      <td>N  GAULT</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>-118.4203</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>2020-10-18 18:45:00</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/10/2024 0:00</td>\n",
       "      <td>9</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>14600    SYLVAN                       ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>-118.4509</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-10-30 12:40:00</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>344</td>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>6000    COMEY                        AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>-118.3747</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-12-24 13:10:00</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/3/2020 0:00</td>\n",
       "      <td>14</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>1300 0344 1606 2032</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>4700    LA VILLA MARINA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>-118.4350</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-09-29 18:30:00</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>21</td>\n",
       "      <td>Topanga</td>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>X</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>22100    ROSCOE                       BL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>-118.6126</td>\n",
       "      <td>Other Crime</td>\n",
       "      <td>2025-02-02 01:30:00</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>4</td>\n",
       "      <td>Hollenbeck</td>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>1258 0553 0602</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>3500    PERCY                        ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>-118.1979</td>\n",
       "      <td>Child-Related Crime</td>\n",
       "      <td>2025-02-18 10:00:00</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>01/31/2025 12:00:00 AM</td>\n",
       "      <td>13</td>\n",
       "      <td>Newton</td>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>300 E  53RD                         ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>-118.2701</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>2025-01-30 15:54:00</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>17</td>\n",
       "      <td>Devonshire</td>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>0400 1259 1822 0356</td>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>9600    ZELZAH                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>-118.5233</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>2025-01-17 16:00:00</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>0529 2024 1815 0913</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>11100    OMELVENY                     AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>-118.4417</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>2025-03-25 12:35:00</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date Rptd  AREA    AREA NAME  Rpt Dist No  Part 1-2  \\\n",
       "0                4/11/2021 0:00    15  N Hollywood         1502         2   \n",
       "1        10/21/2020 12:00:00 AM    15  N Hollywood         1521         1   \n",
       "2               12/10/2024 0:00     9     Van Nuys          933         2   \n",
       "3        12/24/2020 12:00:00 AM     7     Wilshire          782         1   \n",
       "4                10/3/2020 0:00    14      Pacific         1454         1   \n",
       "...                         ...   ...          ...          ...       ...   \n",
       "1004986           2/2/2025 0:00    21      Topanga         2103         2   \n",
       "1004987  02/18/2025 12:00:00 AM     4   Hollenbeck          479         2   \n",
       "1004988  01/31/2025 12:00:00 AM    13       Newton         1372         2   \n",
       "1004989  01/17/2025 12:00:00 AM    17   Devonshire         1774         2   \n",
       "1004990  03/25/2025 12:00:00 AM    19      Mission         1944         2   \n",
       "\n",
       "                                         Mocodes  Vict Age Vict Sex  \\\n",
       "0                                            377        31        M   \n",
       "1        0416 0334 2004 1822 1414 0305 0319 0400        32        M   \n",
       "2                                            377        30        M   \n",
       "3                                            344        47        F   \n",
       "4                            1300 0344 1606 2032        63        M   \n",
       "...                                          ...       ...      ...   \n",
       "1004986                                      NaN        35        M   \n",
       "1004987                           1258 0553 0602        11        M   \n",
       "1004988                                      NaN        16        F   \n",
       "1004989                      0400 1259 1822 0356        17        M   \n",
       "1004990                      0529 2024 1815 0913        35        F   \n",
       "\n",
       "        Vict Descent Status  Status Desc  \\\n",
       "0                  H     IC  Invest Cont   \n",
       "1                  H     IC  Invest Cont   \n",
       "2                  W     IC  Invest Cont   \n",
       "3                  A     IC  Invest Cont   \n",
       "4                  H     IC  Invest Cont   \n",
       "...              ...    ...          ...   \n",
       "1004986            X     IC  Invest Cont   \n",
       "1004987            B     IC  Invest Cont   \n",
       "1004988            H     IC  Invest Cont   \n",
       "1004989            H     IC  Invest Cont   \n",
       "1004990            H     IC  Invest Cont   \n",
       "\n",
       "                                         LOCATION Cross Street      LAT  \\\n",
       "0         7800    BEEMAN                       AV          NaN  34.2124   \n",
       "1                 ATOLL                        AV     N  GAULT  34.1993   \n",
       "2        14600    SYLVAN                       ST          NaN  34.1847   \n",
       "3         6000    COMEY                        AV          NaN  34.0339   \n",
       "4                         4700    LA VILLA MARINA          NaN  33.9813   \n",
       "...                                           ...          ...      ...   \n",
       "1004986  22100    ROSCOE                       BL          NaN  34.2259   \n",
       "1004987   3500    PERCY                        ST          NaN  34.0277   \n",
       "1004988    300 E  53RD                         ST          NaN  33.9942   \n",
       "1004989   9600    ZELZAH                       AV          NaN  34.2450   \n",
       "1004990  11100    OMELVENY                     AV          NaN  34.2722   \n",
       "\n",
       "              LON          Crime_Class        DateTime OCC Weapon_Present  \n",
       "0       -118.4092       Property Crime 2020-11-07 08:45:00         Absent  \n",
       "1       -118.4203        Violent Crime 2020-10-18 18:45:00        Present  \n",
       "2       -118.4509       Property Crime 2020-10-30 12:40:00         Absent  \n",
       "3       -118.3747       Property Crime 2020-12-24 13:10:00         Absent  \n",
       "4       -118.4350       Property Crime 2020-09-29 18:30:00         Absent  \n",
       "...           ...                  ...                 ...            ...  \n",
       "1004986 -118.6126          Other Crime 2025-02-02 01:30:00         Absent  \n",
       "1004987 -118.1979  Child-Related Crime 2025-02-18 10:00:00         Absent  \n",
       "1004988 -118.2701            Sex Crime 2025-01-30 15:54:00         Absent  \n",
       "1004989 -118.5233        Violent Crime 2025-01-17 16:00:00        Present  \n",
       "1004990 -118.4417            Sex Crime 2025-03-25 12:35:00         Absent  \n",
       "\n",
       "[1004991 rows x 18 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Drop the Weapon Used Cd column (if it exists)\n",
    "df_new = df_new.drop(columns=['Weapon Used Cd'], errors='ignore')\n",
    "\n",
    "# 2. Create a binary Weapon_Present column\n",
    "df_new['Weapon_Present'] = df_new['Weapon Desc'].apply(\n",
    "    lambda x: 'Present' if pd.notna(x) and str(x).strip() != '' else 'Absent'\n",
    ")\n",
    "\n",
    "# 3. (Optional) Drop Weapon Desc if you want to fully remove the text info\n",
    "df_new = df_new.drop(columns=['Weapon Desc'], errors='ignore')\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e89334",
   "metadata": {},
   "source": [
    "Check again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c39d79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "sns.heatmap(df_new.isna(), cbar=False, yticklabels=False)\n",
    "plt.title(\"Missing Value Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b8eb84",
   "metadata": {},
   "source": [
    "### Dropping columns that provide meaningless value:\n",
    "\n",
    "Start with obvious ones, Location of the crime will often be unique among all records, but the area/district may not. So it can be dropped.\n",
    "\n",
    "To do so, apply a test such as Pearson Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf261ba",
   "metadata": {},
   "source": [
    "Cross Street possess a lot of missing values. This can be dropped completely if Location is already sufficient info.\n",
    "\n",
    "As for Mo Codes, this is neglectable, since some records may only be a minor offense. So no MO Code may have been recorded.\n",
    "\n",
    "This applies to victim sex and descent as well, since not all crimes have a victim involved, such as vandalisme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bad0fc",
   "metadata": {},
   "source": [
    "### Test Pearson Correlation (Numeric Features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a57ed88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 strongest Pearson correlations (absolute):\n",
      "      Feature 1            Feature 2  Correlation\n",
      "0          AREA          Rpt Dist No     0.999051\n",
      "18          LAT                  LON    -0.998190\n",
      "11     Part 1-2             Vict Age     0.206183\n",
      "17     Vict Age  Crime_Class_numeric    -0.081723\n",
      "14     Part 1-2  Crime_Class_numeric     0.071209\n",
      "13     Part 1-2                  LON     0.029212\n",
      "12     Part 1-2                  LAT    -0.028722\n",
      "3          AREA                  LAT     0.025338\n",
      "8   Rpt Dist No                  LAT     0.025077\n",
      "7   Rpt Dist No             Vict Age     0.022624\n",
      "2          AREA             Vict Age     0.022593\n",
      "4          AREA                  LON    -0.010541\n",
      "9   Rpt Dist No                  LON    -0.010469\n",
      "1          AREA             Part 1-2     0.007675\n",
      "6   Rpt Dist No             Part 1-2     0.007489\n",
      "10  Rpt Dist No  Crime_Class_numeric    -0.003770\n",
      "5          AREA  Crime_Class_numeric    -0.003678\n",
      "16     Vict Age                  LON     0.002219\n",
      "19          LAT  Crime_Class_numeric    -0.001563\n",
      "20          LON  Crime_Class_numeric    -0.001106\n",
      "15     Vict Age                  LAT    -0.000867\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose the DataFrame to analyze; use the most recent processed one if available\n",
    "try:\n",
    "    df_corr_source = df_new.copy()\n",
    "except NameError:\n",
    "    df_corr_source = df_raw.copy()\n",
    "\n",
    "# Ensure target encoding (optional): demonstrate correlation against encoded target when present\n",
    "if 'Crime_Class' in df_corr_source.columns:\n",
    "    df_corr_source['Crime_Class_numeric'] = df_corr_source['Crime_Class'].astype('category').cat.codes\n",
    "\n",
    "# Select only numeric columns\n",
    "num_df = df_corr_source.select_dtypes(include=['number'])\n",
    "\n",
    "# Pearson correlation matrix\n",
    "corr = num_df.corr(numeric_only=True)\n",
    "\n",
    "# Upper triangle flatten for pairwise sorted report\n",
    "upper = corr.where(~np.tril(np.ones(corr.shape)).astype(bool))\n",
    "corr_report = (\n",
    "    upper.stack()\n",
    "          .reset_index()\n",
    "          .rename(columns={'level_0': 'Feature 1', 'level_1': 'Feature 2', 0: 'Correlation'})\n",
    ")\n",
    "\n",
    "# Sort by absolute correlation strength\n",
    "corr_report = corr_report.iloc[corr_report['Correlation'].abs().sort_values(ascending=False).index]\n",
    "\n",
    "# Show top pairs\n",
    "print(\"Top 25 strongest Pearson correlations (absolute):\")\n",
    "print(corr_report.head(25))\n",
    "\n",
    "# Optional: heatmap for a quick visual\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0)\n",
    "plt.title('Pearson Correlation (Numeric Features)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08140085",
   "metadata": {},
   "source": [
    "### What can be derived freom this correlation table?\n",
    "\n",
    "1. Area and Rpt Dist No are inheritelly the same info, if you know the area where the crime occured, is the specific District Number really required?\n",
    "2. Many features have a correlation near 0, this implies that many features are highly independent. In  which, leave them be.\n",
    "3. Latitude and Longitude do provide the coordinates of the crime, but neither predicts each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c173ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correlation_with_Crime_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Vict Age</th>\n",
       "      <td>0.081723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Part 1-2</th>\n",
       "      <td>0.071209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <td>0.003770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AREA</th>\n",
       "      <td>0.003678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAT</th>\n",
       "      <td>0.001563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LON</th>\n",
       "      <td>0.001106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Correlation_with_Crime_Class\n",
       "Vict Age                         0.081723\n",
       "Part 1-2                         0.071209\n",
       "Rpt Dist No                      0.003770\n",
       "AREA                             0.003678\n",
       "LAT                              0.001563\n",
       "LON                              0.001106"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a copy of the data\n",
    "df_corr = df_new.copy()\n",
    "\n",
    "# Convert Crime_Class (categorical) → numeric labels\n",
    "df_corr['Crime_Class_numeric'] = df_corr['Crime_Class'].astype('category').cat.codes\n",
    "\n",
    "# Select only numeric columns\n",
    "num_df = df_corr.select_dtypes(include=['number'])\n",
    "\n",
    "# Compute correlation with the numeric-encoded target\n",
    "target_corr = num_df.corr(numeric_only=True)['Crime_Class_numeric']\n",
    "\n",
    "# Remove the target itself\n",
    "target_corr = target_corr.drop(labels=['Crime_Class_numeric'])\n",
    "\n",
    "# Turn into sorted dataframe\n",
    "target_corr_report = (\n",
    "    target_corr\n",
    "        .abs()\n",
    "        .sort_values(ascending=False)\n",
    "        .rename(\"Correlation_with_Crime_Class\")\n",
    "        .to_frame()\n",
    ")\n",
    "\n",
    "target_corr_report.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5400a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1004991 entries, 0 to 1004990\n",
      "Data columns (total 18 columns):\n",
      " #   Column          Non-Null Count    Dtype         \n",
      "---  ------          --------------    -----         \n",
      " 0   Date Rptd       1004991 non-null  object        \n",
      " 1   AREA            1004991 non-null  int64         \n",
      " 2   AREA NAME       1004991 non-null  object        \n",
      " 3   Rpt Dist No     1004991 non-null  int64         \n",
      " 4   Part 1-2        1004991 non-null  int64         \n",
      " 5   Mocodes         853372 non-null   object        \n",
      " 6   Vict Age        1004991 non-null  int64         \n",
      " 7   Vict Sex        860347 non-null   object        \n",
      " 8   Vict Descent    860335 non-null   object        \n",
      " 9   Status          1004990 non-null  object        \n",
      " 10  Status Desc     1004991 non-null  object        \n",
      " 11  LOCATION        1004991 non-null  object        \n",
      " 12  Cross Street    154236 non-null   object        \n",
      " 13  LAT             1004991 non-null  float64       \n",
      " 14  LON             1004991 non-null  float64       \n",
      " 15  Crime_Class     1004991 non-null  object        \n",
      " 16  DateTime OCC    1004991 non-null  datetime64[ns]\n",
      " 17  Weapon_Present  1004991 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(4), object(11)\n",
      "memory usage: 138.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d75b12",
   "metadata": {},
   "source": [
    "### Let's tackle Mocodes first, these represent a given crime/offense commited. You can find the full list in the file attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caeae450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Clean & explode the MO Codes column ---\n",
    "# Convert NaN to empty string\n",
    "df_new['Mocodes'] = df_new['Mocodes'].fillna('')\n",
    "\n",
    "# Split by spaces → expand into list\n",
    "df_new['MOCODES_LIST'] = df_new['Mocodes'].str.strip().str.split()\n",
    "\n",
    "# Explode (each code becomes a row)\n",
    "exploded = df_new.explode('MOCODES_LIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26002ed3",
   "metadata": {},
   "source": [
    "Then, extract all unique MO code entries present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f15b458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938 unique MO codes found\n"
     ]
    }
   ],
   "source": [
    "all_codes = sorted({code for sublist in df_new['MOCODES_LIST'] for code in sublist})\n",
    "print(len(all_codes), \"unique MO codes found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64adcdd8",
   "metadata": {},
   "source": [
    "Count the frequency of each MO Code in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc5d3d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Count MO code frequencies ---\n",
    "mo_counts = (\n",
    "    exploded['MOCODES_LIST']\n",
    "    .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde9444a",
   "metadata": {},
   "source": [
    "Select the top 100 MO Codes to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff0b5cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Select the Top 100 codes ---\n",
    "top_100 = set(mo_counts.head(100).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb18582",
   "metadata": {},
   "source": [
    "Filter MO list into top codes and “others”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "009be6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Temp\\ipykernel_31080\\2391797412.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
      "C:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Temp\\ipykernel_31080\\2391797412.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
      "C:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Temp\\ipykernel_31080\\2391797412.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
      "C:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Temp\\ipykernel_31080\\2391797412.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
      "C:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Temp\\ipykernel_31080\\2391797412.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
      "C:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Temp\\ipykernel_31080\\2391797412.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
      "C:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Temp\\ipykernel_31080\\2391797412.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
      "C:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Temp\\ipykernel_31080\\2391797412.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
      "C:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Temp\\ipykernel_31080\\2391797412.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
      "C:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Temp\\ipykernel_31080\\2391797412.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new['MO_OTHERS'] = df_new['MOCODES_LIST'].apply(\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Create one-hot columns for each top code ---\n",
    "for code in top_100:\n",
    "    df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
    "\n",
    "# --- Step 5: Create the OTHERS column ---\n",
    "# OTHERS = true if the row contains any MO code NOT in the top 100\n",
    "df_new['MO_OTHERS'] = df_new['MOCODES_LIST'].apply(\n",
    "    lambda lst: any(code not in top_100 for code in lst)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6797c46",
   "metadata": {},
   "source": [
    "Filter each crime’s MO list to only keep top 100 codes, create an Others column to store everything else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc42cdc9",
   "metadata": {},
   "source": [
    "Multi-hot encode only the top 100 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e76fca25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 101 MO Code features (100 Top + OTHERS).\n",
      "['MO_0321', 'MO_2021', 'MO_0928', 'MO_0602', 'MO_0447', 'MO_1414', 'MO_1258', 'MO_0352', 'MO_0448', 'MO_0361']\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: Convert booleans to integers (0/1) ---\n",
    "mo_cols = [col for col in df_new.columns if col.startswith(\"MO_\")]\n",
    "df_new[mo_cols] = df_new[mo_cols].astype(int)\n",
    "\n",
    "# --- Step 7: Clean up temporary column ---\n",
    "df_new_1 = df_new.drop(columns=[\"MOCODES_LIST\"])\n",
    "\n",
    "# --- Done ---\n",
    "print(f\"Created {len(mo_cols)} MO Code features (100 Top + OTHERS).\")\n",
    "print(mo_cols[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0f33476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Rptd</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Vict Age</th>\n",
       "      <th>Vict Sex</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>...</th>\n",
       "      <th>MO_0421</th>\n",
       "      <th>MO_0429</th>\n",
       "      <th>MO_1810</th>\n",
       "      <th>MO_0216</th>\n",
       "      <th>MO_0337</th>\n",
       "      <th>MO_1309</th>\n",
       "      <th>MO_0945</th>\n",
       "      <th>MO_1310</th>\n",
       "      <th>MO_0305</th>\n",
       "      <th>MO_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/11/2021 0:00</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/21/2020 12:00:00 AM</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/10/2024 0:00</td>\n",
       "      <td>9</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/3/2020 0:00</td>\n",
       "      <td>14</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>21</td>\n",
       "      <td>Topanga</td>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>X</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>4</td>\n",
       "      <td>Hollenbeck</td>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>01/31/2025 12:00:00 AM</td>\n",
       "      <td>13</td>\n",
       "      <td>Newton</td>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>17</td>\n",
       "      <td>Devonshire</td>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date Rptd  AREA    AREA NAME  Rpt Dist No  Part 1-2  \\\n",
       "0                4/11/2021 0:00    15  N Hollywood         1502         2   \n",
       "1        10/21/2020 12:00:00 AM    15  N Hollywood         1521         1   \n",
       "2               12/10/2024 0:00     9     Van Nuys          933         2   \n",
       "3        12/24/2020 12:00:00 AM     7     Wilshire          782         1   \n",
       "4                10/3/2020 0:00    14      Pacific         1454         1   \n",
       "...                         ...   ...          ...          ...       ...   \n",
       "1004986           2/2/2025 0:00    21      Topanga         2103         2   \n",
       "1004987  02/18/2025 12:00:00 AM     4   Hollenbeck          479         2   \n",
       "1004988  01/31/2025 12:00:00 AM    13       Newton         1372         2   \n",
       "1004989  01/17/2025 12:00:00 AM    17   Devonshire         1774         2   \n",
       "1004990  03/25/2025 12:00:00 AM    19      Mission         1944         2   \n",
       "\n",
       "         Vict Age Vict Sex Vict Descent Status  Status Desc  ... MO_0421  \\\n",
       "0              31        M            H     IC  Invest Cont  ...       0   \n",
       "1              32        M            H     IC  Invest Cont  ...       0   \n",
       "2              30        M            W     IC  Invest Cont  ...       0   \n",
       "3              47        F            A     IC  Invest Cont  ...       0   \n",
       "4              63        M            H     IC  Invest Cont  ...       0   \n",
       "...           ...      ...          ...    ...          ...  ...     ...   \n",
       "1004986        35        M            X     IC  Invest Cont  ...       0   \n",
       "1004987        11        M            B     IC  Invest Cont  ...       0   \n",
       "1004988        16        F            H     IC  Invest Cont  ...       0   \n",
       "1004989        17        M            H     IC  Invest Cont  ...       0   \n",
       "1004990        35        F            H     IC  Invest Cont  ...       0   \n",
       "\n",
       "        MO_0429  MO_1810  MO_0216 MO_0337 MO_1309 MO_0945  MO_1310  MO_0305  \\\n",
       "0             0        0        0       0       0       0        0        0   \n",
       "1             0        0        0       0       0       0        0        1   \n",
       "2             0        0        0       0       0       0        0        0   \n",
       "3             0        0        0       0       0       0        0        0   \n",
       "4             0        0        0       0       0       0        0        0   \n",
       "...         ...      ...      ...     ...     ...     ...      ...      ...   \n",
       "1004986       0        0        0       0       0       0        0        0   \n",
       "1004987       0        0        0       0       0       0        0        0   \n",
       "1004988       0        0        0       0       0       0        0        0   \n",
       "1004989       0        0        0       0       0       0        0        0   \n",
       "1004990       0        0        0       0       0       0        0        0   \n",
       "\n",
       "         MO_OTHERS  \n",
       "0                1  \n",
       "1                0  \n",
       "2                1  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "1004986          0  \n",
       "1004987          1  \n",
       "1004988          0  \n",
       "1004989          0  \n",
       "1004990          1  \n",
       "\n",
       "[1004991 rows x 118 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_1 = df_new_1.drop(columns=['Mocodes'], errors='ignore')\n",
    "df_new_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2f4b36",
   "metadata": {},
   "source": [
    "### Next, tackle the location based columns\n",
    "\n",
    "As mentioned, since all crimes will more times than not, occur in unique, varying locations, it is best to assume that there is no association or pattern to be determined from them. They are simply too specific to be trained upon.\n",
    "\n",
    "Another key feature that could be dropped is the Date of te Report. Since each report will have its own unique entry date, hence it is safe to assume that the column is noisy and unfeasible in model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae127faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Vict Age</th>\n",
       "      <th>Vict Sex</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>LAT</th>\n",
       "      <th>...</th>\n",
       "      <th>MO_0421</th>\n",
       "      <th>MO_0429</th>\n",
       "      <th>MO_1810</th>\n",
       "      <th>MO_0216</th>\n",
       "      <th>MO_0337</th>\n",
       "      <th>MO_1309</th>\n",
       "      <th>MO_0945</th>\n",
       "      <th>MO_1310</th>\n",
       "      <th>MO_0305</th>\n",
       "      <th>MO_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>21</td>\n",
       "      <td>Topanga</td>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>X</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>4</td>\n",
       "      <td>Hollenbeck</td>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>13</td>\n",
       "      <td>Newton</td>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>17</td>\n",
       "      <td>Devonshire</td>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AREA    AREA NAME  Rpt Dist No  Part 1-2  Vict Age Vict Sex  \\\n",
       "0          15  N Hollywood         1502         2        31        M   \n",
       "1          15  N Hollywood         1521         1        32        M   \n",
       "2           9     Van Nuys          933         2        30        M   \n",
       "3           7     Wilshire          782         1        47        F   \n",
       "4          14      Pacific         1454         1        63        M   \n",
       "...       ...          ...          ...       ...       ...      ...   \n",
       "1004986    21      Topanga         2103         2        35        M   \n",
       "1004987     4   Hollenbeck          479         2        11        M   \n",
       "1004988    13       Newton         1372         2        16        F   \n",
       "1004989    17   Devonshire         1774         2        17        M   \n",
       "1004990    19      Mission         1944         2        35        F   \n",
       "\n",
       "        Vict Descent Status  Status Desc      LAT  ...  MO_0421 MO_0429  \\\n",
       "0                  H     IC  Invest Cont  34.2124  ...        0       0   \n",
       "1                  H     IC  Invest Cont  34.1993  ...        0       0   \n",
       "2                  W     IC  Invest Cont  34.1847  ...        0       0   \n",
       "3                  A     IC  Invest Cont  34.0339  ...        0       0   \n",
       "4                  H     IC  Invest Cont  33.9813  ...        0       0   \n",
       "...              ...    ...          ...      ...  ...      ...     ...   \n",
       "1004986            X     IC  Invest Cont  34.2259  ...        0       0   \n",
       "1004987            B     IC  Invest Cont  34.0277  ...        0       0   \n",
       "1004988            H     IC  Invest Cont  33.9942  ...        0       0   \n",
       "1004989            H     IC  Invest Cont  34.2450  ...        0       0   \n",
       "1004990            H     IC  Invest Cont  34.2722  ...        0       0   \n",
       "\n",
       "        MO_1810  MO_0216  MO_0337  MO_1309  MO_0945  MO_1310  MO_0305  \\\n",
       "0             0        0        0        0        0        0        0   \n",
       "1             0        0        0        0        0        0        1   \n",
       "2             0        0        0        0        0        0        0   \n",
       "3             0        0        0        0        0        0        0   \n",
       "4             0        0        0        0        0        0        0   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "1004986       0        0        0        0        0        0        0   \n",
       "1004987       0        0        0        0        0        0        0   \n",
       "1004988       0        0        0        0        0        0        0   \n",
       "1004989       0        0        0        0        0        0        0   \n",
       "1004990       0        0        0        0        0        0        0   \n",
       "\n",
       "         MO_OTHERS  \n",
       "0                1  \n",
       "1                0  \n",
       "2                1  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "1004986          0  \n",
       "1004987          1  \n",
       "1004988          0  \n",
       "1004989          0  \n",
       "1004990          1  \n",
       "\n",
       "[1004991 rows x 114 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_1 = df_new_1.drop(columns=['LOCATION', 'Cross Street', 'DateTime OCC', 'Date Rptd'], errors='ignore') #Remove the dates\n",
    "df_new_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3e61f9",
   "metadata": {},
   "source": [
    "### Next, we need to choose bewteen keeping AREA, or DISTRICT.\n",
    "\n",
    "AREA:\n",
    "- It encodes neighborhood-level crime patterns\n",
    "- It’s stable and interpretable\n",
    "\n",
    "Rpt District:\n",
    "- This is a finer-grained region ID.\n",
    "- Usually LAPD districts are ~1–2 square miles.\n",
    "\n",
    "But using both AREA and Rpt Dist No creates strong multicollinearity, because:\n",
    "- AREA is a parent region\n",
    "- Rpt Dist No is the subregion\n",
    "\n",
    "Which is Better?\n",
    "\n",
    "Refer back to the correlation test, Rpt District is SLIGHTLY better than AREA, so that is what we will keep. It may contain more info than AREA, as AREA is a bit too general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "178439b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_1 = df_new_1.drop(columns=['AREA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "255b7efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Vict Age</th>\n",
       "      <th>Vict Sex</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Crime_Class</th>\n",
       "      <th>...</th>\n",
       "      <th>MO_0421</th>\n",
       "      <th>MO_0429</th>\n",
       "      <th>MO_1810</th>\n",
       "      <th>MO_0216</th>\n",
       "      <th>MO_0337</th>\n",
       "      <th>MO_1309</th>\n",
       "      <th>MO_0945</th>\n",
       "      <th>MO_1310</th>\n",
       "      <th>MO_0305</th>\n",
       "      <th>MO_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>-118.4092</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>-118.4203</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>-118.4509</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>-118.3747</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>-118.4350</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>X</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>-118.6126</td>\n",
       "      <td>Other Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>-118.1979</td>\n",
       "      <td>Child-Related Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>-118.2701</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>-118.5233</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>-118.4417</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Rpt Dist No  Part 1-2  Vict Age Vict Sex Vict Descent Status  \\\n",
       "0               1502         2        31        M            H     IC   \n",
       "1               1521         1        32        M            H     IC   \n",
       "2                933         2        30        M            W     IC   \n",
       "3                782         1        47        F            A     IC   \n",
       "4               1454         1        63        M            H     IC   \n",
       "...              ...       ...       ...      ...          ...    ...   \n",
       "1004986         2103         2        35        M            X     IC   \n",
       "1004987          479         2        11        M            B     IC   \n",
       "1004988         1372         2        16        F            H     IC   \n",
       "1004989         1774         2        17        M            H     IC   \n",
       "1004990         1944         2        35        F            H     IC   \n",
       "\n",
       "         Status Desc      LAT       LON          Crime_Class  ... MO_0421  \\\n",
       "0        Invest Cont  34.2124 -118.4092       Property Crime  ...       0   \n",
       "1        Invest Cont  34.1993 -118.4203        Violent Crime  ...       0   \n",
       "2        Invest Cont  34.1847 -118.4509       Property Crime  ...       0   \n",
       "3        Invest Cont  34.0339 -118.3747       Property Crime  ...       0   \n",
       "4        Invest Cont  33.9813 -118.4350       Property Crime  ...       0   \n",
       "...              ...      ...       ...                  ...  ...     ...   \n",
       "1004986  Invest Cont  34.2259 -118.6126          Other Crime  ...       0   \n",
       "1004987  Invest Cont  34.0277 -118.1979  Child-Related Crime  ...       0   \n",
       "1004988  Invest Cont  33.9942 -118.2701            Sex Crime  ...       0   \n",
       "1004989  Invest Cont  34.2450 -118.5233        Violent Crime  ...       0   \n",
       "1004990  Invest Cont  34.2722 -118.4417            Sex Crime  ...       0   \n",
       "\n",
       "         MO_0429  MO_1810  MO_0216  MO_0337  MO_1309  MO_0945  MO_1310  \\\n",
       "0              0        0        0        0        0        0        0   \n",
       "1              0        0        0        0        0        0        0   \n",
       "2              0        0        0        0        0        0        0   \n",
       "3              0        0        0        0        0        0        0   \n",
       "4              0        0        0        0        0        0        0   \n",
       "...          ...      ...      ...      ...      ...      ...      ...   \n",
       "1004986        0        0        0        0        0        0        0   \n",
       "1004987        0        0        0        0        0        0        0   \n",
       "1004988        0        0        0        0        0        0        0   \n",
       "1004989        0        0        0        0        0        0        0   \n",
       "1004990        0        0        0        0        0        0        0   \n",
       "\n",
       "         MO_0305  MO_OTHERS  \n",
       "0              0          1  \n",
       "1              1          0  \n",
       "2              0          1  \n",
       "3              0          0  \n",
       "4              0          0  \n",
       "...          ...        ...  \n",
       "1004986        0          0  \n",
       "1004987        0          1  \n",
       "1004988        0          0  \n",
       "1004989        0          0  \n",
       "1004990        0          1  \n",
       "\n",
       "[1004991 rows x 112 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_1 = df_new_1.drop(columns=['AREA NAME'])\n",
    "df_new_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172089c5",
   "metadata": {},
   "source": [
    "### Finally, we need to decide what to do with LAT and LON\n",
    "\n",
    "These are very powerful IF transformed.\n",
    "\n",
    "Raw lat/lon are NOT useful directly because:\n",
    "- models cannot interpret earth geometry\n",
    "- correlation is near zero\n",
    "- linear models especially fail with raw coordinates\n",
    "\n",
    "Raw latitude and longitude values:\n",
    "- have no linear meaning\n",
    "- give almost zero Pearson correlation\n",
    "- confuse tree models (too many splits)\n",
    "- confuse linear models (not linear!)\n",
    "- are extremely sensitive to tiny changes\n",
    "\n",
    "But crimes happen in spatial hotspots:\n",
    "- Downtown\n",
    "- Hollywood\n",
    "- South LA\n",
    "- Venice\n",
    "- San Fernando Valley\n",
    "- Pico-Union\n",
    "- Koreatown\n",
    "- Westlake\n",
    "- etc.\n",
    "\n",
    "### Is there a way to make them useful via transformation?\n",
    "\n",
    "### Clustering the LAT and LON into Bins of range values, may provide much more use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dc24ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Temp\\ipykernel_31080\\2141477543.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_1['Location_Cluster'] = kmeans.fit_predict(coords)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "coords = df_new_1[['LAT', 'LON']].dropna()\n",
    "\n",
    "kmeans = KMeans(n_clusters=100, random_state=42)\n",
    "\n",
    "df_new_1['Location_Cluster'] = kmeans.fit_predict(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2127bc9",
   "metadata": {},
   "source": [
    "### Method 1 — KMeans Clustering\n",
    "\n",
    "This learns 50–200 “crime regions” directly from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "baf0fa8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Vict Age</th>\n",
       "      <th>Vict Sex</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Crime_Class</th>\n",
       "      <th>...</th>\n",
       "      <th>MO_0429</th>\n",
       "      <th>MO_1810</th>\n",
       "      <th>MO_0216</th>\n",
       "      <th>MO_0337</th>\n",
       "      <th>MO_1309</th>\n",
       "      <th>MO_0945</th>\n",
       "      <th>MO_1310</th>\n",
       "      <th>MO_0305</th>\n",
       "      <th>MO_OTHERS</th>\n",
       "      <th>Location_Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>-118.4092</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>-118.4203</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>-118.4509</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>-118.3747</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>-118.4350</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>X</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>-118.6126</td>\n",
       "      <td>Other Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>-118.1979</td>\n",
       "      <td>Child-Related Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>-118.2701</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>-118.5233</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>-118.4417</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Rpt Dist No  Part 1-2  Vict Age Vict Sex Vict Descent Status  \\\n",
       "0               1502         2        31        M            H     IC   \n",
       "1               1521         1        32        M            H     IC   \n",
       "2                933         2        30        M            W     IC   \n",
       "3                782         1        47        F            A     IC   \n",
       "4               1454         1        63        M            H     IC   \n",
       "...              ...       ...       ...      ...          ...    ...   \n",
       "1004986         2103         2        35        M            X     IC   \n",
       "1004987          479         2        11        M            B     IC   \n",
       "1004988         1372         2        16        F            H     IC   \n",
       "1004989         1774         2        17        M            H     IC   \n",
       "1004990         1944         2        35        F            H     IC   \n",
       "\n",
       "         Status Desc      LAT       LON          Crime_Class  ... MO_0429  \\\n",
       "0        Invest Cont  34.2124 -118.4092       Property Crime  ...       0   \n",
       "1        Invest Cont  34.1993 -118.4203        Violent Crime  ...       0   \n",
       "2        Invest Cont  34.1847 -118.4509       Property Crime  ...       0   \n",
       "3        Invest Cont  34.0339 -118.3747       Property Crime  ...       0   \n",
       "4        Invest Cont  33.9813 -118.4350       Property Crime  ...       0   \n",
       "...              ...      ...       ...                  ...  ...     ...   \n",
       "1004986  Invest Cont  34.2259 -118.6126          Other Crime  ...       0   \n",
       "1004987  Invest Cont  34.0277 -118.1979  Child-Related Crime  ...       0   \n",
       "1004988  Invest Cont  33.9942 -118.2701            Sex Crime  ...       0   \n",
       "1004989  Invest Cont  34.2450 -118.5233        Violent Crime  ...       0   \n",
       "1004990  Invest Cont  34.2722 -118.4417            Sex Crime  ...       0   \n",
       "\n",
       "         MO_1810  MO_0216  MO_0337  MO_1309  MO_0945  MO_1310  MO_0305  \\\n",
       "0              0        0        0        0        0        0        0   \n",
       "1              0        0        0        0        0        0        1   \n",
       "2              0        0        0        0        0        0        0   \n",
       "3              0        0        0        0        0        0        0   \n",
       "4              0        0        0        0        0        0        0   \n",
       "...          ...      ...      ...      ...      ...      ...      ...   \n",
       "1004986        0        0        0        0        0        0        0   \n",
       "1004987        0        0        0        0        0        0        0   \n",
       "1004988        0        0        0        0        0        0        0   \n",
       "1004989        0        0        0        0        0        0        0   \n",
       "1004990        0        0        0        0        0        0        0   \n",
       "\n",
       "         MO_OTHERS  Location_Cluster  \n",
       "0                1                71  \n",
       "1                0                57  \n",
       "2                1                27  \n",
       "3                0                33  \n",
       "4                0                 6  \n",
       "...            ...               ...  \n",
       "1004986          0                53  \n",
       "1004987          1                93  \n",
       "1004988          0                 8  \n",
       "1004989          0                44  \n",
       "1004990          1                 0  \n",
       "\n",
       "[1004991 rows x 113 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3807886",
   "metadata": {},
   "source": [
    "### Method 2 — Spatial Binning (ranges)\n",
    "\n",
    "This converts lat/lon into a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e6b522b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Temp\\ipykernel_31080\\536423381.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_1['Lat_bin'] = pd.cut(df_new_1['LAT'], bins=50, labels=False)\n",
      "C:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Temp\\ipykernel_31080\\536423381.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_1['Lon_bin'] = pd.cut(df_new_1['LON'], bins=50, labels=False)\n"
     ]
    }
   ],
   "source": [
    "df_new_1['Lat_bin'] = pd.cut(df_new_1['LAT'], bins=50, labels=False)\n",
    "df_new_1['Lon_bin'] = pd.cut(df_new_1['LON'], bins=50, labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ed89586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Vict Age</th>\n",
       "      <th>Vict Sex</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Crime_Class</th>\n",
       "      <th>...</th>\n",
       "      <th>MO_0216</th>\n",
       "      <th>MO_0337</th>\n",
       "      <th>MO_1309</th>\n",
       "      <th>MO_0945</th>\n",
       "      <th>MO_1310</th>\n",
       "      <th>MO_0305</th>\n",
       "      <th>MO_OTHERS</th>\n",
       "      <th>Location_Cluster</th>\n",
       "      <th>Lat_bin</th>\n",
       "      <th>Lon_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>-118.4092</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>-118.4203</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>-118.4509</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>-118.3747</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>-118.4350</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>X</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>-118.6126</td>\n",
       "      <td>Other Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>-118.1979</td>\n",
       "      <td>Child-Related Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>-118.2701</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>-118.5233</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>-118.4417</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Rpt Dist No  Part 1-2  Vict Age Vict Sex Vict Descent Status  \\\n",
       "0               1502         2        31        M            H     IC   \n",
       "1               1521         1        32        M            H     IC   \n",
       "2                933         2        30        M            W     IC   \n",
       "3                782         1        47        F            A     IC   \n",
       "4               1454         1        63        M            H     IC   \n",
       "...              ...       ...       ...      ...          ...    ...   \n",
       "1004986         2103         2        35        M            X     IC   \n",
       "1004987          479         2        11        M            B     IC   \n",
       "1004988         1372         2        16        F            H     IC   \n",
       "1004989         1774         2        17        M            H     IC   \n",
       "1004990         1944         2        35        F            H     IC   \n",
       "\n",
       "         Status Desc      LAT       LON          Crime_Class  ... MO_0216  \\\n",
       "0        Invest Cont  34.2124 -118.4092       Property Crime  ...       0   \n",
       "1        Invest Cont  34.1993 -118.4203        Violent Crime  ...       0   \n",
       "2        Invest Cont  34.1847 -118.4509       Property Crime  ...       0   \n",
       "3        Invest Cont  34.0339 -118.3747       Property Crime  ...       0   \n",
       "4        Invest Cont  33.9813 -118.4350       Property Crime  ...       0   \n",
       "...              ...      ...       ...                  ...  ...     ...   \n",
       "1004986  Invest Cont  34.2259 -118.6126          Other Crime  ...       0   \n",
       "1004987  Invest Cont  34.0277 -118.1979  Child-Related Crime  ...       0   \n",
       "1004988  Invest Cont  33.9942 -118.2701            Sex Crime  ...       0   \n",
       "1004989  Invest Cont  34.2450 -118.5233        Violent Crime  ...       0   \n",
       "1004990  Invest Cont  34.2722 -118.4417            Sex Crime  ...       0   \n",
       "\n",
       "         MO_0337  MO_1309  MO_0945  MO_1310  MO_0305  MO_OTHERS  \\\n",
       "0              0        0        0        0        0          1   \n",
       "1              0        0        0        0        1          0   \n",
       "2              0        0        0        0        0          1   \n",
       "3              0        0        0        0        0          0   \n",
       "4              0        0        0        0        0          0   \n",
       "...          ...      ...      ...      ...      ...        ...   \n",
       "1004986        0        0        0        0        0          0   \n",
       "1004987        0        0        0        0        0          1   \n",
       "1004988        0        0        0        0        0          0   \n",
       "1004989        0        0        0        0        0          0   \n",
       "1004990        0        0        0        0        0          1   \n",
       "\n",
       "         Location_Cluster  Lat_bin  Lon_bin  \n",
       "0                      71       49        0  \n",
       "1                      57       49        0  \n",
       "2                      27       49        0  \n",
       "3                      33       49        0  \n",
       "4                       6       49        0  \n",
       "...                   ...      ...      ...  \n",
       "1004986                53       49        0  \n",
       "1004987                93       49        0  \n",
       "1004988                 8       49        0  \n",
       "1004989                44       49        0  \n",
       "1004990                 0       49        0  \n",
       "\n",
       "[1004991 rows x 115 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc8c42b",
   "metadata": {},
   "source": [
    "This creates 2 features:\n",
    "- Lat_bin\n",
    "- Lon_bin\n",
    "\n",
    "Which together form a 2D grid, like “Region (12, 34)”.\n",
    "\n",
    "This is good for:\n",
    "- linear models\n",
    "- tree models\n",
    "- giant datasets\n",
    "- preserving spatial structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c6009a",
   "metadata": {},
   "source": [
    "### 🟢 Combining Both Is Even Better\n",
    "\n",
    "Crime prediction systems often use:\n",
    "\n",
    "✔ Location_Cluster (KMeans)\n",
    "\n",
    "✔ Lat_bin + Lon_bin (50x50 grid)\n",
    "\n",
    "This gives:\n",
    "- global structure (clusters)\n",
    "- local structure (grid bins)\n",
    "- Without storing raw LAT/LON."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f917f2",
   "metadata": {},
   "source": [
    "#### Function for Plotting Confusion Matrix. You'll be using this later, so intialize it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee08d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def plot_crime_matrix(y_test, y_pred, model_name=\"Model\", labels=None):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix with counts and percentages.\n",
    "    \"\"\"\n",
    "    # Compute matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Calculate percentages for the heatmap annotations\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=annot, fmt='', cmap='Blues', \n",
    "                xticklabels=labels if labels is not None else \"auto\",\n",
    "                yticklabels=labels if labels is not None else \"auto\")\n",
    "    plt.title(f'Confusion Matrix: {model_name}')\n",
    "    plt.ylabel('Actual Crime Class')\n",
    "    plt.xlabel('Predicted Crime Class')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418e56b4",
   "metadata": {},
   "source": [
    "## Part A - Remodelling with Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d052275e",
   "metadata": {},
   "source": [
    "Now, let's try building the Models again.\n",
    "\n",
    "### Tree-Based: Decision Tree (Processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f9fc9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 0.9819514906331691\n",
      "Testing Set Accuracy: 0.8781119609416977\n",
      "------------------------------------------------------------------------------------\n",
      "Training Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.987960  0.976778  0.982337  356035.000000\n",
      "1              0.999951  0.999988  0.999969  163391.000000\n",
      "2              0.997842  0.994005  0.995920   44202.000000\n",
      "3              0.908648  0.953081  0.930334   86340.000000\n",
      "4              0.999779  0.999559  0.999669   13595.000000\n",
      "5              0.999033  0.998310  0.998671    8282.000000\n",
      "6              0.999605  0.999408  0.999507   15207.000000\n",
      "7              0.995265  0.994908  0.995087   13944.000000\n",
      "8              1.000000  0.981481  0.990654     540.000000\n",
      "9              1.000000  0.999489  0.999744    1957.000000\n",
      "accuracy       0.981951  0.981951  0.981951       0.981951\n",
      "macro avg      0.988809  0.989701  0.989189  703493.000000\n",
      "weighted avg   0.982430  0.981951  0.982109  703493.000000\n",
      "------------------------------------------------------------------------------------\n",
      "Testing Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.927618  0.916967  0.922262  152409.000000\n",
      "1              0.935703  0.931137  0.933414   70096.000000\n",
      "2              0.637012  0.649729  0.643308   18834.000000\n",
      "3              0.800160  0.833715  0.816593   37105.000000\n",
      "4              0.687137  0.688314  0.687725    5836.000000\n",
      "5              0.603382  0.616499  0.609870    3588.000000\n",
      "6              0.904935  0.907831  0.906381    6564.000000\n",
      "7              0.656426  0.658710  0.657566    6033.000000\n",
      "8              0.048980  0.058252  0.053215     206.000000\n",
      "9              0.464548  0.459492  0.462006     827.000000\n",
      "accuracy       0.878112  0.878112  0.878112       0.878112\n",
      "macro avg      0.666590  0.672065  0.669234  301498.000000\n",
      "weighted avg   0.879354  0.878112  0.878668  301498.000000\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# Convert datetime columns to int64 timestamps\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view('int64')\n",
    "\n",
    "# Convert list columns to strings so they can be factorized\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test_dt = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "dt_model_3 = DecisionTreeClassifier()\n",
    "dt_model_3.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_dt = dt_model_3.predict(X_test)\n",
    "y_pred_train = dt_model_3.predict(X_train)\n",
    "\n",
    "# Evaluation\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_dt, y_pred_dt, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test_dt, y_pred_dt)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94530910",
   "metadata": {},
   "source": [
    "A highly Noticeable increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efb18a8",
   "metadata": {},
   "source": [
    "Now, let's plot the Error vs Complexity curve.\n",
    "\n",
    "This first one shall use a stratified sampling approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca247af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import validation_curve\n",
    "import numpy as np\n",
    "\n",
    "# Compute log-loss for Decision Tree\n",
    "train_loss = log_loss(y_train, dt_model_3.predict_proba(X_train))\n",
    "test_loss  = log_loss(y_test,  dt_model_3.predict_proba(X_test))\n",
    "\n",
    "print(\"------------------------\")\n",
    "print(\"Decision Tree Log Loss\")\n",
    "print(\"------------------------\")\n",
    "print(\"Training Loss:\")\n",
    "print(train_loss)\n",
    "print(\"------------------------\")\n",
    "print(\"Testing Loss:\")\n",
    "print(test_loss)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# Gap analysis\n",
    "acc_gap  = train_accuracy - test_accuracy\n",
    "loss_gap = test_loss - train_loss\n",
    "\n",
    "print(\"Accuracy Gap (Train - Test):\")\n",
    "print(acc_gap)\n",
    "print(\"------------------------\")\n",
    "print(\"Loss Gap (Test - Train):\")\n",
    "print(loss_gap)\n",
    "print(\"------------------------\")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 1. FAST STRATIFIED SUBSAMPLING\n",
    "# ================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Take only 5% of the data (tweak 0.05 → 0.02 or 0.01 if still slow)\n",
    "sample_ratio = 0.25  \n",
    "X_small, _, y_small, _ = train_test_split(\n",
    "    X, y, \n",
    "    train_size=sample_ratio, \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split the small subset into train/test\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n",
    "    X_small, y_small,\n",
    "    test_size=0.3,\n",
    "    stratify=y_small,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ==================================\n",
    "# 2. MODEL COMPLEXITY VS ERROR\n",
    "# ==================================\n",
    "depths = range(2, 41, 2)\n",
    "train_losses_curve = []\n",
    "test_losses_curve = []\n",
    "train_acc_curve = []\n",
    "test_acc_curve = []\n",
    "\n",
    "for d in depths:\n",
    "    model = DecisionTreeClassifier(max_depth=d)\n",
    "\n",
    "    # Fit on *small* dataset\n",
    "    model.fit(X_train_s, y_train_s)\n",
    "\n",
    "    # Probabilities\n",
    "    train_proba = model.predict_proba(X_train_s)\n",
    "    test_proba  = model.predict_proba(X_test_s)\n",
    "\n",
    "    # Loss\n",
    "    train_losses_curve.append(log_loss(y_train_s, train_proba))\n",
    "    test_losses_curve.append(log_loss(y_test_s, test_proba))\n",
    "\n",
    "    # Accuracy\n",
    "    y_train_pred = model.predict(X_train_s)\n",
    "    y_test_pred  = model.predict(X_test_s)\n",
    "\n",
    "    train_acc_curve.append(accuracy_score(y_train_s, y_train_pred))\n",
    "    test_acc_curve.append(accuracy_score(y_test_s, y_test_pred))\n",
    "\n",
    "# ================================\n",
    "# 3. PLOT\n",
    "# ================================\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(depths, train_losses_curve, label=\"Training Loss\")\n",
    "plt.plot(depths, test_losses_curve, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Model Complexity (max_depth)\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.title(\"Model Complexity vs Error (Decision Tree)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc51d1",
   "metadata": {},
   "source": [
    "The second one will use all rows present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da9ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Convert y → Series so we can subsample safely\n",
    "# ----------------------------------------------------\n",
    "y_train = pd.Series(y_train).reset_index(drop=True)\n",
    "y_test  = pd.Series(y_test).reset_index(drop=True)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test  = X_test.reset_index(drop=True)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Subsample 250k rows for faster computation\n",
    "# ----------------------------------------------------\n",
    "sample_size = min(250_000, len(X_train), len(X_test))\n",
    "\n",
    "X_train_sub = X_train.sample(sample_size, random_state=42)\n",
    "y_train_sub = y_train.loc[X_train_sub.index]\n",
    "\n",
    "X_test_sub = X_test.sample(sample_size, random_state=42)\n",
    "y_test_sub = y_test.loc[X_test_sub.index]\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Complexity levels (same as original)\n",
    "# ----------------------------------------------------\n",
    "complexity_values = [5, 10, 15, 20, 25, 30, 35, None]\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(\"=== Generating Decision Tree Log-Loss vs Complexity Curve ===\")\n",
    "\n",
    "for depth in complexity_values:\n",
    "    print(f\"Training Decision Tree with max_depth={depth}\")\n",
    "\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        max_depth=depth,\n",
    "        random_state=42  # no tuning params, just default DT\n",
    "    )\n",
    "    \n",
    "    dt_model.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "    # Predict probs so we can compute log-loss\n",
    "    train_proba = dt_model.predict_proba(X_train_sub)\n",
    "    test_proba  = dt_model.predict_proba(X_test_sub)\n",
    "\n",
    "    train_losses.append(log_loss(y_train_sub, train_proba))\n",
    "    test_losses.append(log_loss(y_test_sub, test_proba))\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# PLOT\n",
    "# ----------------------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([str(d) for d in complexity_values], train_losses, marker='o', label=\"Training Log Loss\")\n",
    "plt.plot([str(d) for d in complexity_values], test_losses, marker='o', label=\"Testing Log Loss\")\n",
    "\n",
    "plt.xlabel(\"Model Complexity (max_depth)\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.title(\"Decision Tree Log-Loss vs Complexity Curve (Subsample 250k)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f759bd81",
   "metadata": {},
   "source": [
    "### Evaluate Feature Importance (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c275b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = dt_model_3.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "fi = pd.DataFrame({\"feature\": features, \"importance\": importance})\n",
    "fi.sort_values(by=\"importance\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad7cd55",
   "metadata": {},
   "source": [
    "### Perform Shuffle Split Validation to verify the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2349ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== Decision Tree Cross-Validation: Stratified Shuffle-Split ===\")\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        max_depth=6,      # similar to XGB's depth, tweak as needed\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    dt_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = dt_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Mean Accuracy:  \", np.mean(accuracies))\n",
    "print(\"Std Deviation: \", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f0f6ae",
   "metadata": {},
   "source": [
    "Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5ba55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the class names (optional, makes the plot readable)\n",
    "crime_labels = df_new_1[\"Crime_Class\"].unique()\n",
    "crime_labels.sort() # Ensure they are in the same order as factorize usually does\n",
    "\n",
    "# 2. Plot the matrix\n",
    "# Ensure you pass the predictions you just made (y_pred_test)\n",
    "plot_crime_matrix(y_test_dt, y_pred_dt, model_name=\"Decision Tree\", labels=crime_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb6fbe7",
   "metadata": {},
   "source": [
    "### Tree-Based: Random Forest (Processed)\n",
    "\n",
    "*Yawn..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a36f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Random Forest Crime Classification (PROCESSED) ===\")\n",
    "\n",
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# Convert datetime columns to int64 timestamps\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view('int64')\n",
    "\n",
    "# Convert list columns to strings so they can be factorized\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Fill any remaining NaN values before training\n",
    "X = X.fillna(-1)\n",
    "\n",
    "# Train-test split (stratify for class balance)\n",
    "X_train, X_test, y_train, y_test_rf = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train model (Correctly named rf_model_3)\n",
    "rf_model_3 = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "rf_model_3.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_rf = rf_model_3.predict(X_test)\n",
    "y_pred_train_rf = rf_model_3.predict(X_train)\n",
    "\n",
    "# Evaluation\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_rf, y_pred_rf, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_rf, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_rf)\n",
    "test_accuracy = accuracy_score(y_test_rf, y_pred_rf)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(f\"Overfit Gap:          {train_accuracy - test_accuracy:.4f}\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a706d7e",
   "metadata": {},
   "source": [
    "A respectful increment.\n",
    "\n",
    "### Now, let's validate the results:\n",
    "\n",
    "Since RF is a very complex and time consuming ML, we'll need to use alternatie validation methods to ensure time and compuational efficiency.\n",
    "\n",
    "Method 1: Use Subsamples for Cross Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f537e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Take a manageable subsample\n",
    "sample_size = 100_000\n",
    "X_sub = X.sample(sample_size, random_state=42)\n",
    "y_sub = y[X_sub.index]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accs = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in skf.split(X_sub, y_sub):\n",
    "    X_train, X_test = X_sub.iloc[train_idx], X_sub.iloc[test_idx]\n",
    "    y_train, y_test = y_sub[train_idx], y_sub[test_idx]\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    acc = accuracy_score(y_test, rf.predict(X_test))\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    accs.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"K-Fold CV Accuracy Mean:\", np.mean(accs))\n",
    "print(\"Std:\", np.std(accs))\n",
    "print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf079b52",
   "metadata": {},
   "source": [
    "Method 2: Use Stratified Shuffle-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab4a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== Random Forest Cross-Validation: Stratified Shuffle-Split ===\")\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Mean Accuracy:  \", np.mean(accuracies))\n",
    "print(\"Std Deviation: \", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee42b4c",
   "metadata": {},
   "source": [
    "Plot the error versus complexity curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b0c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# --- 1. Subsample the data to 250k ---\n",
    "print(\"=== Subsampling Training Data ===\")\n",
    "# We verify we have enough data, then sample 250k without replacement\n",
    "n_samples = min(100000, len(X_train))\n",
    "X_train_sub, y_train_sub = resample(\n",
    "    X_train, y_train, \n",
    "    n_samples=n_samples, \n",
    "    replace=False, \n",
    "    random_state=42\n",
    ")\n",
    "print(f\"Training data reduced to: {X_train_sub.shape[0]} samples\")\n",
    "\n",
    "# --- 2. Define Depth Range (Complexity) ---\n",
    "# We range from depth 1 (very simple) to 25 (very complex)\n",
    "depth_settings = range(1, 501) #Adjust to larger value range if needed\n",
    "\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "print(\"=== Generating Error vs Complexity (Max Depth) Curve ===\")\n",
    "\n",
    "for d in depth_settings:\n",
    "    print(f\"Training model with max_depth={d}\")\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=50,  # Fixed: We isolate depth as the variable\n",
    "        max_depth=d,      # Variable: This controls complexity\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Fit on the subsampled data\n",
    "    rf.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "    # Predict\n",
    "    train_pred = rf.predict(X_train_sub)\n",
    "    test_pred  = rf.predict(X_test)\n",
    "\n",
    "    # Compute error (1 - accuracy)\n",
    "    train_err = 1 - accuracy_score(y_train_sub, train_pred)\n",
    "    test_err  = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "    train_errors.append(train_err)\n",
    "    test_errors.append(test_err)\n",
    "\n",
    "# --- 3. Plot ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plotting the curves\n",
    "plt.plot(depth_settings, train_errors, marker='o', label=\"Training Error\", color='blue')\n",
    "plt.plot(depth_settings, test_errors, marker='o', label=\"Testing Error\", color='red')\n",
    "\n",
    "# Formatting\n",
    "plt.xlabel(\"Model Complexity (max_depth)\")\n",
    "plt.ylabel(\"Error (1 - Accuracy)\")\n",
    "plt.title(\"Random Forest: Error vs. Max Depth\")\n",
    "plt.xticks(depth_settings) # Ensure we see all depth ticks\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a040cb6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    " ### Evaluate Feature Importance (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb9903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Feature Importance\n",
    "# -------------------------------------------\n",
    "importance = rf_model_3.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "fi = pd.DataFrame({\"feature\": features, \"importance\": importance})\n",
    "fi.sort_values(by=\"importance\", ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91be946",
   "metadata": {},
   "source": [
    "Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7d1b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the class names (optional, makes the plot readable)\n",
    "crime_labels = df_new_1[\"Crime_Class\"].unique()\n",
    "crime_labels.sort() # Ensure they are in the same order as factorize usually does\n",
    "\n",
    "# 2. Plot the matrix\n",
    "# Ensure you pass the predictions you just made (y_pred_test)\n",
    "plot_crime_matrix(y_test_rf, y_pred_rf, model_name=\"Random Forest\", labels=crime_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d418998f",
   "metadata": {},
   "source": [
    "### Probabilistic: Logistic Regression (Processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b36155fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding columns...\n",
      "Scaling data...\n",
      "Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "Training Set Accuracy: 0.8994830083597136\n",
      "Testing Set Accuracy: 0.8982978328214449\n",
      "------------------------------------------------------------------------------------\n",
      "Training Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.933845  0.935852  0.934847  356035.000000\n",
      "1              0.921360  0.962807  0.941628  163391.000000\n",
      "2              0.819256  0.529953  0.643588   44202.000000\n",
      "3              0.815259  0.950880  0.877862   86340.000000\n",
      "4              0.745560  0.700919  0.722551   13595.000000\n",
      "5              0.834315  0.513161  0.635467    8282.000000\n",
      "6              0.946154  0.905899  0.925589   15207.000000\n",
      "7              0.647402  0.605709  0.625861   13944.000000\n",
      "8              0.500000  0.003704  0.007353     540.000000\n",
      "9              0.634500  0.379663  0.475064    1957.000000\n",
      "accuracy       0.899483  0.899483  0.899483       0.899483\n",
      "macro avg      0.779765  0.648855  0.678981  703493.000000\n",
      "weighted avg   0.897804  0.899483  0.895185  703493.000000\n",
      "------------------------------------------------------------------------------------\n",
      "Testing Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.932686  0.935214  0.933948  152409.000000\n",
      "1              0.920374  0.962509  0.940970   70096.000000\n",
      "2              0.815895  0.518371  0.633961   18834.000000\n",
      "3              0.813814  0.950061  0.876676   37105.000000\n",
      "4              0.744178  0.700822  0.721850    5836.000000\n",
      "5              0.833333  0.512821  0.634921    3588.000000\n",
      "6              0.947057  0.902041  0.924001    6564.000000\n",
      "7              0.652027  0.607824  0.629150    6033.000000\n",
      "8              0.000000  0.000000  0.000000     206.000000\n",
      "9              0.589744  0.361548  0.448276     827.000000\n",
      "accuracy       0.898298  0.898298  0.898298       0.898298\n",
      "macro avg      0.724911  0.645121  0.674375  301498.000000\n",
      "weighted avg   0.896186  0.898298  0.893843  301498.000000\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. Setup Data\n",
    "# (Assuming df_new_1 is already loaded)\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# 2. Prepare X and y\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# 3. Pre-processing (Memory Safe Version)\n",
    "\n",
    "# A. Convert datetimes to int64 (if any exist)\n",
    "# Using 'view' on datetimes is fast and memory efficient\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].values.astype(np.int64)\n",
    "\n",
    "# B. Convert list columns to strings\n",
    "# (Necessary because lists are not hashable and break many functions)\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# C. Factorize Objects (The \"Pro\" way to avoid MemoryError)\n",
    "# We loop instead of using .apply() to save RAM\n",
    "print(\"Encoding columns...\")\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].astype('category').cat.codes\n",
    "\n",
    "# D. Handle Missing Values\n",
    "# Logistic Regression cannot handle NaNs. \n",
    "# Since we used cat.codes, NaNs are already -1, but we ensure everything is numeric.\n",
    "X = X.fillna(-1)\n",
    "\n",
    "# 4. Train-test split\n",
    "X_train, X_test, y_train, y_test_lr = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 5. Scale features \n",
    "# Logistic Regression works best when features are on the same scale (e.g., -1 to 1)\n",
    "print(\"Scaling data...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 6. Build Logistic Regression Model\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr_model_1 = LogisticRegression() # Default parameters\n",
    "\n",
    "# Train model\n",
    "lr_model_1.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 7. Predict\n",
    "print(\"Predicting...\")\n",
    "y_pred_train_1 = lr_model_1.predict(X_train_scaled)\n",
    "y_pred_test_lr = lr_model_1.predict(X_test_scaled)\n",
    "\n",
    "# 8. Evaluation\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_lr, y_pred_test_lr, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_1)\n",
    "test_accuracy = accuracy_score(y_test_lr, y_pred_test_lr)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe518e3",
   "metadata": {},
   "source": [
    "### Probabilistic: Naive Bayes (Processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "871599c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding columns...\n",
      "Scaling data (MinMax)...\n",
      "Training Multinomial Naive Bayes...\n",
      "Predicting...\n",
      "Training Set Accuracy: 0.871889272530075\n",
      "Testing Set Accuracy: 0.8713689643049042\n",
      "------------------------------------------------------------------------------------\n",
      "Training Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.935642  0.916253  0.925846  356035.000000\n",
      "1              0.886901  0.902675  0.894719  163391.000000\n",
      "2              0.672489  0.514750  0.583141   44202.000000\n",
      "3              0.822126  0.945321  0.879430   86340.000000\n",
      "4              0.502667  0.630747  0.559470   13595.000000\n",
      "5              0.778507  0.501207  0.609813    8282.000000\n",
      "6              0.903444  0.895246  0.899326   15207.000000\n",
      "7              0.534854  0.595382  0.563497   13944.000000\n",
      "8              0.085106  0.022222  0.035242     540.000000\n",
      "9              0.275608  0.324476  0.298052    1957.000000\n",
      "accuracy       0.871889  0.871889  0.871889       0.871889\n",
      "macro avg      0.639734  0.624828  0.624854  703493.000000\n",
      "weighted avg   0.872509  0.871889  0.870400  703493.000000\n",
      "------------------------------------------------------------------------------------\n",
      "Testing Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.935249  0.915760  0.925402  152409.000000\n",
      "1              0.887175  0.903490  0.895258   70096.000000\n",
      "2              0.668974  0.508071  0.577524   18834.000000\n",
      "3              0.820982  0.945263  0.878750   37105.000000\n",
      "4              0.500681  0.630055  0.557967    5836.000000\n",
      "5              0.792876  0.502508  0.615148    3588.000000\n",
      "6              0.903410  0.891987  0.897662    6564.000000\n",
      "7              0.535640  0.595392  0.563938    6033.000000\n",
      "8              0.000000  0.000000  0.000000     206.000000\n",
      "9              0.246976  0.296252  0.269379     827.000000\n",
      "accuracy       0.871369  0.871369  0.871369       0.871369\n",
      "macro avg      0.629196  0.618878  0.618103  301498.000000\n",
      "weighted avg   0.872053  0.871369  0.869848  301498.000000\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler  # <--- Changed from StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB   # <--- The Model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. Setup Data\n",
    "# (Assuming df_new_1 is already loaded)\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# 2. Prepare X and y\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# 3. Pre-processing (Memory Safe Version)\n",
    "\n",
    "# A. Convert datetimes to int64\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].values.astype(np.int64)\n",
    "\n",
    "# B. Convert list columns to strings\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# C. Factorize Objects (Using cat.codes for memory efficiency)\n",
    "print(\"Encoding columns...\")\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].astype('category').cat.codes\n",
    "\n",
    "# D. Handle Missing Values\n",
    "# We stick to your logic, but Naive Bayes hates -1.\n",
    "# We will fix the -1s in the Scaling step below.\n",
    "X = X.fillna(-1)\n",
    "\n",
    "# 4. Train-test split\n",
    "X_train, X_test, y_train, y_test_nb = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 5. Scale features \n",
    "# CRITICAL CHANGE: MultinomialNB fails with negative numbers.\n",
    "# StandardScaler produces negatives. MinMaxScaler (0, 1) fixes this.\n",
    "print(\"Scaling data (MinMax)...\")\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 6. Build Naive Bayes Model\n",
    "print(\"Training Multinomial Naive Bayes...\")\n",
    "nb_model_1 = MultinomialNB() \n",
    "\n",
    "# Train model\n",
    "nb_model_1.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 7. Predict\n",
    "print(\"Predicting...\")\n",
    "y_pred_train_1 = nb_model_1.predict(X_train_scaled)\n",
    "y_pred_test_nb = nb_model_1.predict(X_test_scaled)\n",
    "\n",
    "# 8. Evaluation\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_nb, y_pred_test_nb, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_1)\n",
    "test_accuracy = accuracy_score(y_test_nb, y_pred_test_nb)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aa4223",
   "metadata": {},
   "source": [
    "Perform Shuffle-Split Validation for both LR anmd NB models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7575b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Splitter (Same for both)\n",
    "# 5 Splits is a good balance between speed and reliability\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"=========================================================\")\n",
    "print(\"1. Logistic Regression Validation (StandardScaler)\")\n",
    "print(\"=========================================================\")\n",
    "\n",
    "lr_accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    # 1. Slice Data (Memory efficient indexing)\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # 2. Scale (Critical: Fit on Train, Transform Test)\n",
    "    # StandardScaler is best for Logistic Regression speed/convergence\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 3. Train (n_jobs=-1 uses all CPU cores for speed)\n",
    "    lr = LogisticRegression(n_jobs=-1) \n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # 4. Score\n",
    "    acc = accuracy_score(y_test, lr.predict(X_test_scaled))\n",
    "    \n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    lr_accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(f\"LR Mean Accuracy:  {np.mean(lr_accuracies):.8f}\")\n",
    "print(f\"LR Std Deviation:  {np.std(lr_accuracies):.8f}\")\n",
    "\n",
    "\n",
    "print(\"\\n=========================================================\")\n",
    "print(\"2. Multinomial Naive Bayes Validation (MinMaxScaler)\")\n",
    "print(\"=========================================================\")\n",
    "\n",
    "nb_accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    # 1. Slice Data\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # 2. Scale (MinMaxScaler is REQUIRED for NB to avoid negative errors)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 3. Train\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # 4. Score\n",
    "    acc = accuracy_score(y_test, nb.predict(X_test_scaled))\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    nb_accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(f\"NB Mean Accuracy:  {np.mean(nb_accuracies):.8f}\")\n",
    "print(f\"NB Std Deviation:  {np.std(nb_accuracies):.8f}\")\n",
    "print(\"---------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8671203a",
   "metadata": {},
   "source": [
    "Plot the error vs complexity curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94452a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import validation_curve, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# ==========================================\n",
    "# 1. Prepare Data (250K Subsample)\n",
    "# ==========================================\n",
    "print(\"Subsampling 250k rows...\")\n",
    "# Sample first to save time on preprocessing\n",
    "df_sub = df_new_1.sample(n=250000, random_state=42).copy()\n",
    "\n",
    "# Clean up leakage columns\n",
    "drop_cols = [\n",
    "    \"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\",\n",
    "    \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\", \"Crime_Class\"\n",
    "]\n",
    "cols_to_drop = [c for c in drop_cols if c in df_sub.columns]\n",
    "\n",
    "# Prepare X and y\n",
    "y, _ = pd.factorize(df_sub[\"Crime_Class\"])\n",
    "X = df_sub.drop(columns=cols_to_drop) # Drop target + leakage\n",
    "\n",
    "# --- Preprocessing (Optimized) ---\n",
    "# 1. Convert datetimes to int64\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].values.astype(np.int64)\n",
    "\n",
    "# 2. Convert list columns to strings\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# 3. Factorize Objects (cat.codes)\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].astype('category').cat.codes\n",
    "\n",
    "# 4. Handle NaNs/Negatives\n",
    "# Logistic Regression handles -1 fine (as a number), \n",
    "# but NB needs positive. We'll rely on MinMaxScaler for NB later.\n",
    "X = X.fillna(-1)\n",
    "\n",
    "# ==========================================\n",
    "# 2. Setup Models & Validation\n",
    "# ==========================================\n",
    "\n",
    "# Splitter: 3 splits is enough for a curve plot (saves time vs 5)\n",
    "cv_split = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "\n",
    "# Pipeline 1: Logistic Regression (Standard Scaler)\n",
    "pipe_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LogisticRegression(max_iter=1000, n_jobs=-1))\n",
    "])\n",
    "# Test C from 0.001 (Simple) to 100 (Complex)\n",
    "param_range_lr = np.logspace(-3, 5, 9) \n",
    "\n",
    "# Pipeline 2: Naive Bayes (MinMax Scaler)\n",
    "pipe_nb = Pipeline([\n",
    "    ('scaler', MinMaxScaler()), # Fixes negative numbers for NB\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "# Test Alpha from 0.001 (Complex) to 100 (Simple)\n",
    "param_range_nb = np.logspace(-3, 5, 9) \n",
    "\n",
    "# ==========================================\n",
    "# 3. Compute Curves\n",
    "# ==========================================\n",
    "print(\"Computing LR Complexity Curve...\")\n",
    "train_scores_lr, test_scores_lr = validation_curve(\n",
    "    pipe_lr, X, y, \n",
    "    param_name=\"lr__C\", \n",
    "    param_range=param_range_lr,\n",
    "    scoring=\"neg_log_loss\", \n",
    "    cv=cv_split, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Computing NB Complexity Curve...\")\n",
    "train_scores_nb, test_scores_nb = validation_curve(\n",
    "    pipe_nb, X, y, \n",
    "    param_name=\"nb__alpha\", \n",
    "    param_range=param_range_nb,\n",
    "    scoring=\"neg_log_loss\", \n",
    "    cv=cv_split, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Helper to process scores (flip sign for Log Loss)\n",
    "def process_scores(scores):\n",
    "    return -np.mean(scores, axis=1), np.std(scores, axis=1)\n",
    "\n",
    "train_mean_lr, train_std_lr = process_scores(train_scores_lr)\n",
    "test_mean_lr, test_std_lr = process_scores(test_scores_lr)\n",
    "train_mean_nb, train_std_nb = process_scores(train_scores_nb)\n",
    "test_mean_nb, test_std_nb = process_scores(test_scores_nb)\n",
    "\n",
    "# ==========================================\n",
    "# 4. Plotting\n",
    "# ==========================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# LR Plot\n",
    "axes[0].plot(param_range_lr, train_mean_lr, label=\"Training\", color=\"darkorange\", marker='o')\n",
    "axes[0].plot(param_range_lr, test_mean_lr, label=\"Validation\", color=\"navy\", marker='o')\n",
    "axes[0].fill_between(param_range_lr, train_mean_lr - train_std_lr, train_mean_lr + train_std_lr, alpha=0.2, color=\"darkorange\")\n",
    "axes[0].fill_between(param_range_lr, test_mean_lr - test_std_lr, test_mean_lr + test_std_lr, alpha=0.2, color=\"navy\")\n",
    "axes[0].set_title(\"Logistic Regression (Parameter: C)\")\n",
    "axes[0].set_xlabel(\"C (Low=Regulated, High=Complex)\")\n",
    "axes[0].set_ylabel(\"Log Loss (Lower is Better)\")\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# NB Plot\n",
    "axes[1].plot(param_range_nb, train_mean_nb, label=\"Training\", color=\"darkorange\", marker='o')\n",
    "axes[1].plot(param_range_nb, test_mean_nb, label=\"Validation\", color=\"navy\", marker='o')\n",
    "axes[1].fill_between(param_range_nb, train_mean_nb - train_std_nb, train_mean_nb + train_std_nb, alpha=0.2, color=\"darkorange\")\n",
    "axes[1].fill_between(param_range_nb, test_mean_nb - test_std_nb, test_mean_nb + test_std_nb, alpha=0.2, color=\"navy\")\n",
    "axes[1].set_title(\"Naive Bayes (Parameter: Alpha)\")\n",
    "axes[1].set_xlabel(\"Alpha (Low=Complex, High=Smoothed)\")\n",
    "axes[1].set_ylabel(\"Log Loss (Lower is Better)\")\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f0e46",
   "metadata": {},
   "source": [
    "Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9b02fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the class names (optional, makes the plot readable)\n",
    "crime_labels = df_new_1[\"Crime_Class\"].unique()\n",
    "crime_labels.sort() # Ensure they are in the same order as factorize usually does\n",
    "\n",
    "# 2. Plot the matrix\n",
    "# Ensure you pass the predictions you just made (y_pred_test)\n",
    "plot_crime_matrix(y_test_lr, y_pred_test_lr, model_name=\"Logistic Regression\", labels=crime_labels)\n",
    "plot_crime_matrix(y_test_nb, y_pred_test_nb, model_name=\"Naive Bayes\", labels=crime_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26d7540",
   "metadata": {},
   "source": [
    "### XGBoost (Processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f718670c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 0.9191321022384018\n",
      "Testing Set Accuracy: 0.9145267961976531\n",
      "------------------------------------------------------------------------------------\n",
      "Training Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.955065  0.936473  0.945677  356035.000000\n",
      "1              0.942535  0.977135  0.959523  163391.000000\n",
      "2              0.849471  0.655966  0.740282   44202.000000\n",
      "3              0.819817  0.959254  0.884071   86340.000000\n",
      "4              0.804821  0.788305  0.796477   13595.000000\n",
      "5              0.878661  0.608549  0.719075    8282.000000\n",
      "6              0.944647  0.938186  0.941405   15207.000000\n",
      "7              0.740664  0.741036  0.740850   13944.000000\n",
      "8              0.955556  0.079630  0.147009     540.000000\n",
      "9              0.777055  0.671436  0.720395    1957.000000\n",
      "accuracy       0.919132  0.919132  0.919132       0.919132\n",
      "macro avg      0.866829  0.735597  0.759476  703493.000000\n",
      "weighted avg   0.920148  0.919132  0.917484  703493.000000\n",
      "------------------------------------------------------------------------------------\n",
      "Testing Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.953182  0.934814  0.943908  152409.000000\n",
      "1              0.938243  0.973379  0.955488   70096.000000\n",
      "2              0.827347  0.638367  0.720674   18834.000000\n",
      "3              0.817662  0.956448  0.881627   37105.000000\n",
      "4              0.785240  0.769363  0.777220    5836.000000\n",
      "5              0.850962  0.591973  0.698225    3588.000000\n",
      "6              0.934502  0.925960  0.930211    6564.000000\n",
      "7              0.726254  0.719874  0.723050    6033.000000\n",
      "8              0.000000  0.000000  0.000000     206.000000\n",
      "9              0.714072  0.576784  0.638127     827.000000\n",
      "accuracy       0.914527  0.914527  0.914527       0.914527\n",
      "macro avg      0.754746  0.708696  0.726853  301498.000000\n",
      "weighted avg   0.914448  0.914527  0.912639  301498.000000\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# ---- FIX 1: Convert datetime columns to int64 ----\n",
    "for col in X.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "# ---- FIX 2: Convert lists → strings to make them hashable ----\n",
    "for col in X.columns:\n",
    "\t    if X[col].dtype == 'object':\n",
    "\t        X[col] = X[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "# ---- Factorize object columns ----\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test_xgb = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model_2 = XGBClassifier()\n",
    "\n",
    "xgb_model_2.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = xgb_model_2.predict(X_train)\n",
    "y_pred_xgb = xgb_model_2.predict(X_test)\n",
    "\n",
    "# Evaluation reports\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_xgb, y_pred_xgb, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test_xgb, y_pred_xgb)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbfd895",
   "metadata": {},
   "source": [
    "Good Increase.\n",
    "\n",
    "### Validate the results:\n",
    "\n",
    "We'll apply the samne validation methods to ensure time and compuational efficiency.\n",
    "\n",
    "Method 1: Use Subsamples for Cross Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd9efff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Take a manageable subsample\n",
    "sample_size = 100_000\n",
    "X_sub = X.sample(sample_size, random_state=42)\n",
    "y_sub = y[X_sub.index]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accs = []\n",
    "fold = 1\n",
    "\n",
    "print(\"=== XGBoost Stratified K-Fold Validation ===\")\n",
    "\n",
    "for train_idx, test_idx in skf.split(X_sub, y_sub):\n",
    "    X_train, X_test = X_sub.iloc[train_idx], X_sub.iloc[test_idx]\n",
    "    y_train, y_test = y_sub[train_idx], y_sub[test_idx]\n",
    "\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=100,           # you can adjust\n",
    "        max_depth=6,                # default is 6\n",
    "        learning_rate=0.1,          # default\n",
    "        n_jobs=-1,\n",
    "        use_label_encoder=False,    # avoids warning\n",
    "        eval_metric=\"mlogloss\",     # for multiclass\n",
    "        tree_method=\"hist\",         # faster for large datasets\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    acc = accuracy_score(y_test, xgb_model.predict(X_test))\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    accs.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"K-Fold CV Accuracy Mean:\", np.mean(accs))\n",
    "print(\"Std:\", np.std(accs))\n",
    "print(\"---------------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db664690",
   "metadata": {},
   "source": [
    "Method 2: Use Stratified Shuffle-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba8528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== XGBoost Cross-Validation: Stratified Shuffle-Split ===\")\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=100,           # adjust as needed\n",
    "        max_depth=6,                # adjust as needed\n",
    "        learning_rate=0.1,\n",
    "        n_jobs=-1,\n",
    "        use_label_encoder=False,    # avoids warning\n",
    "        eval_metric=\"mlogloss\",     # suitable for multiclass\n",
    "        tree_method=\"hist\",         # faster for large datasets\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Mean Accuracy:  \", np.mean(accuracies))\n",
    "print(\"Std Deviation: \", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c841738",
   "metadata": {},
   "source": [
    "Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the class names (optional, makes the plot readable)\n",
    "crime_labels = df_new_1[\"Crime_Class\"].unique()\n",
    "crime_labels.sort() # Ensure they are in the same order as factorize usually does\n",
    "\n",
    "# 2. Plot the matrix\n",
    "# Ensure you pass the predictions you just made (y_pred_test)\n",
    "plot_crime_matrix(y_test_xgb, y_pred_xgb, model_name=\"XGBoost\", labels=crime_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca84b24",
   "metadata": {},
   "source": [
    "#### Plot the Complexity vs Error Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9510e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "for col in X.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        X[col] = X[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# OPTIONAL: SUBSAMPLE 250K rows for SPEED\n",
    "# ============================================================\n",
    "\n",
    "subset = 250_000\n",
    "# Convert y_train into a Pandas Series with matching indices\n",
    "y_train_series = pd.Series(y_train, index=X_train.index)\n",
    "\n",
    "subset = 250_000\n",
    "if len(X_train) > subset:\n",
    "    X_train_sub = X_train.sample(subset, random_state=42)\n",
    "    y_train_sub = y_train_series.loc[X_train_sub.index]\n",
    "else:\n",
    "    X_train_sub = X_train\n",
    "    y_train_sub = y_train_series\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CREATE CURVE (DEPTH 1 to 50)\n",
    "# ============================================================\n",
    "\n",
    "max_depths = range(1, 51)\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for d in max_depths:\n",
    "    print(f\"Training XGBoost with max_depth={d} ...\")\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        max_depth=d,\n",
    "        objective=\"multi:softprob\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        num_class=len(np.unique(y)),\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "    # Predict PROBABILITIES\n",
    "    y_train_prob = model.predict_proba(X_train_sub)\n",
    "    y_test_prob = model.predict_proba(X_test)\n",
    "\n",
    "    # Log-loss\n",
    "    train_losses.append(log_loss(y_train_sub, y_train_prob))\n",
    "    test_losses.append(log_loss(y_test, y_test_prob))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PLOT THE CURVE\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(max_depths, train_losses, label=\"Training Log-Loss\")\n",
    "plt.plot(max_depths, test_losses, label=\"Validation Log-Loss\")\n",
    "plt.xlabel(\"Model Complexity (max_depth)\")\n",
    "plt.ylabel(\"Log-Loss Error\")\n",
    "plt.title(\"XGBoost Complexity Curve (1–50 Depth)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec435b1",
   "metadata": {},
   "source": [
    "### Evaluate Feature Importance (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf9f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Feature Importance\n",
    "# -------------------------------------------\n",
    "importance = xgb_model_2.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "fi = pd.DataFrame({\"feature\": features, \"importance\": importance})\n",
    "fi.sort_values(by=\"importance\", ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763c6878",
   "metadata": {},
   "source": [
    "## Category: Deep Learning Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb19d92c",
   "metadata": {},
   "source": [
    "\n",
    "### Neural Networks: CNN (Proessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aeb1c82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Temp\\ipykernel_31080\\2039213715.py:10: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  X[col] = X[col].view(\"int64\")\n",
      "c:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 9ms/step - accuracy: 0.9010 - loss: 0.3124 - val_accuracy: 0.9098 - val_loss: 0.2767\n",
      "Epoch 2/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 9ms/step - accuracy: 0.9087 - loss: 0.2798 - val_accuracy: 0.9122 - val_loss: 0.2642\n",
      "Epoch 3/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 10ms/step - accuracy: 0.9106 - loss: 0.2726 - val_accuracy: 0.9130 - val_loss: 0.2613\n",
      "Epoch 4/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 9ms/step - accuracy: 0.9112 - loss: 0.2689 - val_accuracy: 0.9124 - val_loss: 0.2619\n",
      "Epoch 5/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 9ms/step - accuracy: 0.9119 - loss: 0.2665 - val_accuracy: 0.9138 - val_loss: 0.2584\n",
      "Epoch 6/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 10ms/step - accuracy: 0.9125 - loss: 0.2645 - val_accuracy: 0.9138 - val_loss: 0.2575\n",
      "Epoch 7/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 10ms/step - accuracy: 0.9128 - loss: 0.2629 - val_accuracy: 0.9144 - val_loss: 0.2563\n",
      "Epoch 8/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 10ms/step - accuracy: 0.9130 - loss: 0.2623 - val_accuracy: 0.9143 - val_loss: 0.2595\n",
      "Epoch 9/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 10ms/step - accuracy: 0.9132 - loss: 0.2619 - val_accuracy: 0.9139 - val_loss: 0.2593\n",
      "Epoch 10/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 10ms/step - accuracy: 0.9134 - loss: 0.2612 - val_accuracy: 0.9146 - val_loss: 0.2575\n",
      "\u001b[1m21985/21985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 4ms/step\n",
      "\u001b[1m9422/9422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 0.9159124539974101\n",
      "Testing Set Accuracy: 0.9129015781199212\n",
      "------------------------------------------------------------------------------------\n",
      "Training Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.958800  0.935751  0.947135  356035.000000\n",
      "1              0.946160  0.968646  0.957271  163391.000000\n",
      "2              0.849495  0.637958  0.728685   44202.000000\n",
      "3              0.819986  0.958663  0.883918   86340.000000\n",
      "4              0.768069  0.796543  0.782047   13595.000000\n",
      "5              0.783788  0.596595  0.677499    8282.000000\n",
      "6              0.949414  0.917012  0.932932   15207.000000\n",
      "7              0.619571  0.805077  0.700246   13944.000000\n",
      "8              0.000000  0.000000  0.000000     540.000000\n",
      "9              0.715616  0.510475  0.595884    1957.000000\n",
      "accuracy       0.915912  0.915912  0.915912       0.915912\n",
      "macro avg      0.741090  0.712672  0.720562  703493.000000\n",
      "weighted avg   0.917874  0.915912  0.914735  703493.000000\n",
      "------------------------------------------------------------------------------------\n",
      "Testing Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.957212  0.934420  0.945679  152409.000000\n",
      "1              0.943608  0.967045  0.955183   70096.000000\n",
      "2              0.836080  0.622332  0.713542   18834.000000\n",
      "3              0.818088  0.956394  0.881851   37105.000000\n",
      "4              0.762269  0.785127  0.773529    5836.000000\n",
      "5              0.776086  0.582497  0.665499    3588.000000\n",
      "6              0.948279  0.910573  0.929043    6564.000000\n",
      "7              0.606813  0.794298  0.688011    6033.000000\n",
      "8              0.000000  0.000000  0.000000     206.000000\n",
      "9              0.670690  0.470375  0.552950     827.000000\n",
      "accuracy       0.912902  0.912902  0.912902       0.912902\n",
      "macro avg      0.731912  0.702306  0.710529  301498.000000\n",
      "weighted avg   0.914786  0.912902  0.911624  301498.000000\n",
      "------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model_2 = df_new.copy()\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# ---- FIX 1: Convert datetime columns to int64 ----\n",
    "for col in X.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "# ---- FIX 2: Convert lists → strings to make them hashable ----\n",
    "for col in X.columns:\n",
    "\t    if X[col].dtype == 'object':\n",
    "\t        X[col] = X[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ====== RESHAPE FOR CNN (Conv1D needs shape: samples, timesteps, features) ======\n",
    "X_train_cnn = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
    "X_test_cnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# ====== BUILD CNN MODEL ======\n",
    "cnn_model_2 = Sequential([\n",
    "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model_2.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ====== TRAIN ======\n",
    "history = cnn_model_2.fit(\n",
    "    X_train_cnn, y_train_cat,\n",
    "    epochs=10,              # Use epoch size = 10, since the datset is fairly large. Fewer epochs means less strain and timne\n",
    "    batch_size=32,          #Default values is 32.\n",
    "    validation_split=0.2,   #Keras default is 0.0\n",
    "    verbose=1               #Keras default is 1\n",
    ")\n",
    "\n",
    "# ====== PREDICT ======\n",
    "y_pred_train = cnn_model_2.predict(X_train_cnn).argmax(axis=1)\n",
    "y_pred_test = cnn_model_2.predict(X_test_cnn).argmax(axis=1)\n",
    "\n",
    "# ====== EVALUATION ======\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1306a064",
   "metadata": {},
   "source": [
    "#### Perform Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af92eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Use a smaller subsample if your dataset is very large\n",
    "sample_size = 100_000\n",
    "X_sub = X.sample(sample_size, random_state=42)\n",
    "y_sub = y[X_sub.index]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_sub)\n",
    "\n",
    "# Reshape for Conv1D\n",
    "X_cnn = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y_sub))\n",
    "y_cat = to_categorical(y_sub, num_classes)\n",
    "\n",
    "# Stratified Shuffle-Split\n",
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=42)  # fewer splits due to time\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X_cnn, y_sub):\n",
    "    print(f\"=== Fold {fold} ===\")\n",
    "    \n",
    "    X_train, X_test = X_cnn[train_idx], X_cnn[test_idx]\n",
    "    y_train, y_test = y_cat[train_idx], y_cat[test_idx]\n",
    "\n",
    "    # Build CNN model\n",
    "    cnn_model = Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    cnn_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    cnn_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=5,           # keep low for faster CV\n",
    "        batch_size=32,\n",
    "        verbose=0           # silent training for CV\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = cnn_model.predict(X_test).argmax(axis=1)\n",
    "    y_true = y_sub[test_idx]\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Fold {fold} Accuracy: {acc:.4f}\")\n",
    "    accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"CV Accuracy Mean:\", np.mean(accuracies))\n",
    "print(\"CV Accuracy Std:\", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03af14a9",
   "metadata": {},
   "source": [
    "#### Plot the error versus complexity curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683d7db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Use a smaller subsample for speed\n",
    "sample_size = 50_000  # adjust as needed\n",
    "X_sub = X.sample(sample_size, random_state=42)\n",
    "y_sub = y[X_sub.index]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_sub)\n",
    "\n",
    "# Reshape for Conv1D\n",
    "X_cnn = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y_sub))\n",
    "y_cat = to_categorical(y_sub, num_classes)\n",
    "\n",
    "# Complexity levels (number of filters in first Conv1D layer)\n",
    "complexity_values = [8, 16, 32, 64, 128]\n",
    "\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "print(\"=== Generating CNN Error vs Complexity Curve ===\")\n",
    "\n",
    "for filters in complexity_values:\n",
    "    print(f\"Training CNN with {filters} filters in first Conv1D layer\")\n",
    "\n",
    "    # Build CNN model\n",
    "    cnn_model = Sequential([\n",
    "        Conv1D(filters, kernel_size=3, activation='relu', input_shape=(X_cnn.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters*2, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    cnn_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Train (fewer epochs for faster evaluation)\n",
    "    cnn_model.fit(\n",
    "        X_cnn, y_cat,\n",
    "        epochs=5,\n",
    "        batch_size=32,\n",
    "        verbose=0  # silent training\n",
    "    )\n",
    "\n",
    "    # Predict\n",
    "    y_pred_train = cnn_model.predict(X_cnn).argmax(axis=1)\n",
    "    y_true = y_sub\n",
    "    train_err = 1 - accuracy_score(y_true, y_pred_train)\n",
    "\n",
    "    # Optional: split a small testing subset for speed\n",
    "    test_idx = np.random.choice(len(X_cnn), size=int(0.2*len(X_cnn)), replace=False)\n",
    "    X_test_small = X_cnn[test_idx]\n",
    "    y_test_small = y_sub[test_idx]\n",
    "    y_test_cat_small = y_cat[test_idx]\n",
    "\n",
    "    y_pred_test = cnn_model.predict(X_test_small).argmax(axis=1)\n",
    "    test_err = 1 - accuracy_score(y_test_small, y_pred_test)\n",
    "\n",
    "    train_errors.append(train_err)\n",
    "    test_errors.append(test_err)\n",
    "\n",
    "# ---- Plot ----\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(complexity_values, train_errors, marker='o', label=\"Training Error\")\n",
    "plt.plot(complexity_values, test_errors, marker='o', label=\"Testing Error\")\n",
    "plt.xlabel(\"CNN Complexity (Number of Filters in First Conv1D Layer)\")\n",
    "plt.ylabel(\"Error (1 - Accuracy)\")\n",
    "plt.title(\"CNN Error vs Complexity Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f653bf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====== COMPUTE PROBABILITIES ======\n",
    "train_proba = cnn_model_2.predict(X_train_cnn)\n",
    "test_proba  = cnn_model_2.predict(X_test_cnn)\n",
    "\n",
    "# ====== COMPUTE LOG LOSS ======\n",
    "train_loss = log_loss(y_train, train_proba)\n",
    "test_loss  = log_loss(y_test,  test_proba)\n",
    "\n",
    "print(\"------------------------\")\n",
    "print(\"Training Loss\")\n",
    "print(train_loss)\n",
    "print(\"------------------------\")\n",
    "print(\"Testing Loss:\")\n",
    "print(test_loss)\n",
    "print(\"------------------------\")\n",
    "print(\":)\")\n",
    "acc_gap  = train_accuracy - test_accuracy\n",
    "loss_gap = test_loss - train_loss\n",
    "print(\"------------------------\")\n",
    "print(\"Accuracy Gap:\")\n",
    "print(acc_gap)\n",
    "print(\"------------------------\")\n",
    "print(\"Loss Gap:\")\n",
    "print(loss_gap)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# ====== PLOT TRAINING vs VALIDATION LOSS FROM HISTORY ======\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss Curve (CNN)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef14ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "# ======================================================\n",
    "# 1. TAKE A SMALL SUBSET TO AVOID HOURS OF TRAINING\n",
    "# ======================================================\n",
    "subset = 50000   # Use 50k rows for speed (change if needed)\n",
    "\n",
    "X_train_sub = X_train_cnn[:subset]\n",
    "y_train_sub = y_train[:subset]\n",
    "y_train_sub_cat = y_train_cat[:subset]\n",
    "\n",
    "X_val_sub = X_test_cnn[:20000]\n",
    "y_val_sub = y_test[:20000]\n",
    "y_val_sub_cat = y_test_cat[:20000]\n",
    "\n",
    "# ======================================================\n",
    "# 2. DEFINE COMPLEXITY LEVELS (NUMBER OF FILTERS)\n",
    "# ======================================================\n",
    "complexities = [8, 16, 32, 64, 128]\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "# ======================================================\n",
    "# 3. LOOP THROUGH MODEL COMPLEXITIES\n",
    "# ======================================================\n",
    "for filters in complexities:\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv1D(filters, kernel_size=3, activation='relu',\n",
    "               input_shape=(X_train_sub.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "\n",
    "        Conv1D(filters*2, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # short training for speed\n",
    "    model.fit(\n",
    "        X_train_sub, y_train_sub_cat,\n",
    "        epochs=3,          # small number for speed\n",
    "        batch_size=64,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Predictions\n",
    "    train_proba = model.predict(X_train_sub, verbose=0)\n",
    "    test_proba  = model.predict(X_val_sub,   verbose=0)\n",
    "\n",
    "    y_train_pred = np.argmax(train_proba, axis=1)\n",
    "    y_test_pred  = np.argmax(test_proba, axis=1)\n",
    "\n",
    "    # Metrics\n",
    "    train_losses.append(log_loss(y_train_sub, train_proba))\n",
    "    test_losses.append(log_loss(y_val_sub,  test_proba))\n",
    "\n",
    "    train_accs.append(accuracy_score(y_train_sub, y_train_pred))\n",
    "    test_accs.append(accuracy_score(y_val_sub,  y_test_pred))\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 4. PLOT COMPLEXITY vs ERROR\n",
    "# ======================================================\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(complexities, train_losses, label=\"Training Loss\")\n",
    "plt.plot(complexities, test_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Model Complexity (Number of Filters)\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.title(\"CNN Model Complexity vs Error\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0114b1da",
   "metadata": {},
   "source": [
    "### Neural Network: ANN (Processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee57316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Temp\\ipykernel_31080\\2866109942.py:10: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  X[col] = X[col].view(\"int64\")\n",
      "c:\\Users\\wongj_gwtzhu8\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8754 - loss: 0.4091"
     ]
    }
   ],
   "source": [
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model_2 = df_new.copy()\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# ---- FIX 1: Convert datetime columns to int64 ----\n",
    "for col in X.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "# ---- FIX 2: Convert lists → strings to make them hashable ----\n",
    "for col in X.columns:\n",
    "\t    if X[col].dtype == 'object':\n",
    "\t        X[col] = X[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# ====== BUILD ANN MODEL ======\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ====== TRAIN ======\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_cat,\n",
    "    epochs=10,              #Use 10 as a derfault value for epochs\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ====== PREDICT ======\n",
    "y_pred_train = model.predict(X_train_scaled).argmax(axis=1)\n",
    "y_pred_test = model.predict(X_test_scaled).argmax(axis=1)\n",
    "\n",
    "# ====== EVALUATION ======\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2354f92b",
   "metadata": {},
   "source": [
    "Validation Time. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d469d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# Optional subsample for speed (same as CNN version)\n",
    "# ============================================================\n",
    "sample_size = 100_000\n",
    "X_sub = X.sample(sample_size, random_state=42)\n",
    "y_sub = y[X_sub.index]\n",
    "\n",
    "# ============================================================\n",
    "# Scale features\n",
    "# ============================================================\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_sub)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y_sub))\n",
    "y_cat = to_categorical(y_sub, num_classes)\n",
    "\n",
    "# ============================================================\n",
    "# Stratified Shuffle-Split\n",
    "# ============================================================\n",
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X_scaled, y_sub):\n",
    "    print(f\"=== Fold {fold} ===\")\n",
    "\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y_cat[train_idx], y_cat[test_idx]\n",
    "\n",
    "    # ============================================================\n",
    "    # Build ANN model (matching your original architecture)\n",
    "    # ============================================================\n",
    "    ann_model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    ann_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Train (silent for CV)\n",
    "    ann_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=5,          # reduced for faster CV, same as CNN version\n",
    "        batch_size=32,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Predict + evaluate\n",
    "    y_pred = ann_model.predict(X_test).argmax(axis=1)\n",
    "    y_true = y_sub[test_idx]\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"Fold {fold} Accuracy: {acc:.4f}\")\n",
    "    accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "# ============================================================\n",
    "# Summary\n",
    "# ============================================================\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"CV Accuracy Mean:\", np.mean(accuracies))\n",
    "print(\"CV Accuracy Std:\", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3d7f3d",
   "metadata": {},
   "source": [
    "Curve Check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a8794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ============================================================\n",
    "# 1. Prepare Data (Updated for 250k)\n",
    "# ============================================================\n",
    "print(\"=== Preparing Data ===\")\n",
    "# Ensure we don't sample more than we have\n",
    "sample_size = min(250_000, len(X))\n",
    "\n",
    "# Assuming X is a DataFrame (based on your .sample code)\n",
    "X_sub = X.sample(n=sample_size, random_state=42)\n",
    "y_sub = y[X_sub.index] # Align y with X\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_sub)\n",
    "\n",
    "num_classes = len(np.unique(y_sub))\n",
    "y_cat = to_categorical(y_sub, num_classes)\n",
    "\n",
    "# Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled, y_cat, test_size=0.3, random_state=42, stratify=y_sub\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Complexity levels (Wider Range)\n",
    "# ============================================================\n",
    "# We go from very simple (10) to very complex (800) to force the curve\n",
    "complexity_levels = [10, 50, 150, 400, 800]\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(f\"=== Starting Training Loop (Subsample: {sample_size}) ===\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. Train ANN for each complexity level\n",
    "# ============================================================\n",
    "for units in complexity_levels:\n",
    "    print(f\"Training model with {units} neurons...\")\n",
    "\n",
    "    model = Sequential([\n",
    "        # INCREASED COMPLEXITY:\n",
    "        # We use a single massive layer.\n",
    "        # CRITICAL: We REMOVED Dropout to allow overfitting.\n",
    "        Dense(units, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # INCREASED EPOCHS:\n",
    "    # We need enough time for the big models to memorize the noise.\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=20,  # Increased from 5 to 20\n",
    "        batch_size=64, # Slightly larger batch for speed\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Store final epoch losses\n",
    "    train_losses.append(history.history['loss'][-1])\n",
    "    val_losses.append(history.history['val_loss'][-1])\n",
    "\n",
    "# ============================================================\n",
    "# 4. Plot Error vs Complexity\n",
    "# ============================================================\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot lines\n",
    "plt.plot(complexity_levels, train_losses, marker='o', label='Training Loss (Bias)', color='blue')\n",
    "plt.plot(complexity_levels, val_losses, marker='o', label='Validation Loss (Variance)', color='orange')\n",
    "\n",
    "plt.title(\"Bias-Variance Tradeoff: ANN Complexity\")\n",
    "plt.xlabel(\"Model Complexity (Neurons in Hidden Layer)\")\n",
    "plt.ylabel(\"Log Loss (Lower is Better)\")\n",
    "plt.xticks(complexity_levels) # Show exact x-axis values\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefb4b3c",
   "metadata": {},
   "source": [
    "## Part B - Parameters\n",
    "\n",
    "### Now, let's implement Hyperparameter Tuning:\n",
    "\n",
    "This will take a while as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cd37ea",
   "metadata": {},
   "source": [
    "### Naive Bayes (Processed & Tunned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a1b022",
   "metadata": {},
   "source": [
    "WARNING: DO NOT ATTEMPT THIS using the full 1 Milliom. Unless you'd like your laptop to crash over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f13379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 1. Setup Data (Assuming df_new_1 already exists)\n",
    "# ----------------------------------------------------\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. Prepare X and y\n",
    "# ----------------------------------------------------\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. Pre-processing (Memory Safe)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# A. Datetime → int64\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].values.astype(np.int64)\n",
    "\n",
    "# B. List columns → str\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# C. Object columns → category codes\n",
    "print(\"Encoding columns...\")\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        X[col] = X[col].astype(\"category\").cat.codes\n",
    "\n",
    "# D. Missing values → -1\n",
    "# (safe because MinMaxScaler shifts everything to 0–1)\n",
    "X = X.fillna(-1)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4. Train–Test Split\n",
    "# ----------------------------------------------------\n",
    "X_train, X_test, y_train, y_test_nb = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 5. Scaling\n",
    "# ----------------------------------------------------\n",
    "print(\"Scaling data (MinMax)...\")\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 6. Manual Alpha Search (Safe & Lightweight)\n",
    "# ----------------------------------------------------\n",
    "alphas = [0.1, 0.5, 1.0, 2.0, 5.0,10.0]\n",
    "best_alpha = None\n",
    "best_acc = 0\n",
    "\n",
    "print(\"\\nSearching for best alpha...\")\n",
    "\n",
    "for alpha in alphas:\n",
    "    model = MultinomialNB(alpha=alpha)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test_nb, y_pred)\n",
    "\n",
    "    print(f\"Alpha={alpha} → Test Accuracy={acc:.4f}\")\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(f\"\\nBest Alpha Found: {best_alpha} (Accuracy={best_acc:.4f})\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 7. Train Final Model\n",
    "# ----------------------------------------------------\n",
    "print(\"\\nTraining final MultinomialNB model...\")\n",
    "nb_model_1 = MultinomialNB(alpha=best_alpha)\n",
    "nb_model_1.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "print(\"Predicting...\")\n",
    "y_pred_train_1 = nb_model_1.predict(X_train_scaled)\n",
    "y_pred_test_nb = nb_model_1.predict(X_test_scaled)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 8. Evaluation\n",
    "# ----------------------------------------------------\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_1)\n",
    "test_accuracy = accuracy_score(y_test_nb, y_pred_test_nb)\n",
    "\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_nb, y_pred_test_nb, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed723e94",
   "metadata": {},
   "source": [
    "### XGBoost (Processed & Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325e5aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== FAST & MEMORY-EFFICIENT XGBOOST TRAINING ===\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# ============================================================\n",
    "# PREPROCESSING (same as before)\n",
    "# ============================================================\n",
    "\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "# Keep y as a pandas Series instead of numpy array\n",
    "y = pd.Series(pd.factorize(df_model_2[\"Crime_Class\"])[0])\n",
    "\n",
    "\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "X = X.astype(\"float32\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# TINY SUBSAMPLE FOR FAST TUNING\n",
    "# ============================================================\n",
    "\n",
    "tune_size = 10000\n",
    "X_tune = X_train.sample(tune_size, random_state=42)\n",
    "y_tune = y_train[X_tune.index]\n",
    "\n",
    "print(f\"Tuning using {len(X_tune):,} rows\")\n",
    "\n",
    "# ============================================================\n",
    "# FAST XGBOOST RANDOMIZED SEARCH\n",
    "# ============================================================\n",
    "\n",
    "xgb_base = XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=len(np.unique(y)),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"max_depth\": randint(4, 10),\n",
    "    \"learning_rate\": uniform(0.03, 0.2),\n",
    "    \"min_child_weight\": randint(1, 6),\n",
    "    \"subsample\": uniform(0.5, 0.5),\n",
    "    \"colsample_bytree\": uniform(0.5, 0.5),\n",
    "    \"n_estimators\": randint(150, 400)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    xgb_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=15,        # FAST\n",
    "    cv=2,\n",
    "    scoring=\"accuracy\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search.fit(X_tune, y_tune)\n",
    "\n",
    "print(\"\\nBest Params:\", search.best_params_)\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN FINAL MODEL ON FULL DATASET\n",
    "# ============================================================\n",
    "\n",
    "xgb_final = XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=len(np.unique(y)),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    **search.best_params_\n",
    ")\n",
    "\n",
    "xgb_final.fit(X_train, y_train)\n",
    "\n",
    "# ============================================================\n",
    "# EVALUATION\n",
    "# ============================================================\n",
    "\n",
    "y_pred_train = xgb_final.predict(X_train)\n",
    "y_pred_test = xgb_final.predict(X_test)\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "print(\"\\nTRAIN REPORT\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "print(\"\\nTEST REPORT\")\n",
    "print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4044af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== XGBOOST Cross-Validation: Stratified Shuffle-Split ===\\n\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Use your tuned parameters\n",
    "# ------------------------------------------------------------\n",
    "best_params = search.best_params_\n",
    "print(\"Using Best Params:\", best_params, \"\\n\")\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    X_train_cv, X_test_cv = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train_cv, y_test_cv = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # XGBoost model with best params\n",
    "    # --------------------------------------------------------\n",
    "    xgb_cv = XGBClassifier(\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y)),\n",
    "        eval_metric=\"mlogloss\",\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        **best_params\n",
    "    )\n",
    "\n",
    "    xgb_cv.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = xgb_cv.predict(X_test_cv)\n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_test_cv, y_pred)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Mean Accuracy:  \", np.mean(accuracies))\n",
    "print(\"Std Deviation: \", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b75a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Use a subset for speed\n",
    "# -------------------------------\n",
    "subset_size = 250_000  # <--- UPDATED to 250k\n",
    "print(f\"Subsampling {subset_size} rows...\")\n",
    "X_sub = X.sample(subset_size, random_state=42)\n",
    "y_sub = y[X_sub.index] # Ensure target aligns with sampled X\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Complexity range (max_depth)\n",
    "# -------------------------------\n",
    "# Range 1 to 50 with step 5 (1, 6, 11... 46, 51)\n",
    "depth_values = range(1, 51, 5) \n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "# Base tuned params (Make sure 'search' is defined or replace this line!)\n",
    "base_params = search.best_params_.copy()\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Stratified Shuffle-Split\n",
    "# -------------------------------\n",
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "\n",
    "for depth in depth_values:\n",
    "    fold_train_errors = []\n",
    "    fold_test_errors = []\n",
    "    print(f\"Testing max_depth = {depth}...\")\n",
    "\n",
    "    for train_idx, test_idx in sss.split(X_sub, y_sub):\n",
    "        X_train_cv, X_test_cv = X_sub.iloc[train_idx], X_sub.iloc[test_idx]\n",
    "        y_train_cv, y_test_cv = y_sub.iloc[train_idx], y_sub.iloc[test_idx]\n",
    "\n",
    "        # Update params for this specific loop\n",
    "        params = base_params.copy()\n",
    "        params[\"max_depth\"] = depth\n",
    "\n",
    "        model = XGBClassifier(\n",
    "            objective=\"multi:softmax\",\n",
    "            num_class=len(np.unique(y_sub)),\n",
    "            eval_metric=\"mlogloss\",\n",
    "            tree_method=\"hist\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred_train = model.predict(X_train_cv)\n",
    "        y_pred_test  = model.predict(X_test_cv)\n",
    "\n",
    "        # Calculate Error (1 - Accuracy)\n",
    "        fold_train_errors.append(1 - accuracy_score(y_train_cv, y_pred_train))\n",
    "        fold_test_errors.append(1 - accuracy_score(y_test_cv, y_pred_test))\n",
    "\n",
    "    # Average over folds\n",
    "    train_errors.append(np.mean(fold_train_errors))\n",
    "    test_errors.append(np.mean(fold_test_errors))\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Plot\n",
    "# -------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(depth_values, train_errors, marker='o', label=\"Training Error\")\n",
    "plt.plot(depth_values, test_errors, marker='o', label=\"Test Error\")\n",
    "\n",
    "plt.xlabel(\"Model Complexity (max_depth)\")\n",
    "plt.ylabel(\"Error (1 - accuracy)\")\n",
    "plt.title(f\"XGBoost Error vs Model Complexity (Subset: {subset_size:,} rows)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e7cd09",
   "metadata": {},
   "source": [
    "### ANN (Hyperparamters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cae8694",
   "metadata": {},
   "source": [
    "Perform the Shuffle-Split Validation:\n",
    "\n",
    "*Note, if it shows error X_train_scaled is not defined, run the top ANN (Processed) model first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a3d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. Define a lightweight search space\n",
    "# ============================================================\n",
    "\n",
    "param_space = {\n",
    "    \"lr\": [1e-3, 3e-4, 1e-4],\n",
    "    \"hidden_1\": [64, 96, 128],\n",
    "    \"hidden_2\": [32, 48, 64],\n",
    "    \"dropout\": [0.2, 0.3, 0.4],\n",
    "    \"batch_size\": [32, 64, 128]\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Function to build a model from hyperparameters\n",
    "# ============================================================\n",
    "\n",
    "def build_model(params):\n",
    "    model = Sequential([\n",
    "        Dense(params[\"hidden_1\"], activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dropout(params[\"dropout\"]),\n",
    "\n",
    "        Dense(params[\"hidden_2\"], activation='relu'),\n",
    "        Dropout(params[\"dropout\"]),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=Adam(learning_rate=params[\"lr\"]),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. LIGHTWEIGHT BEST PARAMS SEARCH\n",
    "#    (Random sampling + short training + early stopping)\n",
    "# ============================================================\n",
    "\n",
    "def sample_params():\n",
    "    return {\n",
    "        \"lr\": random.choice(param_space[\"lr\"]),\n",
    "        \"hidden_1\": random.choice(param_space[\"hidden_1\"]),\n",
    "        \"hidden_2\": random.choice(param_space[\"hidden_2\"]),\n",
    "        \"dropout\": random.choice(param_space[\"dropout\"]),\n",
    "        \"batch_size\": random.choice(param_space[\"batch_size\"])\n",
    "    }\n",
    "\n",
    "search_results = []\n",
    "N_SEARCH = 4   # Only 4 trials → FAST & LIGHT, it strikes a decent balance; or set to a smaller value if time is a concern (Such as 3), or to a a larger value if you have more time (Such as 5-10)\n",
    "\n",
    "print(\"\\n========== STARTING BEST PARAMS SEARCH ==========\\n\")\n",
    "\n",
    "for i in range(N_SEARCH):\n",
    "    params = sample_params()\n",
    "    print(f\"Trial {i+1}/{N_SEARCH}: {params}\")\n",
    "\n",
    "    model = build_model(params)\n",
    "\n",
    "    es = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # SHORT training for search only\n",
    "    history = model.fit(\n",
    "        X_train_scaled,\n",
    "        y_train_cat,\n",
    "        epochs=8,\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        validation_split=0.2,\n",
    "        verbose=0,\n",
    "        callbacks=[es]\n",
    "    )\n",
    "\n",
    "    val_acc = max(history.history[\"val_accuracy\"])\n",
    "    search_results.append((val_acc, params))\n",
    "\n",
    "    print(f\" → Best Val Accuracy: {val_acc:.4f}\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. Select best params\n",
    "# ============================================================\n",
    "\n",
    "best_val, best_params = max(search_results, key=lambda x: x[0])\n",
    "print(\"\\n========== BEST PARAMS FOUND ==========\")\n",
    "print(best_params)\n",
    "print(\"Best Validation Accuracy:\", best_val)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. Train FINAL MODEL with best params\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n========== TRAINING FINAL MODEL ==========\\n\")\n",
    "\n",
    "final_model = build_model(best_params)\n",
    "\n",
    "es_final = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history_final = final_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_cat,\n",
    "    epochs=25,\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    "    callbacks=[es_final]\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. Evaluate\n",
    "# ============================================================\n",
    "\n",
    "y_pred_train = final_model.predict(X_train_scaled).argmax(axis=1)\n",
    "y_pred_test = final_model.predict(X_test_scaled).argmax(axis=1)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "print(\"\\n===== TRAINING REPORT =====\")\n",
    "print(pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose())\n",
    "\n",
    "print(\"\\n===== TESTING REPORT =====\")\n",
    "print(pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test, output_dict=True)\n",
    ").transpose())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36585e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#                📌 FULL ANN PIPELINE \n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ============================================================\n",
    "# PREPROCESSING\n",
    "# ============================================================\n",
    "\n",
    "df_model_2 = df_new.copy()\n",
    "\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# Convert datetime → int64\n",
    "for col in X.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "# Convert lists → strings\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        X[col] = X[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Fill missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# ============================================================\n",
    "# BEST PARAMS (From your search)\n",
    "# ============================================================\n",
    "best_params = {\n",
    "    \"layer1\": 128,\n",
    "    \"layer2\": 64,\n",
    "    \"layer3\": 32,\n",
    "    \"dropout\": 0.3,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 10,       # base training\n",
    "    \"lr\": 0.001         # default Adam LR\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# MODEL BUILDER FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def build_ann():\n",
    "    model = Sequential([\n",
    "        Dense(best_params[\"layer1\"], activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dropout(best_params[\"dropout\"]),\n",
    "\n",
    "        Dense(best_params[\"layer2\"], activation='relu'),\n",
    "        Dropout(best_params[\"dropout\"]),\n",
    "\n",
    "        Dense(best_params[\"layer3\"], activation='relu'),\n",
    "\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN FINAL MODEL\n",
    "# ============================================================\n",
    "\n",
    "model = build_ann()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_cat,\n",
    "    epochs=best_params[\"epochs\"],\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predict\n",
    "y_pred_train = model.predict(X_train_scaled).argmax(axis=1)\n",
    "y_pred_test = model.predict(X_test_scaled).argmax(axis=1)\n",
    "\n",
    "# Evaluation\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Accuracy:\", train_acc)\n",
    "print(\"Testing Accuracy:\", test_acc)\n",
    "\n",
    "print(\"\\nTRAIN REPORT\")\n",
    "print(pd.DataFrame.from_dict(classification_report(y_train, y_pred_train, output_dict=True)).transpose())\n",
    "\n",
    "print(\"\\nTEST REPORT\")\n",
    "print(pd.DataFrame.from_dict(classification_report(y_test, y_pred_test, output_dict=True)).transpose())\n",
    "\n",
    "# ============================================================\n",
    "# SHUFFLE-SPLIT CROSS VALIDATION (FAST + MEMORY EFFICIENT)\n",
    "# ============================================================\n",
    "\n",
    "def ann_shuffle_split_cv(n_splits=5):\n",
    "\n",
    "    ss = ShuffleSplit(n_splits=n_splits, test_size=0.2, random_state=42)\n",
    "    accuracies = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_idx, val_idx in ss.split(X_train_scaled):\n",
    "\n",
    "        print(f\"\\n===== ShuffleSplit Fold {fold}/{n_splits} =====\")\n",
    "\n",
    "        X_tr, X_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "        y_tr, y_val = y_train_cat[train_idx], y_train_cat[val_idx]\n",
    "\n",
    "        model_cv = build_ann()\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "        model_cv.fit(\n",
    "            X_tr, y_tr,\n",
    "            epochs=12,  # small for speed\n",
    "            batch_size=best_params[\"batch_size\"],\n",
    "            validation_data=(X_val, y_val),\n",
    "            verbose=0,\n",
    "            callbacks=[es]\n",
    "        )\n",
    "\n",
    "        loss, acc = model_cv.evaluate(X_val, y_val, verbose=0)\n",
    "        print(f\"Fold Accuracy: {acc:.4f}\")\n",
    "\n",
    "        accuracies.append(acc)\n",
    "        fold += 1\n",
    "\n",
    "    accuracies = np.array(accuracies)\n",
    "    print(\"\\n========== SHUFFLE SPLIT SUMMARY ==========\")\n",
    "    print(\"Accuracies:\", accuracies)\n",
    "    print(\"Mean CV Accuracy:\", accuracies.mean())\n",
    "    print(\"Std Deviation:\", accuracies.std())\n",
    "    print(\"============================================\")\n",
    "\n",
    "    return accuracies.mean(), accuracies.std()\n",
    "\n",
    "# Run CV\n",
    "cv_mean, cv_sd = ann_shuffle_split_cv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaafc41",
   "metadata": {},
   "source": [
    "### Part B - Applying new preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24787fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the binary \"Victim_Involved?\" column first\n",
    "# We check if 'Vict Age', 'Vict Sex', or 'Vict Descent' have valid data.\n",
    "# Adjust the condition if you only want to check specific columns.\n",
    "# Here, if ALL victim columns are null, it's 0. If ANY has data, it's 1.\n",
    "# (Alternatively, you can just check one if they are always missing together)\n",
    "df_new_1['Victim_Involved?'] = df_new_1.apply(\n",
    "    lambda row: 0 if (pd.isna(row['Vict Sex']) or str(row['Vict Sex']).strip() == '') and \n",
    "                     (pd.isna(row['Vict Descent']) or str(row['Vict Descent']).strip() == '') \n",
    "                else 1, axis=1\n",
    ")\n",
    "\n",
    "# 2. Drop the victim-based columns\n",
    "cols_to_drop = ['Vict Age', 'Vict Sex', 'Vict Descent']\n",
    "df_new_1 = df_new_1.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "# Verify the changes\n",
    "print(df_new_1[['Victim_Involved?']].head())\n",
    "print(df_new_1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2115ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_2 = df_new_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4f8b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9542c3e",
   "metadata": {},
   "source": [
    "# Ensemble: XGBoost + Logistic Regression\n",
    "\n",
    "Combining XGBoost and Logistic Regression predictions using averaging and stacking approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f769b8ec",
   "metadata": {},
   "source": [
    "## Get predictions from both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probability predictions from both models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Get the original 2D feature data by reshaping or using the right variables\n",
    "# X_train and X_test might be 3D for CNN, so we need the 2D version\n",
    "# Check if we have 2D data available\n",
    "if len(X_train.shape) == 3:\n",
    "    # If 3D (for CNN), flatten to 2D\n",
    "    X_train_2d = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test_2d = X_test.reshape(X_test.shape[0], -1)\n",
    "else:\n",
    "    # Already 2D, convert to numpy array if DataFrame\n",
    "    X_train_2d = X_train.values if hasattr(X_train, 'values') else X_train\n",
    "    X_test_2d = X_test.values if hasattr(X_test, 'values') else X_test\n",
    "\n",
    "# Convert y_train from one-hot encoding to class labels if needed\n",
    "if len(y_train.shape) == 2:\n",
    "    # y_train is one-hot encoded, convert to class labels\n",
    "    y_train_labels = np.argmax(y_train, axis=1)\n",
    "    y_test_labels = np.argmax(y_test, axis=1)\n",
    "else:\n",
    "    y_train_labels = y_train\n",
    "    y_test_labels = y_test\n",
    "\n",
    "# Handle missing values by filling with 0\n",
    "X_train_2d = np.nan_to_num(X_train_2d, nan=0.0)\n",
    "X_test_2d = np.nan_to_num(X_test_2d, nan=0.0)\n",
    "\n",
    "# Ensure X and y have the same number of samples\n",
    "print(f\"X_train_2d shape: {X_train_2d.shape}\")\n",
    "print(f\"X_test_2d shape: {X_test_2d.shape}\")\n",
    "print(f\"y_train_labels shape: {y_train_labels.shape}\")\n",
    "print(f\"y_test_labels shape: {y_test_labels.shape}\")\n",
    "\n",
    "# Train XGBoost for ensemble\n",
    "print(\"\\nTraining XGBoost for ensemble...\")\n",
    "xgb_ensemble = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, \n",
    "                             random_state=42, n_jobs=-1, eval_metric='mlogloss')\n",
    "xgb_ensemble.fit(X_train_2d, y_train_labels)\n",
    "xgb_train_proba = xgb_ensemble.predict_proba(X_train_2d)\n",
    "xgb_test_proba = xgb_ensemble.predict_proba(X_test_2d)\n",
    "\n",
    "# Train Logistic Regression for ensemble\n",
    "print(\"Training Logistic Regression for ensemble...\")\n",
    "scaler_lr = StandardScaler()\n",
    "X_train_lr_scaled = scaler_lr.fit_transform(X_train_2d)\n",
    "X_test_lr_scaled = scaler_lr.transform(X_test_2d)\n",
    "\n",
    "# Replace any NaN values that might have appeared after scaling\n",
    "X_train_lr_scaled = np.nan_to_num(X_train_lr_scaled, nan=0.0)\n",
    "X_test_lr_scaled = np.nan_to_num(X_test_lr_scaled, nan=0.0)\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "lr_model.fit(X_train_lr_scaled, y_train_labels)\n",
    "\n",
    "# Get probability predictions\n",
    "lr_train_proba = lr_model.predict_proba(X_train_lr_scaled)\n",
    "lr_test_proba = lr_model.predict_proba(X_test_lr_scaled)\n",
    "\n",
    "print(\"\\nProbability shapes:\")\n",
    "print(\"XGBoost train proba shape:\", xgb_train_proba.shape)\n",
    "print(\"XGBoost test proba shape:\", xgb_test_proba.shape)\n",
    "print(\"LR train proba shape:\", lr_train_proba.shape)\n",
    "print(\"LR test proba shape:\", lr_test_proba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454357fd",
   "metadata": {},
   "source": [
    "## Simple Averaging Ensemble\n",
    "\n",
    "Average the probability predictions from both models and evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768e9af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple averaging: equal weights (0.5, 0.5)\n",
    "avg_train_proba = (xgb_train_proba + lr_train_proba) / 2\n",
    "avg_test_proba = (xgb_test_proba + lr_test_proba) / 2\n",
    "\n",
    "# Get predictions by taking argmax\n",
    "y_train_pred_avg = np.argmax(avg_train_proba, axis=1)\n",
    "y_test_pred_avg = np.argmax(avg_test_proba, axis=1)\n",
    "\n",
    "# Evaluate\n",
    "train_acc_avg = accuracy_score(y_train_labels, y_train_pred_avg)\n",
    "test_acc_avg = accuracy_score(y_test_labels, y_test_pred_avg)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AVERAGING ENSEMBLE (XGBoost + LR)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train Accuracy: {train_acc_avg:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc_avg:.4f}\")\n",
    "print(f\"Gap:           {train_acc_avg - test_acc_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed0cd5",
   "metadata": {},
   "source": [
    "## Stacking Ensemble\n",
    "\n",
    "Use a meta-learner (Logistic Regression) trained on the predictions of both base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e7985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking: concatenate probabilities as features\n",
    "stack_train_features = np.concatenate([xgb_train_proba, lr_train_proba], axis=1)\n",
    "stack_test_features = np.concatenate([xgb_test_proba, lr_test_proba], axis=1)\n",
    "\n",
    "print(f\"Stacked train features shape: {stack_train_features.shape}\")\n",
    "print(f\"Stacked test features shape: {stack_test_features.shape}\")\n",
    "\n",
    "# Train meta-learner (Logistic Regression)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "meta_learner = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "meta_learner.fit(stack_train_features, y_train_labels)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_stack = meta_learner.predict(stack_train_features)\n",
    "y_test_pred_stack = meta_learner.predict(stack_test_features)\n",
    "\n",
    "# Evaluate\n",
    "train_acc_stack = accuracy_score(y_train_labels, y_train_pred_stack)\n",
    "test_acc_stack = accuracy_score(y_test_labels, y_test_pred_stack)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STACKING ENSEMBLE (XGBoost + LR with Meta-Learner)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train Accuracy: {train_acc_stack:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc_stack:.4f}\")\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(y_test_labels, y_test_pred_stack))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a191ee3",
   "metadata": {},
   "source": [
    "## Validation Shuffle Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d66e08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "Averaging Ensemble Accuracy: 0.8383\n",
      "Stacking Ensemble Accuracy:   0.8550\n",
      "\n",
      "===== Fold 2 =====\n",
      "Averaging Ensemble Accuracy: 0.8375\n",
      "Stacking Ensemble Accuracy:   0.8551\n",
      "\n",
      "===== Fold 3 =====\n",
      "Averaging Ensemble Accuracy: 0.8388\n",
      "Stacking Ensemble Accuracy:   0.8557\n",
      "\n",
      "===== Fold 4 =====\n",
      "Averaging Ensemble Accuracy: 0.8392\n",
      "Stacking Ensemble Accuracy:   0.8562\n",
      "\n",
      "===== Fold 5 =====\n",
      "Averaging Ensemble Accuracy: 0.8401\n",
      "Stacking Ensemble Accuracy:   0.8574\n",
      "\n",
      "====================================\n",
      "FINAL MEAN ACCURACY OVER SHUFFLE SPLITS\n",
      "====================================\n",
      "Simple Averaging Mean Accuracy: 0.8388\n",
      "Stacking Ensemble Mean Accuracy: 0.8559\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# ===============================\n",
    "#   SHUFFLE SPLIT VALIDATION \n",
    "# ===============================\n",
    "\n",
    "def shuffle_split_validation(X, y, n_splits=5, test_size=0.2):\n",
    "\n",
    "    ss = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
    "\n",
    "    avg_scores = []\n",
    "    stack_scores = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(ss.split(X)):\n",
    "\n",
    "        print(f\"\\n===== Fold {fold+1} =====\")\n",
    "\n",
    "        # Split data\n",
    "        X_train_fold = X[train_idx]\n",
    "        X_test_fold = X[test_idx]\n",
    "        y_train_fold = y[train_idx]\n",
    "        y_test_fold = y[test_idx]\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # Step 1: Train XGBoost\n",
    "        # -------------------------------------------------------\n",
    "        xgb_model = XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "            eval_metric='mlogloss'\n",
    "        )\n",
    "        xgb_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        xgb_train_proba = xgb_model.predict_proba(X_train_fold)\n",
    "        xgb_test_proba = xgb_model.predict_proba(X_test_fold)\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # Step 2: Train Logistic Regression\n",
    "        # -------------------------------------------------------\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_test_scaled = scaler.transform(X_test_fold)\n",
    "\n",
    "        lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        lr_model.fit(X_train_scaled, y_train_fold)\n",
    "\n",
    "        lr_train_proba = lr_model.predict_proba(X_train_scaled)\n",
    "        lr_test_proba = lr_model.predict_proba(X_test_scaled)\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # SIMPLE AVERAGING ENSEMBLE\n",
    "        # -------------------------------------------------------\n",
    "        avg_test_proba = (xgb_test_proba + lr_test_proba) / 2\n",
    "        y_pred_avg = np.argmax(avg_test_proba, axis=1)\n",
    "\n",
    "        avg_acc = accuracy_score(y_test_fold, y_pred_avg)\n",
    "        avg_scores.append(avg_acc)\n",
    "\n",
    "        print(f\"Averaging Ensemble Accuracy: {avg_acc:.4f}\")\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # STACKING ENSEMBLE\n",
    "        # -------------------------------------------------------\n",
    "        stack_train = np.concatenate([xgb_train_proba, lr_train_proba], axis=1)\n",
    "        stack_test = np.concatenate([xgb_test_proba, lr_test_proba], axis=1)\n",
    "\n",
    "        meta_learner = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        meta_learner.fit(stack_train, y_train_fold)\n",
    "\n",
    "        y_pred_stack = meta_learner.predict(stack_test)\n",
    "\n",
    "        stack_acc = accuracy_score(y_test_fold, y_pred_stack)\n",
    "        stack_scores.append(stack_acc)\n",
    "\n",
    "        print(f\"Stacking Ensemble Accuracy:   {stack_acc:.4f}\")\n",
    "\n",
    "    print(\"\\n====================================\")\n",
    "    print(\"FINAL MEAN ACCURACY OVER SHUFFLE SPLITS\")\n",
    "    print(\"====================================\")\n",
    "    print(f\"Simple Averaging Mean Accuracy: {np.mean(avg_scores):.4f}\")\n",
    "    print(f\"Stacking Ensemble Mean Accuracy: {np.mean(stack_scores):.4f}\")\n",
    "\n",
    "    return avg_scores, stack_scores\n",
    "\n",
    "\n",
    "# ========================================================\n",
    "# RUN SHUFFLE SPLIT VALIDATION ON YOUR EXISTING VARIABLES\n",
    "# ========================================================\n",
    "avg_scores, stack_scores = shuffle_split_validation(X_train_2d, y_train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9e6805",
   "metadata": {},
   "source": [
    "## Complexity vs Error Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca0e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Complexity: n_estimators = 20 ===\n",
      "Mean Validation Error: 0.1789\n",
      "\n",
      "=== Complexity: n_estimators = 40 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Error: 0.1707\n",
      "\n",
      "=== Complexity: n_estimators = 60 ===\n",
      "Mean Validation Error: 0.1665\n",
      "\n",
      "=== Complexity: n_estimators = 80 ===\n",
      "Mean Validation Error: 0.1636\n",
      "\n",
      "=== Complexity: n_estimators = 100 ===\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Complexity range for XGBoost (n_estimators)\n",
    "# -----------------------------------------------\n",
    "complexity_list = [20, 40, 60, 80, 100, 150, 200]\n",
    "ensemble_errors = []\n",
    "\n",
    "# ShuffleSplit for stable validation\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "for n in complexity_list:\n",
    "    fold_errors = []\n",
    "    print(f\"\\n=== Complexity: n_estimators = {n} ===\")\n",
    "\n",
    "    for train_idx, test_idx in ss.split(X):\n",
    "        # Split\n",
    "        X_train_fold = X.iloc[train_idx]\n",
    "        X_test_fold = X.iloc[test_idx]\n",
    "        y_train_fold = y[train_idx]\n",
    "        y_test_fold = y[test_idx]\n",
    "\n",
    "\n",
    "        # ---- Handle CNN 3D shape ----\n",
    "        if len(X_train_fold.shape) == 3:\n",
    "            X_train_2d = X_train_fold.reshape(X_train_fold.shape[0], -1)\n",
    "            X_test_2d = X_test_fold.reshape(X_test_fold.shape[0], -1)\n",
    "        else:\n",
    "            X_train_2d = X_train_fold\n",
    "            X_test_2d = X_test_fold\n",
    "\n",
    "        # ---- Convert one-hot labels ----\n",
    "        if len(y_train_fold.shape) == 2:\n",
    "            y_train_labels = np.argmax(y_train_fold, axis=1)\n",
    "            y_test_labels = np.argmax(y_test_fold, axis=1)\n",
    "        else:\n",
    "            y_train_labels = y_train_fold\n",
    "            y_test_labels = y_test_fold\n",
    "\n",
    "        # Fix NaN\n",
    "        X_train_2d = np.nan_to_num(X_train_2d)\n",
    "        X_test_2d = np.nan_to_num(X_test_2d)\n",
    "\n",
    "        # ====================================================\n",
    "        # TRAIN XGBOOST WITH THIS COMPLEXITY\n",
    "        # ====================================================\n",
    "        xgb = XGBClassifier(\n",
    "            n_estimators=n,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "            eval_metric='mlogloss'\n",
    "        )\n",
    "        xgb.fit(X_train_2d, y_train_labels)\n",
    "\n",
    "        xgb_test_proba = xgb.predict_proba(X_test_2d)\n",
    "\n",
    "        # ====================================================\n",
    "        # TRAIN LOGISTIC REGRESSION (fixed model)\n",
    "        # ====================================================\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_2d)\n",
    "        X_test_scaled  = scaler.transform(X_test_2d)\n",
    "\n",
    "        lr_model = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "        lr_model.fit(X_train_scaled, y_train_labels)\n",
    "\n",
    "        lr_test_proba = lr_model.predict_proba(X_test_scaled)\n",
    "\n",
    "        # ====================================================\n",
    "        # AVERAGING ENSEMBLE (YOUR EXACT FORMULA)\n",
    "        # ====================================================\n",
    "        avg_test_proba = (xgb_test_proba + lr_test_proba) / 2\n",
    "        y_pred = np.argmax(avg_test_proba, axis=1)\n",
    "\n",
    "        error = 1 - accuracy_score(y_test_labels, y_pred)\n",
    "        fold_errors.append(error)\n",
    "\n",
    "    # Mean error across folds\n",
    "    mean_error = np.mean(fold_errors)\n",
    "    ensemble_errors.append(mean_error)\n",
    "    print(f\"Mean Validation Error: {mean_error:.4f}\")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# PLOT THE COMPLEXITY vs ERROR CURVE\n",
    "# -----------------------------------------------\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(complexity_list, ensemble_errors, marker='o')\n",
    "plt.xlabel(\"Complexity (XGBoost n_estimators)\")\n",
    "plt.ylabel(\"Validation Error (Averaging Ensemble)\")\n",
    "plt.title(\"Complexity vs Error Curve — XGBoost + Logistic Regression Ensemble\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c177a2",
   "metadata": {},
   "source": [
    "## Compare All Approaches\n",
    "\n",
    "Summary comparison of individual models vs ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c943b12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare individual models vs ensemble\n",
    "import pandas as pd\n",
    "\n",
    "# Get individual model accuracies from the ensemble models we just trained\n",
    "xgb_train_pred = xgb_ensemble.predict(X_train_2d)\n",
    "xgb_test_pred = xgb_ensemble.predict(X_test_2d)\n",
    "xgb_train_acc = accuracy_score(y_train_labels, xgb_train_pred)\n",
    "xgb_test_acc = accuracy_score(y_test_labels, xgb_test_pred)\n",
    "\n",
    "lr_train_pred = lr_model.predict(X_train_lr_scaled)\n",
    "lr_test_pred = lr_model.predict(X_test_lr_scaled)\n",
    "lr_train_acc = accuracy_score(y_train_labels, lr_train_pred)\n",
    "lr_test_acc = accuracy_score(y_test_labels, lr_test_pred)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['XGBoost', 'Logistic Regression', 'Averaging Ensemble', 'Stacking Ensemble'],\n",
    "    'Train Accuracy': [xgb_train_acc, lr_train_acc, train_acc_avg, train_acc_stack],\n",
    "    'Test Accuracy': [xgb_test_acc, lr_test_acc, test_acc_avg, test_acc_stack],\n",
    "    'Overfitting': [\n",
    "        xgb_train_acc - xgb_test_acc,\n",
    "        lr_train_acc - lr_test_acc,\n",
    "        train_acc_avg - test_acc_avg,\n",
    "        train_acc_stack - test_acc_stack\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON: XGBoost vs LR vs Ensembles\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a329a5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Ensemble: XGBoost + Naive Bayes\n",
    "\n",
    "Combine XGBoost and Naive Bayes predictions using averaging and stacking ensemble techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872801a",
   "metadata": {},
   "source": [
    "## Get Predictions from Both Models\n",
    "\n",
    "Train both XGBoost and Naive Bayes on the same data split and obtain probability predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b4916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what variables are available from Part A\n",
    "print(\"Checking available variables from Part A...\")\n",
    "print(f\"X_train_xgb exists: {'X_train_xgb' in dir()}\")\n",
    "print(f\"X_train_scaled exists: {'X_train_scaled' in dir()}\")\n",
    "print(f\"y_train_labels exists: {'y_train_labels' in dir()}\")\n",
    "\n",
    "if 'X_train_scaled' in dir():\n",
    "    print(f\"\\nX_train_scaled shape: {X_train_scaled.shape}\")\n",
    "if 'X_test_scaled' in dir():\n",
    "    print(f\"X_test_scaled shape: {X_test_scaled.shape}\")\n",
    "if 'y_train_labels' in dir():\n",
    "    print(f\"y_train_labels shape: {y_train_labels.shape}\")\n",
    "    print(f\"y_train_labels unique values: {np.unique(y_train_labels)}\")\n",
    "if 'y_test_labels' in dir():\n",
    "    print(f\"y_test_labels shape: {y_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4015d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probability predictions from both models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# IMPORTANT: Use the same data from Part A (X_train_xgb, y_train_xgb, etc.)\n",
    "# The CNN data has different split and formatting\n",
    "print(\"Using Part A data for ensemble...\")\n",
    "\n",
    "# Use Part A XGBoost data which should exist\n",
    "try:\n",
    "    print(\"Using X_train_xgb from Part A\")\n",
    "    X_train_nb_2d = X_train_xgb\n",
    "    X_test_nb_2d = X_test_xgb\n",
    "    # Check if y labels are one-hot encoded and convert if needed\n",
    "    if len(y_train_xgb.shape) == 2 and y_train_xgb.shape[1] > 1:\n",
    "        print(\"Converting one-hot encoded labels to class labels\")\n",
    "        y_train_nb_labels = np.argmax(y_train_xgb, axis=1)\n",
    "        y_test_nb_labels = np.argmax(y_test_xgb, axis=1)\n",
    "    else:\n",
    "        y_train_nb_labels = y_train_xgb\n",
    "        y_test_nb_labels = y_test_xgb\n",
    "except NameError:\n",
    "    print(\"X_train_xgb not found, using X_train_scaled from Part A\")\n",
    "    # Fall back to scaled data from Part A\n",
    "    X_train_nb_2d = X_train_scaled\n",
    "    X_test_nb_2d = X_test_scaled\n",
    "    # Get labels from y (not the CNN one-hot encoded version)\n",
    "    if 'y_train_labels' in dir():\n",
    "        y_train_nb_labels = y_train_labels\n",
    "        y_test_nb_labels = y_test_labels\n",
    "    else:\n",
    "        # Convert if one-hot encoded\n",
    "        if len(y_train.shape) == 2 and y_train.shape[1] > 1:\n",
    "            y_train_nb_labels = np.argmax(y_train, axis=1)\n",
    "            y_test_nb_labels = np.argmax(y_test, axis=1)\n",
    "        else:\n",
    "            y_train_nb_labels = y_train\n",
    "            y_test_nb_labels = y_test\n",
    "\n",
    "print(f\"Training data shape: {X_train_nb_2d.shape}\")\n",
    "print(f\"Test data shape: {X_test_nb_2d.shape}\")\n",
    "\n",
    "# Train XGBoost for ensemble\n",
    "print(\"\\nTraining XGBoost for XGB+NB ensemble...\")\n",
    "xgb_nb_ensemble = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, \n",
    "                                random_state=42, n_jobs=-1, eval_metric='mlogloss')\n",
    "xgb_nb_ensemble.fit(X_train_nb_2d, y_train_nb_labels)\n",
    "xgb_nb_train_proba = xgb_nb_ensemble.predict_proba(X_train_nb_2d)\n",
    "xgb_nb_test_proba = xgb_nb_ensemble.predict_proba(X_test_nb_2d)\n",
    "\n",
    "# Naive Bayes requires non-negative features\n",
    "# Scale data to be non-negative (Min-Max scaling)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_nb = MinMaxScaler()\n",
    "X_train_nb_scaled = scaler_nb.fit_transform(X_train_nb_2d)\n",
    "X_test_nb_scaled = scaler_nb.transform(X_test_nb_2d)\n",
    "\n",
    "# Tune Naive Bayes alpha parameter\n",
    "print(\"Tuning Naive Bayes alpha parameter...\")\n",
    "alpha_values = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "best_alpha = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    nb_temp = MultinomialNB(alpha=alpha)\n",
    "    nb_temp.fit(X_train_nb_scaled, y_train_nb_labels)\n",
    "    y_val_pred = nb_temp.predict(X_test_nb_scaled)\n",
    "    val_acc = accuracy_score(y_test_nb_labels, y_val_pred)\n",
    "    print(f\"Alpha={alpha:6.2f}: Test Accuracy = {val_acc:.4f}\")\n",
    "    \n",
    "    if val_acc > best_accuracy:\n",
    "        best_accuracy = val_acc\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(f\"\\nBest Alpha: {best_alpha} with Test Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Train Naive Bayes with best alpha for ensemble\n",
    "print(f\"\\nTraining Naive Bayes with alpha={best_alpha} for ensemble...\")\n",
    "nb_ensemble = MultinomialNB(alpha=best_alpha)\n",
    "nb_ensemble.fit(X_train_nb_scaled, y_train_nb_labels)\n",
    "\n",
    "# Get probability predictions\n",
    "nb_train_proba = nb_ensemble.predict_proba(X_train_nb_scaled)\n",
    "nb_test_proba = nb_ensemble.predict_proba(X_test_nb_scaled)\n",
    "\n",
    "print(\"\\nProbability shapes:\")\n",
    "print(\"XGBoost train proba shape:\", xgb_nb_train_proba.shape)\n",
    "print(\"XGBoost test proba shape:\", xgb_nb_test_proba.shape)\n",
    "print(\"Naive Bayes train proba shape:\", nb_train_proba.shape)\n",
    "print(\"Naive Bayes test proba shape:\", nb_test_proba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25442d1f",
   "metadata": {},
   "source": [
    "## Simple Averaging Ensemble\n",
    "\n",
    "Average the probability predictions from XGBoost and Naive Bayes and evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a6e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple averaging: equal weights (0.5, 0.5)\n",
    "avg_nb_train_proba = (xgb_nb_train_proba + nb_train_proba) / 2\n",
    "avg_nb_test_proba = (xgb_nb_test_proba + nb_test_proba) / 2\n",
    "\n",
    "# Get predictions by taking argmax\n",
    "y_train_pred_avg_nb = np.argmax(avg_nb_train_proba, axis=1)\n",
    "y_test_pred_avg_nb = np.argmax(avg_nb_test_proba, axis=1)\n",
    "\n",
    "# Evaluate\n",
    "train_acc_avg_nb = accuracy_score(y_train_nb_labels, y_train_pred_avg_nb)\n",
    "test_acc_avg_nb = accuracy_score(y_test_nb_labels, y_test_pred_avg_nb)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AVERAGING ENSEMBLE (XGBoost + Naive Bayes)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train Accuracy: {train_acc_avg_nb:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc_avg_nb:.4f}\")\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(y_test_nb_labels, y_test_pred_avg_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcb21c1",
   "metadata": {},
   "source": [
    "## Stacking Ensemble\n",
    "\n",
    "Use a meta-learner (Logistic Regression) trained on the predictions of both base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe218afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking: concatenate probabilities as features\n",
    "stack_nb_train_features = np.concatenate([xgb_nb_train_proba, nb_train_proba], axis=1)\n",
    "stack_nb_test_features = np.concatenate([xgb_nb_test_proba, nb_test_proba], axis=1)\n",
    "\n",
    "print(f\"Stacked train features shape: {stack_nb_train_features.shape}\")\n",
    "print(f\"Stacked test features shape: {stack_nb_test_features.shape}\")\n",
    "\n",
    "# Train meta-learner (Logistic Regression)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "meta_learner_nb = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "meta_learner_nb.fit(stack_nb_train_features, y_train_nb_labels)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_stack_nb = meta_learner_nb.predict(stack_nb_train_features)\n",
    "y_test_pred_stack_nb = meta_learner_nb.predict(stack_nb_test_features)\n",
    "\n",
    "# Evaluate\n",
    "train_acc_stack_nb = accuracy_score(y_train_nb_labels, y_train_pred_stack_nb)\n",
    "test_acc_stack_nb = accuracy_score(y_test_nb_labels, y_test_pred_stack_nb)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STACKING ENSEMBLE (XGBoost + NB with Meta-Learner)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train Accuracy: {train_acc_stack_nb:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc_stack_nb:.4f}\")\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(y_test_nb_labels, y_test_pred_stack_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c7dd32",
   "metadata": {},
   "source": [
    "## Validation Shuffle Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e240adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# SHUFFLE SPLIT VALIDATION FOR XGB + NAIVE BAYES\n",
    "# =============================================\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "def shuffle_split_validation_nb(X, y, n_splits=5, test_size=0.2):\n",
    "\n",
    "    ss = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
    "\n",
    "    avg_scores = []\n",
    "    stack_scores = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(ss.split(X)):\n",
    "        print(f\"\\n===== Fold {fold+1} =====\")\n",
    "\n",
    "        # Split\n",
    "        X_train_fold = X[train_idx]\n",
    "        X_test_fold = X[test_idx]\n",
    "        y_train_fold = y[train_idx]\n",
    "        y_test_fold = y[test_idx]\n",
    "\n",
    "        # Ensure NB gets non-negative values\n",
    "        scaler_nb = MinMaxScaler()\n",
    "        X_train_nb = scaler_nb.fit_transform(X_train_fold)\n",
    "        X_test_nb = scaler_nb.transform(X_test_fold)\n",
    "\n",
    "        # ----------------------------------------------\n",
    "        # Train XGBoost\n",
    "        # ----------------------------------------------\n",
    "        xgb_model = XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "            eval_metric=\"mlogloss\"\n",
    "        )\n",
    "        xgb_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        xgb_train_proba = xgb_model.predict_proba(X_train_fold)\n",
    "        xgb_test_proba = xgb_model.predict_proba(X_test_fold)\n",
    "\n",
    "        # ----------------------------------------------\n",
    "        # Train Naive Bayes\n",
    "        # ----------------------------------------------\n",
    "        nb_model = MultinomialNB(alpha=1.0)\n",
    "        nb_model.fit(X_train_nb, y_train_fold)\n",
    "\n",
    "        nb_train_proba = nb_model.predict_proba(X_train_nb)\n",
    "        nb_test_proba = nb_model.predict_proba(X_test_nb)\n",
    "\n",
    "        # ----------------------------------------------\n",
    "        # Simple Averaging Ensemble\n",
    "        # ----------------------------------------------\n",
    "        avg_test_proba = (xgb_test_proba + nb_test_proba) / 2\n",
    "        y_pred_avg = np.argmax(avg_test_proba, axis=1)\n",
    "\n",
    "        avg_acc = accuracy_score(y_test_fold, y_pred_avg)\n",
    "        avg_scores.append(avg_acc)\n",
    "\n",
    "        print(f\"Averaging Ensemble Accuracy: {avg_acc:.4f}\")\n",
    "\n",
    "        # ----------------------------------------------\n",
    "        # Stacking Ensemble\n",
    "        # ----------------------------------------------\n",
    "        stack_train = np.concatenate([xgb_train_proba, nb_train_proba], axis=1)\n",
    "        stack_test = np.concatenate([xgb_test_proba, nb_test_proba], axis=1)\n",
    "\n",
    "        meta_learner = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        meta_learner.fit(stack_train, y_train_fold)\n",
    "\n",
    "        y_pred_stack = meta_learner.predict(stack_test)\n",
    "\n",
    "        stack_acc = accuracy_score(y_test_fold, y_pred_stack)\n",
    "        stack_scores.append(stack_acc)\n",
    "\n",
    "        print(f\"Stacking Ensemble Accuracy: {stack_acc:.4f}\")\n",
    "\n",
    "    print(\"\\n============================================\")\n",
    "    print(\"FINAL MEAN ACCURACY OVER SHUFFLE SPLITS\")\n",
    "    print(\"============================================\")\n",
    "    print(f\"Simple Averaging (XGB+NB): {np.mean(avg_scores):.4f}\")\n",
    "    print(f\"Stacking (XGB+NB):          {np.mean(stack_scores):.4f}\")\n",
    "\n",
    "    return avg_scores, stack_scores\n",
    "\n",
    "\n",
    "# Run validation on your data\n",
    "avg_scores_nb, stack_scores_nb = shuffle_split_validation_nb(X_train_nb_2d, y_train_nb_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b04c6a",
   "metadata": {},
   "source": [
    "## Complexity vs Error Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783dd9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def complexity_curve_xgb_nb(X_train, y_train, X_test, y_test, nb_alpha=1.0):\n",
    "\n",
    "    scaler_nb = MinMaxScaler()\n",
    "    X_train_nb = scaler_nb.fit_transform(X_train)\n",
    "    X_test_nb = scaler_nb.transform(X_test)\n",
    "\n",
    "    complexities = [10, 50, 100, 150, 200, 300]\n",
    "    errors = []\n",
    "\n",
    "    for n in complexities:\n",
    "        print(f\"Training XGBoost with n_estimators = {n}\")\n",
    "\n",
    "        # XGBoost\n",
    "        xgb = XGBClassifier(\n",
    "            n_estimators=n,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "            eval_metric=\"mlogloss\"\n",
    "        )\n",
    "        xgb.fit(X_train, y_train)\n",
    "\n",
    "        xgb_test_proba = xgb.predict_proba(X_test)\n",
    "\n",
    "        # Naive Bayes\n",
    "        nb = MultinomialNB(alpha=nb_alpha)\n",
    "        nb.fit(X_train_nb, y_train)\n",
    "\n",
    "        nb_test_proba = nb.predict_proba(X_test_nb)\n",
    "\n",
    "        # Averaging ensemble\n",
    "        avg_test_proba = (xgb_test_proba + nb_test_proba) / 2\n",
    "        y_pred = np.argmax(avg_test_proba, axis=1)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        error = 1 - acc\n",
    "        errors.append(error)\n",
    "\n",
    "        print(f\"n_estimators={n}: Accuracy={acc:.4f}, Error={error:.4f}\")\n",
    "\n",
    "    # ---- PLOT ----\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(complexities, errors, marker='o')\n",
    "    plt.xlabel(\"XGBoost Model Complexity (n_estimators)\")\n",
    "    plt.ylabel(\"Test Error (1 - Accuracy)\")\n",
    "    plt.title(\"Complexity vs Error Curve (XGBoost + Naive Bayes Ensemble)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run the complexity curve\n",
    "complexity_curve_xgb_nb(X_train_nb_2d, y_train_nb_labels, X_test_nb_2d, y_test_nb_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04b2173",
   "metadata": {},
   "source": [
    "## Compare All Approaches\n",
    "\n",
    "Summary comparison of individual models vs ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4204c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare individual models vs ensemble\n",
    "import pandas as pd\n",
    "\n",
    "# Get individual model accuracies from the ensemble models we just trained\n",
    "xgb_nb_train_pred = xgb_nb_ensemble.predict(X_train_nb_2d)\n",
    "xgb_nb_test_pred = xgb_nb_ensemble.predict(X_test_nb_2d)\n",
    "xgb_nb_train_acc = accuracy_score(y_train_nb_labels, xgb_nb_train_pred)\n",
    "xgb_nb_test_acc = accuracy_score(y_test_nb_labels, xgb_nb_test_pred)\n",
    "\n",
    "nb_train_pred = nb_ensemble.predict(X_train_nb_scaled)\n",
    "nb_test_pred = nb_ensemble.predict(X_test_nb_scaled)\n",
    "nb_train_acc = accuracy_score(y_train_nb_labels, nb_train_pred)\n",
    "nb_test_acc = accuracy_score(y_test_nb_labels, nb_test_pred)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_nb_df = pd.DataFrame({\n",
    "    'Model': ['XGBoost', 'Naive Bayes', 'Averaging Ensemble', 'Stacking Ensemble'],\n",
    "    'Train Accuracy': [xgb_nb_train_acc, nb_train_acc, train_acc_avg_nb, train_acc_stack_nb],\n",
    "    'Test Accuracy': [xgb_nb_test_acc, nb_test_acc, test_acc_avg_nb, test_acc_stack_nb],\n",
    "    'Overfitting': [\n",
    "        xgb_nb_train_acc - xgb_nb_test_acc,\n",
    "        nb_train_acc - nb_test_acc,\n",
    "        train_acc_avg_nb - test_acc_avg_nb,\n",
    "        train_acc_stack_nb - test_acc_stack_nb\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON: XGBoost vs Naive Bayes vs Ensembles\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_nb_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030ab112",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Ensemble: XGBoost + CNN\n",
    "\n",
    "Combine XGBoost and CNN predictions using averaging and stacking ensemble techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b751aacc",
   "metadata": {},
   "source": [
    "## Step 1: Prepare Data and Train Models\n",
    "\n",
    "Train XGBoost and CNN models on the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8939463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PREPARING DATA FOR XGBOOST + CNN ENSEMBLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use the processed data from Part A\n",
    "df_model_xgb_cnn = df_new.copy()\n",
    "\n",
    "# Prepare features and labels\n",
    "X_xgb_cnn = df_model_xgb_cnn.drop(columns=[\"Crime_Class\"])\n",
    "y_xgb_cnn, _ = pd.factorize(df_model_xgb_cnn[\"Crime_Class\"])\n",
    "\n",
    "# Convert datetime columns to int64\n",
    "for col in X_xgb_cnn.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X_xgb_cnn[col] = X_xgb_cnn[col].view(\"int64\")\n",
    "\n",
    "# Convert lists to strings\n",
    "for col in X_xgb_cnn.columns:\n",
    "    if X_xgb_cnn[col].dtype == 'object':\n",
    "        X_xgb_cnn[col] = X_xgb_cnn[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Factorize object columns\n",
    "X_xgb_cnn = X_xgb_cnn.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Handle missing values\n",
    "X_xgb_cnn = X_xgb_cnn.fillna(X_xgb_cnn.median())\n",
    "\n",
    "# Train-test split\n",
    "X_train_xc, X_test_xc, y_train_xc, y_test_xc = train_test_split(\n",
    "    X_xgb_cnn, y_xgb_cnn, test_size=0.3, random_state=42, stratify=y_xgb_cnn\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler_xc = StandardScaler()\n",
    "X_train_xc_scaled = scaler_xc.fit_transform(X_train_xc)\n",
    "X_test_xc_scaled = scaler_xc.transform(X_test_xc)\n",
    "\n",
    "print(f\"\\nTraining set shape: {X_train_xc_scaled.shape}\")\n",
    "print(f\"Testing set shape: {X_test_xc_scaled.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_xgb_cnn))}\")\n",
    "\n",
    "# Train XGBoost\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING XGBOOST MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "xgb_xc = XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss')\n",
    "xgb_xc.fit(X_train_xc_scaled, y_train_xc)\n",
    "\n",
    "xgb_xc_train_pred = xgb_xc.predict(X_train_xc_scaled)\n",
    "xgb_xc_test_pred = xgb_xc.predict(X_test_xc_scaled)\n",
    "xgb_xc_train_proba = xgb_xc.predict_proba(X_train_xc_scaled)\n",
    "xgb_xc_test_proba = xgb_xc.predict_proba(X_test_xc_scaled)\n",
    "\n",
    "xgb_xc_train_acc = accuracy_score(y_train_xc, xgb_xc_train_pred)\n",
    "xgb_xc_test_acc = accuracy_score(y_test_xc, xgb_xc_test_pred)\n",
    "\n",
    "print(f\"XGBoost Train Accuracy: {xgb_xc_train_acc:.4f}\")\n",
    "print(f\"XGBoost Test Accuracy:  {xgb_xc_test_acc:.4f}\")\n",
    "print(f\"Overfitting Gap:        {xgb_xc_train_acc - xgb_xc_test_acc:.4f}\")\n",
    "\n",
    "# Prepare data for CNN (reshape for Conv1D)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING CNN MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "X_train_xc_cnn = X_train_xc_scaled.reshape(X_train_xc_scaled.shape[0], X_train_xc_scaled.shape[1], 1)\n",
    "X_test_xc_cnn = X_test_xc_scaled.reshape(X_test_xc_scaled.shape[0], X_test_xc_scaled.shape[1], 1)\n",
    "\n",
    "# One-hot encode labels for CNN\n",
    "num_classes_xc = len(np.unique(y_xgb_cnn))\n",
    "y_train_xc_cat = to_categorical(y_train_xc, num_classes_xc)\n",
    "y_test_xc_cat = to_categorical(y_test_xc, num_classes_xc)\n",
    "\n",
    "# Build CNN model\n",
    "cnn_xc = Sequential([\n",
    "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_xc_cnn.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes_xc, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_xc.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Training CNN...\")\n",
    "history_xc = cnn_xc.fit(\n",
    "    X_train_xc_cnn, y_train_xc_cat,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Get CNN predictions\n",
    "cnn_xc_train_proba = cnn_xc.predict(X_train_xc_cnn)\n",
    "cnn_xc_test_proba = cnn_xc.predict(X_test_xc_cnn)\n",
    "cnn_xc_train_pred = np.argmax(cnn_xc_train_proba, axis=1)\n",
    "cnn_xc_test_pred = np.argmax(cnn_xc_test_proba, axis=1)\n",
    "\n",
    "cnn_xc_train_acc = accuracy_score(y_train_xc, cnn_xc_train_pred)\n",
    "cnn_xc_test_acc = accuracy_score(y_test_xc, cnn_xc_test_pred)\n",
    "\n",
    "print(f\"\\nCNN Train Accuracy: {cnn_xc_train_acc:.4f}\")\n",
    "print(f\"CNN Test Accuracy:  {cnn_xc_test_acc:.4f}\")\n",
    "print(f\"Overfitting Gap:    {cnn_xc_train_acc - cnn_xc_test_acc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Both models trained successfully!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3861a",
   "metadata": {},
   "source": [
    "## Step 2: Averaging Ensemble (XGBoost + CNN)\n",
    "\n",
    "Average the probability predictions from both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623af245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple averaging: equal weights (0.5, 0.5)\n",
    "avg_xc_train_proba = (xgb_xc_train_proba + cnn_xc_train_proba) / 2\n",
    "avg_xc_test_proba = (xgb_xc_test_proba + cnn_xc_test_proba) / 2\n",
    "\n",
    "# Get predictions by taking argmax\n",
    "y_train_pred_avg_xc = np.argmax(avg_xc_train_proba, axis=1)\n",
    "y_test_pred_avg_xc = np.argmax(avg_xc_test_proba, axis=1)\n",
    "\n",
    "# Evaluate\n",
    "train_acc_avg_xc = accuracy_score(y_train_xc, y_train_pred_avg_xc)\n",
    "test_acc_avg_xc = accuracy_score(y_test_xc, y_test_pred_avg_xc)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"AVERAGING ENSEMBLE (XGBoost + CNN)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Train Accuracy: {train_acc_avg_xc:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc_avg_xc:.4f}\")\n",
    "print(f\"Gap:            {train_acc_avg_xc - test_acc_avg_xc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1807833d",
   "metadata": {},
   "source": [
    "## Step 3: Stacking Ensemble (XGBoost + CNN)\n",
    "\n",
    "Use a meta-learner (Logistic Regression) trained on predictions from both XGBoost and CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5cc668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Stacking: concatenate probabilities as features\n",
    "stack_xc_train_features = np.concatenate([xgb_xc_train_proba, cnn_xc_train_proba], axis=1)\n",
    "stack_xc_test_features = np.concatenate([xgb_xc_test_proba, cnn_xc_test_proba], axis=1)\n",
    "\n",
    "print(f\"Stacked train features shape: {stack_xc_train_features.shape}\")\n",
    "print(f\"Stacked test features shape:  {stack_xc_test_features.shape}\")\n",
    "\n",
    "# Train meta-learner (Logistic Regression)\n",
    "meta_learner_xc = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "meta_learner_xc.fit(stack_xc_train_features, y_train_xc)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_stack_xc = meta_learner_xc.predict(stack_xc_train_features)\n",
    "y_test_pred_stack_xc = meta_learner_xc.predict(stack_xc_test_features)\n",
    "\n",
    "# Evaluate\n",
    "train_acc_stack_xc = accuracy_score(y_train_xc, y_train_pred_stack_xc)\n",
    "test_acc_stack_xc = accuracy_score(y_test_xc, y_test_pred_stack_xc)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STACKING ENSEMBLE (XGBoost + CNN with Meta-Learner)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Train Accuracy: {train_acc_stack_xc:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc_stack_xc:.4f}\")\n",
    "print(f\"Gap:            {train_acc_stack_xc - test_acc_stack_xc:.4f}\")\n",
    "\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(y_test_xc, y_test_pred_stack_xc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2143dd",
   "metadata": {},
   "source": [
    "## Validation Shuffle Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ab35cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "def shuffle_split_validation_xgb_cnn(X, y, cnn_model, n_splits=5, test_size=0.2):\n",
    "    \"\"\"\n",
    "    X: 2D features (scaled)\n",
    "    y: labels\n",
    "    cnn_model: pre-built CNN model (untrained, will clone and train)\n",
    "    \"\"\"\n",
    "    ss = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
    "    \n",
    "    avg_scores = []\n",
    "    stack_scores = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(ss.split(X)):\n",
    "        print(f\"\\n===== Fold {fold+1} =====\")\n",
    "        X_train_fold = X[train_idx]\n",
    "        X_test_fold  = X[test_idx]\n",
    "        y_train_fold = y[train_idx]\n",
    "        y_test_fold  = y[test_idx]\n",
    "\n",
    "        # ---- XGBoost ----\n",
    "        xgb_fold = XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "            eval_metric='mlogloss'\n",
    "        )\n",
    "        xgb_fold.fit(X_train_fold, y_train_fold)\n",
    "        xgb_train_proba = xgb_fold.predict_proba(X_train_fold)\n",
    "        xgb_test_proba  = xgb_fold.predict_proba(X_test_fold)\n",
    "\n",
    "        # ---- CNN ----\n",
    "        # reshape for Conv1D\n",
    "        X_train_cnn = X_train_fold.reshape(X_train_fold.shape[0], X_train_fold.shape[1], 1)\n",
    "        X_test_cnn  = X_test_fold.reshape(X_test_fold.shape[0], X_test_fold.shape[1], 1)\n",
    "\n",
    "        # one-hot encode labels\n",
    "        num_classes = len(np.unique(y))\n",
    "        y_train_cat = to_categorical(y_train_fold, num_classes)\n",
    "        y_test_cat  = to_categorical(y_test_fold, num_classes)\n",
    "\n",
    "        # Clone CNN architecture\n",
    "        from tensorflow.keras.models import clone_model\n",
    "        cnn_fold = clone_model(cnn_model)\n",
    "        cnn_fold.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        cnn_fold.fit(\n",
    "            X_train_cnn, y_train_cat,\n",
    "            epochs=10,\n",
    "            batch_size=128,\n",
    "            verbose=0\n",
    "        )\n",
    "        cnn_train_proba = cnn_fold.predict(X_train_cnn)\n",
    "        cnn_test_proba  = cnn_fold.predict(X_test_cnn)\n",
    "\n",
    "        # ---- Averaging Ensemble ----\n",
    "        avg_test_proba = (xgb_test_proba + cnn_test_proba) / 2\n",
    "        y_pred_avg = np.argmax(avg_test_proba, axis=1)\n",
    "        avg_acc = accuracy_score(y_test_fold, y_pred_avg)\n",
    "        avg_scores.append(avg_acc)\n",
    "        print(f\"Averaging Ensemble Accuracy: {avg_acc:.4f}\")\n",
    "\n",
    "        # ---- Stacking Ensemble ----\n",
    "        stack_train = np.concatenate([xgb_train_proba, cnn_train_proba], axis=1)\n",
    "        stack_test  = np.concatenate([xgb_test_proba, cnn_test_proba], axis=1)\n",
    "\n",
    "        meta_learner = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        meta_learner.fit(stack_train, y_train_fold)\n",
    "        y_pred_stack = meta_learner.predict(stack_test)\n",
    "        stack_acc = accuracy_score(y_test_fold, y_pred_stack)\n",
    "        stack_scores.append(stack_acc)\n",
    "        print(f\"Stacking Ensemble Accuracy: {stack_acc:.4f}\")\n",
    "\n",
    "    print(\"\\n============================================\")\n",
    "    print(\"FINAL MEAN ACCURACY OVER SHUFFLE SPLITS\")\n",
    "    print(\"============================================\")\n",
    "    print(f\"Simple Averaging (XGB+CNN): {np.mean(avg_scores):.4f}\")\n",
    "    print(f\"Stacking (XGB+CNN):          {np.mean(stack_scores):.4f}\")\n",
    "\n",
    "    return avg_scores, stack_scores\n",
    "\n",
    "\n",
    "# Run validation\n",
    "avg_scores_xc, stack_scores_xc = shuffle_split_validation_xgb_cnn(\n",
    "    X_train_xc_scaled, y_train_xc, cnn_model=cnn_xc\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c77c170",
   "metadata": {},
   "source": [
    "## Complexity vs Error Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def complexity_curve_xgb_cnn(X_train, y_train, X_test, y_test, cnn_model):\n",
    "    \"\"\"\n",
    "    Plot XGBoost complexity vs error curve in XGB+CNN ensemble\n",
    "    \"\"\"\n",
    "    # reshape CNN input\n",
    "    X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test_cnn  = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    y_train_cat = to_categorical(y_train, num_classes)\n",
    "    y_test_cat  = to_categorical(y_test, num_classes)\n",
    "\n",
    "    complexities = [10, 50, 100, 150, 200]\n",
    "    errors = []\n",
    "\n",
    "    for n in complexities:\n",
    "        print(f\"\\nTraining XGBoost with n_estimators = {n}\")\n",
    "\n",
    "        # XGBoost\n",
    "        xgb_model = XGBClassifier(\n",
    "            n_estimators=n,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "            eval_metric='mlogloss'\n",
    "        )\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        xgb_test_proba = xgb_model.predict_proba(X_test)\n",
    "\n",
    "        # CNN (fixed)\n",
    "        cnn_clone = clone_model(cnn_model)\n",
    "        cnn_clone.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        cnn_clone.fit(X_train_cnn, y_train_cat, epochs=10, batch_size=128, verbose=0)\n",
    "        cnn_test_proba = cnn_clone.predict(X_test_cnn)\n",
    "\n",
    "        # Averaging ensemble\n",
    "        avg_test_proba = (xgb_test_proba + cnn_test_proba) / 2\n",
    "        y_pred = np.argmax(avg_test_proba, axis=1)\n",
    "        error = 1 - accuracy_score(y_test, y_pred)\n",
    "        errors.append(error)\n",
    "        print(f\"Error: {error:.4f}\")\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(complexities, errors, marker='o')\n",
    "    plt.xlabel(\"XGBoost n_estimators (Complexity)\")\n",
    "    plt.ylabel(\"Test Error (1 - Accuracy)\")\n",
    "    plt.title(\"Complexity vs Error Curve (XGBoost + CNN Ensemble)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run complexity curve\n",
    "complexity_curve_xgb_cnn(\n",
    "    X_train_xc_scaled, y_train_xc,\n",
    "    X_test_xc_scaled, y_test_xc,\n",
    "    cnn_model=cnn_xc\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8160a8c0",
   "metadata": {},
   "source": [
    "## Step 4: Compare All Approaches (XGBoost + CNN)\n",
    "\n",
    "Summary comparison of XGBoost, CNN, and ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe5a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe for XGBoost + CNN\n",
    "comparison_xc_df = pd.DataFrame({\n",
    "    'Model': ['XGBoost', 'CNN', 'Averaging Ensemble', 'Stacking Ensemble'],\n",
    "    'Train Accuracy': [xgb_xc_train_acc, cnn_xc_train_acc, train_acc_avg_xc, train_acc_stack_xc],\n",
    "    'Test Accuracy': [xgb_xc_test_acc, cnn_xc_test_acc, test_acc_avg_xc, test_acc_stack_xc],\n",
    "    'Overfitting': [\n",
    "        xgb_xc_train_acc - xgb_xc_test_acc,\n",
    "        cnn_xc_train_acc - cnn_xc_test_acc,\n",
    "        train_acc_avg_xc - test_acc_avg_xc,\n",
    "        train_acc_stack_xc - test_acc_stack_xc\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON: XGBoost vs CNN vs Ensembles\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_xc_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80c151e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c26357d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Ensemble: Naive Bayes + ANN\n",
    "\n",
    "Combine Naive Bayes and Artificial Neural Network predictions using averaging and stacking ensemble techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630c3e85",
   "metadata": {},
   "source": [
    "## Step 1: Train Naive Bayes and ANN Models\n",
    "\n",
    "Train both models on the same data and obtain probability predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4a3f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PREPARING DATA FOR NAIVE BAYES + ANN ENSEMBLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use the same data as XGB+NB (to ensure consistency)\n",
    "# If precomputed NB datasets exist, use them; otherwise, create them from num_df/y using sss.\n",
    "try:\n",
    "    X_train_nb_ann = X_train_nb_2d.copy()\n",
    "    X_test_nb_ann = X_test_nb_2d.copy()\n",
    "    y_train_nb_ann = y_train_nb_labels.copy()\n",
    "    y_test_nb_ann = y_test_nb_labels.copy()\n",
    "except NameError:\n",
    "    # Build numeric feature matrix and labels from existing variables\n",
    "    X_all = num_df.drop(columns=['Crime_Class_numeric']).values\n",
    "    y_all = y\n",
    "    # Use predefined StratifiedShuffleSplit to ensure consistent class distribution\n",
    "    train_idx, test_idx = next(sss.split(X_all, y_all))\n",
    "    X_train_nb_ann = X_all[train_idx]\n",
    "    X_test_nb_ann = X_all[test_idx]\n",
    "    y_train_nb_ann = y_all[train_idx]\n",
    "    y_test_nb_ann = y_all[test_idx]\n",
    "\n",
    "print(f\"\\nTraining set shape: {X_train_nb_ann.shape}\")\n",
    "print(f\"Testing set shape: {X_test_nb_ann.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_train_nb_ann))}\")\n",
    "\n",
    "# Train Naive Bayes (needs non-negative features)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING NAIVE BAYES MODEL\")\n",
    "print(\"=\"*70)\n",
    "# Impute missing values with 0 (MultinomialNB requires non-negative features)\n",
    "imputer_nb_ann = SimpleImputer(strategy='constant', fill_value=0.0)\n",
    "X_train_nb_ann_imputed = imputer_nb_ann.fit_transform(X_train_nb_ann)\n",
    "X_test_nb_ann_imputed = imputer_nb_ann.transform(X_test_nb_ann)\n",
    "\n",
    "scaler_nb_ann = MinMaxScaler()\n",
    "X_train_nb_ann_scaled = scaler_nb_ann.fit_transform(X_train_nb_ann_imputed)\n",
    "X_test_nb_ann_scaled = scaler_nb_ann.transform(X_test_nb_ann_imputed)\n",
    "\n",
    "# Use the best alpha from previous tuning\n",
    "nb_ann_model = MultinomialNB(alpha=1.0)\n",
    "nb_ann_model.fit(X_train_nb_ann_scaled, y_train_nb_ann)\n",
    "\n",
    "nb_ann_train_pred = nb_ann_model.predict(X_train_nb_ann_scaled)\n",
    "nb_ann_test_pred = nb_ann_model.predict(X_test_nb_ann_scaled)\n",
    "nb_ann_train_proba = nb_ann_model.predict_proba(X_train_nb_ann_scaled)\n",
    "nb_ann_test_proba = nb_ann_model.predict_proba(X_test_nb_ann_scaled)\n",
    "\n",
    "nb_ann_train_acc = accuracy_score(y_train_nb_ann, nb_ann_train_pred)\n",
    "nb_ann_test_acc = accuracy_score(y_test_nb_ann, nb_ann_test_pred)\n",
    "\n",
    "print(f\"Naive Bayes Train Accuracy: {nb_ann_train_acc:.4f}\")\n",
    "print(f\"Naive Bayes Test Accuracy:  {nb_ann_test_acc:.4f}\")\n",
    "\n",
    "# Train ANN (needs standardized features)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING ANN MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "scaler_ann = StandardScaler()\n",
    "scaler_ann = StandardScaler()\n",
    "X_train_ann_scaled = scaler_ann.fit_transform(X_train_nb_ann_imputed)\n",
    "X_test_ann_scaled = scaler_ann.transform(X_test_nb_ann_imputed)\n",
    "# One-hot encode labels for ANN\n",
    "num_classes_ann = len(np.unique(y_train_nb_ann))\n",
    "y_train_ann_cat = to_categorical(y_train_nb_ann, num_classes_ann)\n",
    "y_test_ann_cat = to_categorical(y_test_nb_ann, num_classes_ann)\n",
    "\n",
    "# Build ANN model\n",
    "ann_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_ann_scaled.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes_ann, activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train ANN\n",
    "history_nb_ann = ann_model.fit(\n",
    "    X_train_ann_scaled, y_train_ann_cat,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test_ann_scaled, y_test_ann_cat)\n",
    ")\n",
    "\n",
    "# Get ANN predictions\n",
    "ann_train_proba = ann_model.predict(X_train_ann_scaled)\n",
    "ann_test_proba = ann_model.predict(X_test_ann_scaled)\n",
    "ann_train_pred = np.argmax(ann_train_proba, axis=1)\n",
    "ann_test_pred = np.argmax(ann_test_proba, axis=1)\n",
    "\n",
    "ann_train_acc = accuracy_score(y_train_nb_ann, ann_train_pred)\n",
    "ann_test_acc = accuracy_score(y_test_nb_ann, ann_test_pred)\n",
    "\n",
    "print(f\"\\nANN Train Accuracy: {ann_train_acc:.4f}\")\n",
    "print(f\"ANN Test Accuracy:  {ann_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f28d6f",
   "metadata": {},
   "source": [
    "## Step 2: Averaging Ensemble\n",
    "\n",
    "Average the probability predictions from both models and evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b74b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple averaging: equal weights (0.5, 0.5)\n",
    "avg_nb_ann_train_proba = (nb_ann_train_proba + ann_train_proba) / 2\n",
    "avg_nb_ann_test_proba = (nb_ann_test_proba + ann_test_proba) / 2\n",
    "\n",
    "# Get predictions by taking argmax\n",
    "y_train_pred_avg_nb_ann = np.argmax(avg_nb_ann_train_proba, axis=1)\n",
    "y_test_pred_avg_nb_ann = np.argmax(avg_nb_ann_test_proba, axis=1)\n",
    "\n",
    "# Evaluate\n",
    "train_acc_avg_nb_ann = accuracy_score(y_train_nb_ann, y_train_pred_avg_nb_ann)\n",
    "test_acc_avg_nb_ann = accuracy_score(y_test_nb_ann, y_test_pred_avg_nb_ann)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"AVERAGING ENSEMBLE (Naive Bayes + ANN)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Train Accuracy: {train_acc_avg_nb_ann:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc_avg_nb_ann:.4f}\")\n",
    "print(f\"Gap:            {train_acc_avg_nb_ann - test_acc_avg_nb_ann:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c6711",
   "metadata": {},
   "source": [
    "## Step 3: Stacking Ensemble\n",
    "\n",
    "Use a meta-learner (Logistic Regression) trained on the predictions of both base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2390dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking: concatenate probabilities as features\n",
    "stack_nb_ann_train_features = np.concatenate([nb_ann_train_proba, ann_train_proba], axis=1)\n",
    "stack_nb_ann_test_features = np.concatenate([nb_ann_test_proba, ann_test_proba], axis=1)\n",
    "\n",
    "print(f\"Stacked train features shape: {stack_nb_ann_train_features.shape}\")\n",
    "print(f\"Stacked test features shape: {stack_nb_ann_test_features.shape}\")\n",
    "\n",
    "# Train meta-learner (Logistic Regression)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "meta_learner_nb_ann = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "meta_learner_nb_ann.fit(stack_nb_ann_train_features, y_train_nb_ann)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_stack_nb_ann = meta_learner_nb_ann.predict(stack_nb_ann_train_features)\n",
    "y_test_pred_stack_nb_ann = meta_learner_nb_ann.predict(stack_nb_ann_test_features)\n",
    "\n",
    "# Evaluate\n",
    "train_acc_stack_nb_ann = accuracy_score(y_train_nb_ann, y_train_pred_stack_nb_ann)\n",
    "test_acc_stack_nb_ann = accuracy_score(y_test_nb_ann, y_test_pred_stack_nb_ann)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STACKING ENSEMBLE (Naive Bayes + ANN with Meta-Learner)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Train Accuracy: {train_acc_stack_nb_ann:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc_stack_nb_ann:.4f}\")\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(y_test_nb_ann, y_test_pred_stack_nb_ann))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb87cceb",
   "metadata": {},
   "source": [
    "## Validation Split Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d056cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.models import clone_model\n",
    "import numpy as np\n",
    "\n",
    "def shuffle_split_validation_nb_ann(X, y, ann_model, n_splits=5, test_size=0.2, nb_alpha=1.0):\n",
    "    \"\"\"\n",
    "    ShuffleSplit validation for Naive Bayes + ANN ensemble.\n",
    "    X: feature matrix (2D)\n",
    "    y: labels\n",
    "    ann_model: pre-built ANN model (untrained, will clone and train per fold)\n",
    "    \"\"\"\n",
    "    ss = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
    "    \n",
    "    avg_scores = []\n",
    "    stack_scores = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(ss.split(X)):\n",
    "        print(f\"\\n===== Fold {fold+1} =====\")\n",
    "        X_train_fold = X[train_idx]\n",
    "        X_test_fold  = X[test_idx]\n",
    "        y_train_fold = y[train_idx]\n",
    "        y_test_fold  = y[test_idx]\n",
    "\n",
    "        # ---- Naive Bayes ----\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        scaler_nb = MinMaxScaler()\n",
    "        X_train_nb = scaler_nb.fit_transform(X_train_fold)\n",
    "        X_test_nb  = scaler_nb.transform(X_test_fold)\n",
    "\n",
    "        nb_model = MultinomialNB(alpha=nb_alpha)\n",
    "        nb_model.fit(X_train_nb, y_train_fold)\n",
    "        nb_train_proba = nb_model.predict_proba(X_train_nb)\n",
    "        nb_test_proba  = nb_model.predict_proba(X_test_nb)\n",
    "\n",
    "        # ---- ANN ----\n",
    "        from tensorflow.keras.utils import to_categorical\n",
    "        num_classes = len(np.unique(y))\n",
    "        y_train_cat = to_categorical(y_train_fold, num_classes)\n",
    "        y_test_cat  = to_categorical(y_test_fold, num_classes)\n",
    "\n",
    "        # Standardize features for ANN\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler_ann = StandardScaler()\n",
    "        X_train_ann = scaler_ann.fit_transform(X_train_fold)\n",
    "        X_test_ann  = scaler_ann.transform(X_test_fold)\n",
    "\n",
    "        # Clone ANN architecture\n",
    "        ann_fold = clone_model(ann_model)\n",
    "        ann_fold.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        ann_fold.fit(\n",
    "            X_train_ann, y_train_cat,\n",
    "            epochs=10,\n",
    "            batch_size=32,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        ann_train_proba = ann_fold.predict(X_train_ann)\n",
    "        ann_test_proba  = ann_fold.predict(X_test_ann)\n",
    "\n",
    "        # ---- Simple Averaging Ensemble ----\n",
    "        avg_test_proba = (nb_test_proba + ann_test_proba) / 2\n",
    "        y_pred_avg = np.argmax(avg_test_proba, axis=1)\n",
    "        avg_acc = accuracy_score(y_test_fold, y_pred_avg)\n",
    "        avg_scores.append(avg_acc)\n",
    "        print(f\"Averaging Ensemble Accuracy: {avg_acc:.4f}\")\n",
    "\n",
    "        # ---- Stacking Ensemble ----\n",
    "        stack_train = np.concatenate([nb_train_proba, ann_train_proba], axis=1)\n",
    "        stack_test  = np.concatenate([nb_test_proba, ann_test_proba], axis=1)\n",
    "\n",
    "        meta_learner = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        meta_learner.fit(stack_train, y_train_fold)\n",
    "        y_pred_stack = meta_learner.predict(stack_test)\n",
    "        stack_acc = accuracy_score(y_test_fold, y_pred_stack)\n",
    "        stack_scores.append(stack_acc)\n",
    "        print(f\"Stacking Ensemble Accuracy: {stack_acc:.4f}\")\n",
    "\n",
    "    print(\"\\n============================================\")\n",
    "    print(\"FINAL MEAN ACCURACY OVER SHUFFLE SPLITS\")\n",
    "    print(\"============================================\")\n",
    "    print(f\"Simple Averaging (NB+ANN): {np.mean(avg_scores):.4f}\")\n",
    "    print(f\"Stacking (NB+ANN):          {np.mean(stack_scores):.4f}\")\n",
    "\n",
    "    return avg_scores, stack_scores\n",
    "\n",
    "# Run validation\n",
    "avg_scores_nb_ann, stack_scores_nb_ann = shuffle_split_validation_nb_ann(\n",
    "    X_train_nb_ann_scaled, y_train_nb_ann, ann_model=ann_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08703971",
   "metadata": {},
   "source": [
    "## Complexity vs Error Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd1cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import clone_model\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "\n",
    "def complexity_curve_nb_ann(X_train, y_train, X_test, y_test, ann_model, nb_alpha=1.0):\n",
    "    \"\"\"\n",
    "    Plot complexity vs error curve for Naive Bayes + ANN averaging ensemble\n",
    "    Complexity measured by increasing ANN hidden layer neurons\n",
    "    \"\"\"\n",
    "    # NB preprocessing\n",
    "    scaler_nb = MinMaxScaler()\n",
    "    X_train_nb = scaler_nb.fit_transform(X_train)\n",
    "    X_test_nb  = scaler_nb.transform(X_test)\n",
    "\n",
    "    # ANN preprocessing\n",
    "    scaler_ann = StandardScaler()\n",
    "    X_train_ann = scaler_ann.fit_transform(X_train)\n",
    "    X_test_ann  = scaler_ann.transform(X_test)\n",
    "\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    y_train_cat = to_categorical(y_train, num_classes)\n",
    "    y_test_cat  = to_categorical(y_test, num_classes)\n",
    "\n",
    "    complexities = [16, 32, 64, 128, 256]  # hidden neurons in first layer\n",
    "    errors = []\n",
    "\n",
    "    for neurons in complexities:\n",
    "        print(f\"\\nTraining ANN with {neurons} hidden neurons\")\n",
    "\n",
    "        # Clone ANN architecture and adjust first layer\n",
    "        ann_clone = Sequential([\n",
    "            Dense(neurons, activation='relu', input_shape=(X_train_ann.shape[1],)),\n",
    "            Dropout(0.3),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        ann_clone.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        ann_clone.fit(X_train_ann, y_train_cat, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "        # Predict ANN\n",
    "        ann_test_proba = ann_clone.predict(X_test_ann)\n",
    "\n",
    "        # NB prediction\n",
    "        nb_model = MultinomialNB(alpha=nb_alpha)\n",
    "        nb_model.fit(X_train_nb, y_train)\n",
    "        nb_test_proba = nb_model.predict_proba(X_test_nb)\n",
    "\n",
    "        # Averaging ensemble\n",
    "        avg_test_proba = (nb_test_proba + ann_test_proba) / 2\n",
    "        y_pred = np.argmax(avg_test_proba, axis=1)\n",
    "        error = 1 - accuracy_score(y_test, y_pred)\n",
    "        errors.append(error)\n",
    "        print(f\"Error: {error:.4f}\")\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(complexities, errors, marker='o')\n",
    "    plt.xlabel(\"ANN Hidden Layer Neurons (Complexity)\")\n",
    "    plt.ylabel(\"Test Error (1 - Accuracy)\")\n",
    "    plt.title(\"Complexity vs Error Curve (NB + ANN Ensemble)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Run complexity curve\n",
    "complexity_curve_nb_ann(\n",
    "    X_train_nb_ann_scaled, y_train_nb_ann,\n",
    "    X_test_nb_ann_scaled, y_test_nb_ann,\n",
    "    ann_model=ann_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3235bd",
   "metadata": {},
   "source": [
    "## Step 4: Compare All Approaches\n",
    "\n",
    "Summary comparison of Naive Bayes, ANN, and ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63fae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe for NB + ANN\n",
    "import pandas as pd\n",
    "\n",
    "comparison_nb_ann_df = pd.DataFrame({\n",
    "    'Model': ['Naive Bayes', 'ANN', 'Averaging Ensemble', 'Stacking Ensemble'],\n",
    "    'Train Accuracy': [nb_ann_train_acc, ann_train_acc, train_acc_avg_nb_ann, train_acc_stack_nb_ann],\n",
    "    'Test Accuracy': [nb_ann_test_acc, ann_test_acc, test_acc_avg_nb_ann, test_acc_stack_nb_ann],\n",
    "    'Overfitting': [\n",
    "        nb_ann_train_acc - nb_ann_test_acc,\n",
    "        ann_train_acc - ann_test_acc,\n",
    "        train_acc_avg_nb_ann - test_acc_avg_nb_ann,\n",
    "        train_acc_stack_nb_ann - test_acc_stack_nb_ann\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON: Naive Bayes vs ANN vs Ensembles\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_nb_ann_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
