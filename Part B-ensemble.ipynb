{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee58aa2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Note to self, if it takes too long to run, then just don't run any of the parts that take too long, unless tweaks are applied to the data preprocessing part. You only need to run it once for the output. Hello."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b30daae",
   "metadata": {},
   "source": [
    "### Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c58889a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf145558",
   "metadata": {},
   "source": [
    "## Part A - Model Variety Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28669f8",
   "metadata": {},
   "source": [
    "### Import Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54d9e724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_7704\\1256870994.py:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  df_raw = pd.read_csv(\"C:\\Datasets\\Crime_Data_from_2020_to_Present.csv\", low_memory=\"False\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date Rptd</th>\n",
       "      <th>DATE OCC</th>\n",
       "      <th>TIME OCC</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Crm Cd</th>\n",
       "      <th>Crm Cd Desc</th>\n",
       "      <th>...</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>Crm Cd 1</th>\n",
       "      <th>Crm Cd 2</th>\n",
       "      <th>Crm Cd 3</th>\n",
       "      <th>Crm Cd 4</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>Cross Street</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211507896</td>\n",
       "      <td>11/4/2021 0:00</td>\n",
       "      <td>7/11/2020 0:00</td>\n",
       "      <td>845</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>354</td>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>354.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7800    BEEMAN                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>-118.4092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201516622</td>\n",
       "      <td>10/21/2020 12:00:00 AM</td>\n",
       "      <td>10/18/2020 12:00:00 AM</td>\n",
       "      <td>1845</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ATOLL                        AV</td>\n",
       "      <td>N  GAULT</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>-118.4203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240913563</td>\n",
       "      <td>10/12/2024 0:00</td>\n",
       "      <td>10/30/2020 12:00:00 AM</td>\n",
       "      <td>1240</td>\n",
       "      <td>9</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>354</td>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>354.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14600    SYLVAN                       ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>-118.4509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210704711</td>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>1310</td>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>331</td>\n",
       "      <td>THEFT FROM MOTOR VEHICLE - GRAND ($950.01 AND ...</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>331.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6000    COMEY                        AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>-118.3747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201418201</td>\n",
       "      <td>3/10/2020 0:00</td>\n",
       "      <td>09/29/2020 12:00:00 AM</td>\n",
       "      <td>1830</td>\n",
       "      <td>14</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>THEFT FROM MOTOR VEHICLE - PETTY ($950 &amp; UNDER)</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>420.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4700    LA VILLA MARINA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>-118.4350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>252104112</td>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>130</td>\n",
       "      <td>21</td>\n",
       "      <td>Topanga</td>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>946</td>\n",
       "      <td>OTHER MISCELLANEOUS CRIME</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>946.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22100    ROSCOE                       BL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>-118.6126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>250404100</td>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>Hollenbeck</td>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>237</td>\n",
       "      <td>CHILD NEGLECT (SEE 300 W.I.C.)</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3500    PERCY                        ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>-118.1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>251304095</td>\n",
       "      <td>01/31/2025 12:00:00 AM</td>\n",
       "      <td>01/30/2025 12:00:00 AM</td>\n",
       "      <td>1554</td>\n",
       "      <td>13</td>\n",
       "      <td>Newton</td>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>850</td>\n",
       "      <td>INDECENT EXPOSURE</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300 E  53RD                         ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>-118.2701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>251704066</td>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>1600</td>\n",
       "      <td>17</td>\n",
       "      <td>Devonshire</td>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>624</td>\n",
       "      <td>BATTERY - SIMPLE ASSAULT</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>624.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9600    ZELZAH                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>-118.5233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>251904210</td>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>1235</td>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>850</td>\n",
       "      <td>INDECENT EXPOSURE</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11100    OMELVENY                     AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>-118.4417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Date Rptd                DATE OCC  TIME OCC  \\\n",
       "0        211507896          11/4/2021 0:00          7/11/2020 0:00       845   \n",
       "1        201516622  10/21/2020 12:00:00 AM  10/18/2020 12:00:00 AM      1845   \n",
       "2        240913563         10/12/2024 0:00  10/30/2020 12:00:00 AM      1240   \n",
       "3        210704711  12/24/2020 12:00:00 AM  12/24/2020 12:00:00 AM      1310   \n",
       "4        201418201          3/10/2020 0:00  09/29/2020 12:00:00 AM      1830   \n",
       "...            ...                     ...                     ...       ...   \n",
       "1004986  252104112           2/2/2025 0:00           2/2/2025 0:00       130   \n",
       "1004987  250404100  02/18/2025 12:00:00 AM  02/18/2025 12:00:00 AM      1000   \n",
       "1004988  251304095  01/31/2025 12:00:00 AM  01/30/2025 12:00:00 AM      1554   \n",
       "1004989  251704066  01/17/2025 12:00:00 AM  01/17/2025 12:00:00 AM      1600   \n",
       "1004990  251904210  03/25/2025 12:00:00 AM  03/25/2025 12:00:00 AM      1235   \n",
       "\n",
       "         AREA    AREA NAME  Rpt Dist No  Part 1-2  Crm Cd  \\\n",
       "0          15  N Hollywood         1502         2     354   \n",
       "1          15  N Hollywood         1521         1     230   \n",
       "2           9     Van Nuys          933         2     354   \n",
       "3           7     Wilshire          782         1     331   \n",
       "4          14      Pacific         1454         1     420   \n",
       "...       ...          ...          ...       ...     ...   \n",
       "1004986    21      Topanga         2103         2     946   \n",
       "1004987     4   Hollenbeck          479         2     237   \n",
       "1004988    13       Newton         1372         2     850   \n",
       "1004989    17   Devonshire         1774         2     624   \n",
       "1004990    19      Mission         1944         2     850   \n",
       "\n",
       "                                               Crm Cd Desc  ... Status  \\\n",
       "0                                        THEFT OF IDENTITY  ...     IC   \n",
       "1           ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT  ...     IC   \n",
       "2                                        THEFT OF IDENTITY  ...     IC   \n",
       "3        THEFT FROM MOTOR VEHICLE - GRAND ($950.01 AND ...  ...     IC   \n",
       "4          THEFT FROM MOTOR VEHICLE - PETTY ($950 & UNDER)  ...     IC   \n",
       "...                                                    ...  ...    ...   \n",
       "1004986                          OTHER MISCELLANEOUS CRIME  ...     IC   \n",
       "1004987                     CHILD NEGLECT (SEE 300 W.I.C.)  ...     IC   \n",
       "1004988                                  INDECENT EXPOSURE  ...     IC   \n",
       "1004989                           BATTERY - SIMPLE ASSAULT  ...     IC   \n",
       "1004990                                  INDECENT EXPOSURE  ...     IC   \n",
       "\n",
       "         Status Desc Crm Cd 1 Crm Cd 2  Crm Cd 3 Crm Cd 4  \\\n",
       "0        Invest Cont    354.0      NaN       NaN      NaN   \n",
       "1        Invest Cont    230.0      NaN       NaN      NaN   \n",
       "2        Invest Cont    354.0      NaN       NaN      NaN   \n",
       "3        Invest Cont    331.0      NaN       NaN      NaN   \n",
       "4        Invest Cont    420.0      NaN       NaN      NaN   \n",
       "...              ...      ...      ...       ...      ...   \n",
       "1004986  Invest Cont    946.0      NaN       NaN      NaN   \n",
       "1004987  Invest Cont    237.0      NaN       NaN      NaN   \n",
       "1004988  Invest Cont    850.0      NaN       NaN      NaN   \n",
       "1004989  Invest Cont    624.0      NaN       NaN      NaN   \n",
       "1004990  Invest Cont    850.0      NaN       NaN      NaN   \n",
       "\n",
       "                                         LOCATION Cross Street      LAT  \\\n",
       "0         7800    BEEMAN                       AV          NaN  34.2124   \n",
       "1                 ATOLL                        AV     N  GAULT  34.1993   \n",
       "2        14600    SYLVAN                       ST          NaN  34.1847   \n",
       "3         6000    COMEY                        AV          NaN  34.0339   \n",
       "4                         4700    LA VILLA MARINA          NaN  33.9813   \n",
       "...                                           ...          ...      ...   \n",
       "1004986  22100    ROSCOE                       BL          NaN  34.2259   \n",
       "1004987   3500    PERCY                        ST          NaN  34.0277   \n",
       "1004988    300 E  53RD                         ST          NaN  33.9942   \n",
       "1004989   9600    ZELZAH                       AV          NaN  34.2450   \n",
       "1004990  11100    OMELVENY                     AV          NaN  34.2722   \n",
       "\n",
       "              LON  \n",
       "0       -118.4092  \n",
       "1       -118.4203  \n",
       "2       -118.4509  \n",
       "3       -118.3747  \n",
       "4       -118.4350  \n",
       "...           ...  \n",
       "1004986 -118.6126  \n",
       "1004987 -118.1979  \n",
       "1004988 -118.2701  \n",
       "1004989 -118.5233  \n",
       "1004990 -118.4417  \n",
       "\n",
       "[1004991 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset from a Folder called Datasets, plaed inside C drive.\n",
    "df_raw = pd.read_csv(\"C:\\Datasets\\Crime_Data_from_2020_to_Present.csv\", low_memory=\"False\")\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb98743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1004991 entries, 0 to 1004990\n",
      "Data columns (total 28 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0                   1004991 non-null  int64  \n",
      " 1   Date Rptd       1004991 non-null  object \n",
      " 2   DATE OCC        1004991 non-null  object \n",
      " 3   TIME OCC        1004991 non-null  int64  \n",
      " 4   AREA            1004991 non-null  int64  \n",
      " 5   AREA NAME       1004991 non-null  object \n",
      " 6   Rpt Dist No     1004991 non-null  int64  \n",
      " 7   Part 1-2        1004991 non-null  int64  \n",
      " 8   Crm Cd          1004991 non-null  int64  \n",
      " 9   Crm Cd Desc     1004991 non-null  object \n",
      " 10  Mocodes         853372 non-null   object \n",
      " 11  Vict Age        1004991 non-null  int64  \n",
      " 12  Vict Sex        860347 non-null   object \n",
      " 13  Vict Descent    860335 non-null   object \n",
      " 14  Premis Cd       1004975 non-null  float64\n",
      " 15  Premis Desc     1004403 non-null  object \n",
      " 16  Weapon Used Cd  327247 non-null   float64\n",
      " 17  Weapon Desc     327247 non-null   object \n",
      " 18  Status          1004990 non-null  object \n",
      " 19  Status Desc     1004991 non-null  object \n",
      " 20  Crm Cd 1        1004980 non-null  float64\n",
      " 21  Crm Cd 2        69160 non-null    float64\n",
      " 22  Crm Cd 3        2314 non-null     float64\n",
      " 23  Crm Cd 4        64 non-null       float64\n",
      " 24  LOCATION        1004991 non-null  object \n",
      " 25  Cross Street    154236 non-null   object \n",
      " 26  LAT             1004991 non-null  float64\n",
      " 27  LON             1004991 non-null  float64\n",
      "dtypes: float64(8), int64(7), object(13)\n",
      "memory usage: 214.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807fe6a",
   "metadata": {},
   "source": [
    "### View Unique values for Crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d13c5822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140,\n",
       " array(['THEFT OF IDENTITY',\n",
       "        'ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT',\n",
       "        'THEFT FROM MOTOR VEHICLE - GRAND ($950.01 AND OVER)',\n",
       "        'THEFT FROM MOTOR VEHICLE - PETTY ($950 & UNDER)',\n",
       "        'CRM AGNST CHLD (13 OR UNDER) (14-15 & SUSP 10 YRS OLDER)',\n",
       "        'VEHICLE - STOLEN', 'BURGLARY', 'BURGLARY FROM VEHICLE',\n",
       "        'THEFT PLAIN - PETTY ($950 & UNDER)',\n",
       "        'INTIMATE PARTNER - SIMPLE ASSAULT', 'BATTERY - SIMPLE ASSAULT',\n",
       "        'VANDALISM - MISDEAMEANOR ($399 OR UNDER)',\n",
       "        'VEHICLE - ATTEMPT STOLEN',\n",
       "        'VANDALISM - FELONY ($400 & OVER, ALL CHURCH VANDALISMS)',\n",
       "        'ROBBERY', 'FIREARMS RESTRAINING ORDER (FIREARMS RO)',\n",
       "        'BIKE - STOLEN', 'EMBEZZLEMENT, GRAND THEFT ($950.01 & OVER)',\n",
       "        'CHILD ABUSE (PHYSICAL) - SIMPLE ASSAULT',\n",
       "        'CRIMINAL THREATS - NO WEAPON DISPLAYED',\n",
       "        'THEFT-GRAND ($950.01 & OVER)EXCPT,GUNS,FOWL,LIVESTK,PROD',\n",
       "        'BATTERY WITH SEXUAL CONTACT',\n",
       "        'LETTERS, LEWD  -  TELEPHONE CALLS, LEWD',\n",
       "        'VIOLATION OF COURT ORDER', 'ARSON',\n",
       "        'VIOLATION OF RESTRAINING ORDER', 'THEFT, PERSON',\n",
       "        'CONTEMPT OF COURT', 'INTIMATE PARTNER - AGGRAVATED ASSAULT',\n",
       "        'ATTEMPTED ROBBERY', 'LEWD/LASCIVIOUS ACTS WITH CHILD',\n",
       "        'OTHER MISCELLANEOUS CRIME', 'BRANDISH WEAPON', 'TRESPASSING',\n",
       "        'BUNCO, ATTEMPT', 'SHOPLIFTING - PETTY THEFT ($950 & UNDER)',\n",
       "        'BURGLARY, ATTEMPTED', 'DOCUMENT FORGERY / STOLEN FELONY',\n",
       "        'SHOPLIFTING-GRAND THEFT ($950.01 & OVER)', 'FAILURE TO YIELD',\n",
       "        'BATTERY POLICE (SIMPLE)',\n",
       "        'VEHICLE, STOLEN - OTHER (MOTORIZED SCOOTERS, BIKES, ETC)',\n",
       "        'CHILD NEGLECT (SEE 300 W.I.C.)', 'RAPE, ATTEMPTED',\n",
       "        'BUNCO, GRAND THEFT', 'CONTRIBUTING', 'PIMPING', 'OTHER ASSAULT',\n",
       "        'SODOMY/SEXUAL CONTACT B/W PENIS OF ONE PERS TO ANUS OTH',\n",
       "        'RAPE, FORCIBLE', 'SEX OFFENDER REGISTRANT OUT OF COMPLIANCE',\n",
       "        'DISCHARGE FIREARMS/SHOTS FIRED', 'EXTORTION',\n",
       "        'SHOTS FIRED AT MOVING VEHICLE, TRAIN OR AIRCRAFT',\n",
       "        'ASSAULT WITH DEADLY WEAPON ON POLICE OFFICER',\n",
       "        'BUNCO, PETTY THEFT', 'RESISTING ARREST',\n",
       "        'VIOLATION OF TEMPORARY RESTRAINING ORDER',\n",
       "        'CHILD ANNOYING (17YRS & UNDER)',\n",
       "        'SHOTS FIRED AT INHABITED DWELLING',\n",
       "        'BURGLARY FROM VEHICLE, ATTEMPTED',\n",
       "        'THROWING OBJECT AT MOVING VEHICLE',\n",
       "        'SEX,UNLAWFUL(INC MUTUAL CONSENT, PENETRATION W/ FRGN OBJ',\n",
       "        'ORAL COPULATION', 'SEXUAL PENETRATION W/FOREIGN OBJECT',\n",
       "        'LEWD CONDUCT', 'PICKPOCKET', 'CHILD STEALING', 'PURSE SNATCHING',\n",
       "        'THEFT FROM MOTOR VEHICLE - ATTEMPT',\n",
       "        'HUMAN TRAFFICKING - COMMERCIAL SEX ACTS', 'INDECENT EXPOSURE',\n",
       "        'DISHONEST EMPLOYEE - PETTY THEFT',\n",
       "        'EMBEZZLEMENT, PETTY THEFT ($950 & UNDER)', 'KIDNAPPING',\n",
       "        'DISTURBING THE PEACE', 'UNAUTHORIZED COMPUTER ACCESS',\n",
       "        'CRIMINAL HOMICIDE', 'THEFT PLAIN - ATTEMPT',\n",
       "        'REPLICA FIREARMS(SALE,DISPLAY,MANUFACTURE OR DISTRIBUTE)',\n",
       "        'LYNCHING', 'RECKLESS DRIVING', 'THREATENING PHONE CALLS/LETTERS',\n",
       "        'SHOPLIFTING - ATTEMPT', 'BOMB SCARE',\n",
       "        'CHILD ABUSE (PHYSICAL) - AGGRAVATED ASSAULT', 'STALKING',\n",
       "        'DRIVING WITHOUT OWNER CONSENT (DWOC)', 'BATTERY ON A FIREFIGHTER',\n",
       "        'PEEPING TOM', 'FALSE POLICE REPORT', 'BOAT - STOLEN',\n",
       "        'DEFRAUDING INNKEEPER/THEFT OF SERVICES, $950 & UNDER',\n",
       "        'ILLEGAL DUMPING', 'DRUGS, TO A MINOR',\n",
       "        'THEFT, COIN MACHINE - PETTY ($950 & UNDER)',\n",
       "        'CREDIT CARDS, FRAUD USE ($950 & UNDER', 'MANSLAUGHTER, NEGLIGENT',\n",
       "        'THEFT FROM PERSON - ATTEMPT', 'KIDNAPPING - GRAND ATTEMPT',\n",
       "        'THEFT, COIN MACHINE - ATTEMPT', 'PETTY THEFT - AUTO REPAIR',\n",
       "        'DOCUMENT WORTHLESS ($200 & UNDER)', 'FALSE IMPRISONMENT',\n",
       "        'CREDIT CARDS, FRAUD USE ($950.01 & OVER)',\n",
       "        'DEFRAUDING INNKEEPER/THEFT OF SERVICES, OVER $950.01',\n",
       "        'CHILD PORNOGRAPHY', 'PANDERING',\n",
       "        'HUMAN TRAFFICKING - INVOLUNTARY SERVITUDE', 'CRUELTY TO ANIMALS',\n",
       "        'COUNTERFEIT', 'DISHONEST EMPLOYEE - GRAND THEFT', 'PROWLER',\n",
       "        'DOCUMENT WORTHLESS ($200.01 & OVER)',\n",
       "        'WEAPONS POSSESSION/BOMBING', 'GRAND THEFT / AUTO REPAIR',\n",
       "        'CONSPIRACY', 'DRUNK ROLL', 'LYNCHING - ATTEMPTED',\n",
       "        'THEFT, COIN MACHINE - GRAND ($950.01 & OVER)', 'DISRUPT SCHOOL',\n",
       "        'TILL TAP - PETTY ($950 & UNDER)', 'PICKPOCKET, ATTEMPT',\n",
       "        'GRAND THEFT / INSURANCE FRAUD',\n",
       "        'TILL TAP - GRAND THEFT ($950.01 & OVER)',\n",
       "        'PURSE SNATCHING - ATTEMPT', 'BIKE - ATTEMPTED STOLEN', 'BRIBERY',\n",
       "        'CHILD ABANDONMENT', 'TELEPHONE PROPERTY - DAMAGE',\n",
       "        'BEASTIALITY, CRIME AGAINST NATURE SEXUAL ASSLT WITH ANIM',\n",
       "        'BIGAMY', 'FAILURE TO DISPERSE',\n",
       "        'FIREARMS EMERGENCY PROTECTIVE ORDER (FIREARMS EPO)',\n",
       "        'INCEST (SEXUAL ACTS BETWEEN BLOOD RELATIVES)',\n",
       "        'BLOCKING DOOR INDUCTION CENTER', 'INCITING A RIOT',\n",
       "        'DISHONEST EMPLOYEE ATTEMPTED THEFT', 'TRAIN WRECKING',\n",
       "        'DRUNK ROLL - ATTEMPT'], dtype=object))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_desc = df_raw[\"Crm Cd Desc\"].dropna().unique()\n",
    "len(unique_desc), unique_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e593aa3b",
   "metadata": {},
   "source": [
    "## DataPrep\n",
    "\n",
    "### Map each Crime commited to a matching Criminal Offense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b10537ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crm Cd Desc</th>\n",
       "      <th>Crime_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>\n",
       "      <td>Violent Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THEFT FROM MOTOR VEHICLE - GRAND ($950.01 AND ...</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THEFT FROM MOTOR VEHICLE - PETTY ($950 &amp; UNDER)</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CRM AGNST CHLD (13 OR UNDER) (14-15 &amp; SUSP 10 ...</td>\n",
       "      <td>Other Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CRM AGNST CHLD (13 OR UNDER) (14-15 &amp; SUSP 10 ...</td>\n",
       "      <td>Other Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VEHICLE - STOLEN</td>\n",
       "      <td>Vehicle Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BURGLARY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BURGLARY FROM VEHICLE</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>THEFT PLAIN - PETTY ($950 &amp; UNDER)</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>INTIMATE PARTNER - SIMPLE ASSAULT</td>\n",
       "      <td>Violent Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BATTERY - SIMPLE ASSAULT</td>\n",
       "      <td>Violent Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BURGLARY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BURGLARY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>THEFT PLAIN - PETTY ($950 &amp; UNDER)</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>THEFT PLAIN - PETTY ($950 &amp; UNDER)</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>THEFT PLAIN - PETTY ($950 &amp; UNDER)</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BURGLARY</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>\n",
       "      <td>Violent Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>VANDALISM - MISDEAMEANOR ($399 OR UNDER)</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>VEHICLE - ATTEMPT STOLEN</td>\n",
       "      <td>Vehicle Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>VANDALISM - FELONY ($400 &amp; OVER, ALL CHURCH VA...</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ROBBERY</td>\n",
       "      <td>Other Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>INTIMATE PARTNER - SIMPLE ASSAULT</td>\n",
       "      <td>Violent Crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Crm Cd Desc     Crime_Class\n",
       "0                                   THEFT OF IDENTITY  Property Crime\n",
       "1      ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT   Violent Crime\n",
       "2                                   THEFT OF IDENTITY  Property Crime\n",
       "3   THEFT FROM MOTOR VEHICLE - GRAND ($950.01 AND ...  Property Crime\n",
       "4     THEFT FROM MOTOR VEHICLE - PETTY ($950 & UNDER)  Property Crime\n",
       "5                                   THEFT OF IDENTITY  Property Crime\n",
       "6                                   THEFT OF IDENTITY  Property Crime\n",
       "7   CRM AGNST CHLD (13 OR UNDER) (14-15 & SUSP 10 ...     Other Crime\n",
       "8                                   THEFT OF IDENTITY  Property Crime\n",
       "9                                   THEFT OF IDENTITY  Property Crime\n",
       "10  CRM AGNST CHLD (13 OR UNDER) (14-15 & SUSP 10 ...     Other Crime\n",
       "11                                  THEFT OF IDENTITY  Property Crime\n",
       "12                                   VEHICLE - STOLEN   Vehicle Crime\n",
       "13                                           BURGLARY  Property Crime\n",
       "14                              BURGLARY FROM VEHICLE  Property Crime\n",
       "15                 THEFT PLAIN - PETTY ($950 & UNDER)  Property Crime\n",
       "16                  INTIMATE PARTNER - SIMPLE ASSAULT   Violent Crime\n",
       "17                           BATTERY - SIMPLE ASSAULT   Violent Crime\n",
       "18                                           BURGLARY  Property Crime\n",
       "19                                           BURGLARY  Property Crime\n",
       "20                 THEFT PLAIN - PETTY ($950 & UNDER)  Property Crime\n",
       "21                 THEFT PLAIN - PETTY ($950 & UNDER)  Property Crime\n",
       "22                 THEFT PLAIN - PETTY ($950 & UNDER)  Property Crime\n",
       "23                                           BURGLARY  Property Crime\n",
       "24     ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT   Violent Crime\n",
       "25           VANDALISM - MISDEAMEANOR ($399 OR UNDER)  Property Crime\n",
       "26                           VEHICLE - ATTEMPT STOLEN   Vehicle Crime\n",
       "27  VANDALISM - FELONY ($400 & OVER, ALL CHURCH VA...  Property Crime\n",
       "28                                            ROBBERY     Other Crime\n",
       "29                  INTIMATE PARTNER - SIMPLE ASSAULT   Violent Crime"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keyword-based mapping rules for auto‐labeling\n",
    "mapping_rules = {\n",
    "    \"Violent Crime\": [\n",
    "        \"ASSAULT\", \"BATTERY\", \"HOMICIDE\", \"MANSLAUGHTER\", \"RAPE\",\n",
    "        \"SEXUAL\", \"SODOMY\", \"ORAL COPULATION\", \"KIDNAPPING\",\n",
    "        \"LYNCHING\", \"STALKING\", \"THREATS\", \"INTIMATE PARTNER\"\n",
    "    ],\n",
    "    \"Property Crime\": [\n",
    "        \"THEFT\", \"BURGLARY\", \"VANDALISM\", \"ARSON\", \"SHOPLIFTING\",\n",
    "        \"BIKE - STOLEN\", \"COIN MACHINE\"\n",
    "    ],\n",
    "    \"Vehicle Crime\": [\n",
    "        \"VEHICLE\", \"DRIVING WITHOUT OWNER CONSENT\", \"DWOC\"\n",
    "    ],\n",
    "    \"Fraud / Financial Crime\": [\n",
    "        \"FRAUD\", \"EMBEZZLEMENT\", \"COUNTERFEIT\", \"BUNCO\",\n",
    "        \"CREDIT CARD\", \"DOCUMENT WORTHLESS\", \"INSURANCE\"\n",
    "    ],\n",
    "    \"Weapons / Public Safety\": [\n",
    "        \"FIREARM\", \"WEAPON\", \"SHOTS FIRED\", \"BOMB\", \"BRANDISH\"\n",
    "    ],\n",
    "    \"Sex Crime\": [\n",
    "        \"LEWD\", \"INDECENT EXPOSURE\", \"CHILD PORNOGRAPHY\",\n",
    "        \"PANDERING\", \"PIMPING\", \"HUMAN TRAFFICKING\"\n",
    "    ],\n",
    "    \"Child-Related Crime\": [\n",
    "        \"CHILD\", \"CONTRIBUTING\", \"CHILD NEGLECT\"\n",
    "    ],\n",
    "    \"Court / Restraining Order / Legal\": [\n",
    "        \"COURT\", \"RESTRAINING\", \"CONTEMPT\", \"FAILURE TO APPEAR\",\n",
    "        \"VIOLATION\"\n",
    "    ],\n",
    "    \"Public Disturbance / Disorder\": [\n",
    "        \"DISTURBANCE\", \"PEACE\", \"TRESPASS\", \"DISRUPT\",\n",
    "        \"RIOT\", \"DISOBEY\"\n",
    "    ],\n",
    "    \"Other Crime\": []  # fallback\n",
    "}\n",
    "\n",
    "# Function to classify crimes\n",
    "def classify(description: str):\n",
    "    if not isinstance(description, str):\n",
    "        return \"Other Crime\"\n",
    "    desc = description.upper()\n",
    "    for category, keywords in mapping_rules.items():\n",
    "        for kw in keywords:\n",
    "            if kw in desc:\n",
    "                return category\n",
    "    return \"Other Crime\"\n",
    "\n",
    "# Create new class column\n",
    "df_raw[\"Crime_Class\"] = df_raw[\"Crm Cd Desc\"].apply(classify)\n",
    "\n",
    "# Save a preview\n",
    "preview = df_raw[[\"Crm Cd Desc\", \"Crime_Class\"]].head(30)\n",
    "preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6db03746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crime_Class</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Property Crime</td>\n",
       "      <td>508444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>233487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vehicle Crime</td>\n",
       "      <td>123445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Other Crime</td>\n",
       "      <td>63036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Court / Restraining Order / Legal</td>\n",
       "      <td>21771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Public Disturbance / Disorder</td>\n",
       "      <td>19977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Weapons / Public Safety</td>\n",
       "      <td>19431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>11870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Child-Related Crime</td>\n",
       "      <td>2784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fraud / Financial Crime</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Crime_Class   Count\n",
       "0                     Property Crime  508444\n",
       "1                      Violent Crime  233487\n",
       "2                      Vehicle Crime  123445\n",
       "3                        Other Crime   63036\n",
       "4  Court / Restraining Order / Legal   21771\n",
       "5      Public Disturbance / Disorder   19977\n",
       "6            Weapons / Public Safety   19431\n",
       "7                          Sex Crime   11870\n",
       "8                Child-Related Crime    2784\n",
       "9            Fraud / Financial Crime     746"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['Crime_Class'].value_counts().reset_index(name='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e481ace3",
   "metadata": {},
   "source": [
    "Let's start with RAW, unprocesseed model training, then work our way up.\n",
    "\n",
    "## Category: Machine Learning Models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae13b38",
   "metadata": {},
   "source": [
    "### Tree Based: Decision Tree (RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cac0162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 0.7109182323065049\n",
      "Testing Set Accuracy: 0.7102269335119967\n",
      "------------------------------------------------------------------------------------\n",
      "Training Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.710202  0.946356  0.811446  356035.000000\n",
      "1              0.712402  0.998770  0.831624  163391.000000\n",
      "2              0.000000  0.000000  0.000000   44202.000000\n",
      "3              0.000000  0.000000  0.000000   86340.000000\n",
      "4              0.000000  0.000000  0.000000   13595.000000\n",
      "5              0.000000  0.000000  0.000000    8282.000000\n",
      "6              0.000000  0.000000  0.000000   15207.000000\n",
      "7              0.000000  0.000000  0.000000   13944.000000\n",
      "8              0.000000  0.000000  0.000000     540.000000\n",
      "9              0.000000  0.000000  0.000000    1957.000000\n",
      "accuracy       0.710918  0.710918  0.710918       0.710918\n",
      "macro avg      0.142260  0.194513  0.164307  703493.000000\n",
      "weighted avg   0.524890  0.710918  0.603820  703493.000000\n",
      "------------------------------------------------------------------------------------\n",
      "Testing Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.708894  0.945699  0.810351  152409.000000\n",
      "1              0.712988  0.998616  0.831969   70096.000000\n",
      "2              0.000000  0.000000  0.000000   18834.000000\n",
      "3              0.000000  0.000000  0.000000   37105.000000\n",
      "4              0.000000  0.000000  0.000000    5836.000000\n",
      "5              0.000000  0.000000  0.000000    3588.000000\n",
      "6              0.000000  0.000000  0.000000    6564.000000\n",
      "7              0.000000  0.000000  0.000000    6033.000000\n",
      "8              0.000000  0.000000  0.000000     206.000000\n",
      "9              0.000000  0.000000  0.000000     827.000000\n",
      "accuracy       0.710227  0.710227  0.710227       0.710227\n",
      "macro avg      0.142188  0.194431  0.164232  301498.000000\n",
      "weighted avg   0.524114  0.710227  0.603064  301498.000000\n",
      "------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model = df_raw.drop(columns=[\n",
    "    \"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\",\n",
    "    \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\"\n",
    "])\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model[\"Crime_Class\"])\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "dt_model_1 = DecisionTreeClassifier()\n",
    "dt_model_1.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_test_1 = dt_model_1.predict(X_test)\n",
    "y_pred_train_1 = dt_model_1.predict(X_train)\n",
    "\n",
    "# Evaluation\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_1)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test_1)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381f5ab9",
   "metadata": {},
   "source": [
    "### Tree Based: Random Forest (RAW)\n",
    "\n",
    "*Without any parameters, this thing will take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32cac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Random Forest Crime Classification ===\")\n",
    "\n",
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model = df_raw.drop(columns=[\n",
    "    \"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\",\n",
    "    \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\"\n",
    "])\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model.drop(columns=[\"Crime_Class\"])\n",
    "y, class_names = pd.factorize(df_model[\"Crime_Class\"])\n",
    "\n",
    "# Convert datetime columns to int timestamps\n",
    "for col in X.select_dtypes(include=['datetime', 'datetimetz']).columns:\n",
    "    X[col] = X[col].view('int64')\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Train-test split (stratify for class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Initialize Random Forest with balanced, regularized params\n",
    "rf_model_1 = RandomForestClassifier()\n",
    "# Save paraneter tunning for PART B. \n",
    "\n",
    "rf_model_1.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_test_1 = rf_model_1.predict(X_test)\n",
    "y_pred_train_1 = rf_model_1.predict(X_train)\n",
    "\n",
    "# Accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_1)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test_1)\n",
    "\n",
    "print(\"\\n=== Performance ===\")\n",
    "print(f\"Training Set Accuracy: {train_accuracy}\")\n",
    "print(f\"Testing Set Accuracy:  {test_accuracy}\")\n",
    "print(f\"Overfit Gap:          {train_accuracy - test_accuracy:.4f}\")\n",
    "\n",
    "# Evaluation reports\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e921bb8f",
   "metadata": {},
   "source": [
    "### Linear/Probability Based: Logistic Regression (RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db25b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# ... (Assuming df_raw is already loaded) ...\n",
    "\n",
    "# 1. Remove leakage columns\n",
    "df_model = df_raw.drop(columns=[\n",
    "    \"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\",\n",
    "    \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\"\n",
    "])\n",
    "\n",
    "# 2. Prepare training data\n",
    "X = df_model.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model[\"Crime_Class\"])\n",
    "\n",
    "# 3. Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# 4. Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# 5. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 6. Scale features \n",
    "# (Critically important for Logistic Regression convergence)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CHANGE: Build Logistic Regression Model (No Parameters)\n",
    "# ---------------------------------------------------------\n",
    "lr_model = LogisticRegression() \n",
    "\n",
    "# Train model\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_train_1 = lr_model.predict(X_train_scaled)\n",
    "y_pred_test_1 = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_1)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test_1)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac942c3b",
   "metadata": {},
   "source": [
    "### Linear/Probability Based: Naive Bayes (RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f013c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. Clean up leakage columns first to free space immediately\n",
    "drop_cols = [\n",
    "    \"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\",\n",
    "    \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\"\n",
    "]\n",
    "# Only drop if they actually exist in the dataframe\n",
    "cols_to_drop = [c for c in drop_cols if c in df_raw.columns]\n",
    "df_model = df_raw.drop(columns=cols_to_drop)\n",
    "\n",
    "# 2. Separate Target\n",
    "y, _ = pd.factorize(df_model[\"Crime_Class\"])\n",
    "X = df_model.drop(columns=[\"Crime_Class\"])\n",
    "\n",
    "# 3. THE FIX: In-Place Memory Optimized Conversion\n",
    "# Instead of 'apply' (which clones data), we loop and modify column by column.\n",
    "# .cat.codes is extremely memory efficient.\n",
    "print(\"Converting columns to codes...\")\n",
    "for col in X.columns:\n",
    "    # Convert to category type first\n",
    "    X[col] = X[col].astype('category')\n",
    "    # Extract codes (returns -1 for NaNs)\n",
    "    X[col] = X[col].cat.codes\n",
    "    \n",
    "    # Handle NaNs (-1) by shifting everything up by 1\n",
    "    # This also ensures no value is 0, which MultinomialNB prefers\n",
    "    X[col] = X[col] + 1\n",
    "\n",
    "# 4. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 5. Model\n",
    "# We stick to MultinomialNB because CategoricalNB is the one that wanted 18GB of RAM earlier.\n",
    "print(\"Training MultinomialNB...\")\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Evaluate\n",
    "print(\"Predicting...\")\n",
    "y_pred_train = nb_model.predict(X_train)\n",
    "y_pred_test = nb_model.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Testing Accuracy:  {test_accuracy}\")\n",
    "print(\"-\" * 30)\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e1f1a",
   "metadata": {},
   "source": [
    "### Gradient: XGBoost (RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32bcf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leakage columns\n",
    "df_model = df_raw.drop(columns=[\n",
    "    \"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\",\n",
    "    \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\"\n",
    "])\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model[\"Crime_Class\"])\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model_1 = XGBClassifier()\n",
    "#    n_estimators=300,\n",
    "#    learning_rate=0.1,\n",
    "#    max_depth=6,\n",
    "#    subsample=0.8,\n",
    "#    colsample_bytree=0.8,\n",
    "#    eval_metric=\"mlogloss\",\n",
    "#    random_state=42\n",
    "# )\n",
    "\n",
    "xgb_model_1.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = xgb_model_1.predict(X_train)\n",
    "y_pred_test = xgb_model_1.predict(X_test)\n",
    "\n",
    "# Evaluation reports\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70771cc",
   "metadata": {},
   "source": [
    "## Category: Deep Learning Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaa8b61",
   "metadata": {},
   "source": [
    "\n",
    "### Neural Networks: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0b253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leakage columns\n",
    "df_model = df_raw.drop(columns=[\n",
    "    \"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\",\n",
    "    \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\"\n",
    "])\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model[\"Crime_Class\"])\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ====== RESHAPE FOR CNN (Conv1D needs shape: samples, timesteps, features) ======\n",
    "X_train_cnn = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
    "X_test_cnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# ====== BUILD CNN MODEL ======\n",
    "model = Sequential([\n",
    "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ====== TRAIN ======\n",
    "history = model.fit(\n",
    "    X_train_cnn, y_train_cat,\n",
    "    epochs=10,              # Use epoch size = 10, since the datset is fairly large. Fewer epochs means less strain and timne\n",
    "    batch_size=32,          #Default values is 32.\n",
    "    validation_split=0.2,   #Keras default is 0.0\n",
    "    verbose=1               #Keras default is 1\n",
    ")\n",
    "\n",
    "# ====== PREDICT ======\n",
    "y_pred_train = model.predict(X_train_cnn).argmax(axis=1)\n",
    "y_pred_test = model.predict(X_test_cnn).argmax(axis=1)\n",
    "\n",
    "# ====== EVALUATION ======\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa113a2",
   "metadata": {},
   "source": [
    "### Neural Network: ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leakage columns\n",
    "df_model = df_raw.drop(columns=[\n",
    "    \"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\",\n",
    "    \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\"\n",
    "])\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model[\"Crime_Class\"])\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# ====== BUILD ANN MODEL ======\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ====== TRAIN ======\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_cat,\n",
    "    epochs=10,              #Use 10 as a derfault value for epochs\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ====== PREDICT ======\n",
    "y_pred_train = model.predict(X_train_scaled).argmax(axis=1)\n",
    "y_pred_test = model.predict(X_test_scaled).argmax(axis=1)\n",
    "\n",
    "# ====== EVALUATION ======\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc27ddb",
   "metadata": {},
   "source": [
    "Can be improved? Time to find out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c520d878",
   "metadata": {},
   "source": [
    "## Part A - Feature Engineering and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faab50b",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a48dbe3",
   "metadata": {},
   "source": [
    "Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87b9d9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date Rptd</th>\n",
       "      <th>DATE OCC</th>\n",
       "      <th>TIME OCC</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Crm Cd</th>\n",
       "      <th>Crm Cd Desc</th>\n",
       "      <th>...</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>Crm Cd 1</th>\n",
       "      <th>Crm Cd 2</th>\n",
       "      <th>Crm Cd 3</th>\n",
       "      <th>Crm Cd 4</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>Cross Street</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Crime_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211507896</td>\n",
       "      <td>11/4/2021 0:00</td>\n",
       "      <td>7/11/2020 0:00</td>\n",
       "      <td>845</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>354</td>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>354.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7800    BEEMAN                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>-118.4092</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201516622</td>\n",
       "      <td>10/21/2020 12:00:00 AM</td>\n",
       "      <td>10/18/2020 12:00:00 AM</td>\n",
       "      <td>1845</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ATOLL                        AV</td>\n",
       "      <td>N  GAULT</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>-118.4203</td>\n",
       "      <td>Violent Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240913563</td>\n",
       "      <td>10/12/2024 0:00</td>\n",
       "      <td>10/30/2020 12:00:00 AM</td>\n",
       "      <td>1240</td>\n",
       "      <td>9</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>354</td>\n",
       "      <td>THEFT OF IDENTITY</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>354.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14600    SYLVAN                       ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>-118.4509</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210704711</td>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>1310</td>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>331</td>\n",
       "      <td>THEFT FROM MOTOR VEHICLE - GRAND ($950.01 AND ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>331.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6000    COMEY                        AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>-118.3747</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201418201</td>\n",
       "      <td>3/10/2020 0:00</td>\n",
       "      <td>09/29/2020 12:00:00 AM</td>\n",
       "      <td>1830</td>\n",
       "      <td>14</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>THEFT FROM MOTOR VEHICLE - PETTY ($950 &amp; UNDER)</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>420.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4700    LA VILLA MARINA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>-118.4350</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>252104112</td>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>130</td>\n",
       "      <td>21</td>\n",
       "      <td>Topanga</td>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>946</td>\n",
       "      <td>OTHER MISCELLANEOUS CRIME</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>946.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22100    ROSCOE                       BL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>-118.6126</td>\n",
       "      <td>Other Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>250404100</td>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>Hollenbeck</td>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>237</td>\n",
       "      <td>CHILD NEGLECT (SEE 300 W.I.C.)</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3500    PERCY                        ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>-118.1979</td>\n",
       "      <td>Child-Related Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>251304095</td>\n",
       "      <td>01/31/2025 12:00:00 AM</td>\n",
       "      <td>01/30/2025 12:00:00 AM</td>\n",
       "      <td>1554</td>\n",
       "      <td>13</td>\n",
       "      <td>Newton</td>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>850</td>\n",
       "      <td>INDECENT EXPOSURE</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300 E  53RD                         ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>-118.2701</td>\n",
       "      <td>Sex Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>251704066</td>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>1600</td>\n",
       "      <td>17</td>\n",
       "      <td>Devonshire</td>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>624</td>\n",
       "      <td>BATTERY - SIMPLE ASSAULT</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>624.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9600    ZELZAH                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>-118.5233</td>\n",
       "      <td>Violent Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>251904210</td>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>1235</td>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>850</td>\n",
       "      <td>INDECENT EXPOSURE</td>\n",
       "      <td>...</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11100    OMELVENY                     AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>-118.4417</td>\n",
       "      <td>Sex Crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Date Rptd                DATE OCC  TIME OCC  \\\n",
       "0        211507896          11/4/2021 0:00          7/11/2020 0:00       845   \n",
       "1        201516622  10/21/2020 12:00:00 AM  10/18/2020 12:00:00 AM      1845   \n",
       "2        240913563         10/12/2024 0:00  10/30/2020 12:00:00 AM      1240   \n",
       "3        210704711  12/24/2020 12:00:00 AM  12/24/2020 12:00:00 AM      1310   \n",
       "4        201418201          3/10/2020 0:00  09/29/2020 12:00:00 AM      1830   \n",
       "...            ...                     ...                     ...       ...   \n",
       "1004986  252104112           2/2/2025 0:00           2/2/2025 0:00       130   \n",
       "1004987  250404100  02/18/2025 12:00:00 AM  02/18/2025 12:00:00 AM      1000   \n",
       "1004988  251304095  01/31/2025 12:00:00 AM  01/30/2025 12:00:00 AM      1554   \n",
       "1004989  251704066  01/17/2025 12:00:00 AM  01/17/2025 12:00:00 AM      1600   \n",
       "1004990  251904210  03/25/2025 12:00:00 AM  03/25/2025 12:00:00 AM      1235   \n",
       "\n",
       "         AREA    AREA NAME  Rpt Dist No  Part 1-2  Crm Cd  \\\n",
       "0          15  N Hollywood         1502         2     354   \n",
       "1          15  N Hollywood         1521         1     230   \n",
       "2           9     Van Nuys          933         2     354   \n",
       "3           7     Wilshire          782         1     331   \n",
       "4          14      Pacific         1454         1     420   \n",
       "...       ...          ...          ...       ...     ...   \n",
       "1004986    21      Topanga         2103         2     946   \n",
       "1004987     4   Hollenbeck          479         2     237   \n",
       "1004988    13       Newton         1372         2     850   \n",
       "1004989    17   Devonshire         1774         2     624   \n",
       "1004990    19      Mission         1944         2     850   \n",
       "\n",
       "                                               Crm Cd Desc  ...  Status Desc  \\\n",
       "0                                        THEFT OF IDENTITY  ...  Invest Cont   \n",
       "1           ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT  ...  Invest Cont   \n",
       "2                                        THEFT OF IDENTITY  ...  Invest Cont   \n",
       "3        THEFT FROM MOTOR VEHICLE - GRAND ($950.01 AND ...  ...  Invest Cont   \n",
       "4          THEFT FROM MOTOR VEHICLE - PETTY ($950 & UNDER)  ...  Invest Cont   \n",
       "...                                                    ...  ...          ...   \n",
       "1004986                          OTHER MISCELLANEOUS CRIME  ...  Invest Cont   \n",
       "1004987                     CHILD NEGLECT (SEE 300 W.I.C.)  ...  Invest Cont   \n",
       "1004988                                  INDECENT EXPOSURE  ...  Invest Cont   \n",
       "1004989                           BATTERY - SIMPLE ASSAULT  ...  Invest Cont   \n",
       "1004990                                  INDECENT EXPOSURE  ...  Invest Cont   \n",
       "\n",
       "         Crm Cd 1 Crm Cd 2 Crm Cd 3  Crm Cd 4  \\\n",
       "0           354.0      NaN      NaN       NaN   \n",
       "1           230.0      NaN      NaN       NaN   \n",
       "2           354.0      NaN      NaN       NaN   \n",
       "3           331.0      NaN      NaN       NaN   \n",
       "4           420.0      NaN      NaN       NaN   \n",
       "...           ...      ...      ...       ...   \n",
       "1004986     946.0      NaN      NaN       NaN   \n",
       "1004987     237.0      NaN      NaN       NaN   \n",
       "1004988     850.0      NaN      NaN       NaN   \n",
       "1004989     624.0      NaN      NaN       NaN   \n",
       "1004990     850.0      NaN      NaN       NaN   \n",
       "\n",
       "                                         LOCATION  Cross Street      LAT  \\\n",
       "0         7800    BEEMAN                       AV           NaN  34.2124   \n",
       "1                 ATOLL                        AV      N  GAULT  34.1993   \n",
       "2        14600    SYLVAN                       ST           NaN  34.1847   \n",
       "3         6000    COMEY                        AV           NaN  34.0339   \n",
       "4                         4700    LA VILLA MARINA           NaN  33.9813   \n",
       "...                                           ...           ...      ...   \n",
       "1004986  22100    ROSCOE                       BL           NaN  34.2259   \n",
       "1004987   3500    PERCY                        ST           NaN  34.0277   \n",
       "1004988    300 E  53RD                         ST           NaN  33.9942   \n",
       "1004989   9600    ZELZAH                       AV           NaN  34.2450   \n",
       "1004990  11100    OMELVENY                     AV           NaN  34.2722   \n",
       "\n",
       "              LON          Crime_Class  \n",
       "0       -118.4092       Property Crime  \n",
       "1       -118.4203        Violent Crime  \n",
       "2       -118.4509       Property Crime  \n",
       "3       -118.3747       Property Crime  \n",
       "4       -118.4350       Property Crime  \n",
       "...           ...                  ...  \n",
       "1004986 -118.6126          Other Crime  \n",
       "1004987 -118.1979  Child-Related Crime  \n",
       "1004988 -118.2701            Sex Crime  \n",
       "1004989 -118.5233        Violent Crime  \n",
       "1004990 -118.4417            Sex Crime  \n",
       "\n",
       "[1004991 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df_raw.drop_duplicates()\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb29551d",
   "metadata": {},
   "source": [
    "None found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e092f5",
   "metadata": {},
   "source": [
    "### Removing Columns \n",
    "Do not proceed without caution. In this context, the chosen columns were dropped due to them having a direct relationship to the target class, which may cause a leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b99375f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date Rptd</th>\n",
       "      <th>DATE OCC</th>\n",
       "      <th>TIME OCC</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Mocodes</th>\n",
       "      <th>Vict Age</th>\n",
       "      <th>...</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Weapon Used Cd</th>\n",
       "      <th>Weapon Desc</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>Cross Street</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Crime_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211507896</td>\n",
       "      <td>11/4/2021 0:00</td>\n",
       "      <td>7/11/2020 0:00</td>\n",
       "      <td>845</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>7800    BEEMAN                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>-118.4092</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201516622</td>\n",
       "      <td>10/21/2020 12:00:00 AM</td>\n",
       "      <td>10/18/2020 12:00:00 AM</td>\n",
       "      <td>1845</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>0416 0334 2004 1822 1414 0305 0319 0400</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>200.0</td>\n",
       "      <td>KNIFE WITH BLADE 6INCHES OR LESS</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>ATOLL                        AV</td>\n",
       "      <td>N  GAULT</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>-118.4203</td>\n",
       "      <td>Violent Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240913563</td>\n",
       "      <td>10/12/2024 0:00</td>\n",
       "      <td>10/30/2020 12:00:00 AM</td>\n",
       "      <td>1240</td>\n",
       "      <td>9</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>14600    SYLVAN                       ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>-118.4509</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210704711</td>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>1310</td>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>344</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>6000    COMEY                        AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>-118.3747</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201418201</td>\n",
       "      <td>3/10/2020 0:00</td>\n",
       "      <td>09/29/2020 12:00:00 AM</td>\n",
       "      <td>1830</td>\n",
       "      <td>14</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>1300 0344 1606 2032</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>4700    LA VILLA MARINA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>-118.4350</td>\n",
       "      <td>Property Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>252104112</td>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>130</td>\n",
       "      <td>21</td>\n",
       "      <td>Topanga</td>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>22100    ROSCOE                       BL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>-118.6126</td>\n",
       "      <td>Other Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>250404100</td>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>Hollenbeck</td>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>1258 0553 0602</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>3500    PERCY                        ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>-118.1979</td>\n",
       "      <td>Child-Related Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>251304095</td>\n",
       "      <td>01/31/2025 12:00:00 AM</td>\n",
       "      <td>01/30/2025 12:00:00 AM</td>\n",
       "      <td>1554</td>\n",
       "      <td>13</td>\n",
       "      <td>Newton</td>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>300 E  53RD                         ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>-118.2701</td>\n",
       "      <td>Sex Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>251704066</td>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>1600</td>\n",
       "      <td>17</td>\n",
       "      <td>Devonshire</td>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>0400 1259 1822 0356</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>400.0</td>\n",
       "      <td>STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>9600    ZELZAH                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>-118.5233</td>\n",
       "      <td>Violent Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>251904210</td>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>1235</td>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>0529 2024 1815 0913</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>11100    OMELVENY                     AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>-118.4417</td>\n",
       "      <td>Sex Crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Date Rptd                DATE OCC  TIME OCC  \\\n",
       "0        211507896          11/4/2021 0:00          7/11/2020 0:00       845   \n",
       "1        201516622  10/21/2020 12:00:00 AM  10/18/2020 12:00:00 AM      1845   \n",
       "2        240913563         10/12/2024 0:00  10/30/2020 12:00:00 AM      1240   \n",
       "3        210704711  12/24/2020 12:00:00 AM  12/24/2020 12:00:00 AM      1310   \n",
       "4        201418201          3/10/2020 0:00  09/29/2020 12:00:00 AM      1830   \n",
       "...            ...                     ...                     ...       ...   \n",
       "1004986  252104112           2/2/2025 0:00           2/2/2025 0:00       130   \n",
       "1004987  250404100  02/18/2025 12:00:00 AM  02/18/2025 12:00:00 AM      1000   \n",
       "1004988  251304095  01/31/2025 12:00:00 AM  01/30/2025 12:00:00 AM      1554   \n",
       "1004989  251704066  01/17/2025 12:00:00 AM  01/17/2025 12:00:00 AM      1600   \n",
       "1004990  251904210  03/25/2025 12:00:00 AM  03/25/2025 12:00:00 AM      1235   \n",
       "\n",
       "         AREA    AREA NAME  Rpt Dist No  Part 1-2  \\\n",
       "0          15  N Hollywood         1502         2   \n",
       "1          15  N Hollywood         1521         1   \n",
       "2           9     Van Nuys          933         2   \n",
       "3           7     Wilshire          782         1   \n",
       "4          14      Pacific         1454         1   \n",
       "...       ...          ...          ...       ...   \n",
       "1004986    21      Topanga         2103         2   \n",
       "1004987     4   Hollenbeck          479         2   \n",
       "1004988    13       Newton         1372         2   \n",
       "1004989    17   Devonshire         1774         2   \n",
       "1004990    19      Mission         1944         2   \n",
       "\n",
       "                                         Mocodes  Vict Age  ... Vict Descent  \\\n",
       "0                                            377        31  ...            H   \n",
       "1        0416 0334 2004 1822 1414 0305 0319 0400        32  ...            H   \n",
       "2                                            377        30  ...            W   \n",
       "3                                            344        47  ...            A   \n",
       "4                            1300 0344 1606 2032        63  ...            H   \n",
       "...                                          ...       ...  ...          ...   \n",
       "1004986                                      NaN        35  ...            X   \n",
       "1004987                           1258 0553 0602        11  ...            B   \n",
       "1004988                                      NaN        16  ...            H   \n",
       "1004989                      0400 1259 1822 0356        17  ...            H   \n",
       "1004990                      0529 2024 1815 0913        35  ...            H   \n",
       "\n",
       "        Weapon Used Cd                                     Weapon Desc Status  \\\n",
       "0                  NaN                                             NaN     IC   \n",
       "1                200.0                KNIFE WITH BLADE 6INCHES OR LESS     IC   \n",
       "2                  NaN                                             NaN     IC   \n",
       "3                  NaN                                             NaN     IC   \n",
       "4                  NaN                                             NaN     IC   \n",
       "...                ...                                             ...    ...   \n",
       "1004986            NaN                                             NaN     IC   \n",
       "1004987            NaN                                             NaN     IC   \n",
       "1004988            NaN                                             NaN     IC   \n",
       "1004989          400.0  STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)     IC   \n",
       "1004990            NaN                                             NaN     IC   \n",
       "\n",
       "         Status Desc                                  LOCATION Cross Street  \\\n",
       "0        Invest Cont   7800    BEEMAN                       AV          NaN   \n",
       "1        Invest Cont           ATOLL                        AV     N  GAULT   \n",
       "2        Invest Cont  14600    SYLVAN                       ST          NaN   \n",
       "3        Invest Cont   6000    COMEY                        AV          NaN   \n",
       "4        Invest Cont                   4700    LA VILLA MARINA          NaN   \n",
       "...              ...                                       ...          ...   \n",
       "1004986  Invest Cont  22100    ROSCOE                       BL          NaN   \n",
       "1004987  Invest Cont   3500    PERCY                        ST          NaN   \n",
       "1004988  Invest Cont    300 E  53RD                         ST          NaN   \n",
       "1004989  Invest Cont   9600    ZELZAH                       AV          NaN   \n",
       "1004990  Invest Cont  11100    OMELVENY                     AV          NaN   \n",
       "\n",
       "             LAT       LON          Crime_Class  \n",
       "0        34.2124 -118.4092       Property Crime  \n",
       "1        34.1993 -118.4203        Violent Crime  \n",
       "2        34.1847 -118.4509       Property Crime  \n",
       "3        34.0339 -118.3747       Property Crime  \n",
       "4        33.9813 -118.4350       Property Crime  \n",
       "...          ...       ...                  ...  \n",
       "1004986  34.2259 -118.6126          Other Crime  \n",
       "1004987  34.0277 -118.1979  Child-Related Crime  \n",
       "1004988  33.9942 -118.2701            Sex Crime  \n",
       "1004989  34.2450 -118.5233        Violent Crime  \n",
       "1004990  34.2722 -118.4417            Sex Crime  \n",
       "\n",
       "[1004991 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df_new.drop(columns=[\"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\", \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\"])\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1078baae",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3c66cd",
   "metadata": {},
   "source": [
    "In this phase, TAKE NOTE that anything, once you hit run, results in the dataframe being permanently changed. So to rerun this segment, you MUST reload and reimport the DataFrame again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eebbe734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date Rptd</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Mocodes</th>\n",
       "      <th>Vict Age</th>\n",
       "      <th>Vict Sex</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Weapon Used Cd</th>\n",
       "      <th>Weapon Desc</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>Cross Street</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Crime_Class</th>\n",
       "      <th>DateTime OCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211507896</td>\n",
       "      <td>11/4/2021 0:00</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>7800    BEEMAN                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>-118.4092</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-07-11 08:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201516622</td>\n",
       "      <td>10/21/2020 12:00:00 AM</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>0416 0334 2004 1822 1414 0305 0319 0400</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>200.0</td>\n",
       "      <td>KNIFE WITH BLADE 6INCHES OR LESS</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>ATOLL                        AV</td>\n",
       "      <td>N  GAULT</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>-118.4203</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>2020-10-18 18:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240913563</td>\n",
       "      <td>10/12/2024 0:00</td>\n",
       "      <td>9</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>14600    SYLVAN                       ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>-118.4509</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-10-30 12:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210704711</td>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>344</td>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>6000    COMEY                        AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>-118.3747</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-12-24 13:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201418201</td>\n",
       "      <td>3/10/2020 0:00</td>\n",
       "      <td>14</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>1300 0344 1606 2032</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>4700    LA VILLA MARINA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>-118.4350</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-09-29 18:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>252104112</td>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>21</td>\n",
       "      <td>Topanga</td>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>22100    ROSCOE                       BL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>-118.6126</td>\n",
       "      <td>Other Crime</td>\n",
       "      <td>2025-02-02 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>250404100</td>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>4</td>\n",
       "      <td>Hollenbeck</td>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>1258 0553 0602</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>3500    PERCY                        ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>-118.1979</td>\n",
       "      <td>Child-Related Crime</td>\n",
       "      <td>2025-02-18 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>251304095</td>\n",
       "      <td>01/31/2025 12:00:00 AM</td>\n",
       "      <td>13</td>\n",
       "      <td>Newton</td>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>300 E  53RD                         ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>-118.2701</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>2025-01-30 15:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>251704066</td>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>17</td>\n",
       "      <td>Devonshire</td>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>0400 1259 1822 0356</td>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>400.0</td>\n",
       "      <td>STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>9600    ZELZAH                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>-118.5233</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>2025-01-17 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>251904210</td>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>0529 2024 1815 0913</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>11100    OMELVENY                     AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>-118.4417</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>2025-03-25 12:35:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Date Rptd  AREA    AREA NAME  Rpt Dist No  \\\n",
       "0        211507896          11/4/2021 0:00    15  N Hollywood         1502   \n",
       "1        201516622  10/21/2020 12:00:00 AM    15  N Hollywood         1521   \n",
       "2        240913563         10/12/2024 0:00     9     Van Nuys          933   \n",
       "3        210704711  12/24/2020 12:00:00 AM     7     Wilshire          782   \n",
       "4        201418201          3/10/2020 0:00    14      Pacific         1454   \n",
       "...            ...                     ...   ...          ...          ...   \n",
       "1004986  252104112           2/2/2025 0:00    21      Topanga         2103   \n",
       "1004987  250404100  02/18/2025 12:00:00 AM     4   Hollenbeck          479   \n",
       "1004988  251304095  01/31/2025 12:00:00 AM    13       Newton         1372   \n",
       "1004989  251704066  01/17/2025 12:00:00 AM    17   Devonshire         1774   \n",
       "1004990  251904210  03/25/2025 12:00:00 AM    19      Mission         1944   \n",
       "\n",
       "         Part 1-2                                  Mocodes  Vict Age Vict Sex  \\\n",
       "0               2                                      377        31        M   \n",
       "1               1  0416 0334 2004 1822 1414 0305 0319 0400        32        M   \n",
       "2               2                                      377        30        M   \n",
       "3               1                                      344        47        F   \n",
       "4               1                      1300 0344 1606 2032        63        M   \n",
       "...           ...                                      ...       ...      ...   \n",
       "1004986         2                                      NaN        35        M   \n",
       "1004987         2                           1258 0553 0602        11        M   \n",
       "1004988         2                                      NaN        16        F   \n",
       "1004989         2                      0400 1259 1822 0356        17        M   \n",
       "1004990         2                      0529 2024 1815 0913        35        F   \n",
       "\n",
       "        Vict Descent  Weapon Used Cd  \\\n",
       "0                  H             NaN   \n",
       "1                  H           200.0   \n",
       "2                  W             NaN   \n",
       "3                  A             NaN   \n",
       "4                  H             NaN   \n",
       "...              ...             ...   \n",
       "1004986            X             NaN   \n",
       "1004987            B             NaN   \n",
       "1004988            H             NaN   \n",
       "1004989            H           400.0   \n",
       "1004990            H             NaN   \n",
       "\n",
       "                                            Weapon Desc Status  Status Desc  \\\n",
       "0                                                   NaN     IC  Invest Cont   \n",
       "1                      KNIFE WITH BLADE 6INCHES OR LESS     IC  Invest Cont   \n",
       "2                                                   NaN     IC  Invest Cont   \n",
       "3                                                   NaN     IC  Invest Cont   \n",
       "4                                                   NaN     IC  Invest Cont   \n",
       "...                                                 ...    ...          ...   \n",
       "1004986                                             NaN     IC  Invest Cont   \n",
       "1004987                                             NaN     IC  Invest Cont   \n",
       "1004988                                             NaN     IC  Invest Cont   \n",
       "1004989  STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)     IC  Invest Cont   \n",
       "1004990                                             NaN     IC  Invest Cont   \n",
       "\n",
       "                                         LOCATION Cross Street      LAT  \\\n",
       "0         7800    BEEMAN                       AV          NaN  34.2124   \n",
       "1                 ATOLL                        AV     N  GAULT  34.1993   \n",
       "2        14600    SYLVAN                       ST          NaN  34.1847   \n",
       "3         6000    COMEY                        AV          NaN  34.0339   \n",
       "4                         4700    LA VILLA MARINA          NaN  33.9813   \n",
       "...                                           ...          ...      ...   \n",
       "1004986  22100    ROSCOE                       BL          NaN  34.2259   \n",
       "1004987   3500    PERCY                        ST          NaN  34.0277   \n",
       "1004988    300 E  53RD                         ST          NaN  33.9942   \n",
       "1004989   9600    ZELZAH                       AV          NaN  34.2450   \n",
       "1004990  11100    OMELVENY                     AV          NaN  34.2722   \n",
       "\n",
       "              LON          Crime_Class        DateTime OCC  \n",
       "0       -118.4092       Property Crime 2020-07-11 08:45:00  \n",
       "1       -118.4203        Violent Crime 2020-10-18 18:45:00  \n",
       "2       -118.4509       Property Crime 2020-10-30 12:40:00  \n",
       "3       -118.3747       Property Crime 2020-12-24 13:10:00  \n",
       "4       -118.4350       Property Crime 2020-09-29 18:30:00  \n",
       "...           ...                  ...                 ...  \n",
       "1004986 -118.6126          Other Crime 2025-02-02 01:30:00  \n",
       "1004987 -118.1979  Child-Related Crime 2025-02-18 10:00:00  \n",
       "1004988 -118.2701            Sex Crime 2025-01-30 15:54:00  \n",
       "1004989 -118.5233        Violent Crime 2025-01-17 16:00:00  \n",
       "1004990 -118.4417            Sex Crime 2025-03-25 12:35:00  \n",
       "\n",
       "[1004991 rows x 20 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Clean DATE OCC (mixed formats)\n",
    "df_new['DATE OCC'] = pd.to_datetime(df_new['DATE OCC'], format='mixed', errors='coerce')\n",
    "\n",
    "# 2. Clean TIME OCC (force numeric → Int64 → 4-digit HHMM)\n",
    "df_new['TIME OCC'] = pd.to_numeric(df_new['TIME OCC'], errors='coerce').astype('Int64')\n",
    "time_str = df_new['TIME OCC'].astype(str).str.zfill(4)\n",
    "\n",
    "# 3. Combine DATE OCC + TIME OCC into a single datetime\n",
    "df_new['DateTime OCC'] = pd.to_datetime(\n",
    "    df_new['DATE OCC'].dt.strftime('%Y-%m-%d') + ' ' + time_str,\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# 4. Drop the original columns used for merging\n",
    "df_new = df_new.drop(columns=['DATE OCC', 'TIME OCC'])\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa77d899",
   "metadata": {},
   "source": [
    "### Check for NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0fb6262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       0\n",
       "Date Rptd              0\n",
       "AREA                   0\n",
       "AREA NAME              0\n",
       "Rpt Dist No            0\n",
       "Part 1-2               0\n",
       "Mocodes           151619\n",
       "Vict Age               0\n",
       "Vict Sex          144644\n",
       "Vict Descent      144656\n",
       "Weapon Used Cd    677744\n",
       "Weapon Desc       677744\n",
       "Status                 1\n",
       "Status Desc            0\n",
       "LOCATION               0\n",
       "Cross Street      850755\n",
       "LAT                    0\n",
       "LON                    0\n",
       "Crime_Class            0\n",
       "DateTime OCC           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d7679",
   "metadata": {},
   "source": [
    "Leave as NULL, since some records do in fact not possess the given info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a85df90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Rptd</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Mocodes</th>\n",
       "      <th>Vict Age</th>\n",
       "      <th>Vict Sex</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Weapon Used Cd</th>\n",
       "      <th>Weapon Desc</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>Cross Street</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Crime_Class</th>\n",
       "      <th>DateTime OCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/4/2021 0:00</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>7800    BEEMAN                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>-118.4092</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-07-11 08:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/21/2020 12:00:00 AM</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>0416 0334 2004 1822 1414 0305 0319 0400</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>200.0</td>\n",
       "      <td>KNIFE WITH BLADE 6INCHES OR LESS</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>ATOLL                        AV</td>\n",
       "      <td>N  GAULT</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>-118.4203</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>2020-10-18 18:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/12/2024 0:00</td>\n",
       "      <td>9</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>14600    SYLVAN                       ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>-118.4509</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-10-30 12:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>344</td>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>6000    COMEY                        AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>-118.3747</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-12-24 13:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/10/2020 0:00</td>\n",
       "      <td>14</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>1300 0344 1606 2032</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>4700    LA VILLA MARINA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>-118.4350</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-09-29 18:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>21</td>\n",
       "      <td>Topanga</td>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>22100    ROSCOE                       BL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>-118.6126</td>\n",
       "      <td>Other Crime</td>\n",
       "      <td>2025-02-02 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>4</td>\n",
       "      <td>Hollenbeck</td>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>1258 0553 0602</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>3500    PERCY                        ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>-118.1979</td>\n",
       "      <td>Child-Related Crime</td>\n",
       "      <td>2025-02-18 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>01/31/2025 12:00:00 AM</td>\n",
       "      <td>13</td>\n",
       "      <td>Newton</td>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>300 E  53RD                         ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>-118.2701</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>2025-01-30 15:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>17</td>\n",
       "      <td>Devonshire</td>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>0400 1259 1822 0356</td>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>400.0</td>\n",
       "      <td>STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>9600    ZELZAH                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>-118.5233</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>2025-01-17 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>0529 2024 1815 0913</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>11100    OMELVENY                     AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>-118.4417</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>2025-03-25 12:35:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date Rptd  AREA    AREA NAME  Rpt Dist No  Part 1-2  \\\n",
       "0                11/4/2021 0:00    15  N Hollywood         1502         2   \n",
       "1        10/21/2020 12:00:00 AM    15  N Hollywood         1521         1   \n",
       "2               10/12/2024 0:00     9     Van Nuys          933         2   \n",
       "3        12/24/2020 12:00:00 AM     7     Wilshire          782         1   \n",
       "4                3/10/2020 0:00    14      Pacific         1454         1   \n",
       "...                         ...   ...          ...          ...       ...   \n",
       "1004986           2/2/2025 0:00    21      Topanga         2103         2   \n",
       "1004987  02/18/2025 12:00:00 AM     4   Hollenbeck          479         2   \n",
       "1004988  01/31/2025 12:00:00 AM    13       Newton         1372         2   \n",
       "1004989  01/17/2025 12:00:00 AM    17   Devonshire         1774         2   \n",
       "1004990  03/25/2025 12:00:00 AM    19      Mission         1944         2   \n",
       "\n",
       "                                         Mocodes  Vict Age Vict Sex  \\\n",
       "0                                            377        31        M   \n",
       "1        0416 0334 2004 1822 1414 0305 0319 0400        32        M   \n",
       "2                                            377        30        M   \n",
       "3                                            344        47        F   \n",
       "4                            1300 0344 1606 2032        63        M   \n",
       "...                                          ...       ...      ...   \n",
       "1004986                                      NaN        35        M   \n",
       "1004987                           1258 0553 0602        11        M   \n",
       "1004988                                      NaN        16        F   \n",
       "1004989                      0400 1259 1822 0356        17        M   \n",
       "1004990                      0529 2024 1815 0913        35        F   \n",
       "\n",
       "        Vict Descent  Weapon Used Cd  \\\n",
       "0                  H             NaN   \n",
       "1                  H           200.0   \n",
       "2                  W             NaN   \n",
       "3                  A             NaN   \n",
       "4                  H             NaN   \n",
       "...              ...             ...   \n",
       "1004986            X             NaN   \n",
       "1004987            B             NaN   \n",
       "1004988            H             NaN   \n",
       "1004989            H           400.0   \n",
       "1004990            H             NaN   \n",
       "\n",
       "                                            Weapon Desc Status  Status Desc  \\\n",
       "0                                                   NaN     IC  Invest Cont   \n",
       "1                      KNIFE WITH BLADE 6INCHES OR LESS     IC  Invest Cont   \n",
       "2                                                   NaN     IC  Invest Cont   \n",
       "3                                                   NaN     IC  Invest Cont   \n",
       "4                                                   NaN     IC  Invest Cont   \n",
       "...                                                 ...    ...          ...   \n",
       "1004986                                             NaN     IC  Invest Cont   \n",
       "1004987                                             NaN     IC  Invest Cont   \n",
       "1004988                                             NaN     IC  Invest Cont   \n",
       "1004989  STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)     IC  Invest Cont   \n",
       "1004990                                             NaN     IC  Invest Cont   \n",
       "\n",
       "                                         LOCATION Cross Street      LAT  \\\n",
       "0         7800    BEEMAN                       AV          NaN  34.2124   \n",
       "1                 ATOLL                        AV     N  GAULT  34.1993   \n",
       "2        14600    SYLVAN                       ST          NaN  34.1847   \n",
       "3         6000    COMEY                        AV          NaN  34.0339   \n",
       "4                         4700    LA VILLA MARINA          NaN  33.9813   \n",
       "...                                           ...          ...      ...   \n",
       "1004986  22100    ROSCOE                       BL          NaN  34.2259   \n",
       "1004987   3500    PERCY                        ST          NaN  34.0277   \n",
       "1004988    300 E  53RD                         ST          NaN  33.9942   \n",
       "1004989   9600    ZELZAH                       AV          NaN  34.2450   \n",
       "1004990  11100    OMELVENY                     AV          NaN  34.2722   \n",
       "\n",
       "              LON          Crime_Class        DateTime OCC  \n",
       "0       -118.4092       Property Crime 2020-07-11 08:45:00  \n",
       "1       -118.4203        Violent Crime 2020-10-18 18:45:00  \n",
       "2       -118.4509       Property Crime 2020-10-30 12:40:00  \n",
       "3       -118.3747       Property Crime 2020-12-24 13:10:00  \n",
       "4       -118.4350       Property Crime 2020-09-29 18:30:00  \n",
       "...           ...                  ...                 ...  \n",
       "1004986 -118.6126          Other Crime 2025-02-02 01:30:00  \n",
       "1004987 -118.1979  Child-Related Crime 2025-02-18 10:00:00  \n",
       "1004988 -118.2701            Sex Crime 2025-01-30 15:54:00  \n",
       "1004989 -118.5233        Violent Crime 2025-01-17 16:00:00  \n",
       "1004990 -118.4417            Sex Crime 2025-03-25 12:35:00  \n",
       "\n",
       "[1004991 rows x 19 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df_new.drop(columns=[' '])\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8604b",
   "metadata": {},
   "source": [
    "Remove the Weapon Used Cd column, and change the Weapon Desc column to binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d1dfcf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABFEAAAJ2CAYAAACXYB0TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACV/klEQVR4nOzdeZxO9f//8ed1DcMMg7Ev2cY+liJlK6FkKylFIWulJBSi+pQlUslOKYylLAmJFvsuW2Eo+zL2PUuMbWbevz/8XN+mGebKzDjXdc7jfru51ZxzzLwuZ65znfN6v96vt8sYYwQAAAAAAIDbclsdAAAAAAAAgD8giQIAAAAAAOAFkigAAAAAAABeIIkCAAAAAADgBZIoAAAAAAAAXiCJAgAAAAAA4AWSKAAAAAAAAF4giQIAAAAAAOAFkigAAAAAAABeIIkCAEAiJkyYIJfLJZfLpWXLliXYb4xR0aJF5XK5VKNGjXj7XC6XevfuneIx1ahRI8HPSm2nTp1SYGCgnn/++Vsec+HCBQUHB6thw4Zef9+b/75RUVEpEOV/07p1a2XMmPGW+zNmzKjWrVunagxTpkzR0KFDU/VnAACAlJfG6gAAAPBlISEhGjduXILkxfLly7V3716FhIQk+Dtr1qzRPffck+KxfP755yn+PZOSI0cONWzYULNnz9bZs2cVGhqa4Jhp06bp8uXLateu3V2Pz19NmTJFf/zxh7p06WJ1KAAA4D+gEgUAgNto2rSpZs6cqQsXLsTbPm7cOFWpUkUFChRI8HcqV66cKkmU8PBwhYeHp/j3TUq7du109epVTZ48OdH9ERERypUrlxo0aHCXIwMAALi7SKIAAHAbL7zwgiRp6tSpnm3nz5/XzJkz1bZt20T/zr+n80RHR6tbt24qXLiw0qdPr6xZs6pixYrxvue+ffv0/PPPK2/evEqXLp1y5cqlRx99VJs3b/Yc8+/pPFFRUXK5XPrss880ePBgFS5cWBkzZlSVKlW0du3aBHGNGTNGxYsXV7p06RQeHq4pU6aodevWKlSo0G3/DerUqaN77rlH48ePT7Bv+/btWrdunVq2bKk0adJo4cKFeuqpp3TPPfcoffr0Klq0qNq3b6/Tp0/f9mdIUqFChRKdRpPYNKYLFy54/k0DAwOVL18+denSRZcuXUry59wJb3/eqFGjVL16deXMmVMZMmRQ2bJl9emnn+r69evxXs9PP/2kAwcOeKaMuVwuSf93TgcOHKhPPvlEhQoVUlBQkGrUqKFdu3bp+vXr6tmzp/LmzavMmTPr6aef1smTJ+PF8O233+rxxx9Xnjx5FBQUpFKlSqlnz54JYr05renPP//Uo48+qgwZMihHjhzq2LGjoqOjU+XfEQAAf8d0HgAAbiNTpkx69tlnFRERofbt20u6kVBxu91q2rSpV30t3nrrLX399dfq16+fypcvr0uXLumPP/7QmTNnPMfUr19fsbGx+vTTT1WgQAGdPn1av/76q86dO5fk9x81apRKlizpieX9999X/fr1tX//fmXOnFmS9NVXX6l9+/Zq3LixhgwZovPnz6tPnz66evVqkt/f7XardevW6tevnyIjI3Xvvfd69t1MrNxMKO3du1dVqlTRSy+9pMyZMysqKkqDBw/WQw89pK1btypt2rRJ/rykREdH65FHHtHhw4f17rvvqly5cvrzzz/1wQcfaOvWrVq0aJEnKXE7MTExKf7z9u7dq2bNmnmSLZGRkerfv7927NihiIgISTemZb3yyivau3evvv/++0R/5qhRo1SuXDmNGjVK586dU9euXfXkk0+qUqVKSps2rSIiInTgwAF169ZNL730kubMmeP5u7t371b9+vXVpUsXZciQQTt27NAnn3yi9evXa8mSJfF+zvXr11W/fn21b99ePXv21K+//qp+/frpwIEDmjt3rlf/PgAAOIoBAAAJjB8/3kgyGzZsMEuXLjWSzB9//GGMMeaBBx4wrVu3NsYYU7p0afPII4/E+7uSTK9evTxflylTxjRq1OiWP+v06dNGkhk6dOhtY3rkkUfi/az9+/cbSaZs2bImJibGs339+vVGkpk6daoxxpjY2FiTO3duU6lSpXjf78CBAyZt2rSmYMGCt/25xhizb98+43K5TKdOnTzbrl+/bnLnzm2qVauW6N+Ji4sz169fNwcOHDCSzA8//ODZd/Pfd//+/Z5tBQsWNK1atUrydQ8YMMC43W6zYcOGeMfNmDHDSDI///zzbV9Lq1atjKTb/vlnHHf682JjY83169fNpEmTTEBAgPnrr788+xo0aJDov/vNc3rvvfea2NhYz/ahQ4caSaZhw4bxju/SpYuRZM6fP59oDDfPwfLly40kExkZmeDfYdiwYfH+Tv/+/Y0ks2rVqkS/JwAATsZ0HgAAkvDII4+oSJEiioiI0NatW7Vhw4ZbTuVJzIMPPqhffvlFPXv21LJly3T58uV4+7NmzaoiRYpo4MCBGjx4sDZt2qS4uDivv3+DBg0UEBDg+bpcuXKSpAMHDkiSdu7cqePHj6tJkybx/l6BAgVUrVo1r35G4cKFVbNmTU2ePFnXrl2TJP3yyy86fvx4vH+LkydP6tVXX1X+/PmVJk0apU2bVgULFpR0Y+pPSvjxxx9VpkwZ3XfffYqJifH8qVOnzi1XU/q3oKAgbdiwIdE/QUFBd/zzNm3apIYNGypbtmwKCAhQ2rRp1bJlS8XGxmrXrl1ev8b69evL7f6/27RSpUpJUoK+Mze3Hzx40LNt3759atasmXLnzu2J4ZFHHpGU+Dlo3rx5vK+bNWsmSVq6dKnX8QIA4BRM5wEAIAkul0tt2rTR8OHDdeXKFRUvXlwPP/yw139/+PDhuueee/Ttt9/qk08+Ufr06VWnTh0NHDhQxYoVk8vl0uLFi9W3b199+umn6tq1q7JmzarmzZurf//+ia4A9E/ZsmWL93W6dOkkyZOsuTltKFeuXAn+bq5cubR//36vXke7du3UvHlzzZkzR88++6zGjx+vjBkzepIzcXFxevzxx3X06FG9//77Klu2rDJkyKC4uDhVrlw5QfLoTp04cUJ79uy55dQgb/qvuN1uVaxY8Zb77uTnHTx4UA8//LBKlCihYcOGqVChQkqfPr3Wr1+v119//T+9/qxZs8b7OjAw8Lbbr1y5Ikm6ePGiHn74YaVPn179+vVT8eLFFRwcrEOHDumZZ55JEEOaNGkS/P7kzp1bkuJNNwMAADeQRAEAwAutW7fWBx98oNGjR6t///7/6e9myJBBffr0UZ8+fXTixAlPVcqTTz6pHTt2SJIKFiyocePGSZJ27dql6dOnq3fv3rp27ZpGjx6drNhvPiSfOHEiwb7jx497/X2eeeYZhYaGKiIiQo888oh+/PFHtWzZUhkzZpQk/fHHH4qMjNSECRPUqlUrz9/bs2ePV98/ffr0ifZoOX36tLJnz+75Onv27AoKCvL0GPm3fx6bErz9ebNnz9alS5c0a9YsT/WNpHjNgVPbkiVLdPToUS1btsxTfSLplr11YmJidObMmXiJlJu/E/9OrgAAAFbnAQDAK/ny5VP37t315JNPxksQ/Fe5cuVS69at9cILL2jnzp2JroJSvHhx/e9//1PZsmW1cePG5IQtSSpRooRy586t6dOnx9t+8OBB/frrr15/n/Tp06tZs2ZasGCBPvnkE12/fj3eVJ6bzVVvVsLc9OWXX3r1/QsVKqQtW7bE27Zr1y7t3Lkz3rYnnnhCe/fuVbZs2VSxYsUEf5Jabei/8vbnJfb6jTEaM2ZMgu+ZLl26FKvM+ac7OQf/Xrp6ypQpkpRgRSQAAEAlCgAAXvv444/v6O9VqlRJTzzxhMqVK6fQ0FBt375dX3/9tapUqaLg4GBt2bJFHTt21HPPPadixYopMDBQS5Ys0ZYtW9SzZ89kx+12u9WnTx+1b99ezz77rNq2batz586pT58+ypMnT4LpK7fTrl07jRo1SoMHD1bJkiVVtWpVz76SJUuqSJEi6tmzp4wxypo1q+bOnauFCxd69b1ffPFFtWjRQh06dFDjxo114MABffrpp8qRI0e847p06aKZM2eqevXqevPNN1WuXDnFxcXp4MGDWrBggbp27apKlSp5/ZqS4u3Pq127tgIDA/XCCy/o7bff1pUrV/TFF1/o7NmzCb5n2bJlNWvWLH3xxRe6//77bzu96L+oWrWqQkND9eqrr6pXr15KmzatJk+erMjIyESPDwwM1KBBg3Tx4kU98MADntV56tWrp4ceeijZ8QAAYDckUQAASGW1atXSnDlzNGTIEEVHRytfvnxq2bKl3nvvPUk3elAUKVJEn3/+uQ4dOiSXy6WwsDANGjRIb7zxRorE8Morr8jlcunTTz/V008/rUKFCqlnz5764Ycf4jUlTUr58uVVvnx5bdq0KUFz3bRp02ru3Lnq3Lmz2rdvrzRp0uixxx7TokWLVKBAgSS/d7NmzXT06FGNHj1a48ePV5kyZfTFF1+oT58+8Y7LkCGDVq5cqY8//lhfffWV9u/fr6CgIBUoUECPPfZYileiePvzSpYsqZkzZ+p///ufnnnmGWXLlk3NmjXTW2+9pXr16sX7np07d9aff/6pd999V+fPn5cxRsaYZMeaLVs2/fTTT+ratatatGihDBky6KmnntK3336rChUqJDg+bdq0+vHHH9WpUyf169dPQUFBevnllzVw4MBkxwIAgB25TEp8YgMAAL9z7tw5FS9eXI0aNdJXX31ldTi4y1q3bq0ZM2bo4sWLVocCAIDfoBIFAAAHOH78uPr376+aNWsqW7ZsOnDggIYMGaK///5bnTt3tjo8AAAAv0ASBQAAB0iXLp2ioqLUoUMH/fXXXwoODlblypU1evRolS5d2urwAAAA/ALTeQAAAAAAALzAEscAAAAAAABeIIkCAAAAAADgBZIoAAAAAAAAXiCJAgAAAAAA4AWvV+dJE5gvNeMAAAA+7PLRlVaHgBQQlPdhq0MAvOKUaw7vScB3xFw74tVxVKIAAAAAAAB4gSQKAAAAAACAF7yezgMAd5sTSnmdUMbrhPMIAAAAZyCJAsBnOSHB4AScR3sgGQYAAEASBQAAeIFkGAAAAEkUAADgBSpR7IFkGAAAyUNjWQAAAAAAAC9QiQLAZzlh5NsJo8JOOI8AAABwBpIoAHyWExIMTsB5tAeSYQAAAEznAQAAAAAA8AqVKAAAIElUFAEAAJBEAQAAXmA6jz2QDAMAIHlIogAAAADwKST8APgqkigAAAAAfIpTqt9IFgH+hyQKAJ/lhBsobp4AAAAA/0ESBYDPIsEA+A7ejwAAAJLLGGO8OTBNYL7UjgUAAAAAAOCui7l2xKvjqEQBAABJcsL0OiegoggAgOShEgUAAACAT3FK4pbEJuA7vK1EcadyHAAAAAAAALbAdB4AAJAkp4wK2x2j3gAAJA9JFAA+ywkPbU54oHHCeQQAAIAzkEQB4LOckGBwAs6jPZAMAwAAoCcKAAAAAACAV0iiAAAAAAAAeIEkCgAAAAAAgBfoiQIAAJJEbxsAAAAqUQAAAAAAALxCJQoAAEgSq/PYAxVFAAAkD0kUAACQJB6+AQAASKIAAAAvUIliDyTDAABIHpIoAAAgSTx8AwAAkEQBAABeoBLFHkiGAQCQPKzOAwAAAAAA4AUqUQD4LCeMfDthVNgJ5xEAAADOQBIFgM9yQoLBCTiP9kAyDAAAgOk8AAAAAAAAXqESBQAAJImKIgAAAJIoAADAC0znsQeSYQAAJA9JFAAAAAA+hYQfAF9FEgUAAACAT3FK9RvJIsD/0FgWAAAAAADACyRRAAAAAAAAvMB0HgAAkCRKzgEAAKhEAQAAAAAA8AqVKAB8lhOayjlhdN8J5xHwF0645gAAkJpIogDwWdzs2wPn0R5IhgEAADCdBwAAAAAAwCtUogAAgCRRUQQAAEAlCgAAAAAAgFeoRAEAAEmiJ4o9UFEEAEDykEQBAABJ4uEbAACAJAoAAPAClSj2QDIMAIDkoScKAAAAAACAF0iiAAAAAAAAeIHpPAAAIElMAwEAAKASBQAAAAAAwCtUogAAgCTRWNYeqCgCACB5qEQBAAAAAADwAkkUAAAAAAAALzCdBwAAAIBPYeoZAF/lMsYYbw5ME5gvtWMBAAAAAMf0YSJZBPiOmGtHvDqOShQAAJAkpzzQ2B0PbAAAJA9JFAAAAAA+hYQfAF/FdB4AAAAAAOBoTOcBAAAphuk89sDoPgAAyUMlCgAAAACf4pTELYlNwHdQiQLA7znhBsoJN09OOI+Av3DCNQcAgNREEgWAz+Jm3x44j/ZAMgwAAIAkCgAA8ALJMAAAAJIoAADAC1Si2APJMAAAkockCgAASBIP3wAAACRRAACAF6hEsQeSYQAAJA9LHAMAAAAAAEdjiWMAAJBiqESxBypR4C+ccs3hPQn4H5IoAAAgSdzoAwAAkEQB4MOcMArlhAdTJ5xHwF844ZoDAEBqIokCwGdxs28PnEcAAADYBUkUAACQJCqK7IGkJgAAycPqPAAAAAAAwNFYnQcAAKQYKlHsgUoU+AunXHN4TwL+x211AAAAAAAAAP6AJAoAAAAAAIAXmM4DAAAAwKcwzQWAryKJAgAAAMCn0BMFgK9idR4AAAAAAOBorM4DAABSjFNGhe2OUW/4C6dcc3hPAv6HxrIAAAAAAABeoBIFAAAkidFSAAAAkigAAMALTimttzuSYQAAJA/TeQAAAAAAALxAJQoAAAAAn0LVFABfRRIFgM9ywvQBJ9wkOuE8AgBSllM+O5xwHwDYDUkUAD6LGwt74Dzag1MeaAAAAG6HnigAAAAAAABeoBIFAAAkiYoiAAAAkigAAMALTOexB5JhAAAkD9N5AAAAAAAAvEAlCgAASBIVDAAAAJLLGGO8OTBNYL7UjgUAAAAAAOCui7l2xKvjqEQBAABJoieKPVBRBH/hlGsO70nA/9ATBQAAAAAAwAtUogAAgCQxWgoAAEASBQAAeMEppfV2RzIMAIDkYToPAAAAAACAF6hEAQAASaKCAQAAgCQKAB/mhOkDTngwdcJ5BPyFE645AACkJpIoAHwWN/v2wHm0B5JhAAAA9EQBAAAAAADwCkkUAAAAAAAAL5BEAQAAAAAA8AJJFAAAAAAAAC+QRAEAAAAAAPACSRQAAAAAAAAvsMQxAABIEktVAwAAkEQBAABeuHx0pdUhIAWQDAMAIHlIogAAgCTx8A0AAEASBQAAeIFKFHsgGQYAQPKQRAEAAADgU0j4AfBVLmOM8ebANIH5UjsWAAAAAHBM9RvJIsB3xFw74tVxVKIAAIAkOeWBxu54YAMAIHlIogAAgCTx8A0AAMB0HgAAAAAA4HBM5wEAACmG6Tz2QEUR/IVTrjm8JwH/QxIFAAAkiRt9AAAApvMAAAAAAACHYzoPAABIMU4prbc7KorgL5xyzeE9Cfgft9UBAAAAAAAA+AMqUQAAQJIYLQUAAKASBQAAAAAAwCskUQAAAAAAALzAdB4AAJAkpzR5tDumZQEAkDxUogAAAAAAAHiBJAoAAAAAAIAXmM4DAAAAwKcw9QyAr3IZY4w3B6YJzJfasQAAAACAY/owkSwCfEfMtSNeHUclCgCf5YQbKCfcPDnhPAL+wgnXHAAAUhNJFAA+i5t9e+A82gPJMAAAAJIoAHyYEx7anJBgcMJ5BACkLCd8PgLwT/REAQAASSIZZg88mMJfOOWaw3sS8B30RAEAACmGG30AAACSKAB8mBNGoZzwYOqE8wj4CydccwAASE0kUQD4LG727YHzaA8kwwAAACS31QEAAAAAAAD4AypRAABAkqgoAgAAoBIFAAAAAADAK1SiAACAJNETxR6oKAIAIHmoRAEAAAAAAPACSRQAAAAAAAAvkEQBAAAAAADwAkkUAAAAAAAAL5BEAQAAAAAA8AJJFAAAAAAAAC+QRAEAAAAAAPBCGqsDAAAAvi8o78NWhwAAAGA5kigAACBJl4+utDoEpACSYQAAJA/TeQAAAAAAALzgMsYYbw5ME5gvtWMBAAAAAAC462KuHfHqOKbzAACAJDGdxx6YzgN/4ZRrDu9JwP8wnQcAAAAAAMALVKIA8FlOGIVywgiUE84jACBlOeHzEYB/oicKAAAAAABwNHqiAAAAAPBLTqlipOIG8D9UogAAAAAAAEejEgUAAKQYp4wK2x2j3vAXTrnm8J4E/A+VKAAAAAAAwNGoRAEAACnGKaPCdseoN/yFU645vCcB/+O2OgAAAAAAAAB/QBIFAAAAAADAC0znAQAASaLkHAAAgCQKAADwglP6E9gdyTAAAJKH6TwAAAAAAABeIIkCAAAAAADgBabzAACAJDENBAAAgEoUAAAAAAAAr1CJAgAAkkRjWXugoggAgOShEgUAAAAAAMALVKIA8FlOGPl2wqiwE84jAAAAnMFljDHeHJgmMF9qxwIAAAAAAHDXxVw74tVxVKIAAAAA8ClOqWJ0QkUqYDckUQD4LCfcQDnh5skJ5xHwF0645gAAkJpIogDwWdzs2wPnEQAAAHbB6jwAAAAAAABeoBIFAAAkiWlZ9kBlGAAAyUMlCgAAAAAAgBdIogAAAAAAAHiBJAoAAAAAAIAXSKIAAAAAAAB4gcayAAAAAHwKTZAB+CqSKAAAAAB8ilNWBCNZBPgfkigAACBJ3OgDAADQEwUAAAAAAMArVKIAAIAkOaW03u6oKAIAIHmoRAEAAAAAAPAClSgAfJYTRr4ZFQYAAAD8B0kUAD6LBAPgO3g/AgAAkEQBAABecEJlmBOQDAMAIHlcxhjjzYFpAvOldiwAAAAAAAB3Xcy1I14dRyUKAABIEpUo9kAlCgAAyUMlCgAAAACf4pTELYlNwHdQiQIAAFKMUx5o7I4HNgAAkockCgAASBIP3wAAACRRAACAF6hEsQeSYQAAJI/b6gAAAAAAAAD8AZUoAHyWE0a+GRUGAAAA/AdJFAA+iwQD4Dt4PwIAAJBEAQAAXnBCZZgTkAwDACB5SKIA8FlOeGhzwgONE84jAAAAnIEkCgAAAACf4oRBBgD+iSQKAAAAAJ/ilCpGkkWA/yGJAsBncWNhD5xHe3DKAw0AAMDtkEQBAABJIhkGAAAgua0OAAAAAAAAwB9QiQIAAJLEdB57oKIIAIDkIYkCwGc54aHNCQ80TjiPAAAAcAaSKAB8lhMSDE7AeQQAAIBd0BMFAAAAAADAC1SiAACAJDEtyx6oDAMAIHlIogAAgCTx8A0AAMB0HgAAAAAAAK9QiQIAAJLEdB57oKIIAIDkIYkCwGc54aGNBxoAAADAf5BEAeCzSDAAvoP3IwAAAD1RAAAAAAAAvEIlCgAASJITptc5ARVFAAAkD5UoAAAAAAAAXiCJAgAAAAAA4AWSKAAAAAAAAF4giQIAAAAAAOAFGssC8FlOaGTphCaPTjiPAAAAcAYqUQAAAAAAALxAJQoAn+WEKg0n4DwCAADALqhEAQAAAAAA8AKVKAAAIEn0trEHKsMAAEgeKlEAAAAAAAC8QBIFAAAAAADAC0znAQAASWIaCAAAAJUoAAAAAAAAXiGJAgAAAAAA4AWm8wAAgCSxOo89MC0LAIDkoRIFAAAAAADACy5jjPHmwDSB+VI7FgAAAAAAgLsu5toRr45jOg8AAEgS03nsgek88BdOuebwngT8D9N5AAAAAAAAvMB0HgAAAAAA4GhM5wEAACnGKaX1dsfUAfgLp1xzeE8C/ofpPAAAAAAAAF4giQIAAAAAAOAFkigAAAAAAABeoCcKAABIEvP2AQAASKIA8GFOaCrnhAdTJ5xHwF844ZoDAEBqYjoPAAAAAACAF6hEAeCzGDG1B86jPVBRBAAAQCUKAAAAAACAV6hEAeCznDDyTZUGAAAA4D9IogDwWSQYAN/B+xEAAIAkCgAA8IITKsOcgGQYAADJQxIFAAAkiYdvAAAAyWWMMd4cmCYwX2rHAgAAfBSVKPZAMgwAgMTFXDvi1XEkUQAAAAD4FKckbklsAr7D2yQK03kAAECSnPJAY3c8sAEAkDwkUQAAAAD4FBJ+AHwV03kAAAAA+BSnVL+RLAJ8Bz1RAPg9J9xAOeHmyQnnEfAXTrjmAABwJ0iiAAAAAPBLTknAk9gEfAdJFAAAAAAAAC+wOg8AAEgxThkVtjtGveEvnHLN4T0J+B+31QEAAAAAAAD4AypRAABAkhgtBQAAoBIFAAAAAADAKyRRAAAAAAAAvMB0HgAAkCSnNHm0O6ZlAQCQPFSiAAAAAAAAeIFKFAAAkCQqGAAAAEiiAAAALzCdxx5IhgEAkDxM5wEAAAAAAPAClSgAAAAAfApVUwB8FUkUAAAAAD7FKVMISRYB/ofpPAAAAAAAAF6gEgUAACSJ0VIAAAAqUQAAAAAAALxCJQoAAEiSU/oT2B0VRQAAJA+VKAAAAAAAAF4giQIAAAAAAOAFkigAAAAAAABeIIkCAAAAAADgBZIoAAAAAAAAXiCJAgAAAAAA4AWWOAbgs5ywpKoTlht1wnkEAACAM5BEAeCznJBgcALOoz2QDAMAAJBcxhjjzYFpAvOldiwAAAAAAAB3Xcy1I14dRyUKAJ/lhJFvJ1RpOOE8Av7CCdcc2INTPjt4TwL+hyQKAJ/FjYU9cB4BAABgFyRRAABAkpwyKmx3JDUBAEgekigAACBJPHwDAACQRAEAAF6gEsUeSIYBAJA8rM4DAAAAAAAcjdV5AAAAAPglp1S/UR0G+B+SKAAAIElOeaCxOx7YAABIHrfVAQAAAAAAAPgDKlEA+CwnjHw7YVTYCecRAAAAzkAlCgAAAAAAgBeoRAHgs5xQpeEEnEcAAADYBUkUAACQJKZl2QNJTQAAkofpPAAAAAAAAF4giQIAAAAAAOAFpvMA8FlOmD5AaT0AAADgP0iiAPBZJBgAAAAA+BKSKAAAIEkkNQEAAEiiAPBhTOexByecR8BfOOGaAwBAaiKJAsBncbNvD5xHeyAZBgAAwOo8AAAAAAAAXnEZY4w3B6YJzJfasQAAAAAAANx1MdeOeHUc03kAAECSmM5jD0yvg79wyjWH9yTgf0iiAACAJHGjDwAAQE8UAAAAAAAAr1CJAgAAkuSU0nq7o6IIAIDkIYkCwGc54aHNCQ80TjiPAAAAcAaSKAB8lhMSDE7AeQQAAIBdkEQBAABJoqLIHkhqAgCQPDSWBQAAAAAA8AKVKAAAIElUMAAAAFCJAgAAAAAA4BUqUQD4LCf0YHDC6L4TziPgL5xwzQEAIDWRRAHgs7jZtwfOoz2QDAMAAGA6DwAAAAAAgFeoRAEAAADgU6hiBOCrSKIA8FlOmD7ghJtEJ5xHAEDKcspnhxPuAwC7IYkCwGdxY2EPnEd7cMoDDQAAwO3QEwUAAAAAAMALJFEAAAAAAAC8QBIFAAAAAADACy5jjPHmwDSB+VI7FgAAAAAAgLsu5toRr46jEgUAAAAAAMALrM4DAACSxOo89sBqWfAXTrnm8J4E/A9JFAAAkCRu9AEAAEiiAAAALzhlVNjuSIYBAJA8JFEA+CwnPLQ54YHGCecRAAAAzkASBYDPckKCwQk4jwAAALALljgGAABJoqLIHkhqAgCQOG+XOKYSBYDPcsJDmxMeaJxwHgEAKcspnx1OuA8A7IYkCgCfxY2FPXAe7cEpDzQAAAC3QxIFAAAkiWQYAAAASRQAPswJI99OeDB1wnkE/IUTrjkAAKQmkigAfBY3+/bAebQHkmEAAAAkUQAAgBdIhgEAAEhuqwMAAAAAAADwB1SiAACAJDGdxx6oKAIAIHlIogDwWU54aHPCA40TziMAIGU54fMRgH9yGWOMNwemCcyX2rEAAAAAAADcdTHXjnh1HJUoAAAgSVQU2QOj+/AXTrnm8J4E/A+NZQEAAAAAALxAJQoAAEgSo6UAAAAkUQAAgBecUlpvdyTDAABIHqbzAAAAAAAAeIEkCgAAAAAAgBdIogAAAAAAAHiBnigAACBJ9NIAAAAgiQIAALxAY1l7IBkGAEDyMJ0HAAAAAADACyRRAAAAAAAAvOAyxhhvDkwTmC+1YwEAAAAAALjrYq4d8eo4eqIAAIAk0RPFHuiJAn/hlGsO70nA/1CJAgAAAAAAHI1KFAAAkGKcMipsd4x6w1845ZrDexLwPzSWBQAAAAAA8AJJFAAAAAAAAC/QEwUAAAAAADiatz1RqEQBAAAAAADwAo1lAQAAAPgUGssC8FUkUQD4LCfcQDnh5skJ5xHwF0645gAAkJpIogDwWdzs2wPn0R5IhgEAANATBQAAAAAAwCtUogDwWU4Y+XZClYYTziMAAACcgUoUAAAAAAAAL1CJAsBnOaFKwwk4j/ZARREAAABJFAAA4AWSYQAAACRRAACAF6hEsQeSYQAAJA9JFAAAkCQevgEAAGgsCwAAAAAA4BUqUQD4LCdMH3DC6L4TziPgL5xwzQEAIDWRRAHgs7jZtwfOoz2QDAMAAGA6DwAAAAAAgFdIogAAAAAAAHiBJAoAAAAAAIAX6IkCAACSRG8bAAAAKlEAAAAAAAC8QiUKAABIEqvz2AMVRQAAJA9JFAAAkCQevgEAAEiiAAAAL1CJYg8kwwAASB6XMcZ4c2CawHypHQsAAAAAAMBdF3PtiFfHUYkCAACSRCWKPVCJAn/hlGsO70nA/5BEAQAASeJGHwAAgCQKAADwglNGhe2OZBgAAMnjtjoAAAAAAAAAf0AlCgAASBIVDAAAACRRAACAF5jOYw8kwwAASB6SKAAAIEk8fAMAAJBEAQAAXqASxR5IhgEAkDwkUQAAQJJ4+AYAAGB1HgAAAAAAAK+QRAEAAAAAAPACSRQAAAAAAAAvuIwxxpsD0wTmS+1YAACAj6KxrD3Q2wYAgMTFXDvi1XE0lgUAAADgU5ySuCWxCfgfpvMAAAAAAAB4gUoUAD7LCaNQThiBcsJ5BAAAgDOQRAEApConJIqcgGQYAAAASRQAPoyHbwAAAAC+hCQKAJ/lhJFvJySKnHAeAQAA4Aw0lgUAAAAAAPAClSgAfJYTqjScgPNoD1QUAQAAUIkCAAAAAADgFSpRAABAkqgoAgAAIIkCAAC8wHQeeyAZBgBA8jCdBwAAAAAAwAskUQAAAAAAALzAdB4AAJAkpoEAAACQRAHgw5zQg8EJD6ZOOI+Av3DCNQcAgNTEdB4AAAAAAAAvUIkCwGcxYmoPnEd7oKIIAACAShQAAAAAAACvUIkCAAAAwKdQxQjAV7mMMcabA9ME5kvtWAAAAADAMVMISRYBviPm2hGvjqMSBYDPcsINlBNunpxwHgF/4YRrDgAAqYkkCgCfxc2+PXAeAQAAYBckUQAAQJKoKLIHkpoAACQPSRQAPssJD21OeKBxwnkEAACAM5BEAeCznJBgcALOIwAAAOzCbXUAAAAAAAAA/oBKFAAAkCSmZdkDlWEAACQPlSgAAAAAAABeoBIFAAAAgE+hagqAryKJAsBnOWH6gBNuEp1wHgEAKcspnx1OuA8A7MZljDHeHJgmMF9qxwIAAHyUUx5o7I4HNgAAEhdz7YhXx1GJAgAAAMCnOCVxS2IT8D8kUQAAQJK40QcAACCJAgAAvOCUUWG7IxkGAEDykEQBAABJ4uEbAABAclsdAAAAAAAAgD9gdR4AAJAkpvPYAxVFAAAkztvVeUiiAAAAAPApTkncktgEfAdLHAPwe064gXLCzZMTziPgL5xwzQEAIDWRRAHgs7jZtwfOIwAAAOyC6TwAACBJVBTZA0lNAAASR08UAAAAAAAAL9ATBYDfc8LItxNGhZ1wHgF/4YRrDuzBKZ8dvCcB/0MSBYDP4sbCHjiP9uCUBxoAAIDbIYkCwGc54aHNCQkGJ5xHAAAAOANJFAAAAAA+xQmDDAD8E41lAQAAAACAo9FYFgAApBimZdkDo/vwF0655vCeBPwPSRQAAAAAPoXkAgBfRRIFAAAAgE+hEgWAryKJAgAAksSNPgAAAEkUAADgBaeMCtsdyTAAAJLHbXUAAAAAAAAA/oBKFAA+ywkj304YFXbCeQQAAIAzuIwxxpsD0wTmS+1YAACAjyIZZg9OSNwCAHAnYq4d8eo4KlEAAAAA+BSnJG5JbAL+hyQKAJ/lhBsoJ9w8OeE8AgAAwCGMj7py5Yrp1auXuXLlitWhpBpeoz3wGu2B12gPvEb7cMLr5DXaA6/RHniN9sBrtAdff41e90S52y5cuKDMmTPr/PnzypQpk9XhpApeoz3wGu2B12gPvEb7cMLr5DXaA6/RHniN9sBrtAdff40scQwAAAAAAOAFkigAAAAAAABeIIkCAAAAAADgBZ9NoqRLl069evVSunTprA4l1fAa7YHXaA+8RnvgNdqHE14nr9EeeI32wGu0B16jPfj6a/TZxrIAAAAAAAC+xGcrUQAAAAAAAHwJSRQAAAAAAAAvkEQBAAAAAADwAkkUAAAAAAAAL5BEAZLh8OHDOnLkiNVhAI51+fLlW+47duzYXYwk9QQEBOjkyZMJtp85c0YBAQEWRAQA/m/FihWKiYlJsD0mJkYrVqywICLAec6ePasRI0bowoULCfadP3/+lvuslsbKHz58+HCvj+3UqVMqRmK9zZs367777rM6jDv26aef6o033lBQUJCkGx9MlSpV8ixL9ffff6tHjx76/PPPrQwzRcTFxalfv34aNGiQLl68KEkKCQlR165d9d5778nt9v/c5OHDh5UlSxZlzJgx3vbr169rzZo1ql69ukWR4b9auXKlvvzyS+3du1czZsxQvnz59PXXX6tw4cJ66KGHrA4v2cqXL68pU6aoQoUK8bbPmDFDr732mk6dOmVRZCnnVovoXb16VYGBgXc5mpQVGhoql8vl1bF//fVXKkeT+saPH6+MGTPqueeei7f9u+++U3R0tFq1amVRZCnr0KFDcrlcuueeeyRJ69ev15QpUxQeHq5XXnnF4uiSb8CAAcqVK5fatm0bb3tERIROnTqlHj16WBQZ/ouaNWvq2LFjypkzZ7zt58+fV82aNRUbG2tRZCnn4MGDyp8/v9fXWfiP2NhYbd26VQULFlRoaKjV4dyxkSNHasuWLXrjjTcS7MucObNWrlypCxcu6L333rMgutswFipUqFC8PxkyZDAul8uEhoaa0NBQ43K5TIYMGUzhwoWtDDPVnDt3zowaNcqUL1/euN1uq8NJFrfbbU6cOOH5OiQkxOzdu9fz9fHjx/3+Nd7Us2dPkyNHDvP555+byMhIs3nzZjNq1CiTI0cO8+6771odXrIcPXrUPPDAA8btdpuAgADTsmVL8/fff3v22+k8GmNMdHS0uXTpkufrqKgoM2TIEDN//nwLo0o5M2bMMEFBQeall14y6dKl87wnR40aZerVq2dxdCmjY8eOJl26dGbAgAEmLi7O/P3336ZVq1YmODjYDB8+3OrwkmXYsGFm2LBhxu12m/79+3u+HjZsmBk8eLBp1KiRue+++6wOM1kmTJjg+TNo0CATGhpqnn/+ec/rfP75501oaKgZPHiw1aGmiOLFi5slS5Yk2L5s2TJTvHhxCyJKHQ899JCZNGmSMcaYY8eOmUyZMpkqVaqYbNmymT59+lgcXfIVLFjQrF69OsH2tWvXmkKFClkQEe6Ey+UyJ0+eTLB9586dJiQkxIKIUt6/78/hvzp37mzGjh1rjDEmJibGVKtWzfOsvHTpUmuDS4Z7773XLFq06Jb7Fy1a5JP3Oi5jbjHEdZdNmTJFn3/+ucaNG6cSJUpIknbu3KmXX35Z7du3V/PmzS2OMOUsWbJEERERmjVrlgoWLKjGjRurcePGKl++vNWh3TG3263jx497svkhISGKjIxUWFiYJOnEiRPKmzevLbL6efPm1ejRo9WwYcN423/44Qd16NDBr6f3tGrVSrt27dKIESN07tw5vfPOOzLGaOHChQoNDdWJEyeUJ08excXFWR1qinj88cf1zDPP6NVXX9W5c+dUsmRJpU2bVqdPn9bgwYP12muvWR1ispQvX15vvvmmWrZsGe89uXnzZtWtW1fHjx+3OsQUMW/ePLVp00ZFixbV0aNHlSlTJk2ePFnh4eFWh5YshQsXliQdOHBA99xzT7ypO4GBgSpUqJD69u2rSpUqWRViimrcuLFq1qypjh07xts+cuRILVq0SLNnz7YmsBSUPn167dixQ4UKFYq3PSoqSqVKlbrt9DR/EhoaqrVr16pEiRIaPny4vv32W61evVoLFizQq6++qn379lkdYrKkT59e27dv97xHb9q3b5/Cw8N15coViyJLGTVr1kyycsHlcmnx4sV3KaKU9cwzz0i6cd9Wt25dT9W0dGN0f8uWLSpRooTmzZtnVYgp5t/353Z08OBBr44rUKBAKkeSuu655x7Nnj1bFStW1OzZs/X6669r6dKlmjRpkpYuXarVq1dbHeIdCQkJ0Z9//nnL83Pw4EGVKVPG56b0WDqd55/ef/99zZgxw5NAkaQSJUpoyJAhevbZZ/0+iXL48GFNmDBBERERunTpkpo0aaLr169r5syZfn+j7zR//fWXSpYsmWB7yZIl/b7cfNGiRfr+++9VsWJFSdLDDz+spk2bqlatWp6bJTuVhG7cuFFDhgyRdGP6R65cubRp0ybNnDlTH3zwgd8nUXbu3Jno1KtMmTLp3Llzdz+gVHIzGfbFF18oTZo0mjt3ri2uq/v375d044Fm1qxZfl2u64358+frk08+SbC9Tp066tmzpwURpbycOXNqy5YtCZIokZGRypYtmzVBpYLr1697HkwXLVrkGXQoWbKkLXoV5c+fX6tXr06QRFm9erXy5s1rUVQp53bTyy9cuKCpU6fq6tWrdy+gFJY5c2ZJN6ZKhoSEeKaiSzcS1JUrV9bLL79sVXj4jwoVKpTovakxxrPd5XIl2v/Gn5w+fVq5c+eWJP3888967rnnVLx4cbVr1+4/tcjwNQEBATp69OgtkyhHjx71yVYJPpNEOXbsmK5fv55ge2xsrE6cOGFBRCmnfv36WrVqlZ544gmNGDFCdevWVUBAgEaPHm11aLgD9957r0aOHJnggjVy5Ejde++9FkWVMs6fPx/vQS1dunSaMWOGnnvuOdWsWVPffPONhdGlvOjoaIWEhEiSFixYoGeeeUZut1uVK1fWgQMHLI4u+fLkyaM9e/YkeGBbtWqVp0rM3+3du1fNmjXT8ePHNX/+fC1fvlxPPfWUOnXqpP79+ytt2rRWh5hsS5cutTqEuyJbtmz6/vvv1b1793jbZ8+ebZsEw/PPP69OnTopJCTEk+Bcvny5OnfurOeff97i6FJO6dKlNXr0aDVo0EALFy7Uhx9+KOnGzbAdzuVLL72kLl266Pr166pVq5YkafHixXr77bfVtWtXi6NLvpuDC/8UExOjUaNGqX///sqXL5/nnPqj8ePHS7rx8N2tWzdlyJDB4ohS19ixYxP0uPs3f+49uWnTpkS3G2M0bdo0DR8+PMnX7w9y5cqlbdu2KU+ePJo3b56nz2R0dLRfN5kvX768Zs+ercqVKye6//vvv/fN2RpWziX6pyeeeMKUK1fObNiwwcTFxRljjNmwYYO57777zJNPPmlxdMkTEBBg3nzzTbNr165429OkSWP+/PNPi6JKWS6XK96c/fTp05v333/f83W/fv1s00tj2bJlJkOGDKZUqVKmbdu2pl27dqZUqVImY8aMZsWKFVaHlyxly5Y1M2bMSLD9+vXrplGjRqZAgQK2OY/G3Hi9w4YNMwcPHjSZMmUyv/76qzHGmN9++83kypXL4uiS75NPPjHh4eFm7dq1JiQkxKxcudJ88803JkeOHGbEiBFWh5ciMmbMaJo2bWrOnj3r2bZ69WpTpEgRn5xDeydiYmLM2LFjzQsvvGAeffRRU7NmzXh/7GL8+PHG7Xab+vXrmw8//NB8+OGHpkGDBiYgIMCMHz/e6vBSxNWrV02TJk2My+UyadOmNWnTpjUBAQGmTZs25urVq1aHl2KWLl1qsmTJYtxut2nTpo1n+zvvvGOefvppCyNLGXFxcebtt9826dOnN26327jdbhMcHGyLfi+J+eabb0xYWJjJkyePGTVqlLl+/brVIaWY69evm4ULF5rRo0ebCxcuGGOMOXLkSLx+cP7M5XKZ/PnzJ+hD+c8/duw9uXDhQnP//febkJAQ06tXL1ucz169epnMmTObkiVLmgIFCpgrV64YY4wZN26cqVy5ssXR3bkZM2aYNGnSmBEjRpiYmBjP9piYGDN8+HCTNm1a891331kYYeJ8pifKqVOn1KpVK82bN88zchgTE6M6depo/PjxypUrl8UR3rk1a9YoIiJC06dPV8mSJfXiiy+qadOmyps3ryIjI21Rdn6rUrp/u1me7u+OHj2qUaNGaceOHTLGKDw8XB06dPD7Mt4ePXpo8+bNmj9/foJ9MTExaty4sX788Udb9LaRbkzhadasmWJjY1WrVi0tXLhQ0o2VF1asWKFffvnF4giT77333tOQIUM8c/TTpUunbt26+fUo4j99/fXXevHFFxNs//vvv9WlSxeNGzfOgqhSVseOHTVhwgQ1aNBAefLkSXCtTWzU2F+tW7dOw4cP1/bt2z3X1k6dOtmm78tNu3fv1ubNmxUUFKSyZcuqYMGCVoeU4mJjY3XhwoV41Y1RUVEKDg62TX+Gixcvavv27QoKClKxYsXi9dawg3nz5qlnz57av3+/unXrprfeestWVRsHDhxQ3bp1dfDgQV29elW7du1SWFiYunTpoitXrtiiYtwJPVH+6ffff1fPnj21cuVKvfTSS/rggw9s9dpnzJihQ4cO6bnnnvOsfjZx4kRlyZJFTz31lMXR3bn33ntPAwYMUEhIiMLCwuRyubR3715dvHhR3bt318cff2x1iAn4TBLlpt27d3tunkqVKqXixYtbHVKKiY6O1rRp0xQREaH169crNjZWgwcPVtu2bT1TCgArxcTEKDo6WpkyZUp0f2xsrA4fPmyrG/7jx4/r2LFjuvfeez1zLtevX69MmTIl2vvGH0VHR2vbtm2Ki4tTeHi4Lcpa/+3atWvav3+/ihQpojRpfGamaorInj27Jk2apPr161sdClKYXZaodLoLFy5oyZIlKlGihEqVKmV1OMm2fv169ejRQ2vXrtWrr76q9957T9mzZ7c6rBTXqFEjhYSEaNy4ccqWLZun+fry5cv10ksvaffu3VaHmGwBAQGJLuNsN3v27NF7772nmTNnqkmTJurXr59tpi3fzrlz55QlSxarw0gR69ev1+TJk7Vnzx4ZY1S8eHE1a9ZMDz74oNWhJcpnkih9+/ZVt27dFBwcHG/75cuXNXDgQH3wwQcWRZY6du7cqXHjxunrr7/WuXPnVLt2bc2ZM8fqsHAbTun+/W+rV69WxYoVbTfC9k979uzR3r17Vb16dQUFBcVrRgbfdvnyZXXs2FETJ06UJM9IYqdOnZQvXz716NHD4giTL2/evFq2bJmtBhX+6ejRoxo8eLA++OCDBAnc8+fPq1+/furWrZtfV6Te1KVLF5UtW1bt2rVTbGysHnnkEf36668KDg7Wjz/+qBo1algdYoooXLjwba+h/r46T5MmTVS9enV17NhRly9f1r333quoqChPD4bGjRtbHWKyuN1uBQUFqX379gl6av2TP/fRkG4kqFevXq0SJUrEW8EuKipK4eHhio6OtjrEZEuqEiU2NlZz585Vo0aN7m5gKahDhw4aN26catasqY8//vi2jZH92SeffKJChQqpadOmkm5ch2bOnKk8efLo559/Vrly5SyO0Fl8Jolyq0zpmTNnlDNnTttMH/i3mxeviIgIv06iTJo0yavjWrZsmcqRpB632+2I7t//lilTJm3evNmWGf0zZ86oSZMmWrp0qVwul3bv3q2wsDC1a9dOWbJk0aBBg6wOMVmefvrpRH9nXS6X0qdPr6JFi6pZs2bxVkXzN507d9bq1as1dOhQ1a1bV1u2bFFYWJjmzJmjXr163bLhnD8ZNGiQ9u3bp5EjR9oyudetWzdduHBBX331VaL7X331VWXOnDnRlXv8zb+XqOzQoYOWLVvm90tU/tuwYcPifX39+nVt2rRJ8+bNU/fu3f1+taXcuXNr/vz5uvfeezVlyhT16tVLkZGRmjhxor766iu/v+54M0Xb5XL5fTIsa9asWrVqlcLDw+MlUVatWqXGjRv7/cIWktSnTx917949wSD1jh07FBERoYkTJ+rs2bO6du2aRREmn9vtVvr06ZOsHt64ceNdiih1hIWF6ZtvvlHVqlW1cOFCNWnSRN9++62mT5+ugwcPasGCBVaHeEd2796tDz74QF9++WWiAymvvfaaT1YW+UwSxe1268SJE8qRI0e87UuWLFHTpk116tQpiyJLfcYYnTp1yq9L7dxutzJmzKg0adLoVr9SLpfLr5cAjoyMTHS7+Vf375MnT97lyFLXP28s7KZly5Y6efKkxo4dq1KlSnle54IFC/Tmm2/qzz//tDrEZGndurVmz56tLFmy6P7775cxRps2bdK5c+f0+OOPKzIyUlFRUVq8eLGqVatmdbh3pGDBgvr2229VuXLleL+re/bsUYUKFXThwgWrQ0y2p59+WkuXLlXWrFlVunTpBCsOzZo1y6LIUkaZMmU0evRoPfTQQ4nu//XXX/Xyyy/7/ftRktKnT689e/bonnvu0SuvvKLg4GANHTpU+/fv17333muL39fbGTVqlH777TfP6ij+KigoSLt27VL+/PnVsmVL5c2bVx9//LEOHjyo8PBwXbx40eoQ4YWmTZsqc+bM+uqrrxQSEqItW7YoR44ceuqpp1SgQAG//z39t0uXLunbb7/VuHHjtHbtWtWsWVPPP/+8GjVq5NfTtfr06ePVcb169UrlSFLXP687nTt31pUrV/Tll19q165dqlSpks6ePWt1iHfklVdeUZYsWfTpp58mur9Hjx66cOGCvvjii7sc2e1ZPnE8NDRULpdLLpdLxYsXj5f5jo2N1cWLF/Xqq69aGGHyBQcH68CBA54EUd26dTV+/HjlyZNHknTy5EnlzZvXr6ttSpUqpRMnTqhFixZq27atLUvKElu+eNGiRerZs6d27dqlt99+W926dbMgMtypBQsWaP78+Z7mXDcVK1bMFksc586dW82aNdPIkSM9/V7i4uLUuXNnhYSEaNq0aXr11VfVo0cPrVq1yuJo78ytEtCXLl2yTdVGlixZ9PTTT1sdRqrZv3//badB3nPPPYqKirp7AaUiuy5R6a169erpnXfe8fuH0/z582vNmjXKmjWr5s2bp2nTpkmSzp49q/Tp01scHbw1ZMgQ1axZU+Hh4bpy5YqaNWum3bt3K3v27Jo6darV4aWYNWvWaOzYsZo+fbqKFSum5s2be5p422FxC39PjngrNDRUhw4dUv78+TVv3jz169dP0o3BXH9+hlyxYoW+/vrrW+5v0qSJmjVrdhcj8o7lSZShQ4fKGKO2bduqT58+ypw5s2dfYGCgChUqpCpVqlgYYfJduXIlXnXG6tWrdfny5XjH+EhB0B37888/tW7dOkVERKh69eoqWrSo2rVrp+bNm9+ySak/+3f3759//tmvK4lu58svv7RFL4LEXLp0KUGJqySdPn3aFj1gxo0bp9WrV3sSKNKNqrE33nhDVatW1UcffaSOHTvq4YcftjDK5HnggQf0008/6Y033pAkT+JkzJgxfv/ZcZO/P3AmJSgoSFFRUbdMpERFRSkoKOguR5U62rRpoyZNmnhWWapdu7akG6sS2aWR9e3MmDFDWbNmtTqMZOvSpYuaN2+ujBkzqkCBAp5eNitWrFDZsmWtDS6FxMTEaMiQIZo6dap27doll8ulYsWKqVmzZurcuXOCijh/lDdvXm3evFlTp07Vxo0bFRcX57l3tcs152Zvl2bNmmndunWepIm/T6m7lS1btsT7fbXToO4zzzyjZs2aqVixYjpz5ozq1asnSdq8ebOKFi1qcXR37sCBA7d9hsqePbsOHTp0FyPyjuVJlFatWkm60YSsatWqtrgo3wk7jJhWqlRJlSpV0tChQ/Xdd99p/Pjx6tatmxo1aqSIiAhbPJT+u/v3tm3bbDnN5Z98MfubUqpXr65JkyZ5lvt1uVyKi4vTwIEDVbNmTYujS76YmBjt2LEjQUPSHTt2eEYt0qdP79fXnwEDBqhu3bratm2bYmJiNGzYMP35559as2aNli9fbnV4KSYmJkbLli3T3r171axZM4WEhOjo0aPKlCmT36+2VKlSJX399deqXr16ovsnTZrks935/6vevXurTJkyniUqb34uBgQE2Oqhpnz58vGuK8YYHT9+XKdOnfJU3/izDh066MEHH9ShQ4dUu3ZtT6I6LCzMMzrszy5fvqzatWtrzZo1euyxx1S9enUZY7Rjxw716NFDc+bM0YIFC2xRdRMUFKS2bduqbdu2VoeSKvbs2aPnn39eNWvWtMXKUbeyfv16tWvXTtu2bfMMTLtcLpUuXVrjxo3TAw88YHGEyTdkyBAVKlRIhw4d0qeffur57D927Jg6dOhgcXR3LnPmzNq7d+8tV/7cs2ePbw7IGx8SExNjvvvuO9O3b1/z4YcfmhkzZpjr169bHVayuVwuc+LECc/XGTNmNHv37vV8ffz4ceN2u60ILVUtX77c1KhRw7jdbvPXX39ZHU6yvfbaayYwMNDUqVPHbNq0yepwLLFnzx5Ts2ZNq8NIMX/++afJkSOHqVu3rgkMDDTPPvusKVWqlMmVK5fZs2eP1eEl2xtvvGGyZ89uBg8ebFauXGlWrVplBg8ebLJnz246depkjDFmzJgxplq1ahZHmjxbtmwxLVu2NKVLlzalSpUyzZs3N1u2bLE6rBQTFRVlSpYsaYKDg01AQIDn86Nz586mffv2FkeXfEuWLDEBAQGma9eu5vjx457tx48fN2+99ZYJCAgwixcvtjDC1HH58mWrQ0g1vXr1Mr179/b86du3r/niiy/M9u3brQ4tRV29etXs2LHDFveq//T++++bAgUKmMjIyAT7Nm/ebAoUKGB69ep19wNLBZMmTTLVqlUzefLkMVFRUcYYYwYPHmxmz55tcWQp4/Dhw6Zfv36mSJEiJm/evKZr165m48aNJm3atObPP/+0OrwU8eeff5qMGTOaBx54wEyZMsVs2rTJbNy40UyePNlUrFjRhISE2Oa12tFzzz1nGjVqdMv9DRs2NM8+++xdjMg7PpNE2bp1qwkLCzPBwcGmfPnypnz58iZDhgymUKFCfn8z7Ha7zcmTJz1fh4SEmH379nm+tlMS5fDhw6Z///6maNGiJk+ePKZ79+62uWlyuVwmKCjI8/t5qz92tnnzZtv8rt507Ngx88EHH5gGDRqYevXqmffee88cPXrU6rBSRExMjOnXr5/JnTu3cblcxuVymdy5c5v+/fubmJgYY4wxBw4cMIcOHbI4UtzOU089ZVq0aGGuXr0aLwm/bNkyU7RoUYujSxmjR4826dKlM26322TJksWEhoYat9tt0qVLZz7//HOrw0sxMTExpm/fviZv3rzxEmL/+9//zNixYy2ODt66dOmSadu2rQkICIh3Ht944w0zYMAAi6NLvmLFipkZM2bccv/06dNNsWLF7mJEqePzzz832bNnN/369TPp06f3nMfx48ebGjVqWBxdylu8eLFp3ry5CQoKMi6Xy3Tv3t3s3LnT6rCS7dlnnzVPP/20iYuLS7AvLi7ONGrUyDz33HMWRJY6/vzzT/PLL7+YH374Id4ff7Vx40aTLl0607hxY7Nu3Tpz7tw5c+7cObN27VrzzDPPmHTp0pnff//d6jAT8JnVeSpXrqycOXNq4sSJCg0NlXSjQVfr1q118uRJrVmzxuII75zb7VbmzJk9pa3nzp1TpkyZPOWfxhhduHDBr5sCTZ8+XePHj9fy5ctVp04dtWnTRg0aNLBVozwndP8ePnz4bfcfOXJEn332mV//rjrVzVU/fLIk8g7ExcUpLi5OadL836zUEydOaPTo0bp06ZIaNmx4y9Ve/E327Nm1evVqlShRIt4KRFFRUZ757nZw5MgRTZ8+XXv27JExRsWLF9ezzz6boPGzP+vbt68mTpyovn376uWXX9Yff/yhsLAwTZ8+XUOGDPHre51/CggI0LFjxxLMcz9z5oxy5szp958hdl9aPX369Nq9e7fy58+f6P5Dhw6pWLFiunLlyl2OLGWFh4fro48+UqNGjeJdW//44w/VqFFDp0+ftjrEVHH+/HlNnjxZERER2rhxo8qUKaMtW7ZYHdYdy5Ejh3755RdVrFgx0f0bNmxQ/fr1/X6l13379unpp5/W1q1b5XK54k1bkuTX19Uff/xRbdu21ZkzZ+Jtz5Ytm8aOHauGDRtaFNmt+UwSJSgoSL/99ptKly4db/sff/yhBx54IEEjVn8yceJEr4672R/GH7ndbhUoUEDNmze/bRPSTp063cWo8F+53W7lyZNHgYGBie6/du2ajh8/7tcX6v9yo2CnhmQ3nT17Vt98843GjRunzZs3Wx3OHWvTpo3Spk2rr776SpL0999/q3Tp0rpy5Yry5Mmjbdu26YcfflD9+vUtjjT5smbNqlWrVik8PDzejf6qVavUuHFjnThxwuoQ4aWiRYvqyy+/1KOPPhrvXO7YsUNVqlTx2yUq/83tduv48eMJkihHjx5VkSJF/PqeTrL/0uo5c+bUL7/8ovvvvz/R/Rs2bFCDBg108uTJuxxZygoKCtKOHTtUsGDBeOdx9+7dKleunN//nnpjxYoVGjRokH744QerQ7ljTkn6PfnkkwoICNCYMWMUFham9evX68yZM+ratas+++wzv14kQLrRi2nevHnxBlIef/zxRBeA8AWWN5a9qUSJEjpx4kSCJMrJkyf9uuOw5N/JEW8VKFBALpdLU6ZMueUxLpeLJIqPK1iwoD755BM1adIk0f2bN2++5U2Vv7jvvvs8Gfx/Nz6UlGCZdbtYtGiRxo0bp9mzZyt79ux65plnrA4pWVavXq2RI0d6vp40aZJiYmK0e/duZc6cWT169NDAgQNtkUSpXbu2hg4d6kkYuVwuXbx4Ub169bLF63OSI0eOJHpPExcXp+vXr1sQUcq6Wc3ocrk0duzYeE2PY2NjtWLFClusQmT3pdVr1qypjz76SDNnzkx0/8cff+xZkcifFS5cWJs3b07Q0PKXX36xxdK/3sicObN+/PFHq8NIlkKFCmn9+vW3TKKsW7fulk1L/cmaNWu0ZMkS5ciRQ263W263Ww899JAGDBigTp06+X0FXFBQkJ5++mmrw/CazyRRPvroI3Xq1Em9e/dW5cqVJUlr165V37599cknn8TL6tulHP2mY8eOqX///vEeCPxNVFSU1SEgBdx///36/fffb5lE+Wf5oL/av3+/5/83bdqkbt26qXv37p7lcNesWaNBgwbp008/tSrEFHPw4EGNHz9e48eP18WLF3X27FlNnz5djRs3tjq0ZDty5IiKFSvm+Xrx4sVq3LixMmfOLOlG8touSwMPGTJENWvWVHh4uK5cuaJmzZpp9+7dyp49u6ZOnWp1ePgPSpcurZUrVya4of/uu+9Uvnx5i6JKOUOGDJF0Iyk9evToeFN6AwMDVahQIY0ePdqq8FKM3ZdW79WrlypVqqTKlSvrrbfe8iS+tm3bpiFDhmjbtm1au3atxVEmX/fu3fX666/rypUrMsZo/fr1mjp1qgYMGKCxY8daHR681LRpU7311lsqUaKEypQpE2/f1q1b1a1bN1sMaMfGxnoS09mzZ9fRo0dVokQJFSxYUDt37rQ4uuTxyyXVLenEkoibTQ9dLpdxu93G7XYn+rW/NrX8888/zciRI82XX35pzp49a4wx5tSpU6ZLly4mffr0plSpUtYGmMpOnz5thgwZYnUYSMKff/5pNmzYcMv9165d83Svt4MHHnjA/PTTTwm2//TTT6ZChQoWRJQyvv32W1O7dm0THBxsnn32WTN79mxz9epVkyZNGtt0qM+aNWu815InTx7zzTffeL7eu3evCQoKsiK0VBEdHW0iIiLM66+/bl577TUzZswYEx0dbXVY+I/mzJljMmfObD7++GMTHBxsBg4caF566SUTGBhoFixYYHV4KaZGjRq2WJXvVlavXm1CQkLMq6++atKnT286d+5sHnvsMZMhQwbz22+/WR1eilizZo0JDw9PcB9eqlQps3r1aqvDSzFfffWVKVCggOeZ45577nFUk2c7LBhw+fJlU7VqVRMQEGDq1q1r3nzzTfPmm2+aOnXqmICAAFOlShVbrIb20EMPme+//94YY8wLL7xg6tata1atWuVZndBfRUdHm2rVqhm3220ef/xx07lzZ9OpUyfz+OOPG7fbbR5++GGfPH8+0xNl+fLlXh/7yCOPpGIkKe/HH39U48aNPaW6YWFhGjNmjJo0aaIyZcqoa9eueuKJJyyOMuUZY7RgwQKNGzdOP/zwgzJlyuT3TZ1gL0FBQdq4caNKlSoVb/v27dtVoUIFv50PnSZNGr399tt65513FBIS4tmeNm1aRUZG2qJMuVatWqpUqZIGDBiglStXqkaNGjp8+LDy5MkjSVq4cKFee+017dmzx+JIgfjmz5+vjz76SL///rvi4uJUoUIFffDBB3r88cetDg3/wdatW/XZZ5/FO489evRQ2bJlrQ4tRW3atEm7d++WJBUvXlz33XeftQGlkJiYGE2ePFl16tRR7ty5dfr0acXFxSU6TcvOIiMjVaFCBb+fvnzt2rV4lQzSjd/X559/Xs2bN1evXr0UERFhcZTJM3/+fF26dEnPPPOM9u3bpyeeeEI7duxQtmzZ9O2336pWrVpWh3hHPvjgA02cOFFz585N0IswMjJSDRs2VJs2bdS7d29rArwFn0mi2FmVKlX04IMPqn///vrqq6/UrVs3FStWTGPGjFH16tWtDi/FRUVFKSIiQhMmTNCRI0fUvHlztWzZUjVr1rTFaj2TJk1S06ZNlS5dunjbr127pmnTpqlly5YWRYb/qkKFCipVqpTGjRun9OnTS5KuXr2qtm3bavv27dq4caPFEd6ZV155RdOnT1fp0qX14osvqmnTpgoNDbVVEmXp0qWqX7++8ubNq2PHjumFF17QuHHjPPs7dOigS5cued3Y25cNGDBAuXLlUtu2beNtj4iI0KlTp9SjRw+LIgNu7fDhw5ozZ44OHjyoa9euxds3ePBgi6IC/k9wcLC2b99ui34Zt5JU/7Nz585p+fLlfp9EuR27JIoS89dffyk0NNSvezEVL15cAwYMuOVU8++++07vvfeeJznmK3w+iTJr1iz17t3br5feypIli9avX6/ixYsrJiZG6dOn19y5c1WvXj2rQ0sxV69e1axZszR27Fj9+uuvqlevnpo1a6YXXnjBNg9tN9l96UYnWb9+vZ588knFxcXp3nvvlXTjw9blcunHH3/Ugw8+aHGEd+7y5cuaPn26IiIitG7dOtWpU0c//fSTNm/enGDOsL/atm2bFi5cqNy5c+u5557zLBsvSV999ZUefPBBW4yaFipUSFOmTFHVqlXjbV+3bp2ef/75eH1+/M1/ufn766+/Ujma1GeM0e+//66oqCi5XC6FhYV5ml3byeLFi9WwYUMVLlxYO3fuVJkyZRQVFSVjjCpUqKAlS5ZYHWKynD9/XgsXLox3Hh999FHb9Ox76623vDrO35NhNWvWVOfOndWoUSOrQ0k1bdq08eo4u/QQS4ydkyh24K+rK/lEY9kxY8ZowYIFSps2rTp37qxKlSppyZIl6tq1q3bu3KkXX3zR6hCT5cKFC8qSJYukG2X2QUFBKl68uLVBpbB8+fIpPDxcLVq00IwZMxQaGipJeuGFFyyOLOWZf63qctPhw4c9TS3hHx588EHt379f33zzjXbs2CFjjJo2bapmzZopQ4YMVoeXLEFBQWrVqpVatWql3bt3KyIiQr/99puqVaumBg0a6Nlnn/X7FXrCw8NvmaB95ZVX7nI0qef48eOeaUr/lCNHDh07dsyCiFLO0KFDPf9/5swZ9evXT3Xq1InX6Hn+/Pl6//33LYow5SxdulTt2rXTgQMH4q0GVrhwYUVERNiqMvWdd95R165d1bdvX4WEhGjmzJnKmTOnmjdvrrp161odXrJ888036tixY4JljDNnzqzRo0eradOmFkWWcjZu3JhkYs8Oib8OHTqoa9euOnz4sO6///4En/v/nlrgj+ycHHGC/3KfNmvWrFSMJPVkypRJJ0+evGUS5fjx4z6ZoLa8EuWzzz7Tu+++q3Llymn79u2SpPfee0+DBw/WG2+8oddff13Zs2e3MsRkc7vdWrJkibJmzSpJqlq1qqZPn6577rkn3nH+fLEODQ1VuXLl1KJFCzVt2tTzy26n6QPly5eXy+VSZGSkSpcurTRp/i8HGRsbq/3796tu3bqaPn26hVECtxYXF6effvpJ48aN0y+//KKrV69aHRK8UKxYMfXq1UstWrSIt/3rr79Wr169tG/fPosiS1mNGzdWzZo11bFjx3jbR44cqUWLFmn27NnWBJYC9uzZo3vvvVeVKlVS586dVbJkSRljtG3bNg0fPly//fabtmzZorCwMKtDTREhISHavHmzihQpotDQUK1atUqlS5dWZGSknnrqKb9d0W/jxo2qVKmSmjdvrjfffDPeeRw6dKimTZumDRs2eCob4dv+Wb14081VCF0uF5ULNuHPlSjeVhJJ/pswa9q0qWJiYm65pHrjxo0VEBDgc89XlidRSpUqpe7du6tt27ZatmyZatWqpVq1amnGjBme6g1/53a7k1wa1t8v1leuXNHMmTM1btw4rV27VvXq1fMkVDZv3myLJEqfPn08/+3atatnmTHp/5ZubNy4sQIDA60KMcU4qe/L3r17NXToUG3fvl0ul0ulSpVS586dVaRIEatDS1UnT550XAM9f/XJJ59o4MCBGjhwoKdx3OLFi/X222+ra9eueueddyyOMGVkzJhRmzdvVtGiReNt3717t8qXL6+LFy9aFFnydezYUdu3b9fixYsT7DPG6LHHHlN4eLhGjBhhQXQpL3fu3FqyZInCw8NVunRpDRgwQA0bNlRkZKSqVavmt+eyTZs2unjxor777rtE9z/77LPKlCmT3zewDAsL04YNG5QtWzarQ0lVBw4cuO1+O/dKsRP6vvi3bdu2qVKlSipduvRtl1QvXbq0xZHGZ3kSJTg4WDt27FCBAgUkSenSpdOKFStUqVIlK8NKUUldpCXp7Nmztpi7L914KB0/frwmTpyoI0eO6IUXXlDr1q1Vq1YtWzSWnThxop5//vkECQY7cUrfl/nz56thw4a67777VK1aNRlj9OuvvyoyMlJz585V7dq1rQ4RkDFGPXv21PDhwz0NOtOnT68ePXrogw8+sDi6lFOwYEF17NhR3bt3j7d94MCBGjlypFefpb6qTJkyGjBggJ588slE98+dO1fvvPOO/vjjj7scWepo1KiRGjRooJdffllvv/22vv/+e7Vu3VqzZs1SaGioFi1aZHWId6R48eL6/PPP9dhjjyW6f9GiRerQoYPPNUD8r9xut44fP277RPuKFStUtWrVeJXF0o2Ve3799VdbTbGzM7v3fbly5YoWLFigmjVrxltxUbrRMmLZsmWqU6eOXz+XrF27Vu3atfMMaEo37n1KliypsWPHJugJ5wssT6L8+0IdEhKiyMhI25S03s758+c1efJkjRs3Tps3b7bNg+lNcXFxmj9/vsaNG6e5c+cqJCREp0+ftjqsZDt06JBcLpdnOtb69es1ZcoUhYeH26YPg9vt1okTJ5QjR4542yMjI1WzZk1bNHiUbkzRqlOnjj7++ON423v27KkFCxb47eo8sKeLFy9q+/btCgoKUrFixfz6hikxEyZMULt27VS3bl1PT5S1a9dq3rx5Gjt2rFq3bm1tgMmQKVMmbdmyRYUKFUp0//79+1WuXDn9/fffdzewVLJv3z5dvHhR5cqVU3R0tLp166ZVq1apaNGiGjJkiN+O8GfMmFHbtm3zDPz928GDB1WqVCldunTpLkeWspySRHHKgBH827BhwzRnzpxEKxkl6bHHHlOjRo0STIX1R5s3b463RLUvFxj4RBKlX79+nqkRPXr0UPfu3RP0QenUqZMV4aWKJUuWKCIiQrNmzVLBggXVuHFjNW7cWOXLl7c6tFRz6tQpff311153fPdlDz/8sF555RW9+OKLOn78uIoXL64yZcpo165d6tSpk1+PDDut70v69Om1detWFStWLN72Xbt2qVy5cj7XCRwJ3ars/Ny5c6pQoYJt+oX804ULF7RkyRKVKFFCpUqVsjqcFLVu3ToNHz5c27dvlzFG4eHh6tSpk99Xpyb1UHrixAnlzZuXhzYf55Tz+O9efrfiz738pFsPGO3atUsVK1ZM0DwYsMKDDz6o999//5aVjD/++KP69u2r9evX3+XInM3y1XkKFCigMWPGeL7OnTu3vv7663jHuFwuv0+iHD58WBMmTFBERIQuXbqkJk2a6Pr165o5c6Yt+oUkJUeOHLZIoEjSH3/84Vn6dvr06SpbtqxWr16tBQsW6NVXX/XrJMrNZf42b96sOnXq3LLvi13kyJFDmzdvTpBE2bx5s+1H4OwiKioq0QeWq1ev6siRIxZElPKaNGmi6tWrq2PHjrp8+bIqVqzoWS522rRptnpPVqpUSZMnT7Y6jFSxbds2HT9+PNF9dqjS/Cc7Jzfnz59/y5X4zp07d3eDSUWPPvpoor387NB49WYPDZfLpdatW8er6ouNjdWWLVt8cvoAnGn37t23bVZdrlw57d69+y5GBMkHkij+2qH9v6hfv75WrVqlJ554QiNGjFDdunUVEBCg0aNHWx1aiilcuLBXy+Ht3bv3LkWUeq5fv+75wF20aJEaNmwoSSpZsqTfLzfaq1cvxcbGqmDBgqpTp06iy6raycsvv6xXXnlF+/btU9WqVeVyubRq1Sp98skn6tq1q9XhJZudH2TmzJnj+f9/P9TExsZq8eLFt5w64W9WrFih9957T5L0/fffyxijc+fOaeLEierXr5+tkig3e2rt27dPQ4cOVc6cOTVv3jzlz5/f55rK/VfePJTahZ2Tm61atbrtfrucx3Xr1iWo0LCLm58XxhiFhIQoKCjIsy8wMFCVK1fWyy+/bFV4QDwxMTE6derULacRnjp1SjExMXc5KlieRHGCBQsWqFOnTnrttdcSjHjbRZcuXW65LyoqSl9++aVtllMtXbq0Ro8erQYNGmjhwoX68MMPJUlHjx61RSf7gIAAvfrqq54lx+3s/fffV0hIiAYNGuRZ4SRv3rzq3bu331e/SfZ+kLlZNeVyuRI81KRNm1aFChXSoEGDLIgs5Z0/f95TVj9v3jw1btxYwcHBatCgQYImrP5s+fLlqlevnqpVq6YVK1aoX79+ypkzp7Zs2aKxY8dqxowZVod4x/bv3291CHeF3ZObcXFxVodw1xQoUMC2FZk3G4wWKlRI3bp1U4YMGSyOCLi10qVLa9GiRbr//vsT3b9w4UK/H2TwRyRR7oKVK1cqIiJCFStWVMmSJfXiiy+qadOmVoeVojp37pxg219//aUPP/xQX3zxhSpVqqRPPvnEgshS3ieffKKnn35aAwcOVKtWrTwldnPmzPFM8/F3ZcuW1b59+1S4cGGrQ0lVLpdLb775pt58801PQ8d/dz73R3Z/kJH+72GmcOHC2rBhQ4I+WnaSP39+rVmzRlmzZtW8efM0bdo0STdWdUufPr3F0aWcnj17ql+/fnrrrbfivQ9r1qypYcOGWRhZ8vlrI9X/yknJTac7deqU31eq9OrVK97Xy5cv16VLl1SlShWFhoZaFBUQX9u2bfXWW2+pdOnSeuKJJ+Ltmzt3rvr166fBgwdbFJ2DGdw1ly5dMuPGjTPVqlUzadOmNW632wwdOtRcuHDB6tBSVHR0tOnXr5/JnDmzuffee81PP/1kdUgpLiYmxvz111/xtu3fv9+cOHHCoohS1vz58819991n5s6da44ePWrOnz8f749d7Nu3z+zatSvB9l27dpn9+/ff/YBSiMvlMi6Xy7jdbs//3/wTGBhoihcvbubOnWt1mPDSqFGjTJo0aUyWLFlMuXLlTGxsrDHGmOHDh5saNWpYHF3KyZAhg9m3b58xxpiMGTOavXv3GmNuXFvTpUtnZWj4jwoVKmROnTpldRi4QzVq1DBnz55NsD0uLs789NNP5umnnzaBgYF3P7AU8umnn5oPPvjA83VcXJypU6eO53MyV65c5o8//rAwQiC+5s2bG5fLZUqVKmUaNWpknn76aVOyZEnjdrvN888/b3V4KWbFihWmefPmpnLlyubw4cPGGGMmTZpkVq5caXFkCbmtTuI4SXBwsNq2batVq1Zp69at6tq1qz7++GPlzJnT01fDn8XGxmr06NEKCwvT2LFjNWLECG3atEn169e3OrQUFxAQkGCUolChQrYpfa1bt64iIyPVsGFD3XPPPQoNDVVoaKiyZMliq9GZ1q1b69dff02wfd26dX69nGpcXJzi4uJUoEABnTx50vN1XFycrl69qp07dyYYzfBXnTp10vDhwxNsHzly5G2nGfqTDh06aM2aNYqIiNDq1avldt/46A4LC1O/fv0sji7lZMmSJdG+Ups2bVK+fPksiAj/1bp16/TLL79o//79nuqwSZMmqXDhwsqZM6deeeUV20zttbOlS5cqS5Ysnq/37dun//3vfypQoICaN2+u4OBgT0WcP5o6dWq8RR1mzJihFStWaOXKlTp9+rQqVqyoPn36WBghEN8333yjadOmqXjx4tq1a5d27NihEiVKaOrUqZo6darV4aWImTNnqk6dOgoKCtKmTZs8nxV///23PvroI4ujS8jyJY6dLjY2VnPnzlVERES8Enx/M336dP3vf//T+fPn9e677+q1115TYGCg1WGlmAoVKmjx4sUKDQ31LAN8Kxs3bryLkaWO5cuX33b/I488cpciSV2ZMmXSxo0bVbRo0Xjb9+zZo4oVK9pqpQW7ypcvn+bMmZNgrvDGjRvVsGFDHT582KLIUt61a9e0f/9+FSlSJN7y43bx9ttva82aNfruu+9UvHhxbdy4USdOnFDLli3VsmXLBKX38D1169ZVzZo11aNHD0nS1q1bVaFCBbVu3VqlSpXSwIED1b59e/Xu3dvaQJGkK1euaMaMGRo7dqzWrl2r2rVr65dfftHmzZtVpkwZq8NLltDQUP3666+eJeLbtGmjmJgYz+qga9eu1XPPPadDhw5ZGSZwRz7++GO9+uqr8RKh/qB8+fJ688031bJlS4WEhCgyMlJhYWHavHmz6tate8vV7aziU3dhN7vy7927V8OGDbNVV/5bCQgIUKNGjTzziP3V888/r6CgIL3wwgs6cOCAevbsmehx/jpn76mnnvKsyOPv58obdkmSJMXlcnl6ofzT+fPn/Xbpxn/q1KmTihYtmqBJ7siRI7Vnzx4NHTrUmsBS0JkzZxJdbjRTpky2WTY2Ojpab7zxhiZOnChJ2rVrl8LCwtSpUyflzZv3ltdbf9O/f3+1bt1a+fLlkzFG4eHhio2NVbNmzfS///3P6vDghcjIyHjVUdOmTVOlSpU0ZswYSTf6+/Tq1Yskio/r0KGDpk2bphIlSqhFixaaOXOmsmXLprRp03oq4fzZP1dZlKQ1a9bE6+2XN29e23x+wHk++ugjNWnSxO+SKDt37lT16tUTbM+UKZNPDmr6TBLl3135+/fvb5uu/E5QvXr1JJcw9udl//45Auqk0dDo6GgdPHhQ165di7e9XLlyFkWUsh5++GENGDBAU6dOVUBAgKQb1WEDBgzQQw89ZHF0yTdz5sxEK9yqVq2qjz/+2BZJlKJFi2revHnq2LFjvO2//PKLwsLCLIoqZb3zzjuKjIzUsmXLVLduXc/2xx57TL169bJNEiVt2rSaPHmyPvzwQ23cuFFxcXEqX768bVe1s6OzZ88qV65cnq+XL18e73f2gQcesMXo/qFDh+RyuXTPPfdIktavX68pU6YoPDxcr7zyisXRJd9XX32lHj16qGfPnrZotv5vRYsW1YoVKxQWFqaDBw9q165d8QaPDh8+bIvVFuFM/jrJJE+ePNqzZ0+ChQ9WrVrlk/dzPpNEsXNXfidYtmyZ1SHcNcYY/f7774qKipLL5VLhwoWTnOLjb06dOqU2bdrol19+SXS/Hao0JOnTTz9V9erVVaJECT388MOSbqymdeHCBS1ZssTi6JLPCVUab731ljp27KhTp06pVq1akqTFixdr0KBBtkgSSdLs2bP17bffqnLlyvGuM+Hh4bdNXPursLAwhYWFKTY2Vlu3btXZs2dt04vpxIkT6tatmxYvXqyTJ08muNn192trrly5tH//fuXPn1/Xrl3Txo0b4/WW+Pvvv5U2bVoLI0wZzZo10yuvvKIXX3xRx48fV+3atVW6dGl98803On78uD744AOrQ0yWSZMmafz48cqTJ48aNGigF198MV4yzN+99tpr6tixo1auXKm1a9eqSpUq8XqkLFmyROXLl7cwQsB52rdvr86dOysiIkIul0tHjx7VmjVr1K1bN5+8pvpMEmXr1q2aMmVKgu05cuTQmTNnLIgISGjp0qVq166dDhw44Ln5vZlIiYiISLQMzR916dJFZ8+e1dq1a1WzZk19//33OnHihPr162er5SnDw8O1ZcsWjRw5UpGRkQoKClLLli3VsWNHZc2a1erwks0JVRpt27bV1atX1b9/f3344YeSbjR5/uKLL9SyZUuLo0sZp06dSrRp9aVLl2yVvO3SpYvKli2rdu3aKTY2Vo888oh+/fVXBQcH68cff1SNGjWsDjHZWrdurYMHD+r9999Xnjx5bHX+pBs9UXr27KlPPvlEs2fPVnBwsCdBLUlbtmxRkSJFLIwwZfzxxx968MEHJd3oCVemTBmtXr1aCxYs0KuvvuqTN/z/RbNmzdSsWTNFRUVp/Pjxev311xUdHa24uDht27YtXsLBH7Vv315p0qTRjz/+qOrVqyeoMD569Kjatm1rUXSAM7399ts6f/68atasqStXrqh69epKly6dunXrluA+1idYuDJQPPny5TOrV682xsRf2nDWrFkmLCzMytAAY4wxu3fvNsHBwaZmzZpm9uzZZseOHWb79u1m5syZ5pFHHjEZMmTw/N76u9y5c5t169YZY4wJCQkxO3fuNMYY88MPP5hq1apZGRr+g3HjxpmgoCDzwQcfmGXLlplly5aZ999/3wQHB5uvvvrK6vBS3MmTJ83ff/9tdRgprnr16mb48OHGmBufjzeXAX799ddNnTp1rAwtReXLl89s2LDBGGPM999/b/LkyWN27txp3nvvPVO1alWLo0sZGTNmNJs2bbI6jFRz8uRJ89BDDxmXy2VCQkLMrFmz4u2vVauWeffddy2KLuVkyJDB7N+/3xhjzJNPPmk+/vhjY4wxBw4cMOnTp7cwstQRFxdnfvnlF/Pcc8+ZdOnSmXz58pk33njD6rAAJOKfz9H+6NKlS2bDhg1m3bp1Pn1P5zOVKM2aNVOPHj303XffyeVyKS4uTqtXr1a3bt1sM5oI/zZ06FBVrlxZixcvjre9ZMmSevrpp/XYY49pyJAhGjFihEURppxLly55Rr6zZs2qU6dOqXjx4ipbtqwtVh/6p3PnzmncuHHavn27XC6XwsPD1bZt20SnwfgbJ1Rp/FOOHDmsDiFVDBgwQHXr1tW2bdsUExOjYcOG6c8//9SaNWuSXEnLn5w+fVq5c+eWJP38889q0qSJihcvrnbt2iW6jLU/yp8/v9/OV/dGjhw5tHLlSp0/f14ZM2b09Jq66bvvvlPGjBktii7llC5dWqNHj1aDBg20cOFCz/X16NGjtuyl4XK5VLduXdWtW1d//fWXZ7oPAKS04OBgVaxY0eowkuQzLbb79++vAgUKKF++fLp48aLCw8NVvXp1Va1ala788AnLli1Tly5dEt3ncrnUpUsXLV269O4GlUpKlCihnTt3SpLuu+8+ffnllzpy5IhGjx6tPHnyWBxdyvntt99UpEgRDRkyRH/99ZdOnz6twYMHq0iRIrZJFr322ms6fPiwTpw4oQsXLmjfvn1+n0CpUKGCzp49K+nGkngVKlS45R87qFq1qlavXq3o6GgVKVJECxYsUK5cubRmzZoESzv7s1y5cmnbtm2KjY3VvHnz9Nhjj0m60eD63w/j/mro0KHq2bOnoqKirA4lVWXOnDnRc5Y1a1YFBgZaEFHK+uSTT/Tll1+qRo0aeuGFF3TvvfdKkubMmeOZ5uPvLly4oLi4uATbs2TJorZt2yoyMtKCqAAk5eGHH1ZQUJDVYfxnV65c0cCBA1W/fn1VrFjR5+/nXMbHhkT27dtHV36b2rx5s+677z6rw7hjmTJl0pYtWxJ0jb5p//79KleuXKJL5vqbyZMn69q1a2rTpo02bdqkOnXq6MyZMwoMDNSECRPUtGlTq0NMEQ8//LCKFi2qMWPGKE2aG4V5MTExeumll7Rv3z6tWLHC4giRmD59+qh79+4KDg5W7969b9tXwkmrafm73r17a+jQocqTJ4+io6O1a9cupUuXThERERozZozWrFljdYjJFhoaqujoaMXExCg4ODhBk9W//vrLosjwX8XGxurChQvxmh5HRUUpODg40R5G/uT7779Xjx49tHnzZgUHB8fbFx0drfLly+uzzz7Tk08+aVGEgDPt3btX48eP1969ezVs2DDlzJlT8+bNU/78+VW6dGmrw0uWZs2aaeHChXr22WeVK1euBPd2vnY/5zNJlL59+6pbt24JLtaXL1/WwIED/b5Jl1OdP39ekydP1tixYxUZGenXKw+43W4dP378ljdHJ06cUN68ef36Nd5KdHS0duzYoQIFCih79uxWh5NigoKCtGnTJpUsWTLe9m3btqlixYqKjo62KLI7V6FCBS1evFihoaFJrhrlz9U2/p6U/S/Onz+vhQsXelYECwsL06OPPqpMmTJZHVqKmzFjhg4dOqTnnnvOs3zsxIkTlSVLFj311FMWR5d8EydOvO3+Vq1a3aVIgFt7/PHH1aRJE7300kuJ7o+IiNC3336r+fPn3+XIAOdavny56tWrp2rVqmnFihXavn27wsLC9Omnn2r9+vWaMWOG1SEmS+bMmfXzzz+rWrVqVofiFZ9JogQEBOjYsWMJHlDPnDmjnDlz2vLB1M6WLFmiiIgIzZo1SwULFlTjxo3VuHFjv14yzu12a8mSJbdcteX06dOqXbu2X/+uRkdHq3v37po9e7auX7+uxx57TMOHD7dV4uSfcuXKpa+//lqPP/54vO3z589Xy5YtdeLECYsiu3NOqdJwu90qX768XnrpJTVr1swWPWwS880336hjx466cOFCvO2ZM2fW6NGjbVMVBviTwoUL3/baum/fvrsYTcrLmzevVqxYoaJFiya6f8+ePapevbqOHj16lyNLXRcuXNCSJUtUokQJlSpVyupwgHiqVKmi5557Tm+99ZZCQkIUGRmpsLAwbdiwQY0aNdKRI0esDjFZwsPDNW3aNJUrV87qULziM41ljTGJfiBFRkbaYqlRJzh8+LAmTJigiIgIXbp0SU2aNNH169c1c+ZMv18O76ZHH3000aaALpfrlr/D/qRXr16aMGGCmjdvrvTp02vq1Kl67bXX9N1331kdWqpo2rSp2rVrp88++0xVq1aVy+XSqlWr1L17d73wwgtWh3dHevXq5anS6N27t9XhpJrVq1crIiJCPXv2VNeuXfXMM8+oXbt2qlmzptWhpZiNGzeqTZs2at68ud58802VLFlSxhht27ZNQ4cO1YsvvqiSJUt6+jH4q759+ya6PXPmzCpRooQef/xxud0+08It2WJjYzV79ux4zawbNmxom74vTvDv/mjXr1/Xpk2bNG/ePHXv3t2aoFLQ2bNnFRMTc8v9169f9/Sl8mdNmjRR9erV1bFjR12+fFkVK1ZUVFSUjDGaNm2aGjdubHWIgMfWrVs1ZcqUBNtz5MihM2fOWBBRyho0aJB69Oih0aNHq2DBglaHkyTLkyihoaFyuVxyuVwqXrx4vIfQ2NhYXbx4Ua+++qqFEcIb9evX16pVq/TEE09oxIgRqlu3rgICAjR69GirQ0sx+/fvtzqEVDdr1iyNGzdOzz//vCSpRYsWqlatmmJjY215g//ZZ5/J5XKpZcuWiomJkTFGgYGBeu211/Txxx9bHd4dq1Chgu2rNKpUqaIqVapo+PDhmj59usaPH6/HHntMhQoVUtu2bdWqVSvPdBB/NWLECDVq1EgTJkyIt71ChQqaNGmSoqOjNWzYMEVERFgTYAr5/vvvE91+7tw5HTlyRKVLl9b8+fP9vs+EdGMEv379+jpy5IhKlCghY4x27dql/Pnz66efflKRIkWsDhFe6Ny5c6LbR40apd9+++0uR5PyChUqpN9++y3BVNebfvvtN794yEnKihUr9N5770m6cR0yxujcuXOaOHGi+vXrRxIFPiVLliw6duyYChcuHG/7pk2blC9fPouiSjkVK1bUlStXFBYW5hc9wyyfzjNx4kQZY9S2bVsNHTo03s1+YGCgChUqpCpVqlgYIbyRJk0aderUSa+99lq8ZsBp06ZVZGSkbSpR7C4wMFD79++PdzEOCgry3OTbVXR0tPbu3StjjIoWLZqgN5O/WbNmjSIiIjR9+nRdv37dllUaibnZcG3SpEk6duyYateurZ9//tnqsO5Y8eLF9fnnn3tWqfm3RYsWqUOHDtq1a9ddjuzuOXbsmJo1a6YiRYpo7NixVoeTbPXr15cxRpMnT/ZU2Z45c0YtWrSQ2+3WTz/9ZHGESI59+/bpvvvuSzD9zt+89957+uabb7R+/XrlypUr3r7jx4+rUqVKatGihfr3729RhCnjn/c3LVu2VN68efXxxx/r4MGDCg8P18WLF60OEfB4++23tWbNGn333XcqXry4Nm7cqBMnTqhly5Zq2bKlX0/RlqTHHntMBw8eVLt27RJtLOtrPcMsT6LctHz5clWtWjVB1gn+4Z8PbSVLltSLL76opk2bKm/evCRR/EhAQICOHz+uHDlyeLaFhIRoy5YtCTLf/qxt27ZeHefvI/yXL1/2VGmsXLnSVlUat3Lx4kVNnjxZ7777rs6dO+fXPYoyZsyobdu2qUCBAonuP3jwoEqVKqVLly7d5cjurtWrV+vFF1/0+z4TkpQhQwatXbtWZcuWjbc9MjJS1apV46HNz3366af6/PPP/X4J67///ltVqlTRwYMH1aJFC5UoUUIul0vbt2/X5MmTlT9/fq1du1YhISFWh5osxYsXV79+/dSgQQMVLlxY06ZNU61atRQZGalHH31Up0+ftjpEwOP69etq3bq1pk2bJmOM0qRJo9jYWDVr1kwTJkzw+4rx4OBgrVmzxm+mKFs+neemRx55xPP/ly9f1vXr1+Ptt+MqBHZys7R+2LBhmjZtmiIiIvTWW28pLi5OCxcuVP78+f3+w9YJjDFq3bq10qVL59l25coVvfrqq8qQIYNn26xZs6wIL8VMmDBBBQsWVPny5RPtcWMXQUFBatWqlVq1auWp0vjyyy/Vu3dvv6/S+Lfly5crIiJCM2fOVEBAgJo0aaJ27dpZHVayREdHK3369Lfcny5dOl25cuUuRmSNfPny6eTJk1aHkSLSpUunv//+O8H2ixcvKjAw0IKIcCf+vfKZMUbHjx/XqVOn9Pnnn1sYWcoICQnR6tWr9c477+jbb7/19D8JDQ1VixYt9NFHH9ninq5Lly5q3ry5MmbMqIIFC6pGjRqSbkzz+XeiE7Ba2rRpNXnyZPXt21ebNm1SXFycypcvH28GgD8rWbKkLl++bHUYXvOZSpTo6Gi9/fbbmj59eqLNcfx5NNGpdu7cqXHjxunrr7/WuXPnVLt2bc2ZM8fqsHAbbdq08eq48ePHp3IkqatDhw6aNm2aChQooLZt26pFixaOaGBtpyoNSTp06JAmTJigCRMmaP/+/apataratWunJk2axEv6+Su3262JEyfesqfNuXPn1KZNG78/j0n54Ycf9N577+mPP/6wOpRka9mypTZu3Khx48bpwQcflCStW7dOL7/8su6///4E/W/gm/698pnb7VaOHDlUo0aNW/YR8VfGGJ0+fVrGGOXIkcPvG+j/22+//aZDhw6pdu3aypgxoyTpp59+UpYsWfxmqVXADhYsWKA+ffqof//+Klu2bILZKb5WUOEzSZTXX39dS5cuVd++fdWyZUuNGjVKR44c0ZdffqmPP/5YzZs3tzpE3KHY2FjNnTtXERERJFHgM65evapZs2YpIiJCv/76qxo0aKB27drp8ccft91N4q2qNCpXrmx1aHesdu3aWrp0qXLkyKGWLVuqbdu2KlGihNVhpShvVqRxuVx+n0S5Vf+I8+fPa8OGDeratateeuklTwNIf3bu3Dm1atVKc+fO9dwgxsTEqGHDhpowYYItm0DDv23ZskW7du3yLABh5wqN2NhYbd26VQULFlRoaKjV4QDxGGM0Y8YMLV26VCdPnlRcXFy8/f5eJX7znuff9+A3Vz/1tXsdn0miFChQQJMmTVKNGjWUKVMmbdy4UUWLFtXXX3+tqVOn2qrs3ImMMTp16pQtVleoVauWZs2apSxZssTbfuHCBTVq1EhLliyxJjDcsQMHDmjChAmaNGmSrl+/rm3btnlGpPyV3as0GjZsqHbt2umJJ57w+3nATud2u2+ZuHS5XGrfvr2GDh1qq55pu3fv1vbt2yVJ4eHhKlq0qMUR4b8ICAjQsWPHEtzTnDlzRjlz5vS5m/07sX79erVr107btm3zTHt1uVwqXbq0xo0bpwceeMDiCJOvS5cuKlu2rNq1a6fY2Fg98sgj+vXXXxUcHKwff/zRM70H8AWdOnXSV199pZo1aybaeNXfq8SXL19+2/3/bP3hC3ymJ8pff/3laVyZKVMmzzJGDz30kF577TUrQ4MXgoODdeDAAU9D0rp162r8+PHKkyePJOnkyZPKmzevLW4sli1bpmvXriXYfuXKFa1cudKCiJBcN5dZN8YkyOz7IydUaVDVZh9Lly5NdHumTJlUrFgxv09oJqZYsWKexIndKt+c4Fbjj1evXrVFb5tt27bp0UcfValSpfTNN9+oVKlSMsZo+/btGjJkiB599FGtXbvW7xcNmDFjhlq0aCFJmjt3rvbv368dO3Zo0qRJeu+997R69WqLIwT+zzfffKNZs2apfv36VoeSKnwtSZIUn0mihIWFKSoqSgULFlR4eLimT5+uBx98UHPnzk0w4g/fc+XKlXg3FatXr07QHMhHip7u2JYtWzz/v23bNh0/ftzzdWxsrObNm2eLddqd4p/TeVatWqUnnnhCI0eOVN26db2aRuHLgoKCNHPmTKo04Bf87cYpucaNG6chQ4Zo9+7dkm4kVLp06aKXXnrJ4siQlOHDh0u6kfgaO3ZsvARfbGysVqxYYYueKL169VLt2rU1c+bMeEm+8uXL64UXXtAzzzyj3r17a/r06RZGmXynT59W7ty5JUk///yznnvuORUvXlzt2rXznGvAV2TOnFlhYWFWh5GitmzZojJlysjtdsd7zkpMuXLl7lJU3vGZJEqbNm0UGRmpRx55RO+8844aNGigESNGKCYmRoMHD7Y6PKQAfx9tu++++zwVC7Vq1UqwPygoSCNGjLAgMvxX/2ws26ZNG02bNk3ZsmWzOqwUQ5UG4Jvef/99DRkyRG+88YaqVKkiSVqzZo3efPNNRUVFqV+/fhZHiNsZMmSIpBuDQqNHj46XpA4MDFShQoU0evRoq8JLMcuWLdMvv/yS6H2by+XSu+++a4vR8Fy5cmnbtm3KkyeP5s2b51lZKTo6mgEI+JzevXurT58+ioiIUFBQkNXhpIj77rtPx48fV86cOT3PWYkNutMT5T84ePCgfvvtNxUpUsRv1ot2Mrfb7XkTSDeWx4uMjPRkTE+cOOH303kOHDggY4zCwsK0fv16z9Ql6cbNU86cOfnQ9RNut1sFChRIsEzlv/l7ky4AviV79uwaMWKEXnjhhXjbp06dqjfeeEOnT5+2KDL8FzVr1tSsWbNs23w0ffr02r17t/Lnz5/o/kOHDqlYsWJ+v8R67969NXToUOXJk0fR0dHatWuX0qVLp4iICI0ZM0Zr1qyxOkTAIzo6Ws8884xWr16tQoUKJegTtnHjRosiu3MHDhxQgQIF5HK5dODAgdseW7BgwbsUlXd8phLl3woUKKACBQpYHQa8dLNC41Zf28HNN68demY4XcuWLW33+wnA98XGxqpixYoJtt9///2KiYmxICLciVv18bGLQoUKaf369bdMoqxbt87nHmjuRO/evVWmTBkdOnRIzz33nNKlSyfpRuPgnj17WhwdEF/r1q31+++/q0WLFok2lvVHBQsW9DTq9rdrik9UosTFxWnChAmaNWuWoqKi5HK5VLhwYT377LN68cUXbfFLYndut1uZM2f2nKtz584pU6ZMnt4SxhhduHDBrytR/mnnzp0aMWKEtm/fLpfLpZIlS6pjx462mAsNwLeEhYVpw4YNCaacnTt3ThUqVNC+ffssigz/1RtvvKG0adMmmKbcrVs3Xb58WaNGjbIoMvxXhw8f1pw5c3Tw4MEEzeb9fRp6r169NGHCBP30008qU6ZMvH1bt27Vk08+qVatWqlPnz4WRQg4T4YMGTR//nw99NBDVoeSov49m8FfWF6JYoxRw4YN9fPPP+vee+9V2bJlPR3AW7durVmzZmn27NlWh4kk+PuyWv/FjBkz9MILL6hixYqeOe1r165V2bJlNWXKFD333HMWRwjATqKiohJNQF+9elVHjhyxICIkx7hx47RgwQJVrlxZ0o3Pj0OHDqlly5Z66623PMf5+4O4nS1evFgNGzZU4cKFtXPnTpUpU0ZRUVEyxqhChQpWh5ds77zzjhYtWqT77rtPtWvXVqlSpSTdaKq/aNEiPfjgg3rnnXcsjjJlLF++XJ999plnUKxUqVLq3r27Hn74YatDA+LJnz+/MmXKZHUY+P8sr0QZP368OnfurB9++EE1a9aMt2/JkiVq1KiRRo4cqZYtW1oUIRBfWFiYWrRoob59+8bb3qtXL3399deMCgNIETcbBDdq1EgTJ05U5syZPftiY2O1ePFiLVy4UDt37rQqxBR14sQJdevWTYsXL9bJkycTNJezQyXjv+9zbsXlcmnJkiWpHA3u1IMPPqi6deuqb9++nh5wOXPmVPPmzVW3bl299tprVoeYbNeuXdOQIUM0depU7dq1S5JUvHhxPf/882revLl69eqliIgIi6NMnm+++UZt2rTRM888o2rVqskYo19//VXff/+9JkyYoGbNmlkdIuDx008/acSIERo9erQKFSpkdTgpxu12J7jHSUzDhg3vUkTesTyJ8vjjj6tWrVq3nHv40Ucfafny5Zo/f/5djgwp6dixY+rfv79GjhxpdSjJFhwcrC1btqho0aLxtu/evVv33nuvoqOjLYoMgJ3cnA6ZWLf6tGnTqlChQho0aJCeeOIJK8JLcfXq1dPBgwfVsWNH5cmTJ8FU3qeeesqiyID4QkJCtHnzZhUpUkShoaFatWqVSpcurcjISD311FOKioqyOsRUFRkZqQoVKvh9YrNUqVJ65ZVX9Oabb8bbPnjwYI0ZM0bbt2+3KDIgodDQUEVHRysmJkbBwcEJGsv+9ddfFkWWPDfvdW7HF1fnsXw6z5YtW/Tpp5/ecn+9evVYq91PbNu2TUuXLlXatGnVpEkTZcmSRadPn1b//v01evRoFS5c2OoQU0SNGjW0cuXKBEmUVatWUf4JIMXcbGJduHBhbdiwQdmzZ7c4otS1atUqrVy5Uvfdd5/VoQC3lSFDBl29elWSlDdvXu3du1elS5eWJFZY8iP79u3Tk08+mWB7w4YN9e6771oQEXBrQ4cOtTqEVENPlDvw119/KVeuXLfcnytXLp09e/YuRoQ78eOPP6px48a6fv26JOnTTz/VmDFj1KRJE5UpU0bfffedbUZLGzZsqB49euj333+PN6f9u+++U58+fTwl+DePBYDk2L9/v9Uh3BX58+dPUHFjRxs2bNB3332XaENSllX3D5UrV9bq1asVHh6uBg0aqGvXrtq6datmzZrluS+A78ufP78WL16cYFBs8eLFt1yZCLBKq1atrA4hVfjrAjKWT+cJCAjQ8ePHlSNHjkT3nzhxQnnz5vW5Eh7EV6VKFT344IPq37+/vvrqK3Xr1k3FihXTmDFjVL16davDS1HelJ1Jvll6BsD/dOrUSUWLFlWnTp3ibR85cqT27Nljm9GpBQsWaNCgQfryyy9tNd/7n6ZNm6aWLVvq8ccf18KFC/X4449r9+7dOn78uJ5++mlHNWn3Z/v27dPFixdVrlw5RUdHq1u3blq1apWKFi2qIUOG+N1Snf+VXabzfPHFF+rSpYvatm2rqlWryuVyadWqVZowYYKGDRum9u3bWx0iHO7ChQueZrIXLly47bH+2nTWX1fnsTyJ4na7Va9ePc/a7P929epVzZs3z+8v1HaXJUsWrV+/XsWLF1dMTIzSp0+vuXPnql69elaHBgB+LV++fJozZ47uv//+eNs3btyohg0b6vDhwxZFlrLsOt/7n8qVK6f27dvr9ddf9zQkLVy4sNq3b688efKwZCx8wjPPPHPb/efOndPy5cttcW/+/fffa9CgQZ7+JzdX56EHE3xBQECAjh07ppw5c8rtdidatWGM8euB2zZt2mj48OEKCQmxOpT/xPLpPN6UJrEyj++7cOGCsmTJIklKkyaNgoKCVLx4cWuDssCRI0eUL18+q8MAYCNnzpxJtGt9pkyZbNV/wS4VNbezd+9eNWjQQJKULl06Xbp0SS6XS2+++aZq1apFEsVPhIWFacOGDcqWLVu87efOnVOFChX8fpW+pFbJyJw5s9/fm8fExKh///5q27atVq1aZXU4QKKWLFmirFmzSpKWLl1qcTSp458VmHv37tX48eO1d+9eDRs2TDlz5tS8efOUP39+T98pX2F5EoXSVfvYtm2bjh8/LulGVnTnzp26dOlSvGPKlStnRWip7vjx4+rfv7/Gjh2ry5cvWx0OABspWrSo5s2bp44dO8bb/ssvvygsLMyiqFKeXed7/1PWrFn1999/S7pRYfTHH3+obNmyOnfuHCu7+ZGoqKhER32vXr2qI0eOWBBRynLCvXmaNGk0cOBAR1x34L8eeeQRSTeSfsuWLVPbtm1t269n+fLlqlevnqpVq6YVK1aof//+ypkzp7Zs2aKxY8dqxowZVocYj+VJFNjHo48+Gq8p4M1GsjeX5/TnUjPpxgjT66+/rgULFiht2rTq2bOnOnbsqN69e+uzzz5T6dKlFRERYXWYAGzmrbfeUseOHXXq1CnVqlVL0o3Gh4MGDbJd9UZsbKxmz56t7du3y+VyKTw8XA0bNlRAQIDVoaWIhx9+WAsXLlTZsmXVpEkTde7cWUuWLNHChQv16KOPWh0ekvDPxvHz58+PV7ERGxurxYsX27afjx099thjWrZsmVq3bm11KMBtpUmTRp999pmtk349e/ZUv3799NZbb8Wb2lOzZk0NGzbMwsgSZ3lPFNjDgQMHvDrOn5utdejQQXPnzlXTpk01b948bd/+/9q7+5iq6/6P46/DgTQhE4YSnuQmbiznWWnNiorDF9PMzKw1ttSIsnWzIldjZTemq2xtdml3Zs40ollOF7VcpXNxDgGC4VC8iUxNMwvMVBwQx5Bzfn9cP8/VudDiyiOfAz4f2/nD7+f88dr4Dg+v8/m+Pw266aab5PV6NWfOnEBbDAChtnjxYs2bN0+//PKLJCklJUVz587t9Vvq/2z37t2aOHGifv75Zw0fPlx+v1/ff/+9hg0bps8//1xpaWmmI56xI0eOyOv1aujQofL5fHr11VcDA0lnz56t2NhY0xHxF04Olj/55dCfRUVFKSUlRf/617/6zGmEfd2SJUs0d+5cTZs2TVdeeaWio6OD1jlhEeFkypQpmjJlSp8t/WJiYrRt2zalpqYGZoZdcskl2rdvny699FJ5vV7TEYNQoqDHbNmyRVdccYXpGP9YcnKyli1bphtvvFE//PBD4LSMvvZNMIDwdejQIZ1//vmKiYkxHSXkJk6cKL/frxUrVgSeAT98+LCmT5+uiIgIff7554YTAv+Wmpqq2tpaxcfHm46CM/BXpy329t3T6Hv6eul38cUXa9WqVcrKygoqUT755BMVFRVpz549piMGoUTBWXXs2DGtWLFC7777rurr63v1f0hRUVH68ccfNXToUEnSgAED9M0332jkyJGGkwFA7xcdHa2amho5nc6g6/X19bruuuvU2tpqKFlo9abBeQCA8NDXS78nn3xS1dXVWr16tTIzM1VXV6eDBw8qPz9f+fn5mjNnjumIQU7/0wDOQFlZmaZPn67ExES9+eabmjhxojZt2mQ61hnx+XxBR27a7fYuLTAAhMLo0aN19OhRSdKoUaM0evTo0776in79+gWGrv5Za2urzjvvPAOJQq+8vFxOp1MbN25UaWlpoBjaunVr2H1ARFcbN27Ul19+GXStpKREqampGjJkiB544AEdP37cUDoAfZnP5zvtq7cXKJI0b948JSUlyeFwqLW1VSNGjFB2draysrL03HPPmY7XBYNlETIHDhxQcXGxli9frra2NuXl5amjo0Mff/yxRowYYTreGfP7/SooKFC/fv0kSV6vVw899FCXIqW0tNREPAB9yG233Rb4XXPbbbfJZrMZTnT2TZo0SQ888ICWLVumMWPGSPr3H60PPfRQr9+mfFJvG5yHYHPnzlVOTo5uvvlmSdK2bds0Y8YMFRQU6LLLLtP8+fM1dOhQzZ0712xQ/KWysjI9+uijqqmp0cCBA4PWjh07pqysLC1evFjZ2dmGEgL/0Z379Z133tENN9xgKGFoREVFacWKFXrxxRdVV1cnn8+nUaNGKSMjw3S0U+JxHoTExIkTVVlZqUmTJmnatGmaMGGC7Ha7oqKiVF9f3ydKlHvvvbdb7zsXjgYEcPb19jlS/6vm5mbdc889WrNmTWDX34kTJzR58mQVFxcHnYTSW/W2wXkIlpiYqDVr1uiqq66SJD377LMqLy9XZWWlJGn16tWaM2eOvv32W5Mx8TcmT54sy7L0+OOPn3L9jTfekNvt1ieffNLDyYCuzpX79YUXXlBRUZEGDBgQdL29vV3z58/X888/byjZqVGiICQiIyP12GOP6eGHHw5qDPtSiQIAPSkiIkKjRo3S/fffr6lTp/aJEqE7du3apYaGBknSiBEjlJ6ebjhR6PS2wXkI1r9/f+3atUvDhg2TJF1//fWaMGFCYKv5vn375HQ6T/lYGsJHcnKy1q5dq8suu+yU6999953Gjx+v/fv393AyoKtz5X612+1qbGzUkCFDgq4fPnxYQ4YMCbtHlpiJgpCoqKhQS0uLrrrqKl199dV66623dOjQIdOxAKDXqqqq0ujRozVr1iwlJiZq+vTpcrvdpmOddRkZGbr11lt166239qkCRZKmTp2qp556Sk1NTbLZbPL5fKqqqlJRUVGfOq66r0pISNDevXslSX/88Yfq6up07bXXBtZbWlqCZqchPB08ePAvf06RkZF8hkXYOFfuV7/ff8pHl+vr6wMn9oUTShSExLXXXqulS5eqsbFRDz74oFauXCmHwyGfz6f169fzrQwA/I9O/l5tamrS4sWLdeDAAd14441KS0vTvHnzdODAAdMRQ27ZsmUaOXKk+vfvr/79+2vkyJF69913TccKmd42OA/BJkyYoFmzZqmiokJPP/20BgwYEDSHYOvWrUpLSzOYEN3hcDi0bdu2065v3bpViYmJPZgIOL2+fr/GxsYqLi5ONptNmZmZiouLC7wuvPBCjRs3Tnl5eaZjdsHjPDhrdu7cqWXLlumDDz5Qc3Ozxo0bp88++8x0LADotU4ej1tSUqLGxkaNGzdOX3zxhelYITF79mwtXLhQhYWFgW/3q6ur9dZbb2nmzJl66aWXDCf853bv3h20q2bPnj3avHlz2A/OQ7BDhw7pjjvuUFVVlWJiYvT+++/r9ttvD6yPHTtW11xzjebNm2cwJf5OYWGhPB6Pamtr1b9//6C19vZ2jRkzRpZl6Y033jCUEPiPvn6/vv/++/L7/brvvvv02muvBT26fN555yklJSVox1+4oETBWdfZ2ak1a9Zo+fLllCgAcIZaW1u1YsUKPfPMM2pubg6754T/qfj4eL355pu66667gq5/9NFHKiws1G+//WYo2ZmLiIiQw+GQZVnKzc2VZVlKTk42HQv/0LFjxxQTEyO73R50/ciRI4qJiekzR3L3VQcPHtTo0aNlt9v16KOPavjw4bLZbGpoaNCiRYvU2dmpuro6JSQkmI4KnDP3a3l5ubKysnrNI5GUKAAA9ALl5eVavny5Pv74Y9ntduXl5WnGjBm65pprTEcLidjYWH3zzTdddmV8//33GjNmjJqbm80EC4GKigqVl5fL4/GourpaXq9XSUlJgULFsiw5HA7TMYFzxo8//qiHH35Y69at08k/hWw2m2666Sa9/fbbSklJMRsQ+JNz7X5tb29XR0dH0LX/Pt7ZNEoUAADC1E8//aTi4mIVFxdr7969ysrK0owZM5SXl6fo6GjT8UKqsLBQUVFRWrBgQdD1oqIitbe3a9GiRYaShVZHR4eqq6vl8Xjk8XhUU1Oj48ePKz09XTt37jQdDzinHD16VLt375bf71dGRoZiY2NNRwJOqy/fr7///ruefPJJrVq1SocPH+6yHm67bilRAAAIQ+PGjZPb7dbgwYOVn5+v++67T8OHDzcd66wpLCxUSUmJhg0bFthdU1NTo59++kn5+flBW3z/u2jpjdrb21VZWal169Zp6dKlam1tDbsPiQAA9IRHHnlEbrdbL7zwgvLz87Vo0SL9/PPPWrJkiV555RVNmzbNdMQglCgAAIShyZMna8aMGZo0aVKX2Qt9kWVZ3XqfzWZTWVnZWU4Tel6vVxs2bJDb7Q4MCUxNTZXL5VJ2drZcLheP9AAAzklJSUkqKSlRTk6OBg4cqLq6OqWnp+uDDz7QRx99FHZD9ClRAAAAziKXy6Xa2lqlpaUFChOXy9XrBwECABAKMTEx2rFjh5KTk3XxxRertLRUY8aM0d69e+V0OtXa2mo6YpAI0wEAAAD6sg0bNig+Pl6WZWns2LHKzc2lQAEA4P9dcskl2rdvnyRpxIgRWrVqlSRpzZo1GjRokLlgp8FOFAAAEBZqa2u1evVq7d+/X3/88UfQWmlpqaFUZ66trU0VFRXyeDxyu93asmWLMjMz5XK5lJOTI5fLpcGDB5uOCQCAEQsXLpTdbtdjjz0mt9utW265RZ2dnTpx4oQWLFigmTNnmo4YhBIFAAAYt3LlSuXn52v8+PFav369xo8fr127dqmpqUm333673nvvPdMRQ6alpUWVlZWB+Sj19fXKyMjQ9u3bTUcDAMC4/fv3a9OmTUpLS9Pll19uOk4XkaYDAAAAvPzyy1q4cKEeeeQRXXDBBXr99deVmpqqBx98UImJiabjhVR0dLTi4uIUFxen2NhYRUZGqqGhwXQsAADCQlJSkpKSkkzHOC12ogAAAOOio6O1Y8cOpaSkKD4+Xm63W06nUw0NDcrNzVVjY6PpiP+Yz+fTpk2bAo/zVFVVqa2tTQ6HQ5ZlBV7JycmmowIA0KN8Pp+Ki4tVWlqqffv2yWazKTU1VXfeeafuvvtu2Ww20xG7YCcKAAAwLi4uTi0tLZIkh8Oh7du3y+l0qrm5Wb///rvhdGdm0KBBamtrU2JionJycrRgwQJZlqW0tDTT0QAAMMbv92vy5Mn64osvdPnll8vpdMrv96uhoUEFBQUqLS3Vp59+ajpmF5QoAADAuBtuuEHr16+X0+lUXl6eZs6cqbKyMq1fv15jx441He+MzJ8/X5ZlKTMz03QUAADCRnFxsb7++mt99dVXsiwraK2srExTpkxRSUmJ8vPzDSU8NR7nAQAAxh05ckRer1dDhw6Vz+fTq6++qsrKSqWnp2v27NmKjY01HREAAITQ+PHjlZubq1mzZp1y/eWXX1Z5ebnWrVvXw8n+GiUKAAAAAADoURdddJHWrl2rK6644pTrmzdv1s0336ympqaeDfY3IkwHAAAAkKQ9e/boueee01133aVff/1VkrR27Vrt2LHDcDIAABBqR44cUUJCwmnXExISdPTo0R5M1D2UKAAAwLjy8nI5nU5t3LhRpaWlam1tlSRt3bpVc+bMMZwOAACEWmdnpyIjTz+m1W6368SJEz2YqHsYLAsAAIybNWuWXnrpJT3xxBO64IILAtcty9Lrr79uMBkAADgb/H6/CgoK1K9fv1OuHz9+vIcTdQ8lCgAAMG7btm368MMPu1wfPHiwDh8+bCARAAA4m+65556/fU+4ncwjUaIAAIAwMGjQIDU2Nio1NTXo+ubNm+VwOAylAgAAZ8t7771nOsI/wkwUAABg3NSpU/XUU0+pqalJNptNPp9PVVVVKioqCstvoQAAwLmJI44BAIBxHR0dKigo0MqVK+X3+xUZGanOzk5NnTpVxcXFstvtpiMCAABQogAAAHN2796t9PT0wL/37NmjzZs3y+fzadSoUcrIyDCYDgAAIBglCgAAMCYiIkIOh0OWZSk3N1eWZSk5Odl0LAAAgFOiRAEAAMZUVFSovLxcHo9H1dXV8nq9SkpKChQqlmUxWBYAAIQNShQAABAWOjo6VF1dLY/HI4/Ho5qaGh0/flzp6enauXOn6XgAAACUKAAAILy0t7ersrJS69at09KlS9Xa2qrOzk7TsQAAAChRAACAWV6vVxs2bJDb7ZbH41Ftba1SU1PlcrmUnZ0tl8vFIz0AACAsUKIAAABjXC6XamtrlZaWFihMXC6XEhISTEcDAADoghIFAAAYExUVpcTERE2ZMkU5OTnKzs5WfHy86VgAAACnRIkCAACMaWtrU0VFhTwej9xut7Zs2aLMzEy5XC7l5OTI5XJp8ODBpmMCAABIokQBAABhpKWlRZWVlYH5KPX19crIyND27dtNRwMAAFCE6QAAAAAnRUdHKy4uTnFxcYqNjVVkZKQaGhpMxwIAAJDEThQAAGCQz+fTpk2bAo/zVFVVqa2tTQ6HQ5ZlBV7JycmmowIAAFCiAAAAcwYOHKi2tjYlJiYqJydHOTk5sixLaWlppqMBAAB0QYkCAACMWbJkiSzLUmZmpukoAAAAf4sSBQAAAAAAoBsYLAsAAAAAANANlCgAAAAAAADdQIkCAAAAAADQDZQoAAAAAAAA3UCJAgAAAAAA0A2UKAAAAAAAAN1AiQIAAAAAANANlCgAAAAAAADd8H/qd7QoHTxYyAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "sns.heatmap(df_new.isna(), cbar=False, yticklabels=False)\n",
    "plt.title(\"Missing Value Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6001bce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Rptd</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Mocodes</th>\n",
       "      <th>Vict Age</th>\n",
       "      <th>Vict Sex</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>Cross Street</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Crime_Class</th>\n",
       "      <th>DateTime OCC</th>\n",
       "      <th>Weapon_Present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/4/2021 0:00</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>7800    BEEMAN                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>-118.4092</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-07-11 08:45:00</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/21/2020 12:00:00 AM</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>0416 0334 2004 1822 1414 0305 0319 0400</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>ATOLL                        AV</td>\n",
       "      <td>N  GAULT</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>-118.4203</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>2020-10-18 18:45:00</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/12/2024 0:00</td>\n",
       "      <td>9</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>14600    SYLVAN                       ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>-118.4509</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-10-30 12:40:00</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>344</td>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>6000    COMEY                        AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>-118.3747</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-12-24 13:10:00</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/10/2020 0:00</td>\n",
       "      <td>14</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>1300 0344 1606 2032</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>4700    LA VILLA MARINA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>-118.4350</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>2020-09-29 18:30:00</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>21</td>\n",
       "      <td>Topanga</td>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>X</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>22100    ROSCOE                       BL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>-118.6126</td>\n",
       "      <td>Other Crime</td>\n",
       "      <td>2025-02-02 01:30:00</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>4</td>\n",
       "      <td>Hollenbeck</td>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>1258 0553 0602</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>3500    PERCY                        ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>-118.1979</td>\n",
       "      <td>Child-Related Crime</td>\n",
       "      <td>2025-02-18 10:00:00</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>01/31/2025 12:00:00 AM</td>\n",
       "      <td>13</td>\n",
       "      <td>Newton</td>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>300 E  53RD                         ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>-118.2701</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>2025-01-30 15:54:00</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>17</td>\n",
       "      <td>Devonshire</td>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>0400 1259 1822 0356</td>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>9600    ZELZAH                       AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>-118.5233</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>2025-01-17 16:00:00</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>0529 2024 1815 0913</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>11100    OMELVENY                     AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>-118.4417</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>2025-03-25 12:35:00</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date Rptd  AREA    AREA NAME  Rpt Dist No  Part 1-2  \\\n",
       "0                11/4/2021 0:00    15  N Hollywood         1502         2   \n",
       "1        10/21/2020 12:00:00 AM    15  N Hollywood         1521         1   \n",
       "2               10/12/2024 0:00     9     Van Nuys          933         2   \n",
       "3        12/24/2020 12:00:00 AM     7     Wilshire          782         1   \n",
       "4                3/10/2020 0:00    14      Pacific         1454         1   \n",
       "...                         ...   ...          ...          ...       ...   \n",
       "1004986           2/2/2025 0:00    21      Topanga         2103         2   \n",
       "1004987  02/18/2025 12:00:00 AM     4   Hollenbeck          479         2   \n",
       "1004988  01/31/2025 12:00:00 AM    13       Newton         1372         2   \n",
       "1004989  01/17/2025 12:00:00 AM    17   Devonshire         1774         2   \n",
       "1004990  03/25/2025 12:00:00 AM    19      Mission         1944         2   \n",
       "\n",
       "                                         Mocodes  Vict Age Vict Sex  \\\n",
       "0                                            377        31        M   \n",
       "1        0416 0334 2004 1822 1414 0305 0319 0400        32        M   \n",
       "2                                            377        30        M   \n",
       "3                                            344        47        F   \n",
       "4                            1300 0344 1606 2032        63        M   \n",
       "...                                          ...       ...      ...   \n",
       "1004986                                      NaN        35        M   \n",
       "1004987                           1258 0553 0602        11        M   \n",
       "1004988                                      NaN        16        F   \n",
       "1004989                      0400 1259 1822 0356        17        M   \n",
       "1004990                      0529 2024 1815 0913        35        F   \n",
       "\n",
       "        Vict Descent Status  Status Desc  \\\n",
       "0                  H     IC  Invest Cont   \n",
       "1                  H     IC  Invest Cont   \n",
       "2                  W     IC  Invest Cont   \n",
       "3                  A     IC  Invest Cont   \n",
       "4                  H     IC  Invest Cont   \n",
       "...              ...    ...          ...   \n",
       "1004986            X     IC  Invest Cont   \n",
       "1004987            B     IC  Invest Cont   \n",
       "1004988            H     IC  Invest Cont   \n",
       "1004989            H     IC  Invest Cont   \n",
       "1004990            H     IC  Invest Cont   \n",
       "\n",
       "                                         LOCATION Cross Street      LAT  \\\n",
       "0         7800    BEEMAN                       AV          NaN  34.2124   \n",
       "1                 ATOLL                        AV     N  GAULT  34.1993   \n",
       "2        14600    SYLVAN                       ST          NaN  34.1847   \n",
       "3         6000    COMEY                        AV          NaN  34.0339   \n",
       "4                         4700    LA VILLA MARINA          NaN  33.9813   \n",
       "...                                           ...          ...      ...   \n",
       "1004986  22100    ROSCOE                       BL          NaN  34.2259   \n",
       "1004987   3500    PERCY                        ST          NaN  34.0277   \n",
       "1004988    300 E  53RD                         ST          NaN  33.9942   \n",
       "1004989   9600    ZELZAH                       AV          NaN  34.2450   \n",
       "1004990  11100    OMELVENY                     AV          NaN  34.2722   \n",
       "\n",
       "              LON          Crime_Class        DateTime OCC Weapon_Present  \n",
       "0       -118.4092       Property Crime 2020-07-11 08:45:00         Absent  \n",
       "1       -118.4203        Violent Crime 2020-10-18 18:45:00        Present  \n",
       "2       -118.4509       Property Crime 2020-10-30 12:40:00         Absent  \n",
       "3       -118.3747       Property Crime 2020-12-24 13:10:00         Absent  \n",
       "4       -118.4350       Property Crime 2020-09-29 18:30:00         Absent  \n",
       "...           ...                  ...                 ...            ...  \n",
       "1004986 -118.6126          Other Crime 2025-02-02 01:30:00         Absent  \n",
       "1004987 -118.1979  Child-Related Crime 2025-02-18 10:00:00         Absent  \n",
       "1004988 -118.2701            Sex Crime 2025-01-30 15:54:00         Absent  \n",
       "1004989 -118.5233        Violent Crime 2025-01-17 16:00:00        Present  \n",
       "1004990 -118.4417            Sex Crime 2025-03-25 12:35:00         Absent  \n",
       "\n",
       "[1004991 rows x 18 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Drop the Weapon Used Cd column (if it exists)\n",
    "df_new = df_new.drop(columns=['Weapon Used Cd'], errors='ignore')\n",
    "\n",
    "# 2. Create a binary Weapon_Present column\n",
    "df_new['Weapon_Present'] = df_new['Weapon Desc'].apply(\n",
    "    lambda x: 'Present' if pd.notna(x) and str(x).strip() != '' else 'Absent'\n",
    ")\n",
    "\n",
    "# 3. (Optional) Drop Weapon Desc if you want to fully remove the text info\n",
    "df_new = df_new.drop(columns=['Weapon Desc'], errors='ignore')\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f83dda",
   "metadata": {},
   "source": [
    "Check again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f191894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "sns.heatmap(df_new.isna(), cbar=False, yticklabels=False)\n",
    "plt.title(\"Missing Value Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a6282b",
   "metadata": {},
   "source": [
    "### Dropping columns that provide meaningless value:\n",
    "\n",
    "Start with obvious ones, Location of the crime will often be unique among all records, but the area/district may not. So it can be dropped.\n",
    "\n",
    "To do so, apply a test such as Pearson Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb361d7c",
   "metadata": {},
   "source": [
    "Cross Street possess a lot of missing values. This can be dropped completely if Location is already sufficient info.\n",
    "\n",
    "As for Mo Codes, this is neglectable, since some records may only be a minor offense. So no MO Code may have been recorded.\n",
    "\n",
    "This applies to victim sex and descent as well, since not all crimes have a victim involved, such as vandalisme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e598560",
   "metadata": {},
   "source": [
    "### Test Pearson Correlation (Numeric Features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37d8695e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 strongest Pearson correlations (absolute):\n",
      "      Feature 1            Feature 2  Correlation\n",
      "0          AREA          Rpt Dist No     0.999051\n",
      "18          LAT                  LON    -0.998190\n",
      "11     Part 1-2             Vict Age     0.206183\n",
      "17     Vict Age  Crime_Class_numeric    -0.081723\n",
      "14     Part 1-2  Crime_Class_numeric     0.071209\n",
      "13     Part 1-2                  LON     0.029212\n",
      "12     Part 1-2                  LAT    -0.028722\n",
      "3          AREA                  LAT     0.025338\n",
      "8   Rpt Dist No                  LAT     0.025077\n",
      "7   Rpt Dist No             Vict Age     0.022624\n",
      "2          AREA             Vict Age     0.022593\n",
      "4          AREA                  LON    -0.010541\n",
      "9   Rpt Dist No                  LON    -0.010469\n",
      "1          AREA             Part 1-2     0.007675\n",
      "6   Rpt Dist No             Part 1-2     0.007489\n",
      "10  Rpt Dist No  Crime_Class_numeric    -0.003770\n",
      "5          AREA  Crime_Class_numeric    -0.003678\n",
      "16     Vict Age                  LON     0.002219\n",
      "19          LAT  Crime_Class_numeric    -0.001563\n",
      "20          LON  Crime_Class_numeric    -0.001106\n",
      "15     Vict Age                  LAT    -0.000867\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose the DataFrame to analyze; use the most recent processed one if available\n",
    "try:\n",
    "    df_corr_source = df_new.copy()\n",
    "except NameError:\n",
    "    df_corr_source = df_raw.copy()\n",
    "\n",
    "# Ensure target encoding (optional): demonstrate correlation against encoded target when present\n",
    "if 'Crime_Class' in df_corr_source.columns:\n",
    "    df_corr_source['Crime_Class_numeric'] = df_corr_source['Crime_Class'].astype('category').cat.codes\n",
    "\n",
    "# Select only numeric columns\n",
    "num_df = df_corr_source.select_dtypes(include=['number'])\n",
    "\n",
    "# Pearson correlation matrix\n",
    "corr = num_df.corr(numeric_only=True)\n",
    "\n",
    "# Upper triangle flatten for pairwise sorted report\n",
    "upper = corr.where(~np.tril(np.ones(corr.shape)).astype(bool))\n",
    "corr_report = (\n",
    "    upper.stack()\n",
    "          .reset_index()\n",
    "          .rename(columns={'level_0': 'Feature 1', 'level_1': 'Feature 2', 0: 'Correlation'})\n",
    ")\n",
    "\n",
    "# Sort by absolute correlation strength\n",
    "corr_report = corr_report.iloc[corr_report['Correlation'].abs().sort_values(ascending=False).index]\n",
    "\n",
    "# Show top pairs\n",
    "print(\"Top 25 strongest Pearson correlations (absolute):\")\n",
    "print(corr_report.head(25))\n",
    "\n",
    "# Optional: heatmap for a quick visual\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0)\n",
    "plt.title('Pearson Correlation (Numeric Features)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29de95a8",
   "metadata": {},
   "source": [
    "### What can be derived freom this correlation table?\n",
    "\n",
    "1. Area and Rpt Dist No are inheritelly the same info, if you know the area where the crime occured, is the specific District Number really required?\n",
    "2. Many features have a correlation near 0, this implies that many features are highly independent. In  which, leave them be.\n",
    "3. Latitude and Longitude do provide the coordinates of the crime, but neither predicts each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d885d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correlation_with_Crime_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Vict Age</th>\n",
       "      <td>0.081723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Part 1-2</th>\n",
       "      <td>0.071209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <td>0.003770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AREA</th>\n",
       "      <td>0.003678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAT</th>\n",
       "      <td>0.001563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LON</th>\n",
       "      <td>0.001106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Correlation_with_Crime_Class\n",
       "Vict Age                         0.081723\n",
       "Part 1-2                         0.071209\n",
       "Rpt Dist No                      0.003770\n",
       "AREA                             0.003678\n",
       "LAT                              0.001563\n",
       "LON                              0.001106"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a copy of the data\n",
    "df_corr = df_new.copy()\n",
    "\n",
    "# Convert Crime_Class (categorical) → numeric labels\n",
    "df_corr['Crime_Class_numeric'] = df_corr['Crime_Class'].astype('category').cat.codes\n",
    "\n",
    "# Select only numeric columns\n",
    "num_df = df_corr.select_dtypes(include=['number'])\n",
    "\n",
    "# Compute correlation with the numeric-encoded target\n",
    "target_corr = num_df.corr(numeric_only=True)['Crime_Class_numeric']\n",
    "\n",
    "# Remove the target itself\n",
    "target_corr = target_corr.drop(labels=['Crime_Class_numeric'])\n",
    "\n",
    "# Turn into sorted dataframe\n",
    "target_corr_report = (\n",
    "    target_corr\n",
    "        .abs()\n",
    "        .sort_values(ascending=False)\n",
    "        .rename(\"Correlation_with_Crime_Class\")\n",
    "        .to_frame()\n",
    ")\n",
    "\n",
    "target_corr_report.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "934e0675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1004991 entries, 0 to 1004990\n",
      "Data columns (total 18 columns):\n",
      " #   Column          Non-Null Count    Dtype         \n",
      "---  ------          --------------    -----         \n",
      " 0   Date Rptd       1004991 non-null  object        \n",
      " 1   AREA            1004991 non-null  int64         \n",
      " 2   AREA NAME       1004991 non-null  object        \n",
      " 3   Rpt Dist No     1004991 non-null  int64         \n",
      " 4   Part 1-2        1004991 non-null  int64         \n",
      " 5   Mocodes         853372 non-null   object        \n",
      " 6   Vict Age        1004991 non-null  int64         \n",
      " 7   Vict Sex        860347 non-null   object        \n",
      " 8   Vict Descent    860335 non-null   object        \n",
      " 9   Status          1004990 non-null  object        \n",
      " 10  Status Desc     1004991 non-null  object        \n",
      " 11  LOCATION        1004991 non-null  object        \n",
      " 12  Cross Street    154236 non-null   object        \n",
      " 13  LAT             1004991 non-null  float64       \n",
      " 14  LON             1004991 non-null  float64       \n",
      " 15  Crime_Class     1004991 non-null  object        \n",
      " 16  DateTime OCC    1004991 non-null  datetime64[ns]\n",
      " 17  Weapon_Present  1004991 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(4), object(11)\n",
      "memory usage: 138.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf9ccb",
   "metadata": {},
   "source": [
    "### Let's tackle Mocodes first, these represent a given crime/offense commited. You can find the full list in the file attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36938e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Clean & explode the MO Codes column ---\n",
    "# Convert NaN to empty string\n",
    "df_new['Mocodes'] = df_new['Mocodes'].fillna('')\n",
    "\n",
    "# Split by spaces → expand into list\n",
    "df_new['MOCODES_LIST'] = df_new['Mocodes'].str.strip().str.split()\n",
    "\n",
    "# Explode (each code becomes a row)\n",
    "exploded = df_new.explode('MOCODES_LIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e68a9a",
   "metadata": {},
   "source": [
    "Then, extract all unique MO code entries present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5211905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938 unique MO codes found\n"
     ]
    }
   ],
   "source": [
    "all_codes = sorted({code for sublist in df_new['MOCODES_LIST'] for code in sublist})\n",
    "print(len(all_codes), \"unique MO codes found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8490b2",
   "metadata": {},
   "source": [
    "Count the frequency of each MO Code in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de005d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Count MO code frequencies ---\n",
    "mo_counts = (\n",
    "    exploded['MOCODES_LIST']\n",
    "    .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef4a170",
   "metadata": {},
   "source": [
    "Select the top 100 MO Codes to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3eda6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Select the Top 100 codes ---\n",
    "top_100 = set(mo_counts.head(100).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa6059",
   "metadata": {},
   "source": [
    "Filter MO list into top codes and “others”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94d22fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_7704\\2391797412.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_7704\\2391797412.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_7704\\2391797412.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_7704\\2391797412.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_7704\\2391797412.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_7704\\2391797412.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_7704\\2391797412.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_7704\\2391797412.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_7704\\2391797412.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_7704\\2391797412.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new['MO_OTHERS'] = df_new['MOCODES_LIST'].apply(\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Create one-hot columns for each top code ---\n",
    "for code in top_100:\n",
    "    df_new[f\"MO_{code}\"] = df_new['MOCODES_LIST'].apply(lambda lst: code in lst)\n",
    "\n",
    "# --- Step 5: Create the OTHERS column ---\n",
    "# OTHERS = true if the row contains any MO code NOT in the top 100\n",
    "df_new['MO_OTHERS'] = df_new['MOCODES_LIST'].apply(\n",
    "    lambda lst: any(code not in top_100 for code in lst)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deb5c93",
   "metadata": {},
   "source": [
    "Filter each crime’s MO list to only keep top 100 codes, create an Others column to store everything else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18426a32",
   "metadata": {},
   "source": [
    "Multi-hot encode only the top 100 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5712466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 101 MO Code features (100 Top + OTHERS).\n",
      "['MO_0397', 'MO_1813', 'MO_0443', 'MO_0421', 'MO_1309', 'MO_0701', 'MO_2004', 'MO_0447', 'MO_1266', 'MO_1501']\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: Convert booleans to integers (0/1) ---\n",
    "mo_cols = [col for col in df_new.columns if col.startswith(\"MO_\")]\n",
    "df_new[mo_cols] = df_new[mo_cols].astype(int)\n",
    "\n",
    "# --- Step 7: Clean up temporary column ---\n",
    "df_new_1 = df_new.drop(columns=[\"MOCODES_LIST\"])\n",
    "\n",
    "# --- Done ---\n",
    "print(f\"Created {len(mo_cols)} MO Code features (100 Top + OTHERS).\")\n",
    "print(mo_cols[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9058b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Rptd</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Vict Age</th>\n",
       "      <th>Vict Sex</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>...</th>\n",
       "      <th>MO_0400</th>\n",
       "      <th>MO_0602</th>\n",
       "      <th>MO_1609</th>\n",
       "      <th>MO_0419</th>\n",
       "      <th>MO_0450</th>\n",
       "      <th>MO_0346</th>\n",
       "      <th>MO_1302</th>\n",
       "      <th>MO_0922</th>\n",
       "      <th>MO_1906</th>\n",
       "      <th>MO_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/4/2021 0:00</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/21/2020 12:00:00 AM</td>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/12/2024 0:00</td>\n",
       "      <td>9</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/24/2020 12:00:00 AM</td>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/10/2020 0:00</td>\n",
       "      <td>14</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>2/2/2025 0:00</td>\n",
       "      <td>21</td>\n",
       "      <td>Topanga</td>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>X</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>02/18/2025 12:00:00 AM</td>\n",
       "      <td>4</td>\n",
       "      <td>Hollenbeck</td>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>01/31/2025 12:00:00 AM</td>\n",
       "      <td>13</td>\n",
       "      <td>Newton</td>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>01/17/2025 12:00:00 AM</td>\n",
       "      <td>17</td>\n",
       "      <td>Devonshire</td>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>03/25/2025 12:00:00 AM</td>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date Rptd  AREA    AREA NAME  Rpt Dist No  Part 1-2  \\\n",
       "0                11/4/2021 0:00    15  N Hollywood         1502         2   \n",
       "1        10/21/2020 12:00:00 AM    15  N Hollywood         1521         1   \n",
       "2               10/12/2024 0:00     9     Van Nuys          933         2   \n",
       "3        12/24/2020 12:00:00 AM     7     Wilshire          782         1   \n",
       "4                3/10/2020 0:00    14      Pacific         1454         1   \n",
       "...                         ...   ...          ...          ...       ...   \n",
       "1004986           2/2/2025 0:00    21      Topanga         2103         2   \n",
       "1004987  02/18/2025 12:00:00 AM     4   Hollenbeck          479         2   \n",
       "1004988  01/31/2025 12:00:00 AM    13       Newton         1372         2   \n",
       "1004989  01/17/2025 12:00:00 AM    17   Devonshire         1774         2   \n",
       "1004990  03/25/2025 12:00:00 AM    19      Mission         1944         2   \n",
       "\n",
       "         Vict Age Vict Sex Vict Descent Status  Status Desc  ... MO_0400  \\\n",
       "0              31        M            H     IC  Invest Cont  ...       0   \n",
       "1              32        M            H     IC  Invest Cont  ...       1   \n",
       "2              30        M            W     IC  Invest Cont  ...       0   \n",
       "3              47        F            A     IC  Invest Cont  ...       0   \n",
       "4              63        M            H     IC  Invest Cont  ...       0   \n",
       "...           ...      ...          ...    ...          ...  ...     ...   \n",
       "1004986        35        M            X     IC  Invest Cont  ...       0   \n",
       "1004987        11        M            B     IC  Invest Cont  ...       0   \n",
       "1004988        16        F            H     IC  Invest Cont  ...       0   \n",
       "1004989        17        M            H     IC  Invest Cont  ...       1   \n",
       "1004990        35        F            H     IC  Invest Cont  ...       0   \n",
       "\n",
       "        MO_0602  MO_1609  MO_0419 MO_0450 MO_0346 MO_1302  MO_0922  MO_1906  \\\n",
       "0             0        0        0       0       0       0        0        0   \n",
       "1             0        0        0       0       0       0        0        0   \n",
       "2             0        0        0       0       0       0        0        0   \n",
       "3             0        0        0       0       0       0        0        0   \n",
       "4             0        0        0       0       0       0        0        0   \n",
       "...         ...      ...      ...     ...     ...     ...      ...      ...   \n",
       "1004986       0        0        0       0       0       0        0        0   \n",
       "1004987       1        0        0       0       0       0        0        0   \n",
       "1004988       0        0        0       0       0       0        0        0   \n",
       "1004989       0        0        0       0       0       0        0        0   \n",
       "1004990       0        0        0       0       0       0        0        0   \n",
       "\n",
       "         MO_OTHERS  \n",
       "0                1  \n",
       "1                0  \n",
       "2                1  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "1004986          0  \n",
       "1004987          1  \n",
       "1004988          0  \n",
       "1004989          0  \n",
       "1004990          1  \n",
       "\n",
       "[1004991 rows x 118 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_1 = df_new_1.drop(columns=['Mocodes'], errors='ignore')\n",
    "df_new_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf0a38a",
   "metadata": {},
   "source": [
    "### Next, tackle the location based columns\n",
    "\n",
    "As mentioned, since all crimes will more times than not, occur in unique, varying locations, it is best to assume that there is no association or pattern to be determined from them. They are simply too specific to be trained upon.\n",
    "\n",
    "Another key feature that could be dropped is the Date of te Report. Since each report will have its own unique entry date, hence it is safe to assume that the column is noisy and unfeasible in model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33ef2260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Vict Age</th>\n",
       "      <th>Vict Sex</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>LAT</th>\n",
       "      <th>...</th>\n",
       "      <th>MO_0400</th>\n",
       "      <th>MO_0602</th>\n",
       "      <th>MO_1609</th>\n",
       "      <th>MO_0419</th>\n",
       "      <th>MO_0450</th>\n",
       "      <th>MO_0346</th>\n",
       "      <th>MO_1302</th>\n",
       "      <th>MO_0922</th>\n",
       "      <th>MO_1906</th>\n",
       "      <th>MO_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>N Hollywood</td>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>21</td>\n",
       "      <td>Topanga</td>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>X</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>4</td>\n",
       "      <td>Hollenbeck</td>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>13</td>\n",
       "      <td>Newton</td>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>17</td>\n",
       "      <td>Devonshire</td>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AREA    AREA NAME  Rpt Dist No  Part 1-2  Vict Age Vict Sex  \\\n",
       "0          15  N Hollywood         1502         2        31        M   \n",
       "1          15  N Hollywood         1521         1        32        M   \n",
       "2           9     Van Nuys          933         2        30        M   \n",
       "3           7     Wilshire          782         1        47        F   \n",
       "4          14      Pacific         1454         1        63        M   \n",
       "...       ...          ...          ...       ...       ...      ...   \n",
       "1004986    21      Topanga         2103         2        35        M   \n",
       "1004987     4   Hollenbeck          479         2        11        M   \n",
       "1004988    13       Newton         1372         2        16        F   \n",
       "1004989    17   Devonshire         1774         2        17        M   \n",
       "1004990    19      Mission         1944         2        35        F   \n",
       "\n",
       "        Vict Descent Status  Status Desc      LAT  ...  MO_0400 MO_0602  \\\n",
       "0                  H     IC  Invest Cont  34.2124  ...        0       0   \n",
       "1                  H     IC  Invest Cont  34.1993  ...        1       0   \n",
       "2                  W     IC  Invest Cont  34.1847  ...        0       0   \n",
       "3                  A     IC  Invest Cont  34.0339  ...        0       0   \n",
       "4                  H     IC  Invest Cont  33.9813  ...        0       0   \n",
       "...              ...    ...          ...      ...  ...      ...     ...   \n",
       "1004986            X     IC  Invest Cont  34.2259  ...        0       0   \n",
       "1004987            B     IC  Invest Cont  34.0277  ...        0       1   \n",
       "1004988            H     IC  Invest Cont  33.9942  ...        0       0   \n",
       "1004989            H     IC  Invest Cont  34.2450  ...        1       0   \n",
       "1004990            H     IC  Invest Cont  34.2722  ...        0       0   \n",
       "\n",
       "        MO_1609  MO_0419  MO_0450  MO_0346  MO_1302  MO_0922  MO_1906  \\\n",
       "0             0        0        0        0        0        0        0   \n",
       "1             0        0        0        0        0        0        0   \n",
       "2             0        0        0        0        0        0        0   \n",
       "3             0        0        0        0        0        0        0   \n",
       "4             0        0        0        0        0        0        0   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "1004986       0        0        0        0        0        0        0   \n",
       "1004987       0        0        0        0        0        0        0   \n",
       "1004988       0        0        0        0        0        0        0   \n",
       "1004989       0        0        0        0        0        0        0   \n",
       "1004990       0        0        0        0        0        0        0   \n",
       "\n",
       "         MO_OTHERS  \n",
       "0                1  \n",
       "1                0  \n",
       "2                1  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "1004986          0  \n",
       "1004987          1  \n",
       "1004988          0  \n",
       "1004989          0  \n",
       "1004990          1  \n",
       "\n",
       "[1004991 rows x 114 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_1 = df_new_1.drop(columns=['LOCATION', 'Cross Street', 'DateTime OCC', 'Date Rptd'], errors='ignore') #Remove the dates\n",
    "df_new_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d7b095",
   "metadata": {},
   "source": [
    "### Next, we need to choose bewteen keeping AREA, or DISTRICT.\n",
    "\n",
    "AREA:\n",
    "- It encodes neighborhood-level crime patterns\n",
    "- It’s stable and interpretable\n",
    "\n",
    "Rpt District:\n",
    "- This is a finer-grained region ID.\n",
    "- Usually LAPD districts are ~1–2 square miles.\n",
    "\n",
    "But using both AREA and Rpt Dist No creates strong multicollinearity, because:\n",
    "- AREA is a parent region\n",
    "- Rpt Dist No is the subregion\n",
    "\n",
    "Which is Better?\n",
    "\n",
    "Refer back to the correlation test, Rpt District is SLIGHTLY better than AREA, so that is what we will keep. It may contain more info than AREA, as AREA is a bit too general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d049b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_1 = df_new_1.drop(columns=['AREA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c3fad07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Vict Age</th>\n",
       "      <th>Vict Sex</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Crime_Class</th>\n",
       "      <th>...</th>\n",
       "      <th>MO_0400</th>\n",
       "      <th>MO_0602</th>\n",
       "      <th>MO_1609</th>\n",
       "      <th>MO_0419</th>\n",
       "      <th>MO_0450</th>\n",
       "      <th>MO_0346</th>\n",
       "      <th>MO_1302</th>\n",
       "      <th>MO_0922</th>\n",
       "      <th>MO_1906</th>\n",
       "      <th>MO_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>-118.4092</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>-118.4203</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>-118.4509</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>-118.3747</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>-118.4350</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>X</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>-118.6126</td>\n",
       "      <td>Other Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>-118.1979</td>\n",
       "      <td>Child-Related Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>-118.2701</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>-118.5233</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>-118.4417</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Rpt Dist No  Part 1-2  Vict Age Vict Sex Vict Descent Status  \\\n",
       "0               1502         2        31        M            H     IC   \n",
       "1               1521         1        32        M            H     IC   \n",
       "2                933         2        30        M            W     IC   \n",
       "3                782         1        47        F            A     IC   \n",
       "4               1454         1        63        M            H     IC   \n",
       "...              ...       ...       ...      ...          ...    ...   \n",
       "1004986         2103         2        35        M            X     IC   \n",
       "1004987          479         2        11        M            B     IC   \n",
       "1004988         1372         2        16        F            H     IC   \n",
       "1004989         1774         2        17        M            H     IC   \n",
       "1004990         1944         2        35        F            H     IC   \n",
       "\n",
       "         Status Desc      LAT       LON          Crime_Class  ... MO_0400  \\\n",
       "0        Invest Cont  34.2124 -118.4092       Property Crime  ...       0   \n",
       "1        Invest Cont  34.1993 -118.4203        Violent Crime  ...       1   \n",
       "2        Invest Cont  34.1847 -118.4509       Property Crime  ...       0   \n",
       "3        Invest Cont  34.0339 -118.3747       Property Crime  ...       0   \n",
       "4        Invest Cont  33.9813 -118.4350       Property Crime  ...       0   \n",
       "...              ...      ...       ...                  ...  ...     ...   \n",
       "1004986  Invest Cont  34.2259 -118.6126          Other Crime  ...       0   \n",
       "1004987  Invest Cont  34.0277 -118.1979  Child-Related Crime  ...       0   \n",
       "1004988  Invest Cont  33.9942 -118.2701            Sex Crime  ...       0   \n",
       "1004989  Invest Cont  34.2450 -118.5233        Violent Crime  ...       1   \n",
       "1004990  Invest Cont  34.2722 -118.4417            Sex Crime  ...       0   \n",
       "\n",
       "         MO_0602  MO_1609  MO_0419  MO_0450  MO_0346  MO_1302  MO_0922  \\\n",
       "0              0        0        0        0        0        0        0   \n",
       "1              0        0        0        0        0        0        0   \n",
       "2              0        0        0        0        0        0        0   \n",
       "3              0        0        0        0        0        0        0   \n",
       "4              0        0        0        0        0        0        0   \n",
       "...          ...      ...      ...      ...      ...      ...      ...   \n",
       "1004986        0        0        0        0        0        0        0   \n",
       "1004987        1        0        0        0        0        0        0   \n",
       "1004988        0        0        0        0        0        0        0   \n",
       "1004989        0        0        0        0        0        0        0   \n",
       "1004990        0        0        0        0        0        0        0   \n",
       "\n",
       "         MO_1906  MO_OTHERS  \n",
       "0              0          1  \n",
       "1              0          0  \n",
       "2              0          1  \n",
       "3              0          0  \n",
       "4              0          0  \n",
       "...          ...        ...  \n",
       "1004986        0          0  \n",
       "1004987        0          1  \n",
       "1004988        0          0  \n",
       "1004989        0          0  \n",
       "1004990        0          1  \n",
       "\n",
       "[1004991 rows x 112 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_1 = df_new_1.drop(columns=['AREA NAME'])\n",
    "df_new_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b903cfdd",
   "metadata": {},
   "source": [
    "### Finally, we need to decide what to do with LAT and LON\n",
    "\n",
    "These are very powerful IF transformed.\n",
    "\n",
    "Raw lat/lon are NOT useful directly because:\n",
    "- models cannot interpret earth geometry\n",
    "- correlation is near zero\n",
    "- linear models especially fail with raw coordinates\n",
    "\n",
    "Raw latitude and longitude values:\n",
    "- have no linear meaning\n",
    "- give almost zero Pearson correlation\n",
    "- confuse tree models (too many splits)\n",
    "- confuse linear models (not linear!)\n",
    "- are extremely sensitive to tiny changes\n",
    "\n",
    "But crimes happen in spatial hotspots:\n",
    "- Downtown\n",
    "- Hollywood\n",
    "- South LA\n",
    "- Venice\n",
    "- San Fernando Valley\n",
    "- Pico-Union\n",
    "- Koreatown\n",
    "- Westlake\n",
    "- etc.\n",
    "\n",
    "### Is there a way to make them useful via transformation?\n",
    "\n",
    "### Clustering the LAT and LON into Bins of range values, may provide much more use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d30dcf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_7704\\2141477543.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_1['Location_Cluster'] = kmeans.fit_predict(coords)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "coords = df_new_1[['LAT', 'LON']].dropna()\n",
    "\n",
    "kmeans = KMeans(n_clusters=100, random_state=42)\n",
    "\n",
    "df_new_1['Location_Cluster'] = kmeans.fit_predict(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c294d0b2",
   "metadata": {},
   "source": [
    "### Method 1 — KMeans Clustering\n",
    "\n",
    "This learns 50–200 “crime regions” directly from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0093894c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Vict Age</th>\n",
       "      <th>Vict Sex</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Crime_Class</th>\n",
       "      <th>...</th>\n",
       "      <th>MO_0602</th>\n",
       "      <th>MO_1609</th>\n",
       "      <th>MO_0419</th>\n",
       "      <th>MO_0450</th>\n",
       "      <th>MO_0346</th>\n",
       "      <th>MO_1302</th>\n",
       "      <th>MO_0922</th>\n",
       "      <th>MO_1906</th>\n",
       "      <th>MO_OTHERS</th>\n",
       "      <th>Location_Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>-118.4092</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>-118.4203</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>-118.4509</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>-118.3747</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>-118.4350</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>X</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>-118.6126</td>\n",
       "      <td>Other Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>-118.1979</td>\n",
       "      <td>Child-Related Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>-118.2701</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>-118.5233</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>-118.4417</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Rpt Dist No  Part 1-2  Vict Age Vict Sex Vict Descent Status  \\\n",
       "0               1502         2        31        M            H     IC   \n",
       "1               1521         1        32        M            H     IC   \n",
       "2                933         2        30        M            W     IC   \n",
       "3                782         1        47        F            A     IC   \n",
       "4               1454         1        63        M            H     IC   \n",
       "...              ...       ...       ...      ...          ...    ...   \n",
       "1004986         2103         2        35        M            X     IC   \n",
       "1004987          479         2        11        M            B     IC   \n",
       "1004988         1372         2        16        F            H     IC   \n",
       "1004989         1774         2        17        M            H     IC   \n",
       "1004990         1944         2        35        F            H     IC   \n",
       "\n",
       "         Status Desc      LAT       LON          Crime_Class  ... MO_0602  \\\n",
       "0        Invest Cont  34.2124 -118.4092       Property Crime  ...       0   \n",
       "1        Invest Cont  34.1993 -118.4203        Violent Crime  ...       0   \n",
       "2        Invest Cont  34.1847 -118.4509       Property Crime  ...       0   \n",
       "3        Invest Cont  34.0339 -118.3747       Property Crime  ...       0   \n",
       "4        Invest Cont  33.9813 -118.4350       Property Crime  ...       0   \n",
       "...              ...      ...       ...                  ...  ...     ...   \n",
       "1004986  Invest Cont  34.2259 -118.6126          Other Crime  ...       0   \n",
       "1004987  Invest Cont  34.0277 -118.1979  Child-Related Crime  ...       1   \n",
       "1004988  Invest Cont  33.9942 -118.2701            Sex Crime  ...       0   \n",
       "1004989  Invest Cont  34.2450 -118.5233        Violent Crime  ...       0   \n",
       "1004990  Invest Cont  34.2722 -118.4417            Sex Crime  ...       0   \n",
       "\n",
       "         MO_1609  MO_0419  MO_0450  MO_0346  MO_1302  MO_0922  MO_1906  \\\n",
       "0              0        0        0        0        0        0        0   \n",
       "1              0        0        0        0        0        0        0   \n",
       "2              0        0        0        0        0        0        0   \n",
       "3              0        0        0        0        0        0        0   \n",
       "4              0        0        0        0        0        0        0   \n",
       "...          ...      ...      ...      ...      ...      ...      ...   \n",
       "1004986        0        0        0        0        0        0        0   \n",
       "1004987        0        0        0        0        0        0        0   \n",
       "1004988        0        0        0        0        0        0        0   \n",
       "1004989        0        0        0        0        0        0        0   \n",
       "1004990        0        0        0        0        0        0        0   \n",
       "\n",
       "         MO_OTHERS  Location_Cluster  \n",
       "0                1                34  \n",
       "1                0                69  \n",
       "2                1                78  \n",
       "3                0                67  \n",
       "4                0                66  \n",
       "...            ...               ...  \n",
       "1004986          0                54  \n",
       "1004987          1                57  \n",
       "1004988          0                83  \n",
       "1004989          0                45  \n",
       "1004990          1                30  \n",
       "\n",
       "[1004991 rows x 113 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bab34d",
   "metadata": {},
   "source": [
    "### Method 2 — Spatial Binning (ranges)\n",
    "\n",
    "This converts lat/lon into a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d33027ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_7704\\3423166820.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_1['Lat_bin'] = pd.cut(df_new_1['LAT'], bins=50, labels=False)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_7704\\3423166820.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_1['Lon_bin'] = pd.cut(df_new_1['LON'], bins=50, labels=False)\n"
     ]
    }
   ],
   "source": [
    "df_new_1['Lat_bin'] = pd.cut(df_new_1['LAT'], bins=50, labels=False)\n",
    "df_new_1['Lon_bin'] = pd.cut(df_new_1['LON'], bins=50, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20c910f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Vict Age</th>\n",
       "      <th>Vict Sex</th>\n",
       "      <th>Vict Descent</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Crime_Class</th>\n",
       "      <th>...</th>\n",
       "      <th>MO_0419</th>\n",
       "      <th>MO_0450</th>\n",
       "      <th>MO_0346</th>\n",
       "      <th>MO_1302</th>\n",
       "      <th>MO_0922</th>\n",
       "      <th>MO_1906</th>\n",
       "      <th>MO_OTHERS</th>\n",
       "      <th>Location_Cluster</th>\n",
       "      <th>Lat_bin</th>\n",
       "      <th>Lon_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1502</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2124</td>\n",
       "      <td>-118.4092</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1521</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.1993</td>\n",
       "      <td>-118.4203</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.1847</td>\n",
       "      <td>-118.4509</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.0339</td>\n",
       "      <td>-118.3747</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>33.9813</td>\n",
       "      <td>-118.4350</td>\n",
       "      <td>Property Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>2103</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>X</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2259</td>\n",
       "      <td>-118.6126</td>\n",
       "      <td>Other Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.0277</td>\n",
       "      <td>-118.1979</td>\n",
       "      <td>Child-Related Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004988</th>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>33.9942</td>\n",
       "      <td>-118.2701</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004989</th>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2450</td>\n",
       "      <td>-118.5233</td>\n",
       "      <td>Violent Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004990</th>\n",
       "      <td>1944</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>34.2722</td>\n",
       "      <td>-118.4417</td>\n",
       "      <td>Sex Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004991 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Rpt Dist No  Part 1-2  Vict Age Vict Sex Vict Descent Status  \\\n",
       "0               1502         2        31        M            H     IC   \n",
       "1               1521         1        32        M            H     IC   \n",
       "2                933         2        30        M            W     IC   \n",
       "3                782         1        47        F            A     IC   \n",
       "4               1454         1        63        M            H     IC   \n",
       "...              ...       ...       ...      ...          ...    ...   \n",
       "1004986         2103         2        35        M            X     IC   \n",
       "1004987          479         2        11        M            B     IC   \n",
       "1004988         1372         2        16        F            H     IC   \n",
       "1004989         1774         2        17        M            H     IC   \n",
       "1004990         1944         2        35        F            H     IC   \n",
       "\n",
       "         Status Desc      LAT       LON          Crime_Class  ... MO_0419  \\\n",
       "0        Invest Cont  34.2124 -118.4092       Property Crime  ...       0   \n",
       "1        Invest Cont  34.1993 -118.4203        Violent Crime  ...       0   \n",
       "2        Invest Cont  34.1847 -118.4509       Property Crime  ...       0   \n",
       "3        Invest Cont  34.0339 -118.3747       Property Crime  ...       0   \n",
       "4        Invest Cont  33.9813 -118.4350       Property Crime  ...       0   \n",
       "...              ...      ...       ...                  ...  ...     ...   \n",
       "1004986  Invest Cont  34.2259 -118.6126          Other Crime  ...       0   \n",
       "1004987  Invest Cont  34.0277 -118.1979  Child-Related Crime  ...       0   \n",
       "1004988  Invest Cont  33.9942 -118.2701            Sex Crime  ...       0   \n",
       "1004989  Invest Cont  34.2450 -118.5233        Violent Crime  ...       0   \n",
       "1004990  Invest Cont  34.2722 -118.4417            Sex Crime  ...       0   \n",
       "\n",
       "         MO_0450  MO_0346  MO_1302  MO_0922  MO_1906  MO_OTHERS  \\\n",
       "0              0        0        0        0        0          1   \n",
       "1              0        0        0        0        0          0   \n",
       "2              0        0        0        0        0          1   \n",
       "3              0        0        0        0        0          0   \n",
       "4              0        0        0        0        0          0   \n",
       "...          ...      ...      ...      ...      ...        ...   \n",
       "1004986        0        0        0        0        0          0   \n",
       "1004987        0        0        0        0        0          1   \n",
       "1004988        0        0        0        0        0          0   \n",
       "1004989        0        0        0        0        0          0   \n",
       "1004990        0        0        0        0        0          1   \n",
       "\n",
       "         Location_Cluster  Lat_bin  Lon_bin  \n",
       "0                      34       49        0  \n",
       "1                      69       49        0  \n",
       "2                      78       49        0  \n",
       "3                      67       49        0  \n",
       "4                      66       49        0  \n",
       "...                   ...      ...      ...  \n",
       "1004986                54       49        0  \n",
       "1004987                57       49        0  \n",
       "1004988                83       49        0  \n",
       "1004989                45       49        0  \n",
       "1004990                30       49        0  \n",
       "\n",
       "[1004991 rows x 115 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "267bcd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1004991 entries, 0 to 1004990\n",
      "Data columns (total 115 columns):\n",
      " #    Column            Dtype  \n",
      "---   ------            -----  \n",
      " 0    Rpt Dist No       int64  \n",
      " 1    Part 1-2          int64  \n",
      " 2    Vict Age          int64  \n",
      " 3    Vict Sex          object \n",
      " 4    Vict Descent      object \n",
      " 5    Status            object \n",
      " 6    Status Desc       object \n",
      " 7    LAT               float64\n",
      " 8    LON               float64\n",
      " 9    Crime_Class       object \n",
      " 10   Weapon_Present    object \n",
      " 11   MO_0397           int32  \n",
      " 12   MO_1813           int32  \n",
      " 13   MO_0443           int32  \n",
      " 14   MO_0421           int32  \n",
      " 15   MO_1309           int32  \n",
      " 16   MO_0701           int32  \n",
      " 17   MO_2004           int32  \n",
      " 18   MO_0447           int32  \n",
      " 19   MO_1266           int32  \n",
      " 20   MO_1501           int32  \n",
      " 21   MO_0561           int32  \n",
      " 22   MO_2028           int32  \n",
      " 23   MO_0319           int32  \n",
      " 24   MO_0202           int32  \n",
      " 25   MO_2021           int32  \n",
      " 26   MO_329            int32  \n",
      " 27   MO_0945           int32  \n",
      " 28   MO_1414           int32  \n",
      " 29   MO_0352           int32  \n",
      " 30   MO_1100           int32  \n",
      " 31   MO_1300           int32  \n",
      " 32   MO_0913           int32  \n",
      " 33   MO_0209           int32  \n",
      " 34   MO_0377           int32  \n",
      " 35   MO_1817           int32  \n",
      " 36   MO_1243           int32  \n",
      " 37   MO_0321           int32  \n",
      " 38   MO_0216           int32  \n",
      " 39   MO_1402           int32  \n",
      " 40   MO_0329           int32  \n",
      " 41   MO_1218           int32  \n",
      " 42   MO_1822           int32  \n",
      " 43   MO_0448           int32  \n",
      " 44   MO_0603           int32  \n",
      " 45   MO_0432           int32  \n",
      " 46   MO_2002           int32  \n",
      " 47   MO_344            int32  \n",
      " 48   MO_1307           int32  \n",
      " 49   MO_1814           int32  \n",
      " 50   MO_2024           int32  \n",
      " 51   MO_0930           int32  \n",
      " 52   MO_0444           int32  \n",
      " 53   MO_1606           int32  \n",
      " 54   MO_0500           int32  \n",
      " 55   MO_0429           int32  \n",
      " 56   MO_0394           int32  \n",
      " 57   MO_1420           int32  \n",
      " 58   MO_0910           int32  \n",
      " 59   MO_0337           int32  \n",
      " 60   MO_325            int32  \n",
      " 61   MO_0355           int32  \n",
      " 62   MO_0928           int32  \n",
      " 63   MO_2032           int32  \n",
      " 64   MO_0430           int32  \n",
      " 65   MO_1202           int32  \n",
      " 66   MO_1310           int32  \n",
      " 67   MO_1407           int32  \n",
      " 68   MO_1607           int32  \n",
      " 69   MO_0302           int32  \n",
      " 70   MO_0360           int32  \n",
      " 71   MO_0408           int32  \n",
      " 72   MO_0100           int32  \n",
      " 73   MO_0305           int32  \n",
      " 74   MO_1251           int32  \n",
      " 75   MO_0342           int32  \n",
      " 76   MO_0929           int32  \n",
      " 77   MO_0334           int32  \n",
      " 78   MO_1259           int32  \n",
      " 79   MO_0104           int32  \n",
      " 80   MO_0445           int32  \n",
      " 81   MO_0361           int32  \n",
      " 82   MO_0358           int32  \n",
      " 83   MO_1810           int32  \n",
      " 84   MO_1602           int32  \n",
      " 85   MO_1206           int32  \n",
      " 86   MO_0385           int32  \n",
      " 87   MO_0356           int32  \n",
      " 88   MO_0411           int32  \n",
      " 89   MO_0522           int32  \n",
      " 90   MO_0906           int32  \n",
      " 91   MO_0446           int32  \n",
      " 92   MO_0417           int32  \n",
      " 93   MO_1258           int32  \n",
      " 94   MO_1601           int32  \n",
      " 95   MO_0416           int32  \n",
      " 96   MO_1212           int32  \n",
      " 97   MO_0431           int32  \n",
      " 98   MO_0325           int32  \n",
      " 99   MO_0344           int32  \n",
      " 100  MO_2000           int32  \n",
      " 101  MO_2038           int32  \n",
      " 102  MO_0400           int32  \n",
      " 103  MO_0602           int32  \n",
      " 104  MO_1609           int32  \n",
      " 105  MO_0419           int32  \n",
      " 106  MO_0450           int32  \n",
      " 107  MO_0346           int32  \n",
      " 108  MO_1302           int32  \n",
      " 109  MO_0922           int32  \n",
      " 110  MO_1906           int32  \n",
      " 111  MO_OTHERS         int32  \n",
      " 112  Location_Cluster  int32  \n",
      " 113  Lat_bin           int64  \n",
      " 114  Lon_bin           int64  \n",
      "dtypes: float64(2), int32(102), int64(5), object(6)\n",
      "memory usage: 490.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_new_1.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdc5844",
   "metadata": {},
   "source": [
    "This creates 2 features:\n",
    "- Lat_bin\n",
    "- Lon_bin\n",
    "\n",
    "Which together form a 2D grid, like “Region (12, 34)”.\n",
    "\n",
    "This is good for:\n",
    "- linear models\n",
    "- tree models\n",
    "- giant datasets\n",
    "- preserving spatial structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9023af8a",
   "metadata": {},
   "source": [
    "### 🟢 Combining Both Is Even Better\n",
    "\n",
    "Crime prediction systems often use:\n",
    "\n",
    "✔ Location_Cluster (KMeans)\n",
    "\n",
    "✔ Lat_bin + Lon_bin (50x50 grid)\n",
    "\n",
    "This gives:\n",
    "- global structure (clusters)\n",
    "- local structure (grid bins)\n",
    "- Without storing raw LAT/LON."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c974ec88",
   "metadata": {},
   "source": [
    "#### Function for Plotting Confusion Matrix. You'll be using this later, so intialize it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45d055a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def plot_crime_matrix(y_test, y_pred, model_name=\"Model\", labels=None):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix with counts and percentages.\n",
    "    \"\"\"\n",
    "    # Compute matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Calculate percentages for the heatmap annotations\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=annot, fmt='', cmap='Blues', \n",
    "                xticklabels=labels if labels is not None else \"auto\",\n",
    "                yticklabels=labels if labels is not None else \"auto\")\n",
    "    plt.title(f'Confusion Matrix: {model_name}')\n",
    "    plt.ylabel('Actual Crime Class')\n",
    "    plt.xlabel('Predicted Crime Class')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e95c6c",
   "metadata": {},
   "source": [
    "## Part A - Remodelling with Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cfdaf0",
   "metadata": {},
   "source": [
    "Now, let's try building the Models again.\n",
    "\n",
    "### Tree-Based: Decision Tree (Processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458319a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# Convert datetime columns to int64 timestamps\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view('int64')\n",
    "\n",
    "# Convert list columns to strings so they can be factorized\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test_dt = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "dt_model_3 = DecisionTreeClassifier()\n",
    "dt_model_3.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_dt = dt_model_3.predict(X_test)\n",
    "y_pred_train = dt_model_3.predict(X_train)\n",
    "\n",
    "# Evaluation\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_dt, y_pred_dt, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test_dt, y_pred_dt)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a71a1e",
   "metadata": {},
   "source": [
    "A highly Noticeable increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33dad2e",
   "metadata": {},
   "source": [
    "Now, let's plot the Error vs Complexity curve.\n",
    "\n",
    "This first one shall use a stratified sampling approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c313d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import validation_curve\n",
    "import numpy as np\n",
    "\n",
    "# Compute log-loss for Decision Tree\n",
    "train_loss = log_loss(y_train, dt_model_3.predict_proba(X_train))\n",
    "test_loss  = log_loss(y_test,  dt_model_3.predict_proba(X_test))\n",
    "\n",
    "print(\"------------------------\")\n",
    "print(\"Decision Tree Log Loss\")\n",
    "print(\"------------------------\")\n",
    "print(\"Training Loss:\")\n",
    "print(train_loss)\n",
    "print(\"------------------------\")\n",
    "print(\"Testing Loss:\")\n",
    "print(test_loss)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# Gap analysis\n",
    "acc_gap  = train_accuracy - test_accuracy\n",
    "loss_gap = test_loss - train_loss\n",
    "\n",
    "print(\"Accuracy Gap (Train - Test):\")\n",
    "print(acc_gap)\n",
    "print(\"------------------------\")\n",
    "print(\"Loss Gap (Test - Train):\")\n",
    "print(loss_gap)\n",
    "print(\"------------------------\")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 1. FAST STRATIFIED SUBSAMPLING\n",
    "# ================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Take only 5% of the data (tweak 0.05 → 0.02 or 0.01 if still slow)\n",
    "sample_ratio = 0.25  \n",
    "X_small, _, y_small, _ = train_test_split(\n",
    "    X, y, \n",
    "    train_size=sample_ratio, \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split the small subset into train/test\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n",
    "    X_small, y_small,\n",
    "    test_size=0.3,\n",
    "    stratify=y_small,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ==================================\n",
    "# 2. MODEL COMPLEXITY VS ERROR\n",
    "# ==================================\n",
    "depths = range(2, 41, 2)\n",
    "train_losses_curve = []\n",
    "test_losses_curve = []\n",
    "train_acc_curve = []\n",
    "test_acc_curve = []\n",
    "\n",
    "for d in depths:\n",
    "    model = DecisionTreeClassifier(max_depth=d)\n",
    "\n",
    "    # Fit on *small* dataset\n",
    "    model.fit(X_train_s, y_train_s)\n",
    "\n",
    "    # Probabilities\n",
    "    train_proba = model.predict_proba(X_train_s)\n",
    "    test_proba  = model.predict_proba(X_test_s)\n",
    "\n",
    "    # Loss\n",
    "    train_losses_curve.append(log_loss(y_train_s, train_proba))\n",
    "    test_losses_curve.append(log_loss(y_test_s, test_proba))\n",
    "\n",
    "    # Accuracy\n",
    "    y_train_pred = model.predict(X_train_s)\n",
    "    y_test_pred  = model.predict(X_test_s)\n",
    "\n",
    "    train_acc_curve.append(accuracy_score(y_train_s, y_train_pred))\n",
    "    test_acc_curve.append(accuracy_score(y_test_s, y_test_pred))\n",
    "\n",
    "# ================================\n",
    "# 3. PLOT\n",
    "# ================================\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(depths, train_losses_curve, label=\"Training Loss\")\n",
    "plt.plot(depths, test_losses_curve, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Model Complexity (max_depth)\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.title(\"Model Complexity vs Error (Decision Tree)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc96aa6",
   "metadata": {},
   "source": [
    "The second one will use all rows present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f40206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Convert y → Series so we can subsample safely\n",
    "# ----------------------------------------------------\n",
    "y_train = pd.Series(y_train).reset_index(drop=True)\n",
    "y_test  = pd.Series(y_test).reset_index(drop=True)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test  = X_test.reset_index(drop=True)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Subsample 250k rows for faster computation\n",
    "# ----------------------------------------------------\n",
    "sample_size = min(250_000, len(X_train), len(X_test))\n",
    "\n",
    "X_train_sub = X_train.sample(sample_size, random_state=42)\n",
    "y_train_sub = y_train.loc[X_train_sub.index]\n",
    "\n",
    "X_test_sub = X_test.sample(sample_size, random_state=42)\n",
    "y_test_sub = y_test.loc[X_test_sub.index]\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Complexity levels (same as original)\n",
    "# ----------------------------------------------------\n",
    "complexity_values = [5, 10, 15, 20, 25, 30, 35, None]\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(\"=== Generating Decision Tree Log-Loss vs Complexity Curve ===\")\n",
    "\n",
    "for depth in complexity_values:\n",
    "    print(f\"Training Decision Tree with max_depth={depth}\")\n",
    "\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        max_depth=depth,\n",
    "        random_state=42  # no tuning params, just default DT\n",
    "    )\n",
    "    \n",
    "    dt_model.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "    # Predict probs so we can compute log-loss\n",
    "    train_proba = dt_model.predict_proba(X_train_sub)\n",
    "    test_proba  = dt_model.predict_proba(X_test_sub)\n",
    "\n",
    "    train_losses.append(log_loss(y_train_sub, train_proba))\n",
    "    test_losses.append(log_loss(y_test_sub, test_proba))\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# PLOT\n",
    "# ----------------------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([str(d) for d in complexity_values], train_losses, marker='o', label=\"Training Log Loss\")\n",
    "plt.plot([str(d) for d in complexity_values], test_losses, marker='o', label=\"Testing Log Loss\")\n",
    "\n",
    "plt.xlabel(\"Model Complexity (max_depth)\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.title(\"Decision Tree Log-Loss vs Complexity Curve (Subsample 250k)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612f0c95",
   "metadata": {},
   "source": [
    "### Evaluate Feature Importance (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a46b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = dt_model_3.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "fi = pd.DataFrame({\"feature\": features, \"importance\": importance})\n",
    "fi.sort_values(by=\"importance\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47321775",
   "metadata": {},
   "source": [
    "### Perform Shuffle Split Validation to verify the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aabe00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== Decision Tree Cross-Validation: Stratified Shuffle-Split ===\")\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        max_depth=6,      # similar to XGB's depth, tweak as needed\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    dt_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = dt_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Mean Accuracy:  \", np.mean(accuracies))\n",
    "print(\"Std Deviation: \", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4d5cca",
   "metadata": {},
   "source": [
    "Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4058a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the class names (optional, makes the plot readable)\n",
    "crime_labels = df_new_1[\"Crime_Class\"].unique()\n",
    "crime_labels.sort() # Ensure they are in the same order as factorize usually does\n",
    "\n",
    "# 2. Plot the matrix\n",
    "# Ensure you pass the predictions you just made (y_pred_test)\n",
    "plot_crime_matrix(y_test_dt, y_pred_dt, model_name=\"Decision Tree\", labels=crime_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a9ccd",
   "metadata": {},
   "source": [
    "### Tree-Based: Random Forest (Processed)\n",
    "\n",
    "*Yawn..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f5a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Random Forest Crime Classification (PROCESSED) ===\")\n",
    "\n",
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# Convert datetime columns to int64 timestamps\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view('int64')\n",
    "\n",
    "# Convert list columns to strings so they can be factorized\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Fill any remaining NaN values before training\n",
    "X = X.fillna(-1)\n",
    "\n",
    "# Train-test split (stratify for class balance)\n",
    "X_train, X_test, y_train, y_test_rf = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train model (Correctly named rf_model_3)\n",
    "rf_model_3 = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "rf_model_3.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_rf = rf_model_3.predict(X_test)\n",
    "y_pred_train_rf = rf_model_3.predict(X_train)\n",
    "\n",
    "# Evaluation\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_rf, y_pred_rf, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_rf, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_rf)\n",
    "test_accuracy = accuracy_score(y_test_rf, y_pred_rf)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(f\"Overfit Gap:          {train_accuracy - test_accuracy:.4f}\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8800fb9",
   "metadata": {},
   "source": [
    "A respectful increment.\n",
    "\n",
    "### Now, let's validate the results:\n",
    "\n",
    "Since RF is a very complex and time consuming ML, we'll need to use alternatie validation methods to ensure time and compuational efficiency.\n",
    "\n",
    "Method 1: Use Subsamples for Cross Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad75f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Take a manageable subsample\n",
    "sample_size = 100_000\n",
    "X_sub = X.sample(sample_size, random_state=42)\n",
    "y_sub = y[X_sub.index]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accs = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in skf.split(X_sub, y_sub):\n",
    "    X_train, X_test = X_sub.iloc[train_idx], X_sub.iloc[test_idx]\n",
    "    y_train, y_test = y_sub[train_idx], y_sub[test_idx]\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    acc = accuracy_score(y_test, rf.predict(X_test))\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    accs.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"K-Fold CV Accuracy Mean:\", np.mean(accs))\n",
    "print(\"Std:\", np.std(accs))\n",
    "print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ff5e71",
   "metadata": {},
   "source": [
    "Method 2: Use Stratified Shuffle-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16fbcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== Random Forest Cross-Validation: Stratified Shuffle-Split ===\")\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Mean Accuracy:  \", np.mean(accuracies))\n",
    "print(\"Std Deviation: \", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24436283",
   "metadata": {},
   "source": [
    "Plot the error versus complexity curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67f4576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# --- 1. Subsample the data to 250k ---\n",
    "print(\"=== Subsampling Training Data ===\")\n",
    "# We verify we have enough data, then sample 250k without replacement\n",
    "n_samples = min(100000, len(X_train))\n",
    "X_train_sub, y_train_sub = resample(\n",
    "    X_train, y_train, \n",
    "    n_samples=n_samples, \n",
    "    replace=False, \n",
    "    random_state=42\n",
    ")\n",
    "print(f\"Training data reduced to: {X_train_sub.shape[0]} samples\")\n",
    "\n",
    "# --- 2. Define Depth Range (Complexity) ---\n",
    "# We range from depth 1 (very simple) to 25 (very complex)\n",
    "depth_settings = range(1, 501) #Adjust to larger value range if needed\n",
    "\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "print(\"=== Generating Error vs Complexity (Max Depth) Curve ===\")\n",
    "\n",
    "for d in depth_settings:\n",
    "    print(f\"Training model with max_depth={d}\")\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=50,  # Fixed: We isolate depth as the variable\n",
    "        max_depth=d,      # Variable: This controls complexity\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Fit on the subsampled data\n",
    "    rf.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "    # Predict\n",
    "    train_pred = rf.predict(X_train_sub)\n",
    "    test_pred  = rf.predict(X_test)\n",
    "\n",
    "    # Compute error (1 - accuracy)\n",
    "    train_err = 1 - accuracy_score(y_train_sub, train_pred)\n",
    "    test_err  = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "    train_errors.append(train_err)\n",
    "    test_errors.append(test_err)\n",
    "\n",
    "# --- 3. Plot ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plotting the curves\n",
    "plt.plot(depth_settings, train_errors, marker='o', label=\"Training Error\", color='blue')\n",
    "plt.plot(depth_settings, test_errors, marker='o', label=\"Testing Error\", color='red')\n",
    "\n",
    "# Formatting\n",
    "plt.xlabel(\"Model Complexity (max_depth)\")\n",
    "plt.ylabel(\"Error (1 - Accuracy)\")\n",
    "plt.title(\"Random Forest: Error vs. Max Depth\")\n",
    "plt.xticks(depth_settings) # Ensure we see all depth ticks\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf98a0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    " ### Evaluate Feature Importance (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa4a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Feature Importance\n",
    "# -------------------------------------------\n",
    "importance = rf_model_3.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "fi = pd.DataFrame({\"feature\": features, \"importance\": importance})\n",
    "fi.sort_values(by=\"importance\", ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72983ed",
   "metadata": {},
   "source": [
    "Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02616d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the class names (optional, makes the plot readable)\n",
    "crime_labels = df_new_1[\"Crime_Class\"].unique()\n",
    "crime_labels.sort() # Ensure they are in the same order as factorize usually does\n",
    "\n",
    "# 2. Plot the matrix\n",
    "# Ensure you pass the predictions you just made (y_pred_test)\n",
    "plot_crime_matrix(y_test_rf, y_pred_rf, model_name=\"Random Forest\", labels=crime_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6c21b4",
   "metadata": {},
   "source": [
    "### Probabilistic: Logistic Regression (Processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e08e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. Setup Data\n",
    "# (Assuming df_new_1 is already loaded)\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# 2. Prepare X and y\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# 3. Pre-processing (Memory Safe Version)\n",
    "\n",
    "# A. Convert datetimes to int64 (if any exist)\n",
    "# Using 'view' on datetimes is fast and memory efficient\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].values.astype(np.int64)\n",
    "\n",
    "# B. Convert list columns to strings\n",
    "# (Necessary because lists are not hashable and break many functions)\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# C. Factorize Objects (The \"Pro\" way to avoid MemoryError)\n",
    "# We loop instead of using .apply() to save RAM\n",
    "print(\"Encoding columns...\")\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].astype('category').cat.codes\n",
    "\n",
    "# D. Handle Missing Values\n",
    "# Logistic Regression cannot handle NaNs. \n",
    "# Since we used cat.codes, NaNs are already -1, but we ensure everything is numeric.\n",
    "X = X.fillna(-1)\n",
    "\n",
    "# 4. Train-test split\n",
    "X_train, X_test, y_train, y_test_lr = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 5. Scale features \n",
    "# Logistic Regression works best when features are on the same scale (e.g., -1 to 1)\n",
    "print(\"Scaling data...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 6. Build Logistic Regression Model\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr_model_1 = LogisticRegression() # Default parameters\n",
    "\n",
    "# Train model\n",
    "lr_model_1.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 7. Predict\n",
    "print(\"Predicting...\")\n",
    "y_pred_train_1 = lr_model_1.predict(X_train_scaled)\n",
    "y_pred_test_lr = lr_model_1.predict(X_test_scaled)\n",
    "\n",
    "# 8. Evaluation\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_lr, y_pred_test_lr, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_1)\n",
    "test_accuracy = accuracy_score(y_test_lr, y_pred_test_lr)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc56fd44",
   "metadata": {},
   "source": [
    "Evaluate Feature Importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Feature Importance (Logistic Regression)\n",
    "# -------------------------------------------\n",
    "# We take the mean absolute value of coefficients across all classes\n",
    "importance = np.mean(np.abs(lr_model_1.coef_), axis=0) \n",
    "features = X.columns\n",
    "\n",
    "fi_lr = pd.DataFrame({\"feature\": features, \"importance\": importance})\n",
    "# This outputs the dataframe exactly like your RF example\n",
    "fi_lr.sort_values(by=\"importance\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76cdc8c",
   "metadata": {},
   "source": [
    "### Probabilistic: Naive Bayes (Processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4d4a1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding columns...\n",
      "Scaling data (MinMax)...\n",
      "Training Multinomial Naive Bayes...\n",
      "Predicting...\n",
      "Training Set Accuracy: 0.8719802471382089\n",
      "Testing Set Accuracy: 0.8714087655639506\n",
      "------------------------------------------------------------------------------------\n",
      "Training Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score       support\n",
      "0              0.935688  0.916351  0.925919  356035.00000\n",
      "1              0.887071  0.902810  0.894871  163391.00000\n",
      "2              0.672537  0.514909  0.583261   44202.00000\n",
      "3              0.822132  0.945309  0.879428   86340.00000\n",
      "4              0.502317  0.629864  0.558906   13595.00000\n",
      "5              0.778236  0.500845  0.609462    8282.00000\n",
      "6              0.903331  0.895311  0.899303   15207.00000\n",
      "7              0.535385  0.596242  0.564177   13944.00000\n",
      "8              0.084507  0.022222  0.035191     540.00000\n",
      "9              0.278846  0.326009  0.300589    1957.00000\n",
      "accuracy       0.871980  0.871980  0.871980       0.87198\n",
      "macro avg      0.640005  0.624987  0.625111  703493.00000\n",
      "weighted avg   0.872582  0.871980  0.870485  703493.00000\n",
      "------------------------------------------------------------------------------------\n",
      "Testing Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.935207  0.915792  0.925398  152409.000000\n",
      "1              0.887191  0.903518  0.895280   70096.000000\n",
      "2              0.670006  0.507858  0.577771   18834.000000\n",
      "3              0.821006  0.945290  0.878775   37105.000000\n",
      "4              0.500340  0.629541  0.557554    5836.000000\n",
      "5              0.789934  0.503066  0.614677    3588.000000\n",
      "6              0.903037  0.892444  0.897709    6564.000000\n",
      "7              0.535805  0.596552  0.564549    6033.000000\n",
      "8              0.000000  0.000000  0.000000     206.000000\n",
      "9              0.248980  0.295042  0.270061     827.000000\n",
      "accuracy       0.871409  0.871409  0.871409       0.871409\n",
      "macro avg      0.629151  0.618910  0.618177  301498.000000\n",
      "weighted avg   0.872062  0.871409  0.869871  301498.000000\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler  # <--- Changed from StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB   # <--- The Model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. Setup Data\n",
    "# (Assuming df_new_1 is already loaded)\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# 2. Prepare X and y\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# 3. Pre-processing (Memory Safe Version)\n",
    "\n",
    "# A. Convert datetimes to int64\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].values.astype(np.int64)\n",
    "\n",
    "# B. Convert list columns to strings\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# C. Factorize Objects (Using cat.codes for memory efficiency)\n",
    "print(\"Encoding columns...\")\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].astype('category').cat.codes\n",
    "\n",
    "# D. Handle Missing Values\n",
    "# We stick to your logic, but Naive Bayes hates -1.\n",
    "# We will fix the -1s in the Scaling step below.\n",
    "X = X.fillna(-1)\n",
    "\n",
    "# 4. Train-test split\n",
    "X_train, X_test, y_train, y_test_nb = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 5. Scale features \n",
    "# CRITICAL CHANGE: MultinomialNB fails with negative numbers.\n",
    "# StandardScaler produces negatives. MinMaxScaler (0, 1) fixes this.\n",
    "print(\"Scaling data (MinMax)...\")\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 6. Build Naive Bayes Model\n",
    "print(\"Training Multinomial Naive Bayes...\")\n",
    "nb_model_1 = MultinomialNB() \n",
    "\n",
    "# Train model\n",
    "nb_model_1.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 7. Predict\n",
    "print(\"Predicting...\")\n",
    "y_pred_train_1 = nb_model_1.predict(X_train_scaled)\n",
    "y_pred_test_nb = nb_model_1.predict(X_test_scaled)\n",
    "\n",
    "# 8. Evaluation\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_nb, y_pred_test_nb, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_1)\n",
    "test_accuracy = accuracy_score(y_test_nb, y_pred_test_nb)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be396b4f",
   "metadata": {},
   "source": [
    "Evaluate Feature Importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0b8c152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>MO_0344</td>\n",
       "      <td>0.057695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vict Sex</td>\n",
       "      <td>0.046990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Part 1-2</td>\n",
       "      <td>0.042784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Weapon_Present</td>\n",
       "      <td>0.040625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>MO_0416</td>\n",
       "      <td>0.037799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vict Descent</td>\n",
       "      <td>0.037789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>MO_1822</td>\n",
       "      <td>0.030837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>MO_OTHERS</td>\n",
       "      <td>0.020096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MO_0913</td>\n",
       "      <td>0.019521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>MO_2038</td>\n",
       "      <td>0.018701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MO_0329</td>\n",
       "      <td>0.017866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>MO_0400</td>\n",
       "      <td>0.016326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>MO_0334</td>\n",
       "      <td>0.012371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>MO_2000</td>\n",
       "      <td>0.011752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>MO_344</td>\n",
       "      <td>0.010095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>MO_0444</td>\n",
       "      <td>0.009847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>MO_0446</td>\n",
       "      <td>0.008067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>MO_0325</td>\n",
       "      <td>0.007694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>MO_1906</td>\n",
       "      <td>0.007442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MO_0421</td>\n",
       "      <td>0.006975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  importance\n",
       "98          MO_0344    0.057695\n",
       "3          Vict Sex    0.046990\n",
       "1          Part 1-2    0.042784\n",
       "9    Weapon_Present    0.040625\n",
       "94          MO_0416    0.037799\n",
       "4      Vict Descent    0.037789\n",
       "41          MO_1822    0.030837\n",
       "110       MO_OTHERS    0.020096\n",
       "31          MO_0913    0.019521\n",
       "100         MO_2038    0.018701\n",
       "39          MO_0329    0.017866\n",
       "101         MO_0400    0.016326\n",
       "76          MO_0334    0.012371\n",
       "99          MO_2000    0.011752\n",
       "46           MO_344    0.010095\n",
       "51          MO_0444    0.009847\n",
       "90          MO_0446    0.008067\n",
       "97          MO_0325    0.007694\n",
       "109         MO_1906    0.007442\n",
       "13          MO_0421    0.006975"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# -------------------------------------------\n",
    "# Feature Importance (Naive Bayes)\n",
    "# -------------------------------------------\n",
    "# Calculate importance (this mimics the .feature_importances_ behavior)\n",
    "perm_importance = permutation_importance(nb_model_1, X_test_scaled, y_test_nb, random_state=42)\n",
    "importance = perm_importance.importances_mean\n",
    "features = X.columns\n",
    "\n",
    "fi_nb = pd.DataFrame({\"feature\": features, \"importance\": importance})\n",
    "# This outputs the dataframe exactly like your RF example\n",
    "fi_nb.sort_values(by=\"importance\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89b6040",
   "metadata": {},
   "source": [
    "Perform Shuffle-Split Validation for both LR anmd NB models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c2f867a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================\n",
      "2. Multinomial Naive Bayes Validation (MinMaxScaler)\n",
      "=========================================================\n",
      "Fold 1: Accuracy = 0.8724\n",
      "Fold 2: Accuracy = 0.8719\n",
      "Fold 3: Accuracy = 0.8728\n",
      "Fold 4: Accuracy = 0.8714\n",
      "Fold 5: Accuracy = 0.8723\n",
      "NB Mean Accuracy:  0.87216764\n",
      "NB Std Deviation:  0.00048680\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Splitter (Same for both)\n",
    "# 5 Splits is a good balance between speed and reliability\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "#print(\"=========================================================\")\n",
    "#print(\"1. Logistic Regression Validation (StandardScaler)\")\n",
    "#print(\"=========================================================\")\n",
    "\n",
    "#lr_accuracies = []\n",
    "#fold = 1\n",
    "\n",
    "#for train_idx, test_idx in sss.split(X, y):\n",
    "    # 1. Slice Data (Memory efficient indexing)\n",
    "    #X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    #y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # 2. Scale (Critical: Fit on Train, Transform Test)\n",
    "    # StandardScaler is best for Logistic Regression speed/convergence\n",
    "    #scaler = StandardScaler()\n",
    "    #X_train_scaled = scaler.fit_transform(X_train)\n",
    "    #X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 3. Train (n_jobs=-1 uses all CPU cores for speed)\n",
    "    #lr = LogisticRegression(n_jobs=-1) \n",
    "    #lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # 4. Score\n",
    "    # acc = accuracy_score(y_test, lr.predict(X_test_scaled))\n",
    "    \n",
    "    #print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    #lr_accuracies.append(acc)\n",
    "    #fold += 1\n",
    "\n",
    "#print(f\"LR Mean Accuracy:  {np.mean(lr_accuracies):.8f}\")\n",
    "#print(f\"LR Std Deviation:  {np.std(lr_accuracies):.8f}\")\n",
    "\n",
    "\n",
    "print(\"\\n=========================================================\")\n",
    "print(\"2. Multinomial Naive Bayes Validation (MinMaxScaler)\")\n",
    "print(\"=========================================================\")\n",
    "\n",
    "nb_accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    # 1. Slice Data\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # 2. Scale (MinMaxScaler is REQUIRED for NB to avoid negative errors)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 3. Train\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # 4. Score\n",
    "    acc = accuracy_score(y_test, nb.predict(X_test_scaled))\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    nb_accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(f\"NB Mean Accuracy:  {np.mean(nb_accuracies):.8f}\")\n",
    "print(f\"NB Std Deviation:  {np.std(nb_accuracies):.8f}\")\n",
    "print(\"---------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25ec7ec",
   "metadata": {},
   "source": [
    "Plot the error vs complexity curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf383954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import validation_curve, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# ==========================================\n",
    "# 1. Prepare Data (250K Subsample)\n",
    "# ==========================================\n",
    "print(\"Subsampling 250k rows...\")\n",
    "# Sample first to save time on preprocessing\n",
    "df_sub = df_new_1.sample(n=250000, random_state=42).copy()\n",
    "\n",
    "# Clean up leakage columns\n",
    "drop_cols = [\n",
    "    \"Crm Cd Desc\", \"Crm Cd\", \"Premis Cd\", \"Premis Desc\",\n",
    "    \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\", \"Crime_Class\"\n",
    "]\n",
    "cols_to_drop = [c for c in drop_cols if c in df_sub.columns]\n",
    "\n",
    "# Prepare X and y\n",
    "y, _ = pd.factorize(df_sub[\"Crime_Class\"])\n",
    "X = df_sub.drop(columns=cols_to_drop) # Drop target + leakage\n",
    "\n",
    "# --- Preprocessing (Optimized) ---\n",
    "# 1. Convert datetimes to int64\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].values.astype(np.int64)\n",
    "\n",
    "# 2. Convert list columns to strings\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# 3. Factorize Objects (cat.codes)\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].astype('category').cat.codes\n",
    "\n",
    "# 4. Handle NaNs/Negatives\n",
    "# Logistic Regression handles -1 fine (as a number), \n",
    "# but NB needs positive. We'll rely on MinMaxScaler for NB later.\n",
    "X = X.fillna(-1)\n",
    "\n",
    "# ==========================================\n",
    "# 2. Setup Models & Validation\n",
    "# ==========================================\n",
    "\n",
    "# Splitter: 3 splits is enough for a curve plot (saves time vs 5)\n",
    "cv_split = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "\n",
    "# Pipeline 1: Logistic Regression (Standard Scaler)\n",
    "pipe_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LogisticRegression(max_iter=1000, n_jobs=-1))\n",
    "])\n",
    "# Test C from 0.001 (Simple) to 100 (Complex)\n",
    "param_range_lr = np.logspace(-3, 5, 9) \n",
    "\n",
    "# Pipeline 2: Naive Bayes (MinMax Scaler)\n",
    "pipe_nb = Pipeline([\n",
    "    ('scaler', MinMaxScaler()), # Fixes negative numbers for NB\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "# Test Alpha from 0.001 (Complex) to 100 (Simple)\n",
    "param_range_nb = np.logspace(-3, 5, 9) \n",
    "\n",
    "# ==========================================\n",
    "# 3. Compute Curves\n",
    "# ==========================================\n",
    "print(\"Computing LR Complexity Curve...\")\n",
    "train_scores_lr, test_scores_lr = validation_curve(\n",
    "    pipe_lr, X, y, \n",
    "    param_name=\"lr__C\", \n",
    "    param_range=param_range_lr,\n",
    "    scoring=\"neg_log_loss\", \n",
    "    cv=cv_split, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Computing NB Complexity Curve...\")\n",
    "train_scores_nb, test_scores_nb = validation_curve(\n",
    "    pipe_nb, X, y, \n",
    "    param_name=\"nb__alpha\", \n",
    "    param_range=param_range_nb,\n",
    "    scoring=\"neg_log_loss\", \n",
    "    cv=cv_split, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Helper to process scores (flip sign for Log Loss)\n",
    "def process_scores(scores):\n",
    "    return -np.mean(scores, axis=1), np.std(scores, axis=1)\n",
    "\n",
    "train_mean_lr, train_std_lr = process_scores(train_scores_lr)\n",
    "test_mean_lr, test_std_lr = process_scores(test_scores_lr)\n",
    "train_mean_nb, train_std_nb = process_scores(train_scores_nb)\n",
    "test_mean_nb, test_std_nb = process_scores(test_scores_nb)\n",
    "\n",
    "# ==========================================\n",
    "# 4. Plotting\n",
    "# ==========================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# LR Plot\n",
    "axes[0].plot(param_range_lr, train_mean_lr, label=\"Training\", color=\"darkorange\", marker='o')\n",
    "axes[0].plot(param_range_lr, test_mean_lr, label=\"Validation\", color=\"navy\", marker='o')\n",
    "axes[0].fill_between(param_range_lr, train_mean_lr - train_std_lr, train_mean_lr + train_std_lr, alpha=0.2, color=\"darkorange\")\n",
    "axes[0].fill_between(param_range_lr, test_mean_lr - test_std_lr, test_mean_lr + test_std_lr, alpha=0.2, color=\"navy\")\n",
    "axes[0].set_title(\"Logistic Regression (Parameter: C)\")\n",
    "axes[0].set_xlabel(\"C (Low=Regulated, High=Complex)\")\n",
    "axes[0].set_ylabel(\"Log Loss (Lower is Better)\")\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# NB Plot\n",
    "axes[1].plot(param_range_nb, train_mean_nb, label=\"Training\", color=\"darkorange\", marker='o')\n",
    "axes[1].plot(param_range_nb, test_mean_nb, label=\"Validation\", color=\"navy\", marker='o')\n",
    "axes[1].fill_between(param_range_nb, train_mean_nb - train_std_nb, train_mean_nb + train_std_nb, alpha=0.2, color=\"darkorange\")\n",
    "axes[1].fill_between(param_range_nb, test_mean_nb - test_std_nb, test_mean_nb + test_std_nb, alpha=0.2, color=\"navy\")\n",
    "axes[1].set_title(\"Naive Bayes (Parameter: Alpha)\")\n",
    "axes[1].set_xlabel(\"Alpha (Low=Complex, High=Smoothed)\")\n",
    "axes[1].set_ylabel(\"Log Loss (Lower is Better)\")\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbf6876",
   "metadata": {},
   "source": [
    "Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a89826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the class names (optional, makes the plot readable)\n",
    "crime_labels = df_new_1[\"Crime_Class\"].unique()\n",
    "crime_labels.sort() # Ensure they are in the same order as factorize usually does\n",
    "\n",
    "# 2. Plot the matrix\n",
    "# Ensure you pass the predictions you just made (y_pred_test)\n",
    "plot_crime_matrix(y_test_lr, y_pred_test_lr, model_name=\"Logistic Regression\", labels=crime_labels)\n",
    "plot_crime_matrix(y_test_nb, y_pred_test_nb, model_name=\"Naive Bayes\", labels=crime_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62141b4e",
   "metadata": {},
   "source": [
    "### XGBoost (Processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "485fa506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 0.919119308934133\n",
      "Testing Set Accuracy: 0.91422165321163\n",
      "------------------------------------------------------------------------------------\n",
      "Training Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.954798  0.936492  0.945556  356035.000000\n",
      "1              0.942310  0.977398  0.959533  163391.000000\n",
      "2              0.853089  0.653568  0.740117   44202.000000\n",
      "3              0.819946  0.959775  0.884367   86340.000000\n",
      "4              0.807254  0.792350  0.799733   13595.000000\n",
      "5              0.877943  0.612292  0.721440    8282.000000\n",
      "6              0.944452  0.936937  0.940679   15207.000000\n",
      "7              0.737597  0.737808  0.737703   13944.000000\n",
      "8              0.948718  0.068519  0.127807     540.000000\n",
      "9              0.770142  0.664282  0.713306    1957.000000\n",
      "accuracy       0.919119  0.919119  0.919119       0.919119\n",
      "macro avg      0.865625  0.733942  0.757024  703493.000000\n",
      "weighted avg   0.920153  0.919119  0.917429  703493.000000\n",
      "------------------------------------------------------------------------------------\n",
      "Testing Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.952644  0.934636  0.943554  152409.000000\n",
      "1              0.937334  0.973693  0.955168   70096.000000\n",
      "2              0.828845  0.634066  0.718489   18834.000000\n",
      "3              0.817575  0.956852  0.881747   37105.000000\n",
      "4              0.788377  0.771761  0.779981    5836.000000\n",
      "5              0.852433  0.590858  0.697942    3588.000000\n",
      "6              0.934061  0.925807  0.929916    6564.000000\n",
      "7              0.724428  0.713741  0.719045    6033.000000\n",
      "8              0.400000  0.009709  0.018957     206.000000\n",
      "9              0.723724  0.582830  0.645680     827.000000\n",
      "accuracy       0.914222  0.914222  0.914222       0.914222\n",
      "macro avg      0.795942  0.709395  0.729048  301498.000000\n",
      "weighted avg   0.914380  0.914222  0.912261  301498.000000\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# ---- FIX 1: Convert datetime columns to int64 ----\n",
    "for col in X.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "# ---- FIX 2: Convert lists → strings to make them hashable ----\n",
    "for col in X.columns:\n",
    "\t    if X[col].dtype == 'object':\n",
    "\t        X[col] = X[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "# ---- Factorize object columns ----\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test_xgb = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model_2 = XGBClassifier()\n",
    "\n",
    "xgb_model_2.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = xgb_model_2.predict(X_train)\n",
    "y_pred_xgb = xgb_model_2.predict(X_test)\n",
    "\n",
    "# Evaluation reports\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_xgb, y_pred_xgb, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test_xgb, y_pred_xgb)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e2848",
   "metadata": {},
   "source": [
    "Good Increase.\n",
    "\n",
    "### Validate the results:\n",
    "\n",
    "We'll apply the samne validation methods to ensure time and compuational efficiency.\n",
    "\n",
    "Method 1: Use Subsamples for Cross Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6d9fc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost Stratified K-Fold Validation ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:15:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy = 0.9069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:16:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: Accuracy = 0.9064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:16:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: Accuracy = 0.9024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:16:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: Accuracy = 0.9064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:16:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: Accuracy = 0.9067\n",
      "---------------------------------------------------------\n",
      "K-Fold CV Accuracy Mean: 0.90578\n",
      "Std: 0.0016984110221027224\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Take a manageable subsample\n",
    "sample_size = 100_000\n",
    "X_sub = X.sample(sample_size, random_state=42)\n",
    "y_sub = y[X_sub.index]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accs = []\n",
    "fold = 1\n",
    "\n",
    "print(\"=== XGBoost Stratified K-Fold Validation ===\")\n",
    "\n",
    "for train_idx, test_idx in skf.split(X_sub, y_sub):\n",
    "    X_train, X_test = X_sub.iloc[train_idx], X_sub.iloc[test_idx]\n",
    "    y_train, y_test = y_sub[train_idx], y_sub[test_idx]\n",
    "\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=100,           # you can adjust\n",
    "        max_depth=6,                # default is 6\n",
    "        learning_rate=0.1,          # default\n",
    "        n_jobs=-1,\n",
    "        use_label_encoder=False,    # avoids warning\n",
    "        eval_metric=\"mlogloss\",     # for multiclass\n",
    "        tree_method=\"hist\",         # faster for large datasets\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    acc = accuracy_score(y_test, xgb_model.predict(X_test))\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    accs.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"K-Fold CV Accuracy Mean:\", np.mean(accs))\n",
    "print(\"Std:\", np.std(accs))\n",
    "print(\"---------------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baef29af",
   "metadata": {},
   "source": [
    "Method 2: Use Stratified Shuffle-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c75c6139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost Cross-Validation: Stratified Shuffle-Split ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:16:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy = 0.9089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:18:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: Accuracy = 0.9090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:19:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: Accuracy = 0.9085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:20:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: Accuracy = 0.9085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:21:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: Accuracy = 0.9092\n",
      "---------------------------------------------------------\n",
      "Mean Accuracy:   0.9088086819813066\n",
      "Std Deviation:  0.00027582301235842414\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== XGBoost Cross-Validation: Stratified Shuffle-Split ===\")\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=100,           # adjust as needed\n",
    "        max_depth=6,                # adjust as needed\n",
    "        learning_rate=0.1,\n",
    "        n_jobs=-1,\n",
    "        use_label_encoder=False,    # avoids warning\n",
    "        eval_metric=\"mlogloss\",     # suitable for multiclass\n",
    "        tree_method=\"hist\",         # faster for large datasets\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Mean Accuracy:  \", np.mean(accuracies))\n",
    "print(\"Std Deviation: \", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6b5d8",
   "metadata": {},
   "source": [
    "Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e933df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the class names (optional, makes the plot readable)\n",
    "crime_labels = df_new_1[\"Crime_Class\"].unique()\n",
    "crime_labels.sort() # Ensure they are in the same order as factorize usually does\n",
    "\n",
    "# 2. Plot the matrix\n",
    "# Ensure you pass the predictions you just made (y_pred_test)\n",
    "plot_crime_matrix(y_test_xgb, y_pred_xgb, model_name=\"XGBoost\", labels=crime_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff889f5",
   "metadata": {},
   "source": [
    "#### Plot the Complexity vs Error Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b0d9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "for col in X.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        X[col] = X[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# OPTIONAL: SUBSAMPLE 250K rows for SPEED\n",
    "# ============================================================\n",
    "\n",
    "subset = 250_000\n",
    "# Convert y_train into a Pandas Series with matching indices\n",
    "y_train_series = pd.Series(y_train, index=X_train.index)\n",
    "\n",
    "subset = 250_000\n",
    "if len(X_train) > subset:\n",
    "    X_train_sub = X_train.sample(subset, random_state=42)\n",
    "    y_train_sub = y_train_series.loc[X_train_sub.index]\n",
    "else:\n",
    "    X_train_sub = X_train\n",
    "    y_train_sub = y_train_series\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CREATE CURVE (DEPTH 1 to 50)\n",
    "# ============================================================\n",
    "\n",
    "max_depths = range(1, 51)\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for d in max_depths:\n",
    "    print(f\"Training XGBoost with max_depth={d} ...\")\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        max_depth=d,\n",
    "        objective=\"multi:softprob\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        num_class=len(np.unique(y)),\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "    # Predict PROBABILITIES\n",
    "    y_train_prob = model.predict_proba(X_train_sub)\n",
    "    y_test_prob = model.predict_proba(X_test)\n",
    "\n",
    "    # Log-loss\n",
    "    train_losses.append(log_loss(y_train_sub, y_train_prob))\n",
    "    test_losses.append(log_loss(y_test, y_test_prob))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PLOT THE CURVE\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(max_depths, train_losses, label=\"Training Log-Loss\")\n",
    "plt.plot(max_depths, test_losses, label=\"Validation Log-Loss\")\n",
    "plt.xlabel(\"Model Complexity (max_depth)\")\n",
    "plt.ylabel(\"Log-Loss Error\")\n",
    "plt.title(\"XGBoost Complexity Curve (1–50 Depth)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93ea50a",
   "metadata": {},
   "source": [
    "### Evaluate Feature Importance (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "553a3ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Weapon_Present</td>\n",
       "      <td>0.157673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>MO_2038</td>\n",
       "      <td>0.106914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vict Sex</td>\n",
       "      <td>0.072405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>MO_0355</td>\n",
       "      <td>0.051407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>MO_1906</td>\n",
       "      <td>0.045422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vict Descent</td>\n",
       "      <td>0.043236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MO_0945</td>\n",
       "      <td>0.040018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>MO_0344</td>\n",
       "      <td>0.034082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MO_329</td>\n",
       "      <td>0.026963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>MO_0334</td>\n",
       "      <td>0.024845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>MO_0337</td>\n",
       "      <td>0.022958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MO_1501</td>\n",
       "      <td>0.017702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MO_0329</td>\n",
       "      <td>0.017497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MO_1100</td>\n",
       "      <td>0.015962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Status Desc</td>\n",
       "      <td>0.015532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Part 1-2</td>\n",
       "      <td>0.015109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>MO_0910</td>\n",
       "      <td>0.013649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>MO_0922</td>\n",
       "      <td>0.011072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>MO_0430</td>\n",
       "      <td>0.010772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>MO_1609</td>\n",
       "      <td>0.010123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  importance\n",
       "9    Weapon_Present    0.157673\n",
       "100         MO_2038    0.106914\n",
       "3          Vict Sex    0.072405\n",
       "60          MO_0355    0.051407\n",
       "109         MO_1906    0.045422\n",
       "4      Vict Descent    0.043236\n",
       "26          MO_0945    0.040018\n",
       "98          MO_0344    0.034082\n",
       "25           MO_329    0.026963\n",
       "76          MO_0334    0.024845\n",
       "58          MO_0337    0.022958\n",
       "19          MO_1501    0.017702\n",
       "39          MO_0329    0.017497\n",
       "29          MO_1100    0.015962\n",
       "6       Status Desc    0.015532\n",
       "1          Part 1-2    0.015109\n",
       "57          MO_0910    0.013649\n",
       "108         MO_0922    0.011072\n",
       "63          MO_0430    0.010772\n",
       "103         MO_1609    0.010123"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# Feature Importance\n",
    "# -------------------------------------------\n",
    "importance = xgb_model_2.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "fi = pd.DataFrame({\"feature\": features, \"importance\": importance})\n",
    "fi.sort_values(by=\"importance\", ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f348fd7",
   "metadata": {},
   "source": [
    "## Category: Deep Learning Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dd7664",
   "metadata": {},
   "source": [
    "\n",
    "### Neural Networks: CNN (Proessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d83804d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_7704\\2039213715.py:10: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  X[col] = X[col].view(\"int64\")\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 8ms/step - accuracy: 0.9005 - loss: 0.3149 - val_accuracy: 0.9095 - val_loss: 0.2747\n",
      "Epoch 2/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 8ms/step - accuracy: 0.9084 - loss: 0.2813 - val_accuracy: 0.9116 - val_loss: 0.2649\n",
      "Epoch 3/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 7ms/step - accuracy: 0.9101 - loss: 0.2742 - val_accuracy: 0.9121 - val_loss: 0.2659\n",
      "Epoch 4/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 8ms/step - accuracy: 0.9115 - loss: 0.2698 - val_accuracy: 0.9137 - val_loss: 0.2604\n",
      "Epoch 5/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 8ms/step - accuracy: 0.9118 - loss: 0.2670 - val_accuracy: 0.9135 - val_loss: 0.2626\n",
      "Epoch 6/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 8ms/step - accuracy: 0.9128 - loss: 0.2650 - val_accuracy: 0.9138 - val_loss: 0.2582\n",
      "Epoch 7/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 8ms/step - accuracy: 0.9126 - loss: 0.2635 - val_accuracy: 0.9139 - val_loss: 0.2605\n",
      "Epoch 8/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 7ms/step - accuracy: 0.9131 - loss: 0.2622 - val_accuracy: 0.9140 - val_loss: 0.2598\n",
      "Epoch 9/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 8ms/step - accuracy: 0.9134 - loss: 0.2615 - val_accuracy: 0.9148 - val_loss: 0.2599\n",
      "Epoch 10/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 8ms/step - accuracy: 0.9137 - loss: 0.2604 - val_accuracy: 0.9142 - val_loss: 0.2569\n",
      "\u001b[1m21985/21985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3ms/step\n",
      "\u001b[1m9422/9422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 0.9163175752992567\n",
      "Testing Set Accuracy: 0.91291484520627\n",
      "------------------------------------------------------------------------------------\n",
      "Training Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.952508  0.939116  0.945764  356035.000000\n",
      "1              0.944424  0.969521  0.956808  163391.000000\n",
      "2              0.834852  0.644564  0.727470   44202.000000\n",
      "3              0.820073  0.957065  0.883289   86340.000000\n",
      "4              0.779584  0.790364  0.784937   13595.000000\n",
      "5              0.774903  0.603960  0.678836    8282.000000\n",
      "6              0.922902  0.935951  0.929381   15207.000000\n",
      "7              0.759703  0.696285  0.726613   13944.000000\n",
      "8              0.000000  0.000000  0.000000     540.000000\n",
      "9              0.743041  0.531937  0.620012    1957.000000\n",
      "accuracy       0.916318  0.916318  0.916318       0.916318\n",
      "macro avg      0.753199  0.706876  0.725311  703493.000000\n",
      "weighted avg   0.915776  0.916318  0.914365  703493.000000\n",
      "------------------------------------------------------------------------------------\n",
      "Testing Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.950826  0.937681  0.944208  152409.000000\n",
      "1              0.941946  0.967102  0.954359   70096.000000\n",
      "2              0.818465  0.628863  0.711245   18834.000000\n",
      "3              0.817645  0.954885  0.880952   37105.000000\n",
      "4              0.772797  0.776902  0.774844    5836.000000\n",
      "5              0.762348  0.593645  0.667502    3588.000000\n",
      "6              0.918438  0.928093  0.923240    6564.000000\n",
      "7              0.742244  0.682082  0.710892    6033.000000\n",
      "8              0.000000  0.000000  0.000000     206.000000\n",
      "9              0.674061  0.477630  0.559094     827.000000\n",
      "accuracy       0.912915  0.912915  0.912915       0.912915\n",
      "macro avg      0.739877  0.694688  0.712634  301498.000000\n",
      "weighted avg   0.912126  0.912915  0.910832  301498.000000\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model_2 = df_new.copy()\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# ---- FIX 1: Convert datetime columns to int64 ----\n",
    "for col in X.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "# ---- FIX 2: Convert lists → strings to make them hashable ----\n",
    "for col in X.columns:\n",
    "\t    if X[col].dtype == 'object':\n",
    "\t        X[col] = X[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ====== RESHAPE FOR CNN (Conv1D needs shape: samples, timesteps, features) ======\n",
    "X_train_cnn = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
    "X_test_cnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# ====== BUILD CNN MODEL ======\n",
    "cnn_model_2 = Sequential([\n",
    "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model_2.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ====== TRAIN ======\n",
    "history = cnn_model_2.fit(\n",
    "    X_train_cnn, y_train_cat,\n",
    "    epochs=10,              # Use epoch size = 10, since the datset is fairly large. Fewer epochs means less strain and timne\n",
    "    batch_size=32,          #Default values is 32.\n",
    "    validation_split=0.2,   #Keras default is 0.0\n",
    "    verbose=1               #Keras default is 1\n",
    ")\n",
    "\n",
    "# ====== PREDICT ======\n",
    "y_pred_train = cnn_model_2.predict(X_train_cnn).argmax(axis=1)\n",
    "y_pred_test = cnn_model_2.predict(X_test_cnn).argmax(axis=1)\n",
    "\n",
    "# ====== EVALUATION ======\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ca311a",
   "metadata": {},
   "source": [
    "#### Perform Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d9aff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fold 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "Fold 1 Accuracy: 0.9037\n",
      "=== Fold 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "Fold 2 Accuracy: 0.9058\n",
      "=== Fold 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "Fold 3 Accuracy: 0.9085\n",
      "---------------------------------------------------------\n",
      "CV Accuracy Mean: 0.9059777777777778\n",
      "CV Accuracy Std: 0.001978838666778024\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Use a smaller subsample if your dataset is very large\n",
    "sample_size = 100_000\n",
    "X_sub = X.sample(sample_size, random_state=42)\n",
    "y_sub = y[X_sub.index]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_sub)\n",
    "\n",
    "# Reshape for Conv1D\n",
    "X_cnn = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y_sub))\n",
    "y_cat = to_categorical(y_sub, num_classes)\n",
    "\n",
    "# Stratified Shuffle-Split\n",
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=42)  # fewer splits due to time\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X_cnn, y_sub):\n",
    "    print(f\"=== Fold {fold} ===\")\n",
    "    \n",
    "    X_train, X_test = X_cnn[train_idx], X_cnn[test_idx]\n",
    "    y_train, y_test = y_cat[train_idx], y_cat[test_idx]\n",
    "\n",
    "    # Build CNN model\n",
    "    cnn_model = Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    cnn_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    cnn_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=5,           # keep low for faster CV\n",
    "        batch_size=32,\n",
    "        verbose=0           # silent training for CV\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = cnn_model.predict(X_test).argmax(axis=1)\n",
    "    y_true = y_sub[test_idx]\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Fold {fold} Accuracy: {acc:.4f}\")\n",
    "    accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"CV Accuracy Mean:\", np.mean(accuracies))\n",
    "print(\"CV Accuracy Std:\", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4fd232",
   "metadata": {},
   "source": [
    "Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcdbfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the class names (optional, makes the plot readable)\n",
    "crime_labels = df_new_1[\"Crime_Class\"].unique()\n",
    "crime_labels.sort() # Ensure they are in the same order as factorize usually does\n",
    "\n",
    "# 2. Plot the matrix\n",
    "# Ensure you pass the predictions you just made (y_pred_test) \n",
    "plot_crime_matrix(y_test, y_pred_test, model_name=\"CNN Model\", labels=crime_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d183c9",
   "metadata": {},
   "source": [
    "#### Plot the error versus complexity curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a09659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Use a smaller subsample for speed\n",
    "sample_size = 50_000  # adjust as needed\n",
    "X_sub = X.sample(sample_size, random_state=42)\n",
    "y_sub = y[X_sub.index]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_sub)\n",
    "\n",
    "# Reshape for Conv1D\n",
    "X_cnn = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y_sub))\n",
    "y_cat = to_categorical(y_sub, num_classes)\n",
    "\n",
    "# Complexity levels (number of filters in first Conv1D layer)\n",
    "complexity_values = [8, 16, 32, 64, 128]\n",
    "\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "print(\"=== Generating CNN Error vs Complexity Curve ===\")\n",
    "\n",
    "for filters in complexity_values:\n",
    "    print(f\"Training CNN with {filters} filters in first Conv1D layer\")\n",
    "\n",
    "    # Build CNN model\n",
    "    cnn_model = Sequential([\n",
    "        Conv1D(filters, kernel_size=3, activation='relu', input_shape=(X_cnn.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters*2, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    cnn_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Train (fewer epochs for faster evaluation)\n",
    "    cnn_model.fit(\n",
    "        X_cnn, y_cat,\n",
    "        epochs=5,\n",
    "        batch_size=32,\n",
    "        verbose=0  # silent training\n",
    "    )\n",
    "\n",
    "    # Predict\n",
    "    y_pred_train = cnn_model.predict(X_cnn).argmax(axis=1)\n",
    "    y_true = y_sub\n",
    "    train_err = 1 - accuracy_score(y_true, y_pred_train)\n",
    "\n",
    "    # Optional: split a small testing subset for speed\n",
    "    test_idx = np.random.choice(len(X_cnn), size=int(0.2*len(X_cnn)), replace=False)\n",
    "    X_test_small = X_cnn[test_idx]\n",
    "    y_test_small = y_sub[test_idx]\n",
    "    y_test_cat_small = y_cat[test_idx]\n",
    "\n",
    "    y_pred_test = cnn_model.predict(X_test_small).argmax(axis=1)\n",
    "    test_err = 1 - accuracy_score(y_test_small, y_pred_test)\n",
    "\n",
    "    train_errors.append(train_err)\n",
    "    test_errors.append(test_err)\n",
    "\n",
    "# ---- Plot ----\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(complexity_values, train_errors, marker='o', label=\"Training Error\")\n",
    "plt.plot(complexity_values, test_errors, marker='o', label=\"Testing Error\")\n",
    "plt.xlabel(\"CNN Complexity (Number of Filters in First Conv1D Layer)\")\n",
    "plt.ylabel(\"Error (1 - Accuracy)\")\n",
    "plt.title(\"CNN Error vs Complexity Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd63b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====== COMPUTE PROBABILITIES ======\n",
    "train_proba = cnn_model_2.predict(X_train_cnn)\n",
    "test_proba  = cnn_model_2.predict(X_test_cnn)\n",
    "\n",
    "# ====== COMPUTE LOG LOSS ======\n",
    "train_loss = log_loss(y_train, train_proba)\n",
    "test_loss  = log_loss(y_test,  test_proba)\n",
    "\n",
    "print(\"------------------------\")\n",
    "print(\"Training Loss\")\n",
    "print(train_loss)\n",
    "print(\"------------------------\")\n",
    "print(\"Testing Loss:\")\n",
    "print(test_loss)\n",
    "print(\"------------------------\")\n",
    "print(\":)\")\n",
    "acc_gap  = train_accuracy - test_accuracy\n",
    "loss_gap = test_loss - train_loss\n",
    "print(\"------------------------\")\n",
    "print(\"Accuracy Gap:\")\n",
    "print(acc_gap)\n",
    "print(\"------------------------\")\n",
    "print(\"Loss Gap:\")\n",
    "print(loss_gap)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# ====== PLOT TRAINING vs VALIDATION LOSS FROM HISTORY ======\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss Curve (CNN)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3ec93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "# ======================================================\n",
    "# 1. TAKE A SMALL SUBSET TO AVOID HOURS OF TRAINING\n",
    "# ======================================================\n",
    "subset = 50000   # Use 50k rows for speed (change if needed)\n",
    "\n",
    "X_train_sub = X_train_cnn[:subset]\n",
    "y_train_sub = y_train[:subset]\n",
    "y_train_sub_cat = y_train_cat[:subset]\n",
    "\n",
    "X_val_sub = X_test_cnn[:20000]\n",
    "y_val_sub = y_test[:20000]\n",
    "y_val_sub_cat = y_test_cat[:20000]\n",
    "\n",
    "# ======================================================\n",
    "# 2. DEFINE COMPLEXITY LEVELS (NUMBER OF FILTERS)\n",
    "# ======================================================\n",
    "complexities = [8, 16, 32, 64, 128]\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "# ======================================================\n",
    "# 3. LOOP THROUGH MODEL COMPLEXITIES\n",
    "# ======================================================\n",
    "for filters in complexities:\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv1D(filters, kernel_size=3, activation='relu',\n",
    "               input_shape=(X_train_sub.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "\n",
    "        Conv1D(filters*2, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # short training for speed\n",
    "    model.fit(\n",
    "        X_train_sub, y_train_sub_cat,\n",
    "        epochs=3,          # small number for speed\n",
    "        batch_size=64,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Predictions\n",
    "    train_proba = model.predict(X_train_sub, verbose=0)\n",
    "    test_proba  = model.predict(X_val_sub,   verbose=0)\n",
    "\n",
    "    y_train_pred = np.argmax(train_proba, axis=1)\n",
    "    y_test_pred  = np.argmax(test_proba, axis=1)\n",
    "\n",
    "    # Metrics\n",
    "    train_losses.append(log_loss(y_train_sub, train_proba))\n",
    "    test_losses.append(log_loss(y_val_sub,  test_proba))\n",
    "\n",
    "    train_accs.append(accuracy_score(y_train_sub, y_train_pred))\n",
    "    test_accs.append(accuracy_score(y_val_sub,  y_test_pred))\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 4. PLOT COMPLEXITY vs ERROR\n",
    "# ======================================================\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(complexities, train_losses, label=\"Training Loss\")\n",
    "plt.plot(complexities, test_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Model Complexity (Number of Filters)\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.title(\"CNN Model Complexity vs Error\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773a711e",
   "metadata": {},
   "source": [
    "### Neural Network: ANN (Processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07ccfb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_7704\\2866109942.py:10: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  X[col] = X[col].view(\"int64\")\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4ms/step - accuracy: 0.8949 - loss: 0.3386 - val_accuracy: 0.9088 - val_loss: 0.2806\n",
      "Epoch 2/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4ms/step - accuracy: 0.9055 - loss: 0.2959 - val_accuracy: 0.9115 - val_loss: 0.2681\n",
      "Epoch 3/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4ms/step - accuracy: 0.9065 - loss: 0.2885 - val_accuracy: 0.9119 - val_loss: 0.2649\n",
      "Epoch 4/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4ms/step - accuracy: 0.9074 - loss: 0.2851 - val_accuracy: 0.9119 - val_loss: 0.2644\n",
      "Epoch 5/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 4ms/step - accuracy: 0.9081 - loss: 0.2827 - val_accuracy: 0.9121 - val_loss: 0.2654\n",
      "Epoch 6/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 4ms/step - accuracy: 0.9085 - loss: 0.2812 - val_accuracy: 0.9128 - val_loss: 0.2608\n",
      "Epoch 7/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 4ms/step - accuracy: 0.9088 - loss: 0.2798 - val_accuracy: 0.9132 - val_loss: 0.2620\n",
      "Epoch 8/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 4ms/step - accuracy: 0.9090 - loss: 0.2789 - val_accuracy: 0.9130 - val_loss: 0.2623\n",
      "Epoch 9/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 4ms/step - accuracy: 0.9091 - loss: 0.2788 - val_accuracy: 0.9127 - val_loss: 0.2607\n",
      "Epoch 10/10\n",
      "\u001b[1m17588/17588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 4ms/step - accuracy: 0.9096 - loss: 0.2777 - val_accuracy: 0.9137 - val_loss: 0.2582\n",
      "\u001b[1m21985/21985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step\n",
      "\u001b[1m9422/9422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 0.9145961651359715\n",
      "Testing Set Accuracy: 0.9123974288386656\n",
      "------------------------------------------------------------------------------------\n",
      "Training Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.959333  0.934293  0.946647  356035.000000\n",
      "1              0.942339  0.969215  0.955588  163391.000000\n",
      "2              0.813887  0.655242  0.725999   44202.000000\n",
      "3              0.821406  0.949583  0.880856   86340.000000\n",
      "4              0.754229  0.810151  0.781190   13595.000000\n",
      "5              0.802980  0.585607  0.677280    8282.000000\n",
      "6              0.882147  0.942592  0.911368   15207.000000\n",
      "7              0.686247  0.746486  0.715100   13944.000000\n",
      "8              0.000000  0.000000  0.000000     540.000000\n",
      "9              0.687349  0.435871  0.533458    1957.000000\n",
      "accuracy       0.914596  0.914596  0.914596       0.914596\n",
      "macro avg      0.734992  0.702904  0.712749  703493.000000\n",
      "weighted avg   0.914941  0.914596  0.913189  703493.000000\n",
      "------------------------------------------------------------------------------------\n",
      "Testing Set Report\n",
      "------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score        support\n",
      "0              0.958296  0.933560  0.945766  152409.000000\n",
      "1              0.939915  0.967644  0.953578   70096.000000\n",
      "2              0.801911  0.641606  0.712857   18834.000000\n",
      "3              0.820037  0.948551  0.879625   37105.000000\n",
      "4              0.751851  0.800548  0.775436    5836.000000\n",
      "5              0.803095  0.578595  0.672607    3588.000000\n",
      "6              0.881594  0.936929  0.908419    6564.000000\n",
      "7              0.676939  0.739102  0.706656    6033.000000\n",
      "8              0.000000  0.000000  0.000000     206.000000\n",
      "9              0.665354  0.408706  0.506367     827.000000\n",
      "accuracy       0.912397  0.912397  0.912397       0.912397\n",
      "macro avg      0.729899  0.695524  0.706131  301498.000000\n",
      "weighted avg   0.912637  0.912397  0.910896  301498.000000\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Remove Crm Cd Desc to avoid leakage\n",
    "df_model_2 = df_new.copy()\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# ---- FIX 1: Convert datetime columns to int64 ----\n",
    "for col in X.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "# ---- FIX 2: Convert lists → strings to make them hashable ----\n",
    "for col in X.columns:\n",
    "\t    if X[col].dtype == 'object':\n",
    "\t        X[col] = X[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# ====== BUILD ANN MODEL ======\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ====== TRAIN ======\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_cat,\n",
    "    epochs=10,              #Use 10 as a derfault value for epochs\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ====== PREDICT ======\n",
    "y_pred_train = model.predict(X_train_scaled).argmax(axis=1)\n",
    "y_pred_test = model.predict(X_test_scaled).argmax(axis=1)\n",
    "\n",
    "# ====== EVALUATION ======\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Set Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c51f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ==========================================\n",
    "# 1. Get Class Names\n",
    "# ==========================================\n",
    "# We grab the unique classes from 'df_model_2' (the dataframe used for this ANN)\n",
    "# We strictly preserve the order of appearance to match pd.factorize behavior\n",
    "crime_labels = df_model_2[\"Crime_Class\"].unique()\n",
    "\n",
    "# ==========================================\n",
    "# 2. Plot Confusion Matrix\n",
    "# ==========================================\n",
    "# Use y_test (Actuals) and y_pred_test (Predictions from ANN)\n",
    "plot_crime_matrix(y_test, y_pred_test, model_name=\"ANN Model\", labels=crime_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0569f99",
   "metadata": {},
   "source": [
    "Validation Time. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e59fe14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fold 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Fold 1 Accuracy: 0.9039\n",
      "=== Fold 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Fold 2 Accuracy: 0.9060\n",
      "=== Fold 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Fold 3 Accuracy: 0.9070\n",
      "---------------------------------------------------------\n",
      "CV Accuracy Mean: 0.9056333333333333\n",
      "CV Accuracy Std: 0.0012918548250050695\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# Optional subsample for speed (same as CNN version)\n",
    "# ============================================================\n",
    "sample_size = 100_000\n",
    "X_sub = X.sample(sample_size, random_state=42)\n",
    "y_sub = y[X_sub.index]\n",
    "\n",
    "# ============================================================\n",
    "# Scale features\n",
    "# ============================================================\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_sub)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y_sub))\n",
    "y_cat = to_categorical(y_sub, num_classes)\n",
    "\n",
    "# ============================================================\n",
    "# Stratified Shuffle-Split\n",
    "# ============================================================\n",
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X_scaled, y_sub):\n",
    "    print(f\"=== Fold {fold} ===\")\n",
    "\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y_cat[train_idx], y_cat[test_idx]\n",
    "\n",
    "    # ============================================================\n",
    "    # Build ANN model (matching your original architecture)\n",
    "    # ============================================================\n",
    "    ann_model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    ann_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Train (silent for CV)\n",
    "    ann_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=5,          # reduced for faster CV, same as CNN version\n",
    "        batch_size=32,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Predict + evaluate\n",
    "    y_pred = ann_model.predict(X_test).argmax(axis=1)\n",
    "    y_true = y_sub[test_idx]\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"Fold {fold} Accuracy: {acc:.4f}\")\n",
    "    accuracies.append(acc)\n",
    "    fold += 1\n",
    "\n",
    "# ============================================================\n",
    "# Summary\n",
    "# ============================================================\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"CV Accuracy Mean:\", np.mean(accuracies))\n",
    "print(\"CV Accuracy Std:\", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e2fc1",
   "metadata": {},
   "source": [
    "Curve Check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872e6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ============================================================\n",
    "# 1. Prepare Data (Updated for 250k)\n",
    "# ============================================================\n",
    "print(\"=== Preparing Data ===\")\n",
    "# Ensure we don't sample more than we have\n",
    "sample_size = min(250_000, len(X))\n",
    "\n",
    "# Assuming X is a DataFrame (based on your .sample code)\n",
    "X_sub = X.sample(n=sample_size, random_state=42)\n",
    "y_sub = y[X_sub.index] # Align y with X\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_sub)\n",
    "\n",
    "num_classes = len(np.unique(y_sub))\n",
    "y_cat = to_categorical(y_sub, num_classes)\n",
    "\n",
    "# Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled, y_cat, test_size=0.3, random_state=42, stratify=y_sub\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Complexity levels (Wider Range)\n",
    "# ============================================================\n",
    "# We go from very simple (10) to very complex (800) to force the curve\n",
    "complexity_levels = [10, 50, 150, 400, 800]\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(f\"=== Starting Training Loop (Subsample: {sample_size}) ===\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. Train ANN for each complexity level\n",
    "# ============================================================\n",
    "for units in complexity_levels:\n",
    "    print(f\"Training model with {units} neurons...\")\n",
    "\n",
    "    model = Sequential([\n",
    "        # INCREASED COMPLEXITY:\n",
    "        # We use a single massive layer.\n",
    "        # CRITICAL: We REMOVED Dropout to allow overfitting.\n",
    "        Dense(units, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # INCREASED EPOCHS:\n",
    "    # We need enough time for the big models to memorize the noise.\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=20,  # Increased from 5 to 20\n",
    "        batch_size=64, # Slightly larger batch for speed\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Store final epoch losses\n",
    "    train_losses.append(history.history['loss'][-1])\n",
    "    val_losses.append(history.history['val_loss'][-1])\n",
    "\n",
    "# ============================================================\n",
    "# 4. Plot Error vs Complexity\n",
    "# ============================================================\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot lines\n",
    "plt.plot(complexity_levels, train_losses, marker='o', label='Training Loss (Bias)', color='blue')\n",
    "plt.plot(complexity_levels, val_losses, marker='o', label='Validation Loss (Variance)', color='orange')\n",
    "\n",
    "plt.title(\"Bias-Variance Tradeoff: ANN Complexity\")\n",
    "plt.xlabel(\"Model Complexity (Neurons in Hidden Layer)\")\n",
    "plt.ylabel(\"Log Loss (Lower is Better)\")\n",
    "plt.xticks(complexity_levels) # Show exact x-axis values\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fee3c0",
   "metadata": {},
   "source": [
    "## Part B - Parameters\n",
    "\n",
    "### Now, let's implement Hyperparameter Tuning:\n",
    "\n",
    "This will take a while as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa775c49",
   "metadata": {},
   "source": [
    "### Naive Bayes (Processed & Tunned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a55c01",
   "metadata": {},
   "source": [
    "WARNING: DO NOT ATTEMPT Logistic Regression using the full 1 Milliom. Unless you'd like your laptop to crash over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41117caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 1. Setup Data (Assuming df_new_1 already exists)\n",
    "# ----------------------------------------------------\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. Prepare X and y\n",
    "# ----------------------------------------------------\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. Pre-processing (Memory Safe)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# A. Datetime → int64\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].values.astype(np.int64)\n",
    "\n",
    "# B. List columns → str\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# C. Object columns → category codes\n",
    "print(\"Encoding columns...\")\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        X[col] = X[col].astype(\"category\").cat.codes\n",
    "\n",
    "# D. Missing values → -1\n",
    "# (safe because MinMaxScaler shifts everything to 0–1)\n",
    "X = X.fillna(-1)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4. Train–Test Split\n",
    "# ----------------------------------------------------\n",
    "X_train, X_test, y_train, y_test_nb = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 5. Scaling\n",
    "# ----------------------------------------------------\n",
    "print(\"Scaling data (MinMax)...\")\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 6. Manual Alpha Search (Safe & Lightweight)\n",
    "# ----------------------------------------------------\n",
    "alphas = [0.1, 0.5, 1.0, 2.0, 5.0,10.0]\n",
    "best_alpha = None\n",
    "best_acc = 0\n",
    "\n",
    "print(\"\\nSearching for best alpha...\")\n",
    "\n",
    "for alpha in alphas:\n",
    "    model = MultinomialNB(alpha=alpha)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test_nb, y_pred)\n",
    "\n",
    "    print(f\"Alpha={alpha} → Test Accuracy={acc:.4f}\")\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(f\"\\nBest Alpha Found: {best_alpha} (Accuracy={best_acc:.4f})\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 7. Train Final Model\n",
    "# ----------------------------------------------------\n",
    "print(\"\\nTraining final MultinomialNB model...\")\n",
    "nb_model_1 = MultinomialNB(alpha=best_alpha)\n",
    "nb_model_1.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "print(\"Predicting...\")\n",
    "y_pred_train_1 = nb_model_1.predict(X_train_scaled)\n",
    "y_pred_test_nb = nb_model_1.predict(X_test_scaled)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 8. Evaluation\n",
    "# ----------------------------------------------------\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_1)\n",
    "test_accuracy = accuracy_score(y_test_nb, y_pred_test_nb)\n",
    "\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_nb, y_pred_test_nb, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcd2b21",
   "metadata": {},
   "source": [
    "Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Splitter\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"\\n=========================================================\")\n",
    "print(\"1. Multinomial Naive Bayes Validation (MinMaxScaler)\")\n",
    "print(\"=========================================================\")\n",
    "\n",
    "# 🔥 Alpha values to test (keep small to avoid RAM issues)\n",
    "alpha_values = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    print(f\"\\nTesting Alpha = {alpha}\")\n",
    "    nb_accuracies = []\n",
    "    fold = 1\n",
    "\n",
    "    for train_idx, test_idx in sss.split(X, y):\n",
    "        # 1. Slice Data\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # 2. MinMax scaling required for NB\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # 3. Train NB with CURRENT alpha\n",
    "        nb = MultinomialNB(alpha=alpha)\n",
    "        nb.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # 4. Score\n",
    "        acc = accuracy_score(y_test, nb.predict(X_test_scaled))\n",
    "\n",
    "        print(f\"  Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "        nb_accuracies.append(acc)\n",
    "        fold += 1\n",
    "\n",
    "    # Per-alpha summary\n",
    "    print(f\"Alpha {alpha} Mean Accuracy: {np.mean(nb_accuracies):.8f}\")\n",
    "    print(f\"Alpha {alpha} Std Deviation: {np.std(nb_accuracies):.8f}\")\n",
    "    print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bd4908",
   "metadata": {},
   "source": [
    "### XGBoost (Processed & Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c05cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== FAST & MEMORY-EFFICIENT XGBOOST TRAINING ===\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# ============================================================\n",
    "# PREPROCESSING (same as before)\n",
    "# ============================================================\n",
    "\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "# Keep y as a pandas Series instead of numpy array\n",
    "y = pd.Series(pd.factorize(df_model_2[\"Crime_Class\"])[0])\n",
    "\n",
    "\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "X = X.astype(\"float32\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# TINY SUBSAMPLE FOR FAST TUNING\n",
    "# ============================================================\n",
    "\n",
    "tune_size = 10000\n",
    "X_tune = X_train.sample(tune_size, random_state=42)\n",
    "y_tune = y_train[X_tune.index]\n",
    "\n",
    "print(f\"Tuning using {len(X_tune):,} rows\")\n",
    "\n",
    "# ============================================================\n",
    "# FAST XGBOOST RANDOMIZED SEARCH\n",
    "# ============================================================\n",
    "\n",
    "xgb_base = XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=len(np.unique(y)),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"max_depth\": randint(4, 10),\n",
    "    \"learning_rate\": uniform(0.03, 0.2),\n",
    "    \"min_child_weight\": randint(1, 6),\n",
    "    \"subsample\": uniform(0.5, 0.5),\n",
    "    \"colsample_bytree\": uniform(0.5, 0.5),\n",
    "    \"n_estimators\": randint(150, 400)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    xgb_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=15,        # FAST\n",
    "    cv=2,\n",
    "    scoring=\"accuracy\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search.fit(X_tune, y_tune)\n",
    "\n",
    "print(\"\\nBest Params:\", search.best_params_)\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN FINAL MODEL ON FULL DATASET\n",
    "# ============================================================\n",
    "\n",
    "xgb_final = XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=len(np.unique(y)),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    **search.best_params_\n",
    ")\n",
    "\n",
    "xgb_final.fit(X_train, y_train)\n",
    "\n",
    "# ============================================================\n",
    "# EVALUATION\n",
    "# ============================================================\n",
    "\n",
    "y_pred_train = xgb_final.predict(X_train)\n",
    "y_pred_test = xgb_final.predict(X_test)\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "print(\"\\nTRAIN REPORT\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "print(\"\\nTEST REPORT\")\n",
    "print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16afe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== XGBOOST Cross-Validation: Stratified Shuffle-Split ===\\n\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Use your tuned parameters\n",
    "# ------------------------------------------------------------\n",
    "best_params = search.best_params_\n",
    "print(\"Using Best Params:\", best_params, \"\\n\")\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    X_train_cv, X_test_cv = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train_cv, y_test_cv = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # XGBoost model with best params\n",
    "    # --------------------------------------------------------\n",
    "    xgb_cv = XGBClassifier(\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y)),\n",
    "        eval_metric=\"mlogloss\",\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        **best_params\n",
    "    )\n",
    "\n",
    "    xgb_cv.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = xgb_cv.predict(X_test_cv)\n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_test_cv, y_pred)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Mean Accuracy:  \", np.mean(accuracies))\n",
    "print(\"Std Deviation: \", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f4d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Use a subset for speed\n",
    "# -------------------------------\n",
    "subset_size = 250_000  # <--- UPDATED to 250k\n",
    "print(f\"Subsampling {subset_size} rows...\")\n",
    "X_sub = X.sample(subset_size, random_state=42)\n",
    "y_sub = y[X_sub.index] # Ensure target aligns with sampled X\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Complexity range (max_depth)\n",
    "# -------------------------------\n",
    "# Range 1 to 50 with step 5 (1, 6, 11... 46, 51)\n",
    "depth_values = range(1, 51, 5) \n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "# Base tuned params (Make sure 'search' is defined or replace this line!)\n",
    "base_params = search.best_params_.copy()\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Stratified Shuffle-Split\n",
    "# -------------------------------\n",
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "\n",
    "for depth in depth_values:\n",
    "    fold_train_errors = []\n",
    "    fold_test_errors = []\n",
    "    print(f\"Testing max_depth = {depth}...\")\n",
    "\n",
    "    for train_idx, test_idx in sss.split(X_sub, y_sub):\n",
    "        X_train_cv, X_test_cv = X_sub.iloc[train_idx], X_sub.iloc[test_idx]\n",
    "        y_train_cv, y_test_cv = y_sub.iloc[train_idx], y_sub.iloc[test_idx]\n",
    "\n",
    "        # Update params for this specific loop\n",
    "        params = base_params.copy()\n",
    "        params[\"max_depth\"] = depth\n",
    "\n",
    "        model = XGBClassifier(\n",
    "            objective=\"multi:softmax\",\n",
    "            num_class=len(np.unique(y_sub)),\n",
    "            eval_metric=\"mlogloss\",\n",
    "            tree_method=\"hist\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred_train = model.predict(X_train_cv)\n",
    "        y_pred_test  = model.predict(X_test_cv)\n",
    "\n",
    "        # Calculate Error (1 - Accuracy)\n",
    "        fold_train_errors.append(1 - accuracy_score(y_train_cv, y_pred_train))\n",
    "        fold_test_errors.append(1 - accuracy_score(y_test_cv, y_pred_test))\n",
    "\n",
    "    # Average over folds\n",
    "    train_errors.append(np.mean(fold_train_errors))\n",
    "    test_errors.append(np.mean(fold_test_errors))\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Plot\n",
    "# -------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(depth_values, train_errors, marker='o', label=\"Training Error\")\n",
    "plt.plot(depth_values, test_errors, marker='o', label=\"Test Error\")\n",
    "\n",
    "plt.xlabel(\"Model Complexity (max_depth)\")\n",
    "plt.ylabel(\"Error (1 - accuracy)\")\n",
    "plt.title(f\"XGBoost Error vs Model Complexity (Subset: {subset_size:,} rows)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61925d86",
   "metadata": {},
   "source": [
    "### ANN (Hyperparamters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8957426f",
   "metadata": {},
   "source": [
    "If this doesn't run, run the default ANN (Processed) first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30818fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. IMPORTS\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ============================================================\n",
    "# 2. DATA PREPARATION (Your First Block)\n",
    "# ============================================================\n",
    "# NOTE: Ensure 'df_new' is loaded before this line, or add: df_new = pd.read_csv('your_file.csv')\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, unique_classes = pd.factorize(df_model_2[\"Crime_Class\"]) # Capture classes for report later\n",
    "\n",
    "# ---- FIX 1: Convert datetime columns to int64 ----\n",
    "for col in X.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "# ---- FIX 2: Convert lists -> strings to make them hashable ----\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 3. BRIDGE CODE (Crucial Missing Steps)\n",
    "# ============================================================\n",
    "# Your ANN expects scaled data and categorical targets, which were missing above.\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One-hot encode the targets (needed for categorical_crossentropy)\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# ============================================================\n",
    "# 4. ANN MODEL SETUP & SEARCH (Your Second Block)\n",
    "# ============================================================\n",
    "\n",
    "param_space = {\n",
    "    \"lr\": [1e-3, 3e-4, 1e-4],\n",
    "    \"hidden_1\": [64, 96, 128],\n",
    "    \"hidden_2\": [32, 48, 64],\n",
    "    \"dropout\": [0.2, 0.3, 0.4],\n",
    "    \"batch_size\": [32, 64, 128]\n",
    "}\n",
    "\n",
    "def build_model(params):\n",
    "    model = Sequential([\n",
    "        Dense(params[\"hidden_1\"], activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dropout(params[\"dropout\"]),\n",
    "\n",
    "        Dense(params[\"hidden_2\"], activation='relu'),\n",
    "        Dropout(params[\"dropout\"]),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=Adam(learning_rate=params[\"lr\"]),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def sample_params():\n",
    "    return {\n",
    "        \"lr\": random.choice(param_space[\"lr\"]),\n",
    "        \"hidden_1\": random.choice(param_space[\"hidden_1\"]),\n",
    "        \"hidden_2\": random.choice(param_space[\"hidden_2\"]),\n",
    "        \"dropout\": random.choice(param_space[\"dropout\"]),\n",
    "        \"batch_size\": random.choice(param_space[\"batch_size\"])\n",
    "    }\n",
    "\n",
    "search_results = []\n",
    "N_SEARCH = 4   \n",
    "\n",
    "print(\"\\n========== STARTING BEST PARAMS SEARCH ==========\\n\")\n",
    "\n",
    "for i in range(N_SEARCH):\n",
    "    params = sample_params()\n",
    "    print(f\"Trial {i+1}/{N_SEARCH}: {params}\")\n",
    "\n",
    "    model = build_model(params)\n",
    "\n",
    "    es = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # SHORT training for search only\n",
    "    history = model.fit(\n",
    "        X_train_scaled,\n",
    "        y_train_cat,\n",
    "        epochs=8,\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        validation_split=0.2,\n",
    "        verbose=0,\n",
    "        callbacks=[es]\n",
    "    )\n",
    "\n",
    "    val_acc = max(history.history[\"val_accuracy\"])\n",
    "    search_results.append((val_acc, params))\n",
    "\n",
    "    print(f\" -> Best Val Accuracy: {val_acc:.4f}\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. FINAL TRAINING & EVALUATION\n",
    "# ============================================================\n",
    "\n",
    "best_val, best_params = max(search_results, key=lambda x: x[0])\n",
    "print(\"\\n========== BEST PARAMS FOUND ==========\")\n",
    "print(best_params)\n",
    "print(\"Best Validation Accuracy:\", best_val)\n",
    "\n",
    "print(\"\\n========== TRAINING FINAL MODEL ==========\\n\")\n",
    "\n",
    "final_model = build_model(best_params)\n",
    "\n",
    "es_final = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history_final = final_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_cat,\n",
    "    epochs=25,\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    "    callbacks=[es_final]\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred_train = final_model.predict(X_train_scaled).argmax(axis=1)\n",
    "y_pred_test = final_model.predict(X_test_scaled).argmax(axis=1)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "print(\"\\n===== TRAINING REPORT =====\")\n",
    "print(pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose())\n",
    "\n",
    "print(\"\\n===== TESTING REPORT =====\")\n",
    "print(pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test, output_dict=True)\n",
    ").transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef3a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#                📌 FULL ANN PIPELINE \n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ============================================================\n",
    "# PREPROCESSING\n",
    "# ============================================================\n",
    "\n",
    "df_model_2 = df_new_1.copy()\n",
    "\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# Convert datetime → int64\n",
    "for col in X.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "# Convert lists → strings\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        X[col] = X[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Fill missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# ============================================================\n",
    "# BEST PARAMS (From your search)\n",
    "# ============================================================\n",
    "best_params = {\n",
    "    \"layer1\": 128,\n",
    "    \"layer2\": 64,\n",
    "    \"layer3\": 32,\n",
    "    \"dropout\": 0.3,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 10,       # base training\n",
    "    \"lr\": 0.001         # default Adam LR\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# MODEL BUILDER FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def build_ann():\n",
    "    model = Sequential([\n",
    "        Dense(best_params[\"layer1\"], activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dropout(best_params[\"dropout\"]),\n",
    "\n",
    "        Dense(best_params[\"layer2\"], activation='relu'),\n",
    "        Dropout(best_params[\"dropout\"]),\n",
    "\n",
    "        Dense(best_params[\"layer3\"], activation='relu'),\n",
    "\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN FINAL MODEL\n",
    "# ============================================================\n",
    "\n",
    "model = build_ann()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_cat,\n",
    "    epochs=best_params[\"epochs\"],\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predict\n",
    "y_pred_train = model.predict(X_train_scaled).argmax(axis=1)\n",
    "y_pred_test = model.predict(X_test_scaled).argmax(axis=1)\n",
    "\n",
    "# Evaluation\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Accuracy:\", train_acc)\n",
    "print(\"Testing Accuracy:\", test_acc)\n",
    "\n",
    "print(\"\\nTRAIN REPORT\")\n",
    "print(pd.DataFrame.from_dict(classification_report(y_train, y_pred_train, output_dict=True)).transpose())\n",
    "\n",
    "print(\"\\nTEST REPORT\")\n",
    "print(pd.DataFrame.from_dict(classification_report(y_test, y_pred_test, output_dict=True)).transpose())\n",
    "\n",
    "# ============================================================\n",
    "# SHUFFLE-SPLIT CROSS VALIDATION (FAST + MEMORY EFFICIENT)\n",
    "# ============================================================\n",
    "\n",
    "def ann_shuffle_split_cv(n_splits=5):\n",
    "\n",
    "    ss = ShuffleSplit(n_splits=n_splits, test_size=0.2, random_state=42)\n",
    "    accuracies = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_idx, val_idx in ss.split(X_train_scaled):\n",
    "\n",
    "        print(f\"\\n===== ShuffleSplit Fold {fold}/{n_splits} =====\")\n",
    "\n",
    "        X_tr, X_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "        y_tr, y_val = y_train_cat[train_idx], y_train_cat[val_idx]\n",
    "\n",
    "        model_cv = build_ann()\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "        model_cv.fit(\n",
    "            X_tr, y_tr,\n",
    "            epochs=12,  # small for speed\n",
    "            batch_size=best_params[\"batch_size\"],\n",
    "            validation_data=(X_val, y_val),\n",
    "            verbose=0,\n",
    "            callbacks=[es]\n",
    "        )\n",
    "\n",
    "        loss, acc = model_cv.evaluate(X_val, y_val, verbose=0)\n",
    "        print(f\"Fold Accuracy: {acc:.4f}\")\n",
    "\n",
    "        accuracies.append(acc)\n",
    "        fold += 1\n",
    "\n",
    "    accuracies = np.array(accuracies)\n",
    "    print(\"\\n========== SHUFFLE SPLIT SUMMARY ==========\")\n",
    "    print(\"Accuracies:\", accuracies)\n",
    "    print(\"Mean CV Accuracy:\", accuracies.mean())\n",
    "    print(\"Std Deviation:\", accuracies.std())\n",
    "    print(\"============================================\")\n",
    "\n",
    "    return accuracies.mean(), accuracies.std()\n",
    "\n",
    "# Run CV\n",
    "cv_mean, cv_sd = ann_shuffle_split_cv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb6deb8",
   "metadata": {},
   "source": [
    "## Part B - Applying new preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbba625e",
   "metadata": {},
   "source": [
    "#### We previously left the victim family of columns as is. This time, let's apply the same transformations as we did for the weapon family of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d47e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the binary \"Victim_Involved?\" column first\n",
    "# We check if 'Vict Age', 'Vict Sex', or 'Vict Descent' have valid data.\n",
    "# Adjust the condition if you only want to check specific columns.\n",
    "# Here, if ALL victim columns are null, it's 0. If ANY has data, it's 1.\n",
    "# (Alternatively, you can just check one if they are always missing together)\n",
    "df_new_1['Victim_Involved?'] = df_new_1.apply(\n",
    "    lambda row: 0 if (pd.isna(row['Vict Sex']) or str(row['Vict Sex']).strip() == '') and \n",
    "                     (pd.isna(row['Vict Descent']) or str(row['Vict Descent']).strip() == '') \n",
    "                else 1, axis=1\n",
    ")\n",
    "\n",
    "# 2. Drop the victim-based columns\n",
    "cols_to_drop = ['Vict Age', 'Vict Sex', 'Vict Descent']\n",
    "df_new_1 = df_new_1.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "# Verify the changes\n",
    "print(df_new_1[['Victim_Involved?']].head())\n",
    "print(df_new_1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bcfd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_2 = df_new_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8c9cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193b6af5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "262df8ed",
   "metadata": {},
   "source": [
    "### Naive Bayes (Processed, Tunned, & New Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8697fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 1. Setup Data (Assuming df_new_1 already exists)\n",
    "# ----------------------------------------------------\n",
    "df_model_2 = df_new_2.copy()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. Prepare X and y\n",
    "# ----------------------------------------------------\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. Pre-processing (Memory Safe)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# A. Datetime → int64\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].values.astype(np.int64)\n",
    "\n",
    "# B. List columns → str\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "# C. Object columns → category codes\n",
    "print(\"Encoding columns...\")\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        X[col] = X[col].astype(\"category\").cat.codes\n",
    "\n",
    "# D. Missing values → -1\n",
    "# (safe because MinMaxScaler shifts everything to 0–1)\n",
    "X = X.fillna(-1)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4. Train–Test Split\n",
    "# ----------------------------------------------------\n",
    "X_train, X_test, y_train, y_test_nb = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 5. Scaling\n",
    "# ----------------------------------------------------\n",
    "print(\"Scaling data (MinMax)...\")\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 6. Manual Alpha Search (Safe & Lightweight)\n",
    "# ----------------------------------------------------\n",
    "alphas = [0.1, 0.5, 1.0, 2.0, 5.0,10.0]\n",
    "best_alpha = None\n",
    "best_acc = 0\n",
    "\n",
    "print(\"\\nSearching for best alpha...\")\n",
    "\n",
    "for alpha in alphas:\n",
    "    model = MultinomialNB(alpha=alpha)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test_nb, y_pred)\n",
    "\n",
    "    print(f\"Alpha={alpha} → Test Accuracy={acc:.4f}\")\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(f\"\\nBest Alpha Found: {best_alpha} (Accuracy={best_acc:.4f})\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 7. Train Final Model\n",
    "# ----------------------------------------------------\n",
    "print(\"\\nTraining final MultinomialNB model...\")\n",
    "nb_model_1 = MultinomialNB(alpha=best_alpha)\n",
    "nb_model_1.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "print(\"Predicting...\")\n",
    "y_pred_train_1 = nb_model_1.predict(X_train_scaled)\n",
    "y_pred_test_nb = nb_model_1.predict(X_test_scaled)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 8. Evaluation\n",
    "# ----------------------------------------------------\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_1)\n",
    "test_accuracy = accuracy_score(y_test_nb, y_pred_test_nb)\n",
    "\n",
    "report_train = pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train_1, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "report_test = pd.DataFrame.from_dict(\n",
    "    classification_report(y_test_nb, y_pred_test_nb, output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\")\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_train)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Testing Report\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(report_test)\n",
    "print(\"------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7514f919",
   "metadata": {},
   "source": [
    "Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ce49a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Splitter\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"\\n=========================================================\")\n",
    "print(\"1. Multinomial Naive Bayes Validation (MinMaxScaler)\")\n",
    "print(\"=========================================================\")\n",
    "\n",
    "# 🔥 Alpha values to test (keep small to avoid RAM issues)\n",
    "alpha_values = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    print(f\"\\nTesting Alpha = {alpha}\")\n",
    "    nb_accuracies = []\n",
    "    fold = 1\n",
    "\n",
    "    for train_idx, test_idx in sss.split(X, y):\n",
    "        # 1. Slice Data\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # 2. MinMax scaling required for NB\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # 3. Train NB with CURRENT alpha\n",
    "        nb = MultinomialNB(alpha=alpha)\n",
    "        nb.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # 4. Score\n",
    "        acc = accuracy_score(y_test, nb.predict(X_test_scaled))\n",
    "\n",
    "        print(f\"  Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "        nb_accuracies.append(acc)\n",
    "        fold += 1\n",
    "\n",
    "    # Per-alpha summary\n",
    "    print(f\"Alpha {alpha} Mean Accuracy: {np.mean(nb_accuracies):.8f}\")\n",
    "    print(f\"Alpha {alpha} Std Deviation: {np.std(nb_accuracies):.8f}\")\n",
    "    print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32937ef7",
   "metadata": {},
   "source": [
    "### XGBoost (Processed, Parameters, & New Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2354325",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== FAST & MEMORY-EFFICIENT XGBOOST TRAINING ===\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# ============================================================\n",
    "# PREPROCESSING (same as before)\n",
    "# ============================================================\n",
    "\n",
    "df_model_2 = df_new_2.copy()\n",
    "\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "# Keep y as a pandas Series instead of numpy array\n",
    "y = pd.Series(pd.factorize(df_model_2[\"Crime_Class\"])[0])\n",
    "\n",
    "\n",
    "for col in X.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "X = X.astype(\"float32\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# TINY SUBSAMPLE FOR FAST TUNING\n",
    "# ============================================================\n",
    "\n",
    "tune_size = 10000\n",
    "X_tune = X_train.sample(tune_size, random_state=42)\n",
    "y_tune = y_train[X_tune.index]\n",
    "\n",
    "print(f\"Tuning using {len(X_tune):,} rows\")\n",
    "\n",
    "# ============================================================\n",
    "# FAST XGBOOST RANDOMIZED SEARCH\n",
    "# ============================================================\n",
    "\n",
    "xgb_base = XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=len(np.unique(y)),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"max_depth\": randint(4, 10),\n",
    "    \"learning_rate\": uniform(0.03, 0.2),\n",
    "    \"min_child_weight\": randint(1, 6),\n",
    "    \"subsample\": uniform(0.5, 0.5),\n",
    "    \"colsample_bytree\": uniform(0.5, 0.5),\n",
    "    \"n_estimators\": randint(150, 400)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    xgb_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=15,        # FAST\n",
    "    cv=2,\n",
    "    scoring=\"accuracy\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search.fit(X_tune, y_tune)\n",
    "\n",
    "print(\"\\nBest Params:\", search.best_params_)\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN FINAL MODEL ON FULL DATASET\n",
    "# ============================================================\n",
    "\n",
    "xgb_final = XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=len(np.unique(y)),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    **search.best_params_\n",
    ")\n",
    "\n",
    "xgb_final.fit(X_train, y_train)\n",
    "\n",
    "# ============================================================\n",
    "# EVALUATION\n",
    "# ============================================================\n",
    "\n",
    "y_pred_train = xgb_final.predict(X_train)\n",
    "y_pred_test = xgb_final.predict(X_test)\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "print(\"\\nTRAIN REPORT\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "print(\"\\nTEST REPORT\")\n",
    "print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b9df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== XGBOOST Cross-Validation: Stratified Shuffle-Split ===\\n\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Use your tuned parameters\n",
    "# ------------------------------------------------------------\n",
    "best_params = search.best_params_\n",
    "print(\"Using Best Params:\", best_params, \"\\n\")\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y):\n",
    "    X_train_cv, X_test_cv = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train_cv, y_test_cv = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # XGBoost model with best params\n",
    "    # --------------------------------------------------------\n",
    "    xgb_cv = XGBClassifier(\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=len(np.unique(y)),\n",
    "        eval_metric=\"mlogloss\",\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        **best_params\n",
    "    )\n",
    "\n",
    "    xgb_cv.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = xgb_cv.predict(X_test_cv)\n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_test_cv, y_pred)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "    print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Mean Accuracy:  \", np.mean(accuracies))\n",
    "print(\"Std Deviation: \", np.std(accuracies))\n",
    "print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49b0fc7",
   "metadata": {},
   "source": [
    "### ANN (Hyperparamters & New Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. IMPORTS\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ============================================================\n",
    "# 2. DATA PREPARATION (Your First Block)\n",
    "# ============================================================\n",
    "# NOTE: Changed towards the new preprocessed dataframe\n",
    "df_model_2 = df_new_2.copy()\n",
    "\n",
    "# Prepare training data\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, unique_classes = pd.factorize(df_model_2[\"Crime_Class\"]) # Capture classes for report later\n",
    "\n",
    "# ---- FIX 1: Convert datetime columns to int64 ----\n",
    "for col in X.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "# ---- FIX 2: Convert lists -> strings to make them hashable ----\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 3. BRIDGE CODE (Crucial Missing Steps)\n",
    "# ============================================================\n",
    "# Your ANN expects scaled data and categorical targets, which were missing above.\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One-hot encode the targets (needed for categorical_crossentropy)\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# ============================================================\n",
    "# 4. ANN MODEL SETUP & SEARCH (Your Second Block)\n",
    "# ============================================================\n",
    "\n",
    "param_space = {\n",
    "    \"lr\": [1e-3, 3e-4, 1e-4],\n",
    "    \"hidden_1\": [64, 96, 128],\n",
    "    \"hidden_2\": [32, 48, 64],\n",
    "    \"dropout\": [0.2, 0.3, 0.4],\n",
    "    \"batch_size\": [32, 64, 128]\n",
    "}\n",
    "\n",
    "def build_model(params):\n",
    "    model = Sequential([\n",
    "        Dense(params[\"hidden_1\"], activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dropout(params[\"dropout\"]),\n",
    "\n",
    "        Dense(params[\"hidden_2\"], activation='relu'),\n",
    "        Dropout(params[\"dropout\"]),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=Adam(learning_rate=params[\"lr\"]),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def sample_params():\n",
    "    return {\n",
    "        \"lr\": random.choice(param_space[\"lr\"]),\n",
    "        \"hidden_1\": random.choice(param_space[\"hidden_1\"]),\n",
    "        \"hidden_2\": random.choice(param_space[\"hidden_2\"]),\n",
    "        \"dropout\": random.choice(param_space[\"dropout\"]),\n",
    "        \"batch_size\": random.choice(param_space[\"batch_size\"])\n",
    "    }\n",
    "\n",
    "search_results = []\n",
    "N_SEARCH = 4   \n",
    "\n",
    "print(\"\\n========== STARTING BEST PARAMS SEARCH ==========\\n\")\n",
    "\n",
    "for i in range(N_SEARCH):\n",
    "    params = sample_params()\n",
    "    print(f\"Trial {i+1}/{N_SEARCH}: {params}\")\n",
    "\n",
    "    model = build_model(params)\n",
    "\n",
    "    es = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # SHORT training for search only\n",
    "    history = model.fit(\n",
    "        X_train_scaled,\n",
    "        y_train_cat,\n",
    "        epochs=8,\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        validation_split=0.2,\n",
    "        verbose=0,\n",
    "        callbacks=[es]\n",
    "    )\n",
    "\n",
    "    val_acc = max(history.history[\"val_accuracy\"])\n",
    "    search_results.append((val_acc, params))\n",
    "\n",
    "    print(f\" -> Best Val Accuracy: {val_acc:.4f}\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. FINAL TRAINING & EVALUATION\n",
    "# ============================================================\n",
    "\n",
    "best_val, best_params = max(search_results, key=lambda x: x[0])\n",
    "print(\"\\n========== BEST PARAMS FOUND ==========\")\n",
    "print(best_params)\n",
    "print(\"Best Validation Accuracy:\", best_val)\n",
    "\n",
    "print(\"\\n========== TRAINING FINAL MODEL ==========\\n\")\n",
    "\n",
    "final_model = build_model(best_params)\n",
    "\n",
    "es_final = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history_final = final_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_cat,\n",
    "    epochs=25,\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    "    callbacks=[es_final]\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred_train = final_model.predict(X_train_scaled).argmax(axis=1)\n",
    "y_pred_test = final_model.predict(X_test_scaled).argmax(axis=1)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "print(\"\\n===== TRAINING REPORT =====\")\n",
    "print(pd.DataFrame.from_dict(\n",
    "    classification_report(y_train, y_pred_train, output_dict=True)\n",
    ").transpose())\n",
    "\n",
    "print(\"\\n===== TESTING REPORT =====\")\n",
    "print(pd.DataFrame.from_dict(\n",
    "    classification_report(y_test, y_pred_test, output_dict=True)\n",
    ").transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a79a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#                📌 FULL ANN PIPELINE \n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ============================================================\n",
    "# PREPROCESSING\n",
    "# ============================================================\n",
    "\n",
    "df_model_2 = df_new_2.copy()\n",
    "\n",
    "X = df_model_2.drop(columns=[\"Crime_Class\"])\n",
    "y, _ = pd.factorize(df_model_2[\"Crime_Class\"])\n",
    "\n",
    "# Convert datetime → int64\n",
    "for col in X.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X[col] = X[col].view(\"int64\")\n",
    "\n",
    "# Convert lists → strings\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        X[col] = X[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Factorize object columns\n",
    "X = X.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "# Fill missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# ============================================================\n",
    "# BEST PARAMS (From your search)\n",
    "# ============================================================\n",
    "best_params = {\n",
    "    \"layer1\": 128,\n",
    "    \"layer2\": 64,\n",
    "    \"layer3\": 32,\n",
    "    \"dropout\": 0.3,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 10,       # base training\n",
    "    \"lr\": 0.001         # default Adam LR\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# MODEL BUILDER FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def build_ann():\n",
    "    model = Sequential([\n",
    "        Dense(best_params[\"layer1\"], activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dropout(best_params[\"dropout\"]),\n",
    "\n",
    "        Dense(best_params[\"layer2\"], activation='relu'),\n",
    "        Dropout(best_params[\"dropout\"]),\n",
    "\n",
    "        Dense(best_params[\"layer3\"], activation='relu'),\n",
    "\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN FINAL MODEL\n",
    "# ============================================================\n",
    "\n",
    "model = build_ann()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_cat,\n",
    "    epochs=best_params[\"epochs\"],\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predict\n",
    "y_pred_train = model.predict(X_train_scaled).argmax(axis=1)\n",
    "y_pred_test = model.predict(X_test_scaled).argmax(axis=1)\n",
    "\n",
    "# Evaluation\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Accuracy:\", train_acc)\n",
    "print(\"Testing Accuracy:\", test_acc)\n",
    "\n",
    "print(\"\\nTRAIN REPORT\")\n",
    "print(pd.DataFrame.from_dict(classification_report(y_train, y_pred_train, output_dict=True)).transpose())\n",
    "\n",
    "print(\"\\nTEST REPORT\")\n",
    "print(pd.DataFrame.from_dict(classification_report(y_test, y_pred_test, output_dict=True)).transpose())\n",
    "\n",
    "# ============================================================\n",
    "# SHUFFLE-SPLIT CROSS VALIDATION (FAST + MEMORY EFFICIENT)\n",
    "# ============================================================\n",
    "\n",
    "def ann_shuffle_split_cv(n_splits=5):\n",
    "\n",
    "    ss = ShuffleSplit(n_splits=n_splits, test_size=0.2, random_state=42)\n",
    "    accuracies = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_idx, val_idx in ss.split(X_train_scaled):\n",
    "\n",
    "        print(f\"\\n===== ShuffleSplit Fold {fold}/{n_splits} =====\")\n",
    "\n",
    "        X_tr, X_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "        y_tr, y_val = y_train_cat[train_idx], y_train_cat[val_idx]\n",
    "\n",
    "        model_cv = build_ann()\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "        model_cv.fit(\n",
    "            X_tr, y_tr,\n",
    "            epochs=12,  # small for speed\n",
    "            batch_size=best_params[\"batch_size\"],\n",
    "            validation_data=(X_val, y_val),\n",
    "            verbose=0,\n",
    "            callbacks=[es]\n",
    "        )\n",
    "\n",
    "        loss, acc = model_cv.evaluate(X_val, y_val, verbose=0)\n",
    "        print(f\"Fold Accuracy: {acc:.4f}\")\n",
    "\n",
    "        accuracies.append(acc)\n",
    "        fold += 1\n",
    "\n",
    "    accuracies = np.array(accuracies)\n",
    "    print(\"\\n========== SHUFFLE SPLIT SUMMARY ==========\")\n",
    "    print(\"Accuracies:\", accuracies)\n",
    "    print(\"Mean CV Accuracy:\", accuracies.mean())\n",
    "    print(\"Std Deviation:\", accuracies.std())\n",
    "    print(\"============================================\")\n",
    "\n",
    "    return accuracies.mean(), accuracies.std()\n",
    "\n",
    "# Run CV\n",
    "cv_mean, cv_sd = ann_shuffle_split_cv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0077033a",
   "metadata": {},
   "source": [
    "### Ensemble : XGBoost + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "966dcb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabular train shape: (803992, 114)\n",
      "CNN train shape   : (803992, 114, 1)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# DATA PREP FOR XGBOOST + CNN ENSEMBLE\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Work on a fresh copy so earlier cells stay unchanged\n",
    "# Gracefully handle missing df_new_2 by falling back to df_new_1\n",
    "if \"df_new_2\" in globals():\n",
    "    df_model_xgb_cnn = df_new_2.copy()\n",
    "elif \"df_new_1\" in globals():\n",
    "    df_model_xgb_cnn = df_new_1.copy()\n",
    "else:\n",
    "    raise ValueError(\"df_new_2 or df_new_1 must exist before running this cell.\")\n",
    "\n",
    "X_xgb_cnn = df_model_xgb_cnn.drop(columns=[\"Crime_Class\"])\n",
    "y_xgb_cnn, crime_labels = pd.factorize(df_model_xgb_cnn[\"Crime_Class\"])\n",
    "\n",
    "# Convert datetimes and list-like objects into numeric representations\n",
    "for col in X_xgb_cnn.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "    X_xgb_cnn[col] = X_xgb_cnn[col].view(\"int64\")\n",
    "\n",
    "for col in X_xgb_cnn.columns:\n",
    "    if X_xgb_cnn[col].dtype == \"object\":\n",
    "        X_xgb_cnn[col] = X_xgb_cnn[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "X_xgb_cnn = X_xgb_cnn.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "X_xgb_cnn = X_xgb_cnn.fillna(X_xgb_cnn.median())\n",
    "\n",
    "X_train_xgb_cnn, X_test_xgb_cnn, y_train_xgb_cnn, y_test_xgb_cnn = train_test_split(\n",
    "    X_xgb_cnn,\n",
    "    y_xgb_cnn,\n",
    "    test_size=0.2,\n",
    "    stratify=y_xgb_cnn,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "scaler_xgb_cnn = StandardScaler()\n",
    "X_train_xgb_cnn_scaled = scaler_xgb_cnn.fit_transform(X_train_xgb_cnn)\n",
    "X_test_xgb_cnn_scaled = scaler_xgb_cnn.transform(X_test_xgb_cnn)\n",
    "\n",
    "# CNN expects a 3D tensor (samples, timesteps, channels)\n",
    "X_train_cnn = X_train_xgb_cnn_scaled[..., np.newaxis]\n",
    "X_test_cnn = X_test_xgb_cnn_scaled[..., np.newaxis]\n",
    "\n",
    "num_classes = len(crime_labels)\n",
    "y_train_cat = to_categorical(y_train_xgb_cnn, num_classes)\n",
    "y_test_cat = to_categorical(y_test_xgb_cnn, num_classes)\n",
    "\n",
    "print(f\"Tabular train shape: {X_train_xgb_cnn.shape}\")\n",
    "print(f\"CNN train shape   : {X_train_cnn.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6bc56485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 37ms/step - accuracy: 0.8953 - loss: 0.3386 - val_accuracy: 0.9076 - val_loss: 0.2858\n",
      "Epoch 2/20\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 36ms/step - accuracy: 0.9054 - loss: 0.2937 - val_accuracy: 0.9093 - val_loss: 0.2733\n",
      "Epoch 3/20\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 39ms/step - accuracy: 0.9079 - loss: 0.2821 - val_accuracy: 0.9111 - val_loss: 0.2638\n",
      "Epoch 4/20\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 38ms/step - accuracy: 0.9097 - loss: 0.2751 - val_accuracy: 0.9117 - val_loss: 0.2616\n",
      "Epoch 5/20\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 38ms/step - accuracy: 0.9108 - loss: 0.2713 - val_accuracy: 0.9136 - val_loss: 0.2592\n",
      "Epoch 6/20\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 39ms/step - accuracy: 0.9115 - loss: 0.2679 - val_accuracy: 0.9130 - val_loss: 0.2582\n",
      "Epoch 7/20\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 39ms/step - accuracy: 0.9118 - loss: 0.2654 - val_accuracy: 0.9134 - val_loss: 0.2573\n",
      "Epoch 8/20\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 39ms/step - accuracy: 0.9124 - loss: 0.2636 - val_accuracy: 0.9141 - val_loss: 0.2552\n",
      "Epoch 9/20\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 40ms/step - accuracy: 0.9127 - loss: 0.2622 - val_accuracy: 0.9137 - val_loss: 0.2541\n",
      "Epoch 10/20\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 38ms/step - accuracy: 0.9131 - loss: 0.2610 - val_accuracy: 0.9139 - val_loss: 0.2542\n",
      "Epoch 11/20\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 38ms/step - accuracy: 0.9133 - loss: 0.2600 - val_accuracy: 0.9139 - val_loss: 0.2558\n",
      "Epoch 12/20\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 38ms/step - accuracy: 0.9136 - loss: 0.2585 - val_accuracy: 0.9135 - val_loss: 0.2547\n",
      "CNN train accuracy : 0.9158\n",
      "CNN test accuracy  : 0.9138\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CNN BASE LEARNER\n",
    "# ============================================================\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "cnn_ensemble = Sequential([\n",
    "    Conv1D(64, kernel_size=3, activation=\"relu\", input_shape=(X_train_cnn.shape[1], 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(128, kernel_size=3, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "cnn_ensemble.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "es_cnn = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "\n",
    "history_cnn = cnn_ensemble.fit(\n",
    "    X_train_cnn,\n",
    "    y_train_cat,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[es_cnn],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "cnn_train_proba = cnn_ensemble.predict(X_train_cnn, verbose=0)\n",
    "cnn_test_proba = cnn_ensemble.predict(X_test_cnn, verbose=0)\n",
    "\n",
    "cnn_train_pred = cnn_train_proba.argmax(axis=1)\n",
    "cnn_test_pred = cnn_test_proba.argmax(axis=1)\n",
    "\n",
    "print(f\"CNN train accuracy : {accuracy_score(y_train_xgb_cnn, cnn_train_pred):.4f}\")\n",
    "print(f\"CNN test accuracy  : {accuracy_score(y_test_xgb_cnn, cnn_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b498bc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost train accuracy : 0.9246\n",
      "XGBoost test accuracy  : 0.9172\n",
      "\n",
      "=== Ensemble Evaluation ===\n",
      "Blend accuracy : 0.9171\n",
      "Stack accuracy : 0.9169\n",
      "\n",
      "Stacked Classification Report\n",
      "                                   precision    recall  f1-score  \\\n",
      "Property Crime                      0.961613  0.932412  0.946787   \n",
      "Violent Crime                       0.946417  0.967515  0.956850   \n",
      "Other Crime                         0.796120  0.696597  0.743041   \n",
      "Vehicle Crime                       0.816318  0.959618  0.882186   \n",
      "Weapons / Public Safety             0.784991  0.777921  0.781440   \n",
      "Sex Crime                           0.750617  0.640270  0.691066   \n",
      "Court / Restraining Order / Legal   0.931513  0.924667  0.928077   \n",
      "Public Disturbance / Disorder       0.752457  0.727978  0.740015   \n",
      "Fraud / Financial Crime             0.075000  0.020134  0.031746   \n",
      "Child-Related Crime                 0.668663  0.601436  0.633270   \n",
      "accuracy                            0.916855  0.916855  0.916855   \n",
      "macro avg                           0.748371  0.724855  0.733448   \n",
      "weighted avg                        0.917670  0.916855  0.916130   \n",
      "\n",
      "                                         support  \n",
      "Property Crime                     101689.000000  \n",
      "Violent Crime                       46698.000000  \n",
      "Other Crime                         12607.000000  \n",
      "Vehicle Crime                       24689.000000  \n",
      "Weapons / Public Safety              3886.000000  \n",
      "Sex Crime                            2374.000000  \n",
      "Court / Restraining Order / Legal    4354.000000  \n",
      "Public Disturbance / Disorder        3996.000000  \n",
      "Fraud / Financial Crime               149.000000  \n",
      "Child-Related Crime                   557.000000  \n",
      "accuracy                                0.916855  \n",
      "macro avg                          200999.000000  \n",
      "weighted avg                       200999.000000  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# XGBOOST BASE LEARNER + STACKED ENSEMBLE\n",
    "# ============================================================\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "xgb_ensemble = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=num_classes,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=250,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_ensemble.fit(X_train_xgb_cnn, y_train_xgb_cnn)\n",
    "\n",
    "xgb_train_proba = xgb_ensemble.predict_proba(X_train_xgb_cnn)\n",
    "xgb_test_proba = xgb_ensemble.predict_proba(X_test_xgb_cnn)\n",
    "\n",
    "xgb_train_pred = xgb_ensemble.predict(X_train_xgb_cnn)\n",
    "xgb_test_pred = xgb_ensemble.predict(X_test_xgb_cnn)\n",
    "\n",
    "print(f\"XGBoost train accuracy : {accuracy_score(y_train_xgb_cnn, xgb_train_pred):.4f}\")\n",
    "print(f\"XGBoost test accuracy  : {accuracy_score(y_test_xgb_cnn, xgb_test_pred):.4f}\")\n",
    "\n",
    "# Simple probability averaging as a sanity check\n",
    "blend_test_proba = 0.5 * cnn_test_proba + 0.5 * xgb_test_proba\n",
    "blend_test_pred = blend_test_proba.argmax(axis=1)\n",
    "\n",
    "# Stack probabilities as meta-features for a second-stage XGBoost\n",
    "stack_train = np.hstack([xgb_train_proba, cnn_train_proba])\n",
    "stack_test = np.hstack([xgb_test_proba, cnn_test_proba])\n",
    "\n",
    "xgb_stack = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=num_classes,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.08,\n",
    "    n_estimators=300,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_stack.fit(stack_train, y_train_xgb_cnn)\n",
    "\n",
    "stack_test_pred = xgb_stack.predict(stack_test)\n",
    "\n",
    "print(\"\\n=== Ensemble Evaluation ===\")\n",
    "print(f\"Blend accuracy : {accuracy_score(y_test_xgb_cnn, blend_test_pred):.4f}\")\n",
    "print(f\"Stack accuracy : {accuracy_score(y_test_xgb_cnn, stack_test_pred):.4f}\")\n",
    "\n",
    "stack_report = classification_report(\n",
    "    y_test_xgb_cnn,\n",
    "    stack_test_pred,\n",
    "    target_names=[str(lbl) for lbl in crime_labels],\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "print(\"\\nStacked Classification Report\")\n",
    "print(pd.DataFrame(stack_report).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3bc8e3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ShuffleSplit Validation (stacked XGBoost) ===\n",
      "Fold 1: accuracy = 0.9284\n",
      "Fold 2: accuracy = 0.9286\n",
      "Fold 3: accuracy = 0.9276\n",
      "Fold 4: accuracy = 0.9281\n",
      "Fold 5: accuracy = 0.9279\n",
      "-------------------------------------------\n",
      "Mean accuracy : 0.9281\n",
      "Std deviation : 0.0004\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SHUFFLE-SPLIT VALIDATION FOR STACKED ENSEMBLE\n",
    "# ============================================================\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "print(\"=== ShuffleSplit Validation (stacked XGBoost) ===\")\n",
    "for fold, (train_idx, val_idx) in enumerate(ss.split(stack_train), start=1):\n",
    "    X_tr, X_val = stack_train[train_idx], stack_train[val_idx]\n",
    "    y_tr, y_val = y_train_xgb_cnn[train_idx], y_train_xgb_cnn[val_idx]\n",
    "\n",
    "    xgb_stack_cv = XGBClassifier(\n",
    "        objective=\"multi:softprob\",\n",
    "        num_class=num_classes,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.08,\n",
    "        n_estimators=300,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        random_state=fold * 13,\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    xgb_stack_cv.fit(X_tr, y_tr)\n",
    "    fold_pred = xgb_stack_cv.predict(X_val)\n",
    "    fold_acc = accuracy_score(y_val, fold_pred)\n",
    "    cv_scores.append(fold_acc)\n",
    "    print(f\"Fold {fold}: accuracy = {fold_acc:.4f}\")\n",
    "\n",
    "cv_scores = np.array(cv_scores)\n",
    "print(\"-------------------------------------------\")\n",
    "print(f\"Mean accuracy : {cv_scores.mean():.4f}\")\n",
    "print(f\"Std deviation : {cv_scores.std():.4f}\")\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d7e69c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Complexity vs Error (Stacked XGBoost) ===\n",
      "max_depth= 3 -> error=0.0832\n",
      "max_depth= 4 -> error=0.0832\n",
      "max_depth= 5 -> error=0.0831\n",
      "max_depth= 6 -> error=0.0831\n",
      "max_depth= 7 -> error=0.0829\n",
      "max_depth= 8 -> error=0.0827\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# COMPLEXITY (MAX_DEPTH) VS ERROR FOR META XGBOOST\n",
    "# ============================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stack_depths = [3, 4, 5, 6, 7, 8]\n",
    "stack_errors = []\n",
    "\n",
    "print(\"=== Complexity vs Error (Stacked XGBoost) ===\")\n",
    "for depth in stack_depths:\n",
    "    model_depth = XGBClassifier(\n",
    "        objective=\"multi:softprob\",\n",
    "        num_class=num_classes,\n",
    "        max_depth=depth,\n",
    "        learning_rate=0.08,\n",
    "        n_estimators=300,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        random_state=depth * 31,\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model_depth.fit(stack_train, y_train_xgb_cnn)\n",
    "    preds_depth = model_depth.predict(stack_test)\n",
    "    error_depth = 1.0 - accuracy_score(y_test_xgb_cnn, preds_depth)\n",
    "    stack_errors.append(error_depth)\n",
    "    print(f\"max_depth={depth:2d} -> error={error_depth:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(stack_depths, stack_errors, marker='o', linewidth=2, color='tab:blue')\n",
    "plt.title(\"Stacked Ensemble: Complexity vs Error\")\n",
    "plt.xlabel(\"Meta XGBoost max_depth (complexity)\")\n",
    "plt.ylabel(\"Classification Error (1 - accuracy)\")\n",
    "plt.grid(True, linestyle='--', alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d838d0",
   "metadata": {},
   "source": [
    "## Ensemble : Naive Bayes + ANN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0e11ef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 6ms/step - accuracy: 0.8885 - loss: 0.3601 - val_accuracy: 0.9074 - val_loss: 0.2793\n",
      "Epoch 2/10\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.9042 - loss: 0.2987 - val_accuracy: 0.9089 - val_loss: 0.2717\n",
      "Epoch 3/10\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.9061 - loss: 0.2892 - val_accuracy: 0.9111 - val_loss: 0.2658\n",
      "Epoch 4/10\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.9073 - loss: 0.2846 - val_accuracy: 0.9111 - val_loss: 0.2632\n",
      "Epoch 5/10\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.9079 - loss: 0.2815 - val_accuracy: 0.9121 - val_loss: 0.2610\n",
      "Epoch 6/10\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - accuracy: 0.9081 - loss: 0.2794 - val_accuracy: 0.9113 - val_loss: 0.2620\n",
      "Epoch 7/10\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7ms/step - accuracy: 0.9084 - loss: 0.2775 - val_accuracy: 0.9119 - val_loss: 0.2606\n",
      "Epoch 8/10\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - accuracy: 0.9088 - loss: 0.2755 - val_accuracy: 0.9118 - val_loss: 0.2603\n",
      "Epoch 9/10\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6ms/step - accuracy: 0.9092 - loss: 0.2744 - val_accuracy: 0.9123 - val_loss: 0.2597\n",
      "Epoch 10/10\n",
      "\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.9093 - loss: 0.2739 - val_accuracy: 0.9121 - val_loss: 0.2603\n",
      "ANN train accuracy : 0.9140\n",
      "ANN test accuracy  : 0.9127\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# DATA PREP FOR ANN + NAIVE BAYES ENSEMBLE (Guarded)\n",
    "# ============================================================\n",
    "# Creates the tensors this cell expects if they don't exist yet.\n",
    "if \"X_train_nb_ann_scaled\" not in globals():\n",
    "    # Select the most recent preprocessed dataframe\n",
    "    if \"df_new_2\" in globals():\n",
    "        df_model_nb_ann = df_new_2.copy()\n",
    "    elif \"df_new_1\" in globals():\n",
    "        df_model_nb_ann = df_new_1.copy()\n",
    "    else:\n",
    "        raise ValueError(\"df_new_2 or df_new_1 must exist before running this cell.\")\n",
    "\n",
    "    # Features and target\n",
    "    X_nb_ann = df_model_nb_ann.drop(columns=[\"Crime_Class\"])\n",
    "    y_nb_ann, _ = pd.factorize(df_model_nb_ann[\"Crime_Class\"])\n",
    "\n",
    "    # Convert datetime → int64\n",
    "    for col in X_nb_ann.select_dtypes(include=[\"datetime64[ns]\", \"datetimetz\"]).columns:\n",
    "        X_nb_ann[col] = X_nb_ann[col].view(\"int64\")\n",
    "\n",
    "    # Convert lists → strings; then factorize object columns\n",
    "    for col in X_nb_ann.columns:\n",
    "        if X_nb_ann[col].dtype == \"object\":\n",
    "            X_nb_ann[col] = X_nb_ann[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "    X_nb_ann = X_nb_ann.apply(lambda col: pd.factorize(col)[0] if col.dtype == \"object\" else col)\n",
    "\n",
    "    # Fill missing values\n",
    "    X_nb_ann = X_nb_ann.fillna(X_nb_ann.median())\n",
    "\n",
    "    # Split\n",
    "    X_train_nb_ann, X_test_nb_ann, y_train_nb_ann, y_test_nb_ann = train_test_split(\n",
    "        X_nb_ann, y_nb_ann, test_size=0.2, stratify=y_nb_ann, random_state=42\n",
    "    )\n",
    "\n",
    "    # Scale\n",
    "    scaler_nb_ann = StandardScaler()\n",
    "    X_train_nb_ann_scaled = scaler_nb_ann.fit_transform(X_train_nb_ann)\n",
    "    X_test_nb_ann_scaled = scaler_nb_ann.transform(X_test_nb_ann)\n",
    "\n",
    "    # One-hot targets\n",
    "    num_classes_nb_ann = len(np.unique(y_nb_ann))\n",
    "    y_train_nb_ann_cat = to_categorical(y_train_nb_ann, num_classes_nb_ann)\n",
    "    y_test_nb_ann_cat = to_categorical(y_test_nb_ann, num_classes_nb_ann)\n",
    "\n",
    "# ============================================================\n",
    "# ANN BASE LEARNER\n",
    "# ============================================================\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "ann_nb_model = Sequential([\n",
    "    Dense(128, activation=\"relu\", input_shape=(X_train_nb_ann_scaled.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(num_classes_nb_ann, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "ann_nb_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "es_ann = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "\n",
    "history_ann_nb = ann_nb_model.fit(\n",
    "    X_train_nb_ann_scaled,\n",
    "    y_train_nb_ann_cat,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[es_ann],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "ann_train_proba = ann_nb_model.predict(X_train_nb_ann_scaled, verbose=0)\n",
    "ann_test_proba = ann_nb_model.predict(X_test_nb_ann_scaled, verbose=0)\n",
    "\n",
    "ann_train_pred = ann_train_proba.argmax(axis=1)\n",
    "ann_test_pred = ann_test_proba.argmax(axis=1)\n",
    "\n",
    "print(f\"ANN train accuracy : {accuracy_score(y_train_nb_ann, ann_train_pred):.4f}\")\n",
    "print(f\"ANN test accuracy  : {accuracy_score(y_test_nb_ann, ann_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b272fafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Alpha = 0.01 ---\n",
      "Multinomial Naive Bayes train accuracy : 0.8716\n",
      "Multinomial Naive Bayes test accuracy  : 0.8717\n",
      "--- Alpha = 0.1 ---\n",
      "Multinomial Naive Bayes train accuracy : 0.8716\n",
      "Multinomial Naive Bayes test accuracy  : 0.8717\n",
      "--- Alpha = 1.0 ---\n",
      "Multinomial Naive Bayes train accuracy : 0.8715\n",
      "Multinomial Naive Bayes test accuracy  : 0.8717\n",
      "--- Alpha = 10.0 ---\n",
      "Multinomial Naive Bayes train accuracy : 0.8712\n",
      "Multinomial Naive Bayes test accuracy  : 0.8715\n",
      "--- Alpha = 100.0 ---\n",
      "Multinomial Naive Bayes train accuracy : 0.8684\n",
      "Multinomial Naive Bayes test accuracy  : 0.8686\n",
      "\n",
      "==================================================\n",
      "🏆 Best Alpha (based on test accuracy): 1.0\n",
      "   Test Accuracy: 0.8717\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MULTINOMIAL NAIVE BAYES WITH ALPHA TUNING\n",
    "# ============================================================\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Map standardized features to non-negative range [0, 1] for MultinomialNB\n",
    "minmax_nb = MinMaxScaler()\n",
    "X_train_nb_ann_nonneg = minmax_nb.fit_transform(X_train_nb_ann_scaled)\n",
    "X_test_nb_ann_nonneg = minmax_nb.transform(X_test_nb_ann_scaled)\n",
    "\n",
    "# Define the alpha values to test\n",
    "alphas = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "# Dictionary to store results\n",
    "alpha_results = {}\n",
    "\n",
    "# Iterate over each alpha value\n",
    "for alpha_val in alphas:\n",
    "    # 1. Initialize Multinomial Naive Bayes with the current alpha\n",
    "    multinomial_nb = MultinomialNB(alpha=alpha_val)\n",
    "\n",
    "    # 2. Fit the model (using your existing data variables)\n",
    "    multinomial_nb.fit(X_train_nb_ann_nonneg, y_train_nb_ann)\n",
    "\n",
    "    # 3. Predict\n",
    "    nb_train_pred = multinomial_nb.predict(X_train_nb_ann_nonneg)\n",
    "    nb_test_pred = multinomial_nb.predict(X_test_nb_ann_nonneg)\n",
    "\n",
    "    # 4. Calculate accuracy\n",
    "    train_accuracy = accuracy_score(y_train_nb_ann, nb_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test_nb_ann, nb_test_pred)\n",
    "\n",
    "    # 5. Store results\n",
    "    alpha_results[alpha_val] = {\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"model\": multinomial_nb  # Store the trained model if needed later\n",
    "    }\n",
    "\n",
    "    # 6. Print results for the current alpha\n",
    "    print(f\"--- Alpha = {alpha_val} ---\")\n",
    "    print(f\"Multinomial Naive Bayes train accuracy : {train_accuracy:.4f}\")\n",
    "    print(f\"Multinomial Naive Bayes test accuracy  : {test_accuracy:.4f}\")\n",
    "\n",
    "# Optional: Find the best alpha based on test accuracy\n",
    "best_alpha = max(alpha_results, key=lambda k: alpha_results[k]['test_accuracy'])\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"🏆 Best Alpha (based on test accuracy): {best_alpha}\")\n",
    "print(f\"   Test Accuracy: {alpha_results[best_alpha]['test_accuracy']:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# If you need the probability predictions for the best model:\n",
    "best_model = alpha_results[best_alpha]['model']\n",
    "nb_train_proba = best_model.predict_proba(X_train_nb_ann_nonneg)\n",
    "nb_test_proba = best_model.predict_proba(X_test_nb_ann_nonneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b78aa67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ensemble Evaluation (Naive Bayes + ANN) ===\n",
      "ANN only accuracy       : 0.9127\n",
      "Naive Bayes only accuracy: 0.8686\n",
      "Blend accuracy           : 0.9018\n",
      "Stacked accuracy         : 0.9128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stacked Classification Report\n",
      "                                   precision    recall  f1-score  \\\n",
      "Property Crime                      0.958904  0.933208  0.945882   \n",
      "Violent Crime                       0.938894  0.972932  0.955610   \n",
      "Other Crime                         0.781836  0.648687  0.709065   \n",
      "Vehicle Crime                       0.818826  0.954838  0.881617   \n",
      "Weapons / Public Safety             0.784850  0.767885  0.776275   \n",
      "Sex Crime                           0.792697  0.566976  0.661100   \n",
      "Court / Restraining Order / Legal   0.933631  0.911116  0.922236   \n",
      "Public Disturbance / Disorder       0.663160  0.709960  0.685763   \n",
      "Fraud / Financial Crime             0.000000  0.000000  0.000000   \n",
      "Child-Related Crime                 0.700272  0.461400  0.556277   \n",
      "accuracy                            0.912811  0.912811  0.912811   \n",
      "macro avg                           0.737307  0.692700  0.709382   \n",
      "weighted avg                        0.912760  0.912811  0.911288   \n",
      "\n",
      "                                         support  \n",
      "Property Crime                     101689.000000  \n",
      "Violent Crime                       46698.000000  \n",
      "Other Crime                         12607.000000  \n",
      "Vehicle Crime                       24689.000000  \n",
      "Weapons / Public Safety              3886.000000  \n",
      "Sex Crime                            2374.000000  \n",
      "Court / Restraining Order / Legal    4354.000000  \n",
      "Public Disturbance / Disorder        3996.000000  \n",
      "Fraud / Financial Crime               149.000000  \n",
      "Child-Related Crime                   557.000000  \n",
      "accuracy                                0.912811  \n",
      "macro avg                          200999.000000  \n",
      "weighted avg                       200999.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STACKED ENSEMBLE (ANN + NAIVE BAYES)\n",
    "# ============================================================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "stack_nb_ann_train = np.hstack([ann_train_proba, nb_train_proba])\n",
    "stack_nb_ann_test = np.hstack([ann_test_proba, nb_test_proba])\n",
    "\n",
    "meta_nb_ann = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    multi_class=\"multinomial\",\n",
    "    solver=\"lbfgs\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "meta_nb_ann.fit(stack_nb_ann_train, y_train_nb_ann)\n",
    "\n",
    "stack_nb_ann_pred = meta_nb_ann.predict(stack_nb_ann_test)\n",
    "stack_nb_ann_proba = meta_nb_ann.predict_proba(stack_nb_ann_test)\n",
    "\n",
    "ann_nb_blend = 0.5 * ann_test_proba + 0.5 * nb_test_proba\n",
    "ann_nb_blend_pred = ann_nb_blend.argmax(axis=1)\n",
    "\n",
    "print(\"=== Ensemble Evaluation (Naive Bayes + ANN) ===\")\n",
    "print(f\"ANN only accuracy       : {accuracy_score(y_test_nb_ann, ann_test_pred):.4f}\")\n",
    "print(f\"Naive Bayes only accuracy: {accuracy_score(y_test_nb_ann, nb_test_pred):.4f}\")\n",
    "print(f\"Blend accuracy           : {accuracy_score(y_test_nb_ann, ann_nb_blend_pred):.4f}\")\n",
    "print(f\"Stacked accuracy         : {accuracy_score(y_test_nb_ann, stack_nb_ann_pred):.4f}\")\n",
    "\n",
    "# Ensure label names are defined and aligned with factorization used for NB+ANN\n",
    "if \"nb_ann_labels\" not in globals():\n",
    "    if \"df_model_nb_ann\" in globals():\n",
    "        nb_ann_labels = pd.factorize(df_model_nb_ann[\"Crime_Class\"])[1]\n",
    "    elif \"df_new_2\" in globals():\n",
    "        nb_ann_labels = pd.factorize(df_new_2[\"Crime_Class\"])[1]\n",
    "    else:\n",
    "        nb_ann_labels = pd.factorize(df_new_1[\"Crime_Class\"])[1]\n",
    "\n",
    "stack_nb_ann_report = classification_report(\n",
    "    y_test_nb_ann,\n",
    "    stack_nb_ann_pred,\n",
    "    target_names=[str(lbl) for lbl in nb_ann_labels],\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "print(\"\\nStacked Classification Report\")\n",
    "print(pd.DataFrame(stack_nb_ann_report).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0fe554cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ShuffleSplit Validation (ANN + Naive Bayes stack) ===\n",
      "Fold 1: accuracy = 0.9144\n",
      "Fold 2: accuracy = 0.9146\n",
      "Fold 3: accuracy = 0.9130\n",
      "Fold 4: accuracy = 0.9140\n",
      "Fold 5: accuracy = 0.9135\n",
      "-------------------------------------------\n",
      "Mean accuracy : 0.9139\n",
      "Std deviation : 0.0006\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SHUFFLE-SPLIT CROSS-VALIDATION (ANN + NB STACK)\n",
    "# ============================================================\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "stack_features_train = np.hstack([ann_train_proba, nb_train_proba])\n",
    "\n",
    "ss_nb_ann = ShuffleSplit(n_splits=5, test_size=0.25, random_state=42)\n",
    "cv_scores_nb_ann = []\n",
    "\n",
    "print(\"=== ShuffleSplit Validation (ANN + Naive Bayes stack) ===\")\n",
    "for fold, (train_idx, val_idx) in enumerate(ss_nb_ann.split(stack_features_train), start=1):\n",
    "    X_tr, X_val = stack_features_train[train_idx], stack_features_train[val_idx]\n",
    "    y_tr, y_val = y_train_nb_ann[train_idx], y_train_nb_ann[val_idx]\n",
    "\n",
    "    meta_cv = LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        multi_class=\"multinomial\",\n",
    "        solver=\"lbfgs\",\n",
    "        n_jobs=-1,\n",
    "        random_state=fold * 17\n",
    "    )\n",
    "\n",
    "    meta_cv.fit(X_tr, y_tr)\n",
    "    fold_pred = meta_cv.predict(X_val)\n",
    "    fold_acc = accuracy_score(y_val, fold_pred)\n",
    "    cv_scores_nb_ann.append(fold_acc)\n",
    "    print(f\"Fold {fold}: accuracy = {fold_acc:.4f}\")\n",
    "\n",
    "cv_scores_nb_ann = np.array(cv_scores_nb_ann)\n",
    "print(\"-------------------------------------------\")\n",
    "print(f\"Mean accuracy : {cv_scores_nb_ann.mean():.4f}\")\n",
    "print(f\"Std deviation : {cv_scores_nb_ann.std():.4f}\")\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b237aca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
